# RAG Conversational Flow Agent with Dynamic Index & Hybrid Search (BM25 + Neural + Search Pipeline)

## Overview
This script demonstrates **hybrid search capabilities** combining BM25 (keyword-based), neural (semantic), and normalized ranking through a search pipeline. It showcases dynamic index selection and query methodology for comprehensive information retrieval with the RAG agent.

---

## Architecture Flow

```mermaid
graph TD
    A["üåê Initialize OpenSearch"] -->|Configure| B["‚öôÔ∏è Setup Cluster"]
    B -->|ML Commons| C["üì¶ Register Model"]
    
    C -->|Deploy| D["üîå Create Pipeline"]
    D -->|Configure| E["üìá Create Index"]
    E -->|Setup| F["üìä Load Data"]
    
    F -->|Sample Data| G["‚úÖ Index Ready"]
    
    G -->|Setup LLM| H["ü§ù Model Group"]
    H -->|Create| I["üîó Connector"]
    I -->|Register| J["üîë OpenAI Model"]
    
    J -->|Deploy| K["üß™ Test Model"]
    K -->|Create| L["ü§ñ Agent with SearchIndexTool"]
    
    L -->|Execute| M["User Query"]
    
    M -->|Route| N["SearchIndexTool"]
    N -->|Dynamic| O{Query Type}
    
    O -->|BM25| P["Keyword Search"]
    O -->|Neural| Q["Semantic Search"]
    O -->|Hybrid| R["Combined Search"]
    
    P -->|Results| S["Normalize Scores"]
    Q -->|Results| S
    R -->|Results| S
    
    S -->|Pipeline| T["Search Pipeline Processor"]
    T -->|Min-Max Norm| U["Normalize to 0-1"]
    T -->|Arithmetic Mean| V["Weighted Combination"]
    
    U -->|Weight 0.3| V
    V -->|Weight 0.7| W["Re-ranked Results"]
    
    W -->|Top Results| X["MLModelTool"]
    X -->|Context| Y["LLM Generation"]
    Y -->|Response| Z["Return Answer"]
    
    style A fill:#e1f5ff
    style B fill:#b3e5fc
    style C fill:#81d4fa
    style D fill:#4fc3f7
    style E fill:#29b6f6
    style F fill:#03a9f4
    style L fill:#9c27b0,color:#fff
    style P fill:#4fc3f7
    style Q fill:#0288d1
    style R fill:#01579b,color:#fff
    style T fill:#ffca28
    style V fill:#f57f17
    style W fill:#ff6f00
    style Y fill:#bf360c,color:#fff
```

---

## Hybrid Search Architecture

```mermaid
graph TD
    Query["üîç User Query"]
    
    Query -->|Input| HybridSearch["Hybrid Query"]
    
    HybridSearch -->|Branch 1| BM25Q["BM25 Query"]
    HybridSearch -->|Branch 2| NeuralQ["Neural Query"]
    
    BM25Q -->|Lucene Search| BM25R["BM25 Results"]
    NeuralQ -->|Vector Search| VectorR["Vector Results"]
    
    BM25R -->|Scores| Norm1["Normalize Scores<br/>Min-Max to [0,1]"]
    VectorR -->|Scores| Norm2["Normalize Scores<br/>Min-Max to [0,1]"]
    
    Norm1 -->|Weight 0.3| Combine["Arithmetic Mean<br/>Combination"]
    Norm2 -->|Weight 0.7| Combine
    
    Combine -->|Final Scores| Rerank["Re-ranked Results"]
    Rerank -->|Top K Docs| Output["‚úÖ Final Results"]
    
    Output -->|Send to LLM| LLM["GPT-3.5 Response"]
    LLM -->|Generate| Answer["Answer with Context"]
    
    style Query fill:#4fc3f7
    style BM25Q fill:#29b6f6
    style NeuralQ fill:#0288d1
    style BM25R fill:#0277bd
    style VectorR fill:#01579b
    style Norm1 fill:#ffca28
    style Norm2 fill:#fbc02d
    style Combine fill:#f57f17,color:#fff
    style Rerank fill:#ff6f00
    style Output fill:#ff5722,color:#fff
    style LLM fill:#ce93d8
    style Answer fill:#8e24aa,color:#fff
```

---

## Detailed Component Flows

### 1. **Setup & Model Deployment**
```mermaid
graph LR
    A["Register Model"] -->|Task| B["Monitor Status"]
    B -->|Model ID| C["Deploy Model"]
    C -->|Task| D["Monitor Deployment"]
    D -->|COMPLETED| E["‚úÖ Ready"]
    
    F["Create Pipeline"] -->|Processor| G["Text Embedding"]
    G -->|Model ID| H["Field Map"]
    H -->|text‚Üíembedding| I["Pipeline Ready"]
    
    E -->|Index Setup| J["Create Index"]
    I -->|Default Pipeline| J
    
    style A fill:#4fc3f7
    style B fill:#29b6f6
    style C fill:#0288d1
    style D fill:#0277bd
    style E fill:#01579b,color:#fff
    style I fill:#81d4fa
    style J fill:#29b6f6
```

### 2. **Index Creation & Data Ingestion**
```mermaid
sequenceDiagram
    participant Script
    participant OpenSearch
    participant Ingest
    participant Index
    
    Script ->> OpenSearch: Delete old index
    activate OpenSearch
    OpenSearch -->> Script: OK
    deactivate OpenSearch
    
    Script ->> OpenSearch: Create new index
    activate OpenSearch
    OpenSearch ->> Index: Initialize
    Index -->> OpenSearch: Index created
    deactivate OpenSearch
    
    Script ->> OpenSearch: Bulk insert documents
    activate Ingest
    Ingest ->> Index: Apply pipeline
    Index ->> Index: Generate embeddings
    Index ->> Index: Create KNN vectors
    deactivate Ingest
    
    OpenSearch -->> Script: Indexing complete
```

### 3. **BM25 Query Execution**
```mermaid
graph TD
    A["BM25 Query"] -->|Query Type| B["match query"]
    B -->|Field| C["text field"]
    C -->|Input| D["User Question"]
    
    D -->|Search| E["Lucene Search"]
    E -->|Scoring| F["TF-IDF Scoring"]
    F -->|Results| G["Keyword Matches"]
    
    G -->|Size Limit| H["Top 2 Documents"]
    H -->|Source| I["Return full text"]
    I -->|Output| J["BM25 Results<br/>for context"]
    
    style A fill:#4fc3f7
    style B fill:#29b6f6
    style E fill:#0288d1
    style F fill:#0277bd
    style J fill:#0277bd,color:#fff
```

### 4. **Neural/Vector Query Execution**
```mermaid
graph TD
    A["Neural Query"] -->|Query Type| B["neural query"]
    B -->|Field| C["embedding field"]
    C -->|Model| D["Embedding Model"]
    
    D -->|Encode| E["Query Text"]
    E -->|Generate| F["384-dim Vector"]
    
    F -->|Search| G["HNSW Index"]
    G -->|Similarity| H["Cosine/L2 Distance"]
    H -->|k=10| I["Search K Neighbors"]
    
    I -->|Results| J["Vector Matches"]
    J -->|Size Limit| K["Top 2 Documents"]
    K -->|Source| L["Return full text"]
    L -->|Output| M["Neural Results<br/>for context"]
    
    style A fill:#0288d1
    style B fill:#0277bd
    style F fill:#01579b,color:#fff
    style G fill:#01579b,color:#fff
    style M fill:#01579b,color:#fff
```

### 5. **Hybrid Query Combination**
```mermaid
graph TD
    A["Hybrid Query"] -->|Component 1| B["BM25 match"]
    A -->|Component 2| C["Neural search"]
    
    B -->|Execute| D["Get BM25 Scores"]
    C -->|Execute| E["Get Vector Scores"]
    
    D -->|Scores 0 to inf| F["Normalize<br/>Min-Max"]
    E -->|Scores 0 to 1| F
    
    F -->|Normalized to 0-1| G["Score1_norm"]
    F -->|Normalized to 0-1| H["Score2_norm"]
    
    G -->|Weight W1| I["Combined Score<br/>= W1*Score1<br/>+ W2*Score2"]
    H -->|Weight W2| I
    
    I -->|Final Scores| J["Re-ranked"]
    J -->|Top 2| K["Results<br/>Hybrid"]
    
    style A fill:#4fc3f7
    style B fill:#29b6f6
    style C fill:#0288d1
    style D fill:#0277bd
    style E fill:#01579b,color:#fff
    style F fill:#ffca28,color:#000
    style I fill:#f57f17,color:#fff
    style J fill:#ff6f00,color:#fff
    style K fill:#bf360c,color:#fff
```

### 6. **Search Pipeline Processor**
```mermaid
graph TD
    A["Search Pipeline Config"] -->|Type| B["nlp-search-pipeline"]
    B -->|Processor| C["Normalization Processor"]
    
    C -->|Technique| D["Min-Max Normalization"]
    D -->|Formula| E["(x - min) / (max - min)"]
    E -->|Range| F["[0, 1] interval"]
    
    C -->|Combination| G["Arithmetic Mean"]
    G -->|Weights| H["[0.3, 0.7]"]
    H -->|Formula| I["0.3√óBM25 + 0.7√óNeural"]
    
    F -->|Apply| J["Normalized Scores"]
    I -->|Apply| K["Weighted Combination"]
    
    J -->|Output| L["Final Rankings"]
    K -->|Output| L
    
    L -->|Return| M["‚úÖ Pipeline Ready"]
    
    style A fill:#ffca28
    style C fill:#fbc02d
    style D fill:#f57f17
    style G fill:#ff6f00
    style H fill:#ff5722
    style M fill:#bf360c,color:#fff
```

### 7. **Agent Execution Flow**
```mermaid
sequenceDiagram
    participant User
    participant Agent
    participant SearchTool
    participant Index as OpenSearch
    participant LLM
    
    User ->> Agent: Query with question
    
    Agent ->> SearchTool: Execute query
    SearchTool ->> Index: BM25 Search
    Index -->> SearchTool: Results
    
    SearchTool ->> Index: Neural Search
    Index -->> SearchTool: Results
    
    SearchTool ->> Index: Combine (Hybrid)
    Index -->> SearchTool: Ranked Results
    
    SearchTool -->> Agent: Search Output
    
    Agent ->> LLM: Context + Question
    activate LLM
    LLM ->> LLM: Process context
    LLM -->> Agent: Generated response
    deactivate LLM
    
    Agent -->> User: Answer
```

### 8. **Response Generation with Context**
```mermaid
graph TD
    A["Search Results"] -->|Top K| B["Extract Context"]
    B -->|Text Content| C["Relevant Documents"]
    
    D["System Prompt"] -->|Role| E["Professional Data Analyst"]
    E -->|Instruction| F["Answer based on context"]
    F -->|Fallback| G["Analyze if needed"]
    
    C -->|Prepare| H["Build LLM Request"]
    E -->|Prepare| H
    
    I["User Question"] -->|Include| H
    H -->|Send to| J["OpenAI API"]
    
    J -->|GPT-3.5-turbo| K["Generate Response"]
    K -->|Output| L["Answer from LLM"]
    
    L -->|Return| M["‚úÖ Final Answer"]
    
    style D fill:#ce93d8
    style E fill:#ba68c8
    style K fill:#9c27b0,color:#fff
    style M fill:#9c27b0,color:#fff
```

---

## Query Comparison Matrix

| Search Type | Method | Strength | Weakness |
|-------------|--------|----------|----------|
| **BM25** | Keyword Matching | Exact term matches | Misses semantic meaning |
| **Neural** | Vector Similarity | Semantic understanding | Computationally expensive |
| **Hybrid** | Combined | Best of both | Requires tuning |

---

## Key Features

### üéØ **Advanced Search Capabilities**
- **BM25 Search**: Traditional keyword-based retrieval using TF-IDF
- **Neural Search**: Semantic search using vector embeddings (HNSW)
- **Hybrid Search**: Combines BM25 and neural with normalized scoring
- **Search Pipeline**: Post-processor for score normalization and weighting
- **Dynamic Index**: Single parameter-driven interface for different query types
- **Re-ranking**: Scores merged via weighted arithmetic mean (0.3 BM25, 0.7 Neural)

### üîç **Search Pipeline Configuration**
```
Normalization:
  - Min-Max: Scales scores to [0, 1]
  
Combination:
  - Technique: Arithmetic Mean
  - Weights: [0.3, 0.7]
  - Formula: 0.3 √ó BM25_score + 0.7 √ó Neural_score
```

---

## Execution Flow

```mermaid
graph LR
    subgraph Query
        A["Question:<br/>Seattle Pop"]
    end
    
    subgraph Search
        B["BM25"]
        C["Neural"]
    end
    
    subgraph Process
        D["Normalize"]
        E["Weight"]
        F["Combine"]
    end
    
    subgraph Generate
        G["LLM"]
        H["Answer"]
    end
    
    A --> B
    A --> C
    B --> D
    C --> D
    D --> E
    E --> F
    F --> G
    G --> H
    
    style A fill:#4fc3f7
    style B fill:#0288d1
    style C fill:#0277bd
    style D fill:#ffca28
    style E fill:#f57f17
    style F fill:#ff6f00
    style G fill:#ce93d8
    style H fill:#8e24aa,color:#fff
```

---

## Main Components

### SearchIndexTool Configuration
```json
{
  "type": "SearchIndexTool",
  "parameters": {
    "input": '{"index": "${parameters.index}", "query": ${parameters.query} }'
  }
}
```

### Query Parameters Structure
```python
{
  "question": "What's the population...",
  "index": "my_test_data",
  "query": {
    # BM25 Query
    "query": {"match": {"text": "${parameters.question}"}},
    "size": 2,
    "_source": "text"
  }
}
```

---

## Technologies Used
- üîç **OpenSearch**: Search engine with pipeline support
- üìä **BM25 Algorithm**: Probabilistic ranking function
- ü§ñ **Sentence Transformers**: Neural embedding generation
- üß† **OpenAI GPT-3.5-turbo**: Language generation
- üîÑ **Search Pipeline**: Post-processing & normalization
- ‚öôÔ∏è **Ingest Pipeline**: Auto-embedding on indexing

---

## Unique Aspects
1. **Three Search Modes**: Flexible query execution (BM25, Neural, Hybrid)
2. **Score Normalization**: Min-Max scaling ensures comparable scores
3. **Weighted Combination**: Tunable weights for ranking preference
4. **Dynamic Index Selection**: Parameter-driven query routing
5. **Pipeline Architecture**: Extensible for additional processors
6. **Context Quality**: Hybrid approach ensures both relevance and recall
