{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbdd9d4e",
   "metadata": {},
   "source": [
    "# üåê WebSearchTool - Integrate External Web Search\n",
    "\n",
    "```mermaid\n",
    "%%{init: {'theme':'base', 'themeVariables': { 'primaryColor':'#3498DB', 'primaryTextColor':'#fff', 'primaryBorderColor':'#2980B9', 'lineColor':'#F39C12', 'secondaryColor':'#E67E22', 'tertiaryColor':'#27AE60', 'fontSize':'16px'}}}%%\n",
    "graph TB\n",
    "    A[üë§ User Query<br/>OpenSearch features] --> B[ü§ñ Flow Agent]\n",
    "    B --> C{üåê WebSearchTool}\n",
    "    C --> D[üîç DuckDuckGo API]\n",
    "    D --> E[üåç Web Search]\n",
    "    E --> F[üìÑ Top Results]\n",
    "    F --> G[üì§ Formatted Response]\n",
    "    \n",
    "    style A fill:#3498DB,stroke:#2980B9,color:#fff\n",
    "    style C fill:#3498DB,stroke:#2980B9,color:#fff\n",
    "    style D fill:#E67E22,stroke:#D35400,color:#fff\n",
    "    style E fill:#1ABC9C,stroke:#16A085,color:#fff\n",
    "    style G fill:#27AE60,stroke:#229954,color:#fff\n",
    "```\n",
    "\n",
    "## üìö Learning Objectives\n",
    "\n",
    "In this notebook, you'll learn:\n",
    "1. ‚úÖ How to use **WebSearchTool** to integrate external web search\n",
    "2. ‚úÖ Using **DuckDuckGo** for web search (no API key required)\n",
    "3. ‚úÖ Configuring **Google Custom Search** (when API key available)\n",
    "4. ‚úÖ Integrating **custom search APIs**\n",
    "5. ‚úÖ Building agents that combine internal and external knowledge\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ What is WebSearchTool?\n",
    "\n",
    "**WebSearchTool** enables OpenSearch agents to search the external web using various search engines. This is essential for:\n",
    "- üåç **External Knowledge**: Access information beyond your indices\n",
    "- üì∞ **Real-Time Data**: Get current information not in your database\n",
    "- üîó **Augmented Answers**: Combine internal data with web sources\n",
    "- üéì **Research Automation**: Gather external context automatically\n",
    "\n",
    "**Key Features**:\n",
    "- **DuckDuckGo**: No API key required, simple setup\n",
    "- **Google Custom Search**: More results, requires API key\n",
    "- **Custom APIs**: Integrate any HTTP search endpoint\n",
    "- No LLM required for search execution\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913e052d",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35143e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "\n",
    "# Add parent directory to path to import helper functions\n",
    "sys.path.append('..')\n",
    "from agent_helpers import (\n",
    "    get_os_client,\n",
    "    create_flow_agent,\n",
    "    execute_agent,\n",
    "    cleanup_resources\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c92d51",
   "metadata": {},
   "source": [
    "## Step 2: Initialize OpenSearch Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c84be0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to OpenSearch cluster: opensearch-cluster\n",
      "üìä Version: 3.3.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenSearch client\n",
    "client = get_os_client()\n",
    "\n",
    "# Verify connection\n",
    "info = client.info()\n",
    "print(f\"‚úÖ Connected to OpenSearch cluster: {info['cluster_name']}\")\n",
    "print(f\"üìä Version: {info['version']['number']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285a2f77",
   "metadata": {},
   "source": [
    "## Step 3: Create Flow Agent with WebSearchTool (DuckDuckGo)\n",
    "\n",
    "We'll start with DuckDuckGo since it doesn't require an API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca35426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Registering flow agent: Web_Search_Agent_DDG...\n",
      "   ‚úì Agent registered: Q_f9bZoBs1yJlE-jKeEe\n",
      "‚úÖ Flow agent created with ID: Q_f9bZoBs1yJlE-jKeEe\n",
      "üîß Tool configured: WebSearchTool\n",
      "üîç Search Engine: DuckDuckGo (no API key required)\n"
     ]
    }
   ],
   "source": [
    "# Define the tool configuration for DuckDuckGo\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"WebSearchTool\",\n",
    "        \"parameters\": {\n",
    "            \"engine\": \"duckduckgo\",\n",
    "            \"input\": \"${parameters.question}\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create the flow agent\n",
    "agent_id = create_flow_agent(\n",
    "    client,\n",
    "    \"Web_Search_Agent_DDG\",\n",
    "    \"An agent that searches the web using DuckDuckGo to find external information\",\n",
    "    tools\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Flow agent created with ID: {agent_id}\")\n",
    "print(f\"üîß Tool configured: WebSearchTool\")\n",
    "print(f\"üîç Search Engine: DuckDuckGo (no API key required)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a3108b",
   "metadata": {},
   "source": [
    "## Step 4: Test Case 1 - Search for OpenSearch Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eaef3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì Question: How to create an index pattern in OpenSearch?\n",
      "============================================================\n",
      "\n",
      "üåê Web Search Results:\n",
      "{\n",
      "  \"inference_results\": [\n",
      "    {\n",
      "      \"output\": [\n",
      "        {\n",
      "          \"name\": \"response\",\n",
      "          \"result\": \"{\\\"next_page\\\":\\\"https://duckduckgo.com/html?q=How+to+create+an+index+pattern+in+OpenSearch?&s=10&nextParams=&v=l&o=json&dc=11&api=d.js&vqd=4-321549925823353496162181061207099390480&kl=wt-wt\\\",\\\"items\\\":[{\\\"url\\\":\\\"https://docs.opensearch.org/latest/dashboards/management/index-patterns/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Regular expression syntax Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Using UBI in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Dashboards Management Index patterns Index patterns Index patterns are essential for accessing OpenSearch data. An index pattern references one or more indexes, data streams, or index aliases. For example, an index pattern can point you to your log data from yesterday or all indexes that contain that data. If you store data in multiple indexes, creating an index pattern enables your visualizations to retrieve data from all indexes that match the index pattern. You need to create index patterns to define how data is retrieved and fields are formatted so that you can query, search, and display data. Get started In this tutorial, you\\u2019ll learn to create index patterns. Note To create or modify index patterns, you must have create, manage, and delete permissions. Contact your administrator for support. For more information, refer to Multi-tenancy configuration. Prerequisites Before you can create an index pattern, your data must be indexed. To learn about indexing your data in OpenSearch, see Managing indexes. Best practices Consider the following best practices when creating index patterns: Make your index patterns specific. Instead of creating an index pattern that matches all indexes, create an index pattern that matches all indexes starting with a certain prefix, for example, my-index-. The more specific your index patterns, the better it will be to query and analyze your data. Use wildcards sparingly. Wildcards can be useful for matching multiple indexes, but they can also make it more difficult to manage your index patterns. Try to use wildcards as specifically as possible. Test your index patterns. Make sure to test your index patterns to ensure that they match the correct indexes. Creating an index pattern If you added sample data, you have index patterns that you can use to analyze that data. To create an index pattern for your own data, follow these steps. Step 1: Define the index pattern Go to OpenSearch Dashboards, and select Management > Dashboards Management > Index patterns. Select Create index pattern. From the Create index pattern window, define the index pattern by entering a name for your index pattern in the Index pattern name field. Dashboards automatically adds a wildcard, *, once you start typing. Using a wildcard is helpful for matching an index pattern to multiple sources or indexes. A dropdown list displaying all the indexes that match your index pattern appears when you start typing. Select Next step. An example of step 1 is shown in the following image. Note that the index pattern security* matches three indexes. By defining the pattern with a wildcard *, you can query and visualize all the data in your indexes. Step 2: Configure the settings Select @timestamp from the dropdown menu to specify the time field for OpenSearch to use when filtering documents based on time. Selecting this time filter determines which field the time filter is applied to. It can be the timestamp of a request or any relevant timestamp field. If you don\\u2019t want to use a time filter, select that option from the dropdown menu. If you select this option, OpenSearch returns all of the data in the indexes that match the pattern. Select Create index pattern. An example is shown in the following image. Once the index pattern has been created, you can view the mapping of the matching indexes. Within the table, you can see the list of fields, along with their data type and properties. An example is shown in the following image. Next steps Understand your data through visuals. Dig into your data. Get started Prerequisites Best practices Creating an index pattern Step 1: Define the index pattern Step 2: Configure the settings Next steps WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright \\u00a9 OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\\\"},{\\\"url\\\":\\\"https://repost.aws/knowledge-center/opensearch-index-pattern\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to content By using AWS re:Post, you agree to the AWS re:Post Terms of Use re:Post Search About re:Post English EnglishDeutschEspa\\u00f1olFran\\u00e7aisItaliano\\u65e5\\u672c\\u8a9e\\ud55c\\uad6d\\uc5b4Portugu\\u00eas\\u4e2d\\u6587 (\\u7b80\\u4f53)\\u4e2d\\u6587 (\\u7e41\\u9ad4) Resources Sign in Home Questions Knowledge Center Articles Selections Tags Topics Community Groups AWS Support Official AWS Trust & Safety Center Ask question / How do I create an index pattern in my OpenSearch Service cluster?lg.../ How do I create an index pattern in my OpenSearch Service cluster? 5 minute read 1 I want to create an index pattern in my Amazon OpenSearch Service cluster. Resolution Prerequisites: The AWS Identity and Access Management (IAM) user must have PUT and POST permissions to create an index pattern. Example access policy: {  \\\\\\\"Version\\\\\\\": \\\\\\\"2012-10-17\\\\\\\",\\\\n  \\\\\\\"Statement\\\\\\\": [\\\\n    {\\\\n      \\\\\\\"Sid\\\\\\\": \\\\\\\"VisualEditor0\\\\\\\",\\\\n      \\\\\\\"Effect\\\\\\\": \\\\\\\"Allow\\\\\\\",\\\\n      \\\\\\\"Action\\\\\\\": [\\\\n        \\\\\\\"es:ESHttpHead\\\\\\\",\\\\n        \\\\\\\"es:ESHttpPost\\\\\\\",\\\\n        \\\\\\\"es:ESHttpGet\\\\\\\",\\\\n        \\\\\\\"es:ESHttpDelete\\\\\\\",\\\\n        \\\\\\\"es:ESHttpPut\\\\\\\"\\\\n      ],\\\\n      \\\\\\\"Resource\\\\\\\": \\\\\\\"arn:aws:es:region:account-id:domain/domain-name/*\\\\\\\"\\\\n    }\\\\n  ]\\\\n} Note: Replace region with your AWS Region, account-id with your AWS account, and domain-name with your domain name. Your cluster version must allow index patterns. Create the index pattern Use OpenSearch Dashboards You can use OpenSearch Dashboards to create an index pattern for OpenSearch Service or Elasticsearch clusters with or without fine-grained access control. For instructions, see Creating an index pattern on the OpenSearch website. Use curl commands To create an index pattern for clusters without fine-grained access control, run the following command based on the cluster type. Elasticsearch clusters: curl -X POST  https://elasticsearch-end-point/_plugin/kibana/api/saved_objects/index-pattern/ \\\\\\\\\\\\n-H \\\\\\\"kbn-xsrf: true\\\\\\\" \\\\\\\\\\\\n\\\\n-H \\\\\\\"content-type: application/json\\\\\\\" \\\\\\\\\\\\n\\\\n-d '{ \\\\\\\"attributes\\\\\\\": { \\\\\\\"title\\\\\\\": \\\\\\\"sample-index*\\\\\\\" } }' Note: Replace sample-index with your index name or pattern. OpenSearch Service clusters: curl -X POST  https://opensearch-end-point/_dashboards/api/saved_objects/index-pattern/ \\\\\\\\\\\\n-H \\\\\\\"kbn-xsrf: true\\\\\\\" \\\\\\\\\\\\n\\\\n-H \\\\\\\"content-type: application/json\\\\\\\" \\\\\\\\\\\\n\\\\n-d '{ \\\\\\\"attributes\\\\\\\": { \\\\\\\"title\\\\\\\": \\\\\\\"sample-index*\\\\\\\" } }' Note: Replace sample-index with your index name or pattern. For clusters with fine-grained access control, complete the following steps: To generate authorization cookies in the auth.txt file, run the following command based on the cluster type. Elasticsearch clusters: curl -X POST  https://elasticsearch-end-point/_plugin/kibana/auth/login  \\\\\\\\\\\\n-H \\\\\\\"kbn-xsrf: true\\\\\\\" \\\\\\\\\\\\n-H \\\\\\\"content-type: application/json\\\\\\\" \\\\\\\\\\\\n-d '{\\\\\\\"username\\\\\\\":\\\\\\\"usernameexample\\\\\\\", \\\\\\\"password\\\\\\\":\\\\\\\"passwordexample\\\\\\\"}' \\\\\\\\\\\\n-c auth.txt Note: Replace usernameexample with your username and passwordexample with your password. OpenSearch Service clusters: curl -X POST  https://opensearch-end-point/_dashboards/auth/login  \\\\\\\\\\\\n-H \\\\\\\"kbn-xsrf: true\\\\\\\" \\\\\\\\\\\\n-H \\\\\\\"content-type: application/json\\\\\\\" \\\\\\\\\\\\n-d '{\\\\\\\"username\\\\\\\":\\\\\\\"usernameexample\\\\\\\", \\\\\\\"password\\\\\\\":\\\\\\\"passwordexample\\\\\\\"}' \\\\\\\\\\\\n-c auth.txt Note: Replace usernameexample with your username and passwordexample with your password. To submit the index pattern creation request, run the following command based on your cluster type: Elasticsearch clusters: curl -X POST  https://elasticsearch-end-point/_plugin/kibana/api/saved_objects/index-pattern/test  \\\\\\\\\\\\n-H \\\\\\\"kbn-xsrf: true\\\\\\\" \\\\\\\\\\\\n-H \\\\\\\"content-type: application/json\\\\\\\" \\\\\\\\\\\\n-d '{ \\\\\\\"attributes\\\\\\\": { \\\\\\\"title\\\\\\\": \\\\\\\"sample-index*\\\\\\\" } }' \\\\\\\\\\\\n-b auth.txt Note: Replace sample-index with your index name or pattern. OpenSearch Service clusters: curl -X POST  https://opensearch-end-point/_dashboards/api/saved_objects/index-pattern/  \\\\\\\\\\\\n-H \\\\\\\"kbn-xsrf: true\\\\\\\" \\\\\\\\\\\\n-H \\\\\\\"content-type: application/json\\\\\\\" \\\\\\\\\\\\n-d '{ \\\\\\\"attributes\\\\\\\": { \\\\\\\"title\\\\\\\": \\\\\\\"sample-index*\\\\\\\" } }' \\\\\\\\\\\\n-b auth.txt Note: Replace sample-index with your index name or pattern. Use Python Prerequisites: Map the role that runs the Python code to the backend role for fine-grained access control clusters. Run the following commands to install the required dependencies: pip install boto3\\\\npip install opensearch-py\\\\npip install requests\\\\npip install requests-aws4auth Run the following Python command to create the index pattern for OpenSearch Service clusters: import boto3\\\\nimport requests\\\\nfrom requests_aws4auth import AWS4Auth\\\\n\\\\nhost = 'https://domain-endpoint/' # include trailing /\\\\nregion = 'aos-region' # example us-west-1\\\\nservice = 'es'\\\\ncredentials = boto3.Session().get_credentials()\\\\nawsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)\\\\n\\\\n\\\\npath = '_dashboards/api/saved_objects/index-pattern' # _plugin/kibana/api/saved_objects/index-pattern for es versions\\\\nurl = host + path\\\\npayload = {\\\\\\\"attributes\\\\\\\":{\\\\\\\"title\\\\\\\":\\\\\\\"multi-logs-*\\\\\\\",\\\\\\\"fields\\\\\\\":\\\\\\\"[]\\\\\\\"}}\\\\nheaders = {\\\\\\\"Content-Type\\\\\\\": \\\\\\\"application/json\\\\\\\", \\\\\\\"osd-xsrf\\\\\\\": \\\\\\\"true\\\\\\\", \\\\\\\"security_tenant\\\\\\\": \\\\\\\"global\\\\\\\" }\\\\nr = requests.post (url, auth=awsauth, json=payload, headers=headers)\\\\nprint(r.status_code)\\\\nprint(r.text) Note: Replace domain-endpoint with your domain endpoint, and aos-region with your Region. For Elasticsearch clusters, replace _dashboards/api/saved_objects/index-pattern with _plugin/kibana/api/saved_objects/index-pattern. Troubleshoot index pattern creation issues You use fine-grained access control with SAML 2.0 or Amazon Cognito authentication If the domain for your cluster uses SAML 2.0 or Amazon Cognito for authentication, then create an internal user to manage the index pattern. Note: For clusters where you activated fine-grained access control, the user must have ESHttpPut and ESHttpPost permissions to create an index pattern. You can't create the index pattern in the Global tenant By default, OpenSearch Dashboards creates index patterns under the Global tenant. To create an index pattern outside of the Global tenant, run the following command: curl -s -X POST https://opensearch-end-point/_dashboards/api/saved_objects/index-pattern/sample-index -d '{\\\\\\\"attributes\\\\\\\": {\\\\\\\"title\\\\\\\": \\\\\\\"sample-index*\\\\\\\"}}' \\\\\\\\\\\\n-H \\\\\\\"osd-xsrf:true\\\\\\\" \\\\\\\\\\\\n-H \\\\\\\"securitytenant: private\\\\\\\" \\\\\\\\\\\\n-H \\\\\\\"content-type:application/json\\\\\\\" \\\\\\\\\\\\n-b auth.txt Note: Replace sample-index with your index name or pattern. You didn't include the .kibana alias in the cluster To troubleshoot this issue, complete the following steps: To check whether the .kibana alias exists in the cluster, run the following command: curl -XGET https://opensearch-end-point/_cat/aliases Note: For clusters with fine-grained access control, include the -u flag with your username and password. Example command: curl -XPOST -u 'master-user:master-user-password' 'domain-endpoint/_cat/indices If the .kibana index doesn't exist, then proceed to step 4. To create a backup of .kibana index, run the following command: curl -XPOST \\\\\\\"https://domain-endpoint/_reindex\\\\\\\" -H 'Content-Type: application/json' -d'{\\\\n  \\\\\\\"source\\\\\\\": {\\\\n    \\\\\\\"index\\\\\\\": \\\\\\\".kibana\\\\\\\"\\\\n  },\\\\n  \\\\\\\"dest\\\\\\\": {\\\\n \\\\\\\"index\\\\\\\": \\\\\\\".kibana_backup\\\\\\\"\\\\n  }\\\\n}' Note: Replace domain-endpoint with your domain endpoint. For clusters with fine-grained access control, include the -u flag with your username and password. To delete the .kibana index, run the following command: curl -XDELETE \\\\\\\"https://domain-endpoint/.kibana\\\\\\\" Note: Replace domain-endpoint with your domain endpoint. For clusters with fine-grained access control, include the -u flag with your username and password. To create a .kibana alias and point it to the .kibana_backup index, run the following command: curl -XPOST \\\\\\\"https://domain-endpoint/_aliases\\\\\\\" -H 'Content-Type: application/json' -d'{\\\\n  \\\\\\\"actions\\\\\\\": [\\\\n    {\\\\n      \\\\\\\"add\\\\\\\": {\\\\n        \\\\\\\"index\\\\\\\": \\\\\\\".kibana_backup\\\\\\\",\\\\n        \\\\\\\"alias\\\\\\\": \\\\\\\".kibana\\\\\\\"\\\\n      }\\\\n    }\\\\n  ]\\\\n}' Note: Replace domain-endpoint with your domain endpoint. For clusters with fine-grained access control, include the -u flag with your username and password. Related information Export and import Kibana dashboards with OpenSearch Service Why does the rollover index action in my ISM policy keep failing in OpenSearch Service? Follow Share Topics Analytics Tags Amazon OpenSearch Service Language English Related videos Watch Sujata's video to learn more (3:59) AWS OFFICIALUpdated 3 months ago 2 Comments This can also be done using basic auth using session object without signing the request if that is the use case. [+] Session Object = https://requests.readthedocs.io/en/latest/user/advanced/#session-objects #! /bin/python3\\\\nimport requests\\\\nhost = 'https://<domain_endpoint_ending_with_slash>/'\\\\npath = '_dashboards/auth/login'\\\\nregion = 'us-east-1'\\\\nurl = host + path;\\\\n# Set headers as mentioned. Here we will create index pattern in global tenant hence the value is global\\\\nheaders = {\\\\\\\"Content-Type\\\\\\\": \\\\\\\"application/json\\\\\\\",\\\\\\\"kbn-xsrf\\\\\\\": \\\\\\\"true\\\\\\\",\\\\\\\"osd-xsrf\\\\\\\":\\\\\\\"true\\\\\\\",\\\\\\\"security_tenant\\\\\\\":\\\\\\\"global\\\\\\\"};\\\\npayload = {\\\\n \\\\\\\"username\\\\\\\":\\\\\\\"username\\\\\\\",\\\\n    \\\\\\\"password\\\\\\\":\\\\\\\"password\\\\\\\"\\\\n}\\\\n\\\\n#Creating a session because requests wont store the cookie\\\\n\\\\nsession=requests.Session();\\\\n\\\\nr=session.post(url,headers=headers,json=payload);\\\\n# You can skip these lines with print. Basically the above line will do a post request with my credentials and will create a cookie and will store it\\\\nprint(r.text);\\\\nprint(r.status_code);\\\\n\\\\n# title is the name of my index pattern\\\\n\\\\npayload={\\\\n\\\\\\\"attributes\\\\\\\": { \\\\\\\"title\\\\\\\": \\\\\\\"random*\\\\\\\" } \\\\n\\\\n}\\\\n\\\\npath=\\\\\\\"_dashboards/api/saved_objects/index-pattern/random*\\\\\\\";\\\\nurl=host+path;\\\\n\\\\n#Changed the path variable to the one which is mentioned above. Notice the end of the URL, my index pattern name will be random*\\\\n\\\\nr=session.post(url,headers=headers,json=payload);\\\\n\\\\nprint(r.text);\\\\nprint(r.status_code);\\\\nsession.close();\\\\n Share rePost-User-6420587 replied 2 years ago Thank you for your comment. We'll review and update the Knowledge Center article as needed. Share MODERATOR AWS Official replied 2 years ago Comment on this article Clear Post comment Relevant content Got an error \\\\\\\"Request Entity Too Large\\\\\\\" when creating index pattern in AWS Opensearch soop_minjaeoh asked a year ago How to create and configure an Open Search Serverless index via API? Zach asked 9 months ago OpenSearch Dashboards Index Pattern and Discover issues mdkail asked 4 years ago Index is not created inside the Amazon OpenSearch cluster Accepted Answer stratosb asked 2 years ago Access denied (403) when creating an index in OpenSearch Serverless. AlwaysLearning asked 2 years ago Why does the rollover index action in my ISM policy fail in OpenSearch Service? AWS OFFICIALUpdated a month ago Why can't I delete an index or upgrade my OpenSearch Service cluster? AWS OFFICIALUpdated a year ago How do I resolve the 403 \\\\\\\"index_create_block_exception\\\\\\\" or \\\\\\\"cluster_block_exception\\\\\\\" error in OpenSearch Service? AWS OFFICIALUpdated 3 years ago How do I use ISM to manage low storage space in Amazon OpenSearch Service? AWS OFFICIALUpdated 2 months ago How to combine ISM policy actions to control shard size EXPERT Sherin Chandy published a year ago FEEDBACK Privacy| Site Terms| Cookie Preferences | Sitemap| Legal| \\u00a9 2025, Amazon Web Services, Inc. or its affiliates. All rights reserved. Community Guidelines\\\"},{\\\"url\\\":\\\"https://www.youtube.com/watch?v=pbABIerUYQI\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"AboutPressCopyrightContact usCreatorsAdvertiseDevelopersTermsPrivacyPolicy & SafetyHow YouTube worksTest new featuresNFL Sunday Ticket \\u00a9 2025 Google LLC\\\"},{\\\"url\\\":\\\"https://github.com/fidelity-contributions/opensearch-project-opensearch-py/blob/main/guides/index_template.md\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to content Navigation Menu Toggle navigation Sign in Appearance settings Platform AI CODE CREATION GitHub CopilotWrite better code with AI GitHub SparkBuild and deploy intelligent apps GitHub ModelsManage and compare prompts MCP RegistryNewDiscover and integrate external tools DEVELOPER WORKFLOWS ActionsAutomate any workflow CodespacesInstant dev environments IssuesPlan and track work Code ReviewManage code changes APPLICATION SECURITY GitHub Advanced SecurityFind and fix vulnerabilities Code securitySecure your code as you build Secret protectionStop leaks before they start EXPLORE Why GitHub Documentation Blog Changelog Marketplace View all features Solutions BY COMPANY SIZE Enterprises Small and medium teams Startups Nonprofits BY USE CASE App Modernization DevSecOps DevOps CI/CD View all use cases BY INDUSTRY Healthcare Financial services Manufacturing Government View all industries View all solutions Resources EXPLORE BY TOPIC AI Software Development DevOps Security View all topics EXPLORE BY TYPE Customer stories Events & webinars Ebooks & reports Business insights GitHub Skills SUPPORT & SERVICES Documentation Customer support Community forum Trust center Partners Open Source COMMUNITY GitHub SponsorsFund open source developers PROGRAMS Security Lab Maintainer Community Accelerator Archive Program REPOSITORIES Topics Trending Collections Enterprise ENTERPRISE SOLUTIONS Enterprise platformAI-powered developer platform AVAILABLE ADD-ONS GitHub Advanced SecurityEnterprise-grade security features Copilot for BusinessEnterprise-grade AI features Premium SupportEnterprise-grade 24/7 support Pricing Search or jump to... Search code, repositories, users, issues, pull requests... Search Clear Search syntax tips Provide feedback We read every piece of feedback, and take your input very seriously. Include my email address so I can be contacted Cancel Submit feedback Saved searches Use saved searches to filter your results more quickly Name Query To see all available qualifiers, see our documentation. Cancel Create saved search Sign in Sign up Appearance settings Resetting focus You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert {{ message }} fidelity-contributions / opensearch-project-opensearch-py Public forked from opensearch-project/opensearch-py Notifications You must be signed in to change notification settings Fork 0 Star 0 Code Pull requests 0 Security Uh oh! There was an error while loading. Please reload this page. Insights Additional navigation options Code Pull requests Security Insights Footer \\u00a9 2025 GitHub, Inc. Footer navigation Terms Privacy Security Status Community Docs Contact Manage cookies Do not share my personal information You can\\u2019t perform that action at this time.\\\"},{\\\"url\\\":\\\"https://deepwiki.com/johnny-chivers/amazon-opensearch-service/3.1-index-patterns\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Index your code with Devin DeepWiki DeepWiki johnny-chivers/amazon-opensearch-service Index your code with Devin Edit Wiki Share Last indexed: 25 May 2025 (924181) Overview Getting Started Tutorial Domain Setup Data Upload and Indexing Search Operations Cleanup and Domain Deletion Index Management Index Patterns Field Configuration Security and Access Control Access Control Systems Access Policies System Architecture Data Node Architecture Network Configuration Development and Testing Menu Index Patterns Relevant source files pictures/12-define-index-pattern.png pictures/13-createe-index-pattern.png Purpose and Scope This document covers the creation and configuration of index patterns in Amazon OpenSearch Service, specifically focusing on how they enable data discovery and visualization through the OpenSearch Dashboards interface. Index patterns define how OpenSearch Dashboards connects to and interprets the data stored in your OpenSearch indices. This guide specifically covers the index pattern workflow for the movies dataset used in the tutorial. For information about the underlying index field configuration and data types, see Field Configuration. For the broader context of data upload and indexing operations, see Data Upload and Indexing. Overview of Index Patterns Index patterns in OpenSearch Dashboards serve as a bridge between raw index data and the visualization layer. They define which indices contain the data you want to explore and specify how that data should be interpreted for search and analysis operations. In the context of this tutorial, index patterns enable access to the movies index that contains the bulk movie dataset from bulk_movies.json. Sources: Based on tutorial workflow and OpenSearch Dashboards architecture patterns. Index Pattern Creation Workflow The index pattern creation process follows a specific sequence within the OpenSearch Dashboards interface, as documented in the tutorial screenshots. Sources: Tutorial workflow sequence and OpenSearch Dashboards interface patterns. Pattern Definition and Configuration Index patterns use wildcard matching to identify which indices they should include. For the movies dataset, the pattern typically follows this structure: Pattern Element Purpose Example Index Name Base index identifier movies Wildcard Pattern matching movies* Time Field Timestamp field for time-based data Not applicable for movies dataset Field Discovery Automatic field detection Enabled The pattern configuration process involves several key steps: Sources: OpenSearch Dashboards index pattern creation workflow and field detection mechanisms. Field Mapping and Data Types Once an index pattern is created, OpenSearch Dashboards automatically discovers and maps the fields from the underlying movies index. This process examines the data structure from the documents uploaded via bulk_movies.json. The field mapping process identifies several categories of data: Field Category Examples from Movies Data OpenSearch Type Text Fields title, director, genre text or keyword Numeric Fields year, rating integer or float Date Fields release_date date Boolean Fields available boolean Sources: OpenSearch field mapping documentation and movies dataset structure analysis. Integration with Discovery Interface Index patterns enable the Discover interface to provide search and exploration capabilities across the movie dataset. The integration allows for both simple and complex query operations. The discovery workflow leverages the index pattern to: Field-based Filtering: Use detected fields for creating search filters Time-based Navigation: Handle temporal data if time fields are configured Aggregation Operations: Support grouping and statistical operations Export Functionality: Enable data export based on search results Sources: OpenSearch Dashboards Discover interface capabilities and query processing architecture. Pattern Management and Maintenance Index patterns require ongoing management as data structures evolve. The tutorial demonstrates basic pattern creation, but production environments often need pattern updates and field refresh operations. Key maintenance operations include: Field Refresh: Update field mappings when new fields are added to indices Pattern Modification: Adjust pattern matching rules for new indices Performance Optimization: Configure field settings for optimal query performance Access Control: Manage pattern visibility and permissions The movies dataset provides a stable example for learning these concepts, as the data structure remains consistent throughout the tutorial workflow. Sources: OpenSearch index pattern management best practices and tutorial documentation structure. Dismiss Refresh this wiki Enter email to refresh On this page Index Patterns Purpose and Scope Overview of Index Patterns Index Pattern Creation Workflow Pattern Definition and Configuration Field Mapping and Data Types Integration with Discovery Interface Pattern Management and Maintenance\\\"},{\\\"url\\\":\\\"https://opster.com/guides/opensearch/opensearch-data-architecture/index-templating-in-opensearch-how-to-use-composable-templates/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Product BUILT FOR ELASTICSEARCH AutoOps Prevent & resolve issues, cut down administration time & hardware costs. Community Tools Tools For The Community Check-Up, Search Log Analyzer & OpsGPT Resources Guides Technical guides on Elasticsearch & Opensearch Blog Insights, Opster news, blogs and more Documentation Opster product documentation Error Messages Error Repository About About Our story & vision Login AutoOps Login Contact Login Contact Running self-managed Elasticsearch just got easier. Announcing AutoOps for your clusters. Read the announcement \\ud83c\\udf89\\ud83c\\udf89 Opensearch Guides > OpenSearch Data Architecture Elasticsearch Index Templates in OpenSearch \\u2013 How to Use Composable Templates By Opster Expert Team Updated: Jun 28, 2023 | 6 min read Quick links Overview \\u2013 mapping, settings and aliases Index templates \\u2013 composable templates and component templates How to create composable index templates Creating an index Creating component templates Template priority Precedence of templates Summary The source code for this article is available here. Overview An OpenSearch index can be configured through mapping, settings and aliases: Mapping definitions specify the data schema. Settings will set the shard sizing and refresh rates. Aliases are used to give the index alternate names. When we index a document for the first time or create an empty index using the Create Index API, the index will be created with default settings, without data schema and without aliases. These defaults work pretty well in development and testing environments, but we may need to customize our indices for production environments. Working with the default mappings and settings in production might result in poor indexing and search performance. Instantiating indices manually is a tedious and time consuming process. Recreating such indices on every environment is especially impractical if we have an elaborate mapping schema as well as customized settings and aliases. Fortunately, OpenSearch provides us with a tool to automatically apply a predefined configuration when creating indices in the form of index templates. Index templates Index templates allow us to create indices with user defined configuration. An index can pull the configuration from these templates, for example a set number of shards and replicas or field mappings, during its instantiation. A template will be defined with a name pattern and some configuration in it. If the name of the index matches the template\\u2019s naming pattern, the new index will be created with the configuration defined in the template. Types of templates Index templates can be classified into two categories: Index templates (or composabale index templates): The composable index templates can either exist on their own, or can be composed of none or more component templates (see the second category). Component templates: The component template is a reusable template on its own that defines the required configuration. Usually the component template is expected to be associated with an index template. Each of the component templates can be attached with one or many index templates. As you can see in the image below, the index templates A and B share component templates (in this case just one \\u2013 Template 3) between themselves. An index template can consist of none or many component templates and each of the component templates can be associated with none or many index templates. Both types of templates can exist on their own, however component templates are of no use unless they are attached to an index template. The general idea is to develop a catalogue of component templates for an organization to use for various needs (for example, specifying the various component templates for individual environments) and attach them to various indices via the composable index templates. How to create composable (index) templates OpenSearch provides an _index_template endpoint for managing index templates. The user provides all the required mappings, settings, and aliases along with an index name pattern in this template. Let\\u2019s run through an example of creating a template for a microservice application customer-order-service which is responsible for order generation logic. Let\\u2019s say our requirement is to create a template for customer orders, represented with a pattern having wildcards: *orders. This template is expected to have certain mappings and settings, such as the order_date field, as well as shards and replica numbers. Any index that gets matched with this template during its creation inherits the configurations defined in this template. For example a black_friday_orders index will have the order_date field, shards will be set to 5 and the replicas set to 2. In addition to this, all indices created from this template inherit a single alias name, too!Let\\u2019s create this orders_template with an index pattern defined as *orders and with a mapping schema consisting of a single oder_date field with a predefined date format dd-MM-yyyy. The code below shows how to create this index template. PUT _index_template/orders_template\\\\n{\\\\n  \\\\\\\"index_patterns\\\\\\\": [\\\\\\\"*orders\\\\\\\"],\\\\n  \\\\\\\"priority\\\\\\\": 300,\\\\n  \\\\\\\"template\\\\\\\": {\\\\n    \\\\\\\"mappings\\\\\\\": {\\\\n      \\\\\\\"properties\\\\\\\": {\\\\n        \\\\\\\"order_date\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"date\\\\\\\",\\\\n          \\\\\\\"format\\\\\\\":\\\\\\\"dd-MM-yyyy\\\\\\\"\\\\n        }\\\\n      }\\\\n    },\\\\n    \\\\\\\"settings\\\\\\\":{\\\\n      \\\\\\\"number_of_shards\\\\\\\":5,\\\\n      \\\\\\\"number_of_replicas\\\\\\\":2\\\\n    },\\\\n    \\\\\\\"aliases\\\\\\\":{\\\\n      \\\\\\\"all_orders\\\\\\\":{}\\\\n    }\\\\n  }\\\\n} When you execute this query in Kibana\\u2019s DevTools, the template is created with the index pattern *orders along with the predefined mapping, settings and an alias. The index_patterns is an array of match patterns; any index matching this pattern will be deriving the template configuration. You can execute the following to retrieve the persisted template that should reiterate what we did: GET _index_template/orders_template There\\u2019s also a priority, a positive number, defined when creating the template attribute defined on the template: every template is defined with a priority so that any conflicting changes from different templates will be resolved by using this value with precedence given to the higher priority value. We\\u2019ll dive more deeply into template priority below. Creating an index with the template Now we have a template \\u2013 a blueprint for creating indices \\u2013 the next step is to create an index. When the name of the index matches with the given pattern, the templated configurations are applied automatically. To prove the point, as the code below shows, let\\u2019s create a brand new index named: blackfriday_orders: PUT blackfriday_orders As the name of the index (blackfriday_orders) matches with the naming pattern defined in template (i.e. *orders), the index should get all the configuration derived from the template. Let\\u2019s retrieve this freshly created index and check if this is indeed true by executing the following code: GET blackfriday_orders This should return: {\\\\n  \\\\\\\"blackfriday_orders\\\\\\\" : {\\\\n    \\\\\\\"aliases\\\\\\\" : {\\\\n      \\\\\\\"all_orders\\\\\\\" : { }\\\\n    },\\\\n    \\\\\\\"mappings\\\\\\\" : {\\\\n      \\\\\\\"properties\\\\\\\" : {\\\\n        \\\\\\\"order_date\\\\\\\" : {\\\\n          \\\\\\\"type\\\\\\\" : \\\\\\\"date\\\\\\\",\\\\n          \\\\\\\"format\\\\\\\" : \\\\\\\"dd-MM-yyyy\\\\\\\"\\\\n        }\\\\n      }\\\\n    },\\\\n    \\\\\\\"settings\\\\\\\" : {\\\\n      \\\\\\\"index\\\\\\\" : {\\\\n         ...\\\\n        \\\\\\\"number_of_shards\\\\\\\" : \\\\\\\"5\\\\\\\",\\\\n        \\\\\\\"number_of_replicas\\\\\\\" : \\\\\\\"2\\\\\\\"\\\\n      }\\\\n    }\\\\n  }\\\\n} As the response indicates, the configuration of the blackfriday_orders has been inherited from the template. We can try with various combinations of the indices that will successfully inherit the templated configuration: PUT blackfriday_orders\\\\nPUT americaorders\\\\nPUT cancelled--orders\\\\nPUT undefined101orders However, the following indices will not be inheriting the configuration as the name will not match with the pattern: PUT blackfriday_orders2\\\\nPUT open_orders_\\\\nPUT allorders_total One important thing to remember is that all the indices derived from a template have the same alias \\u2013 all_orders \\u2013 in this case. There is an advantage of having such alias \\u2013 we can simply query on this single alias rather than multiple indices. GET blackfriday_orders,americaorders,undefined101orders/_search\\\\nGET all_orders/_search \\\\n{\\\\n  \\\\\\\"query\\\\\\\": {\\\\n    \\\\\\\"range\\\\\\\": {\\\\n      \\\\\\\"order_date\\\\\\\": {\\\\n        \\\\\\\"gte\\\\\\\": \\\\\\\"01-12-2021\\\\\\\",\\\\n        \\\\\\\"lte\\\\\\\": \\\\\\\"31-12-2021\\\\\\\"\\\\n      }\\\\n    }\\\\n  }\\\\n} While we create a template for *orders, any matching index is expected to adopt the template configuration. Usually, knowingly or unknowingly, teams may create a few more templates for various reasons. This means that at times the index name may match two different template patterns! OpenSearch has to decide which of the configurations from those templates it needs to apply. Fortunately, this dilemma can be solved by using the template priority. Creating component templates We learned about index templates in the earlier part of this article. There are a couple of disadvantages of creating the templates with the configuration built in \\u2013 one such disadvantage being that the configuration is not exportable for other templates. If we wish to have similar configuration, say for customer related templates (*customers), we may have to re-create the whole template. That means, we may be creating dozens of them in a typical organization (plus you may have a few more based on the environments). As we always look forward to reusability, OpenSearch redesigned the templates keeping reusability in mind. The component templates fit that bill. If you are from a DevOps background, most likely you\\u2019d have a requirement to create indices with a preset configuration for each of the environments. Rather than tediously applying each of these configurations manually, you can create a component template for each of the environments. A component template is nothing but a reusable block of configurations that we can use to make up more index templates. Do note that the component templates are of no value unless they are clubbed with index templates. They are exposed via a _component_template endpoint. Let\\u2019s see how this all fits together. Settings template Let\\u2019s extract the settings we defined in our index template earlier and create a component template out of it. The settings_component_template is expected to have five primary shards with two replicas per primary shard. The first step, as the code listing below shows, is to declare and execute a component template with this configuration. PUT _component_template/settings_component_template\\\\n{\\\\n  \\\\\\\"template\\\\\\\":{\\\\n    \\\\\\\"settings\\\\\\\":{\\\\n      \\\\\\\"number_of_shards\\\\\\\":5,\\\\n      \\\\\\\"number_of_replicas\\\\\\\":2\\\\n    }\\\\n  }\\\\n} As the code above shows, we use the _component_template endpoint to create a component template. The body of the request holds the template information in a template object. The settings_component_template is now available for use elsewhere in the index templates. One notable difference is that this template does not define any index pattern; it\\u2019s simply a code block that configures some properties for us. Mappings template In the same way, let\\u2019s create another template. This time, let\\u2019s extract the mapping schema we had defined earlier in the standalone index templates. The code below shows the script: PUT _component_template/mappings_component_template\\\\n{\\\\n  \\\\\\\"template\\\\\\\": {\\\\n    \\\\\\\"mappings\\\\\\\": {\\\\n      \\\\\\\"properties\\\\\\\": {\\\\n        \\\\\\\"order_date\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"date\\\\\\\",\\\\n          \\\\\\\"format\\\\\\\":\\\\\\\"dd-MM-yyyy\\\\\\\"\\\\n        }\\\\n      }\\\\n    }\\\\n  }\\\\n} Aliases template Going with the same flow, we can also have a component template with the aliases \\u2013 two aliases (all_orders and sales_orders): PUT _component_template/aliases_component_template\\\\n{\\\\n  \\\\\\\"template\\\\\\\": {\\\\n    \\\\\\\"aliases\\\\\\\": {\\\\n      \\\\\\\"all_orders\\\\\\\": {},\\\\n      \\\\\\\"sales_orders\\\\\\\":{}\\\\n    }\\\\n  }\\\\n} Composable index template Now that we have these three component templates, the next step is to put them to use. We can do this by letting an index template for, say christmas_orders, use it: PUT _index_template/composed_orders_template\\\\n{\\\\n  \\\\\\\"index_patterns\\\\\\\": [\\\\n    \\\\\\\"*orders\\\\\\\"\\\\n  ],\\\\n  \\\\\\\"priority\\\\\\\": 500,\\\\n  \\\\\\\"composed_of\\\\\\\": [\\\\n    \\\\\\\"settings_component_template\\\\\\\",\\\\n    \\\\\\\"mappings_component_template\\\\\\\",\\\\n    \\\\\\\"aliases_component_template\\\\\\\"\\\\n  ]\\\\n} The composed_of tag is a collection of all the component templates that make up this template. In this case, we are choosing the settings, mappings and aliases component templates. We are also bumping up the priority so this template trumps any others. Once the template is ready, any indices that match the *orders pattern will inherit the configuration from these three component templates. Having said that, should we wish to create a new template, say customers, with just one of the existing (settings_component_template) and a newly created aliases (aliases_component_template \\u2013 see below) template, we can do so with: PUT _component_template/aliases_component_template2\\\\n{\\\\n  \\\\\\\"template\\\\\\\": {\\\\n    \\\\\\\"aliases\\\\\\\": {\\\\n      \\\\\\\"all_customers\\\\\\\": {}\\\\n    }\\\\n  }\\\\n} The index template goes like this: PUT _index_template/composed_customers_template\\\\n{\\\\n  \\\\\\\"index_patterns\\\\\\\": [\\\\n    \\\\\\\"*customers*\\\\\\\"\\\\n  ],\\\\n  \\\\\\\"priority\\\\\\\": 200,\\\\n  \\\\\\\"composed_of\\\\\\\": [\\\\n    \\\\\\\"settings_component_template\\\\\\\",\\\\n    \\\\\\\"aliases_component_template2\\\\\\\"\\\\n  ]\\\\n} Did you see that the settings_component_template has been (re)used across two different templates? That is the power of component templates. Template priority There is a chance that developers may create multiple index templates without looking at the existing stock. It is important to set a priority on each of these templates so the one with higher priority will be used. For example, the my_orders_template_1 overrides the my_orders_template_2 in the following code snippet: PUT _index_template/my_orders_template_1\\\\n{\\\\n  \\\\\\\"index_patterns\\\\\\\": [\\\\\\\"*orders\\\\\\\"],\\\\n  \\\\\\\"priority\\\\\\\": 1000,\\\\n  \\\\\\\"template\\\\\\\": { ... }\\\\n}\\\\nPUT _index_template/my_orders_template2\\\\n{\\\\n  \\\\\\\"index_patterns\\\\\\\": [\\\\\\\"*orders\\\\\\\"],\\\\n  \\\\\\\"priority\\\\\\\": 300,\\\\n  \\\\\\\"template\\\\\\\": { ... }\\\\n} When you have multiple templates matching the indices that are being created, OpenSearch applies all the configurations from all matching templates but overrides anything that has higher priority. Precedence of templates Finally, you may be wondering about the precedence of the templates \\u2013 does the configuration defined in the component template override the one defined on the main index template itself? Or the other way around? Well, there are some rules: An index created with configurations explicitly takes precedence over everything \\u2013 this means if you create an index with explicit configuration, don\\u2019t expect them to be overridden by the templates. Summary An index contains mappings, settings and aliases: the mappings define the fields schema, settings set the index parameters such as number of shards and replicas, and aliases give alternate names to the index. Templates allow us to create indices with predefined configurations. Naming an index with a name that matches the index-pattern defined in a specific template will automatically configure that index according to the template. The composable templates consist of none or more component templates. An index template can have its own configuration defined too. A component template is a reusable template with predefined configuration, just like a composable index template. However, component templates are expected to be part of an index template; They are useless if they are not \\u201ccomposed\\u201d into an index template. Component templates have no index pattern defined in them \\u2013 which is another reason they are \\u201cexpected\\u201d to be part of an index template. Each of the templates has a priority \\u2013 a positive number. The higher the number, the greater the precedence for that template to be applied. Related Articles 3 Pagination Techniques in Elasticsearch Elasticsearch Large Cluster State - How to Discover & Prevent Backblaze Optimized OpenSearch Back to all articles Product AutoOps for Elasticsearch Community Tools Tools for the Community Company About Our Customers info@opster.com Resources Documentation Blog Guides Elasticsearch Error Messages Elasticsearch Log Errors Taking Care of Your Entire Search Operation. Opster\\u2019s solutions reduce the time and cost of running Elasticsearch. Get Improved performance & stability with less hardware. Contact Us \\u00a9 2025 Opster Privacy Policy Terms of Use We use cookies to ensure that we give you the best experience on our website. By continuing to browse this site, you agree to our Privacy Policy and Terms of Use. Agree Close GDPR Cookie Settings Privacy Overview Strictly Necessary Cookies Powered by GDPR Cookie Compliance Privacy Overview This website uses cookies so that we can provide you with the best user experience possible. Cookie information is stored in your browser and performs functions such as recognising you when you return to our website and helping our team to understand which sections of the website you find most interesting and useful. Strictly Necessary Cookies Strictly Necessary Cookie should be enabled at all times so that we can save your preferences for cookie settings. Enable or Disable Cookies Enabled Disabled Enable All Save Settings\\\"},{\\\"url\\\":\\\"https://docs.opensearch.org/latest/im-plugin/index-templates/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Regular expression syntax Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Using UBI in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Index templates Index templates let you initialize new indexes with predefined mappings and settings. For example, if you continuously index log data, you can define an index template so that all of these indexes have the same number of shards and replicas. Create a template To create an index template, use a PUT or POST request: PUT _index_template/<template name>\\\\nPOST _index_template/<template name>\\\\n This command creates a template named daily_logs and applies it to any new index whose name matches the pattern logs-2020-01-* and also adds it to the my_logs alias: PUT _index_template/daily_logs\\\\n{\\\\n  \\\\\\\"index_patterns\\\\\\\": [\\\\n    \\\\\\\"logs-2020-01-*\\\\\\\"\\\\n  ],\\\\n  \\\\\\\"template\\\\\\\": {\\\\n    \\\\\\\"aliases\\\\\\\": {\\\\n      \\\\\\\"my_logs\\\\\\\": {}\\\\n    },\\\\n    \\\\\\\"settings\\\\\\\": {\\\\n      \\\\\\\"number_of_shards\\\\\\\": 2,\\\\n      \\\\\\\"number_of_replicas\\\\\\\": 1\\\\n    },\\\\n    \\\\\\\"mappings\\\\\\\": {\\\\n      \\\\\\\"properties\\\\\\\": {\\\\n        \\\\\\\"timestamp\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"date\\\\\\\",\\\\n          \\\\\\\"format\\\\\\\": \\\\\\\"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\\\\\\\"\\\\n        },\\\\n        \\\\\\\"value\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"double\\\\\\\"\\\\n        }\\\\n      }\\\\n    }\\\\n  }\\\\n}\\\\n You should see the following response: {\\\\n  \\\\\\\"acknowledged\\\\\\\": true\\\\n}\\\\n If you create an index named logs-2020-01-01, you can see that it has the mappings and settings from the template: PUT logs-2020-01-01\\\\nGET logs-2020-01-01\\\\n {\\\\n  \\\\\\\"logs-2020-01-01\\\\\\\": {\\\\n    \\\\\\\"aliases\\\\\\\": {\\\\n      \\\\\\\"my_logs\\\\\\\": {}\\\\n    },\\\\n    \\\\\\\"mappings\\\\\\\": {\\\\n      \\\\\\\"properties\\\\\\\": {\\\\n        \\\\\\\"timestamp\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"date\\\\\\\",\\\\n          \\\\\\\"format\\\\\\\": \\\\\\\"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\\\\\\\"\\\\n        },\\\\n        \\\\\\\"value\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"double\\\\\\\"\\\\n        }\\\\n      }\\\\n    },\\\\n    \\\\\\\"settings\\\\\\\": {\\\\n      \\\\\\\"index\\\\\\\": {\\\\n        \\\\\\\"creation_date\\\\\\\": \\\\\\\"1578107970779\\\\\\\",\\\\n        \\\\\\\"number_of_shards\\\\\\\": \\\\\\\"2\\\\\\\",\\\\n        \\\\\\\"number_of_replicas\\\\\\\": \\\\\\\"1\\\\\\\",\\\\n        \\\\\\\"uuid\\\\\\\": \\\\\\\"U1vMDMOHSAuS2IzPcPHpOA\\\\\\\",\\\\n        \\\\\\\"version\\\\\\\": {\\\\n          \\\\\\\"created\\\\\\\": \\\\\\\"7010199\\\\\\\"\\\\n        },\\\\n        \\\\\\\"provided_name\\\\\\\": \\\\\\\"logs-2020-01-01\\\\\\\"\\\\n      }\\\\n    }\\\\n  }\\\\n}\\\\n Any additional indexes that match this pattern\\u2014logs-2020-01-02, logs-2020-01-03, and so on\\u2014will inherit the same mappings and settings. Index patterns cannot contain any of the following characters: :, \\\\\\\", +, /, \\\\\\\\, |, ?, #, >, and <. Retrieve a template To list all index templates: GET _cat/templates\\\\nGET /_index_template\\\\n To find a template by its name: GET _index_template/daily_logs\\\\n To get a list of all templates that match a pattern: GET _index_template/daily*\\\\n To check if a specific template exists: HEAD _index_template/<name>\\\\n Configure multiple templates You can create multiple index templates for your indexes. If the index name matches more than one template, OpenSearch takes the mappings and settings from the template with the highest priority and applies it to the index. For example, say you have the following two templates that both match the logs-2020-01-02 index and there\\u2019s a conflict in the number_of_shards field: Template 1 PUT _index_template/template-01\\\\n{\\\\n  \\\\\\\"index_patterns\\\\\\\": [\\\\n    \\\\\\\"logs*\\\\\\\"\\\\n  ],\\\\n  \\\\\\\"priority\\\\\\\": 0,\\\\n  \\\\\\\"template\\\\\\\": {\\\\n    \\\\\\\"settings\\\\\\\": {\\\\n      \\\\\\\"number_of_shards\\\\\\\": 2,\\\\n      \\\\\\\"number_of_replicas\\\\\\\": 2\\\\n    }\\\\n  }\\\\n}\\\\n Template 2 PUT _index_template/template-02\\\\n{\\\\n  \\\\\\\"index_patterns\\\\\\\": [\\\\n    \\\\\\\"logs-2020-01-*\\\\\\\"\\\\n  ],\\\\n  \\\\\\\"priority\\\\\\\": 1,\\\\n  \\\\\\\"template\\\\\\\": {\\\\n    \\\\\\\"settings\\\\\\\": {\\\\n      \\\\\\\"number_of_shards\\\\\\\": 3\\\\n    }\\\\n  }\\\\n}\\\\n Because template-02 has a higher priority value, it takes precedence over template-01 . The logs-2020-01-02 index would have the number_of_shards value as 3 and the number_of_replicas as the default value 1. Delete a template You can delete an index template using its name: DELETE _index_template/daily_logs\\\\n Composable index templates Managing multiple index templates has the following challenges: If you have duplication between index templates, storing these index templates results in a bigger cluster state. If you want to make a change across all your index templates, you have to manually make the change for each template. You can use composable index templates to overcome these challenges. Composable index templates let you abstract common settings, mappings, and aliases into a reusable building block called a component template. You can combine component templates to compose an index template. Settings and mappings that you specify directly in the create index request override any settings or mappings specified in an index template and its component templates. Create a component template Let\\u2019s define two component templates\\u2060\\u2014component_template_1 and component_template_2: Component template 1 PUT _component_template/component_template_1\\\\n{\\\\n  \\\\\\\"template\\\\\\\": {\\\\n    \\\\\\\"mappings\\\\\\\": {\\\\n      \\\\\\\"properties\\\\\\\": {\\\\n        \\\\\\\"@timestamp\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"date\\\\\\\"\\\\n        }\\\\n      }\\\\n    }\\\\n  }\\\\n}\\\\n Component template 2 PUT _component_template/component_template_2\\\\n{\\\\n  \\\\\\\"template\\\\\\\": {\\\\n    \\\\\\\"mappings\\\\\\\": {\\\\n      \\\\\\\"properties\\\\\\\": {\\\\n        \\\\\\\"ip_address\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"ip\\\\\\\"\\\\n        }\\\\n      }\\\\n    }\\\\n  }\\\\n}\\\\n Use component templates to create an index template When creating index templates, you need to include the component templates in a composed_of list. OpenSearch applies the component templates in the order in which you specify them within the index template. The settings, mappings, and aliases that you specify inside the index template are applied last. PUT _index_template/daily_logs\\\\n{\\\\n  \\\\\\\"index_patterns\\\\\\\": [\\\\n    \\\\\\\"logs-2020-01-*\\\\\\\"\\\\n  ],\\\\n  \\\\\\\"template\\\\\\\": {\\\\n    \\\\\\\"aliases\\\\\\\": {\\\\n      \\\\\\\"my_logs\\\\\\\": {}\\\\n    },\\\\n    \\\\\\\"settings\\\\\\\": {\\\\n      \\\\\\\"number_of_shards\\\\\\\": 2,\\\\n      \\\\\\\"number_of_replicas\\\\\\\": 1\\\\n    },\\\\n    \\\\\\\"mappings\\\\\\\": {\\\\n      \\\\\\\"properties\\\\\\\": {\\\\n        \\\\\\\"timestamp\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"date\\\\\\\",\\\\n          \\\\\\\"format\\\\\\\": \\\\\\\"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\\\\\\\"\\\\n        },\\\\n        \\\\\\\"value\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"double\\\\\\\"\\\\n        }\\\\n      }\\\\n    }\\\\n  },\\\\n  \\\\\\\"priority\\\\\\\": 200,\\\\n  \\\\\\\"composed_of\\\\\\\": [\\\\n    \\\\\\\"component_template_1\\\\\\\",\\\\n    \\\\\\\"component_template_2\\\\\\\"\\\\n  ],\\\\n  \\\\\\\"version\\\\\\\": 3,\\\\n  \\\\\\\"_meta\\\\\\\": {\\\\n    \\\\\\\"description\\\\\\\": \\\\\\\"using component templates\\\\\\\"\\\\n  }\\\\n}\\\\n If you create an index named logs-2020-01-01, you can see that it derives its mappings and settings from both the component templates: PUT logs-2020-01-01\\\\nGET logs-2020-01-01\\\\n Example response {\\\\n  \\\\\\\"logs-2020-01-01\\\\\\\": {\\\\n    \\\\\\\"aliases\\\\\\\": {\\\\n      \\\\\\\"my_logs\\\\\\\": {}\\\\n    },\\\\n    \\\\\\\"mappings\\\\\\\": {\\\\n      \\\\\\\"properties\\\\\\\": {\\\\n        \\\\\\\"@timestamp\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"date\\\\\\\"\\\\n        },\\\\n        \\\\\\\"ip_address\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"ip\\\\\\\"\\\\n        },\\\\n        \\\\\\\"timestamp\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"date\\\\\\\",\\\\n          \\\\\\\"format\\\\\\\": \\\\\\\"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\\\\\\\"\\\\n        },\\\\n        \\\\\\\"value\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"double\\\\\\\"\\\\n        }\\\\n      }\\\\n    },\\\\n    \\\\\\\"settings\\\\\\\": {\\\\n      \\\\\\\"index\\\\\\\": {\\\\n        \\\\\\\"creation_date\\\\\\\": \\\\\\\"1625382479459\\\\\\\",\\\\n        \\\\\\\"number_of_shards\\\\\\\": \\\\\\\"2\\\\\\\",\\\\n        \\\\\\\"number_of_replicas\\\\\\\": \\\\\\\"1\\\\\\\",\\\\n        \\\\\\\"uuid\\\\\\\": \\\\\\\"rYUlpOXDSUSuZifQLPfa5A\\\\\\\",\\\\n        \\\\\\\"version\\\\\\\": {\\\\n          \\\\\\\"created\\\\\\\": \\\\\\\"7100299\\\\\\\"\\\\n        },\\\\n        \\\\\\\"provided_name\\\\\\\": \\\\\\\"logs-2020-01-01\\\\\\\"\\\\n      }\\\\n    }\\\\n  }\\\\n}\\\\n Index template options You can specify the following template options: Option Type Description Required template Object Specify index settings, mappings, and aliases. No priority Integer The priority of the index template. No composed_of String array The names of component templates applied on a new index together with the current template. No version Integer Specify a version number to simplify template management. Default is null. No _meta Object Specify meta information about the template. No Create a template Retrieve a template Configure multiple templates Delete a template Create a component template Use component templates to create an index template WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright \\u00a9 OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\\\"},{\\\"url\\\":\\\"https://stackoverflow.com/questions/71816340/how-to-create-an-index-pattern-in-opensearch-using-api\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to main content Stack Overflow About Products For Teams Stack Overflow for Teams Where developers & technologists share private knowledge with coworkers Advertising Reach devs & technologists worldwide about your product, service or employer brand Knowledge Solutions Data licensing offering for businesses to build and improve AI tools and models Labs The future of collective knowledge sharing About the company Visit the blog Loading\\u2026 current community Stack Overflow help chat Meta Stack Overflow your communities Sign up or log in to customize your list. more stack exchange communities company blog Log in Sign up Home Questions AI Assist Labs Tags Challenges Chat Articles Users Jobs Companies Collectives Communities for your favorite technologies. Explore all Collectives Teams Ask questions, find answers and collaborate at work with Stack Overflow for Teams. Try Teams for free Explore Teams Teams Ask questions, find answers and collaborate at work with Stack Overflow for Teams. Explore Teams Collectives\\u2122 on Stack Overflow Find centralized, trusted content and collaborate around the technologies you use most. Learn more about Collectives Teams Q&A for work Connect and share knowledge within a single location that is structured and easy to search. Learn more about Teams How to create an index pattern in Opensearch using API? Ask Question Asked 3 years, 7 months ago Modified 11 months ago Viewed 15k times Part of AWS Collective 5 I want to create an index pattern using Opensearch API. I tried to replicate what could be made graphically in the following image window, using as index pattern name cwl-* and then as time field @timestamp. My domain has OpenSearch 1.2 installed. Using curl (directly modifiend the command in kibana doc): curl -u '****:*****' -X POST \\\\\\\"https://******.eu-central-1.es.amazonaws.com/api/index_patterns/index_pattern\\\\\\\" -H 'osd-xsrf: true' -H 'Content-Type: application/json' -d'\\\\n{\\\\n  \\\\\\\"index_pattern\\\\\\\": {\\\\n     \\\\\\\"title\\\\\\\": \\\\\\\"cwl-*\\\\\\\",\\\\n     \\\\\\\"timeFieldName\\\\\\\": \\\\\\\"@timestamp\\\\\\\"\\\\n  }\\\\n}'\\\\n but I receive {\\\\\\\"error\\\\\\\":{\\\\\\\"root_cause\\\\\\\":[{\\\\\\\"type\\\\\\\":\\\\\\\"illegal_argument_exception\\\\\\\",\\\\\\\"reason\\\\\\\":\\\\\\\"Rejecting mapping update to [api] as the final mapping would have more than 1 type: [_doc, index_patterns]\\\\\\\"}],\\\\\\\"type\\\\\\\":\\\\\\\"illegal_argument_exception\\\\\\\",\\\\\\\"reason\\\\\\\":\\\\\\\"Rejecting mapping update to [api] as the final mapping would have more than 1 type: [_doc, index_patterns]\\\\\\\"},\\\\\\\"status\\\\\\\":400}\\\\n amazon-web-services shell aws-elasticsearch opensearch Share Improve this question Follow edited Apr 10, 2022 at 17:50 asked Apr 10, 2022 at 11:54 Dresult 30311 gold badge22 silver badges1212 bronze badges 9 Are you using any sort of IAM authentication? Ermiya Eskandary \\u2013 Ermiya Eskandary 2022-04-10 15:58:49 +00:00 Commented Apr 10, 2022 at 15:58 @ErmiyaEskandary just the Fine-grained access control but it works because I don't have any problem in performing other requests... Dresult \\u2013 Dresult 2022-04-10 16:01:55 +00:00 Commented Apr 10, 2022 at 16:01 Ahhhhhh - remove saved_objects from your URL. Ermiya Eskandary \\u2013 Ermiya Eskandary 2022-04-10 16:10:33 +00:00 Commented Apr 10, 2022 at 16:10 @ErmiyaEskandary Unfortunately I had already tried, it says {\\\\\\\"statusCode\\\\\\\":404,\\\\\\\"error\\\\\\\":\\\\\\\"Not Found\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Not Found\\\\\\\"} Dresult \\u2013 Dresult 2022-04-10 16:13:39 +00:00 Commented Apr 10, 2022 at 16:13 Your URL is somehow wrong - I don't have docs in front of me right now but try removing _dashboards from the URL and if that doesn't work, also remove api Ermiya Eskandary \\u2013 Ermiya Eskandary 2022-04-10 16:17:22 +00:00 Commented Apr 10, 2022 at 16:17 | Show 4 more comments 3 Answers 3 Sorted by: Reset to default Highest score (default) Trending (recent votes count more) Date modified (newest first) Date created (oldest first) 3 Tested with the latest OpenSearch version 2.18.0. To simply create an index pattern via the API, a POST request should be used:     curl -XPOST \\\\\\\"http://localhost:5601/api/saved_objects/index-pattern\\\\\\\" \\\\\\\\\\\\n-u \\\\\\\"user:pass\\\\\\\" \\\\\\\\\\\\n-H 'osd-xsrf: true' \\\\\\\\\\\\n-H 'Content-Type: application/json' \\\\\\\\\\\\n-d ' \\\\n{\\\\n  \\\\\\\"attributes\\\\\\\": {\\\\n    \\\\\\\"title\\\\\\\": \\\\\\\"pattern-*\\\\\\\",\\\\n    \\\\\\\"timeFieldName\\\\\\\": \\\\\\\"@timestamp\\\\\\\"\\\\n  }\\\\n}'\\\\n If you want to create an OpenSearch index pattern with a specific ID, you can generate it or copy it from another source (in my case, I copied the ID of the missing pattern from the broken Dashboard) and include it as part of the request: curl -XPOST \\\\\\\"http://localhost:5601/api/saved_objects/index-pattern/90bd9a00-ad57-41a0-b16a-b134a8c51e98\\\\\\\" \\\\\\\\\\\\n-u \\\\\\\"user:pass\\\\\\\" \\\\\\\\\\\\n-H 'osd-xsrf: true' \\\\\\\\\\\\n-H 'Content-Type: application/json' \\\\\\\\\\\\n-d ' \\\\n{\\\\n  \\\\\\\"attributes\\\\\\\": {\\\\n    \\\\\\\"title\\\\\\\": \\\\\\\"pattern-*\\\\\\\",\\\\n    \\\\\\\"timeFieldName\\\\\\\": \\\\\\\"@timestamp\\\\\\\"\\\\n  }\\\\n}'\\\\n If you need to update existing index pattern, a PUT request should be used, with existing ID: curl -XPUT \\\\\\\"http://localhost:5601/api/saved_objects/index-pattern/90bd9a00-ad57-41a0-b16a-b134a8c51e98\\\\\\\" \\\\\\\\\\\\n-u \\\\\\\"user:pass\\\\\\\" \\\\\\\\\\\\n-H 'osd-xsrf: true' \\\\\\\\\\\\n-H 'Content-Type: application/json' \\\\\\\\\\\\n-d ' \\\\n{\\\\n  \\\\\\\"attributes\\\\\\\": {\\\\n    \\\\\\\"title\\\\\\\": \\\\\\\"pattern-*\\\\\\\",\\\\n    \\\\\\\"timeFieldName\\\\\\\": \\\\\\\"@timestamp\\\\\\\"\\\\n  }\\\\n}'\\\\n Share Improve this answer Follow answered Nov 26, 2024 at 21:35 nmishin 3,20255 gold badges2222 silver badges3737 bronze badges Sign up to request clarification or add additional context in comments. Comments Add a comment 1 curl -u '****:*****' -X POST \\\\\\\"https://******.eu-central-1.es.amazonaws.com/api/index_patterns/cwl-*\\\\\\\" -H 'osd-xsrf: true' -H 'Content-Type: application/json' -d'\\\\n{\\\\n  \\\\\\\"index_pattern\\\\\\\": {\\\\n     \\\\\\\"title\\\\\\\": \\\\\\\"cwl-*\\\\\\\",\\\\n     \\\\\\\"timeFieldName\\\\\\\": \\\\\\\"@timestamp\\\\\\\"\\\\n  }\\\\n}'\\\\n change api/index_patterns/index_pattern to api/index_patterns/cwl-* and try again? Share Improve this answer Follow answered Apr 14, 2022 at 8:33 doge76 2122 bronze badges 4 Comments Add a comment Dresult Dresult Over a year ago It works in a sense that the command creates something but I cannot see anything among saved objects and seams that in this way only an index which name is \\\\\\\"api\\\\\\\" is created not an index pattern therefore each time I access the dashboard, once it finds data, it ask me if I want to create it. 2022-04-15T11:15:21.423Z+00:00 0 Reply Copy link doge76 doge76 Over a year ago if you want the index-pattern to be global, try to add this attribute in header: securitytenant: \\\\\\\"global\\\\\\\"? 2022-04-15T12:03:44.13Z+00:00 0 Reply Copy link Dresult Dresult Over a year ago already done, I've added -H 'securitytenant: global' to the curl string 2022-04-15T13:56:58.873Z+00:00 0 Reply Copy link Kasami Kasami Over a year ago @Dresult Did you ever manage to figure this out? I am encountering the same issue, it seems. 2022-10-10T22:50:32.3Z+00:00 2 Reply Copy link Add a comment 0 It worked for me in OpenSearch 1.3 when I added an ID in the URI and used saved_objects instead of index_patterns. So your cURL-request should work when looking like this. curl -u '****:*****' -X POST \\\\\\\"https://<opensearch-dashboards-host>.eu-central-1.es.amazonaws.com/api/saved_objects/index-pattern/<ID>\\\\\\\" \\\\n-H 'osd-xsrf: true' \\\\n-H 'Content-Type: application/json' \\\\n-d \\\\n   '{\\\\n      \\\\\\\"index_pattern\\\\\\\": {\\\\n         \\\\\\\"title\\\\\\\": \\\\\\\"cwl-*\\\\\\\",\\\\n         \\\\\\\"timeFieldName\\\\\\\": \\\\\\\"@timestamp\\\\\\\"\\\\n      }\\\\n    }'\\\\n Share Improve this answer Follow edited Dec 16, 2022 at 13:09 answered Aug 25, 2022 at 8:51 mgr110 111 bronze badge 3 Comments Add a comment K.Thanvi K.Thanvi Over a year ago I am getting no handler found for uri [/api/saved_objects/index-pattern/cwl-*] and method [POST] error for this.. using opensearch1.3. 2022-12-14T17:09:27.72Z+00:00 0 Reply Copy link mgr110 mgr110 Over a year ago @K.Thanvi This is probably because you are sending the request to the OpenSearch-host. The request is meant to be sent to the OpenSearch Dashboards-host (or Kibana-host if you use that). Using the Dev Tools will send the request to the OpenSearch-host. 2022-12-15T11:44:04.903Z+00:00 1 Reply Copy link K.Thanvi K.Thanvi Over a year ago Thanks! Yes that was the issue. i had to send the request to my <opensearch_domain>/_dashboards/api/saved_objects/index-pattern endpoint. 2023-01-09T17:07:40.23Z+00:00 1 Reply Copy link Add a comment Your Answer Thanks for contributing an answer to Stack Overflow! Please be sure to answer the question. Provide details and share your research! But avoid \\u2026 Asking for help, clarification, or responding to other answers. Making statements based on opinion; back them up with references or personal experience. To learn more, see our tips on writing great answers. Draft saved Draft discarded Sign up or log in Sign up using Google Sign up using Email and Password Submit Post as a guest Name Email Required, but never shown Post as a guest Name Email Required, but never shown Post Your Answer Discard By clicking \\u201cPost Your Answer\\u201d, you agree to our terms of service and acknowledge you have read our privacy policy. Start asking to get answers Find the answer to your question by asking. Ask question Explore related questions amazon-web-services shell aws-elasticsearch opensearch See similar questions with these tags. AWS Collective See more This question is in a collective: a subcommunity defined by tags with relevant content and experts. The Overflow Blog The AI ick Revealing the unknown unknowns in your software Featured on Meta Results of the October 2025 Community Asks Sprint: copy button for code... Chat room owners can now establish room guidelines Policy: Generative AI (e.g., ChatGPT) is banned Opinion-based questions alpha experiment on Stack Overflow Related 1 Create Index - Elastic Search - Java API 14 Create index in Elastic Search by Java API 0 How to do an automated index creation at ElasticSearch? 21 How to configure index pattern in Kibana 2 How does one create an Index Pattern in Kibana? 3 Is there API based method to create an index pattern in Kibana if its index is present in ES 0 How to create new index pattern with custom pattern ID from the elastic API? 1 How to create Index pattern using API and Index Name 0 How to create an ElasticSearch Index as curl 0 How to create index pattern in elastic seach programmatically Hot Network Questions What is the earliest work of SF to mention a concern about time travel causing unintended space travel Why do we chase after things which make us happy? When did Soviet industrial planners start tooling for tank production? Shall I change my supervisor, who is nearing retirement? Sum of a sequence What is the most humane way to kill humans for meat? Is it possible to increase the rotation of a black hole without increasing the mass? Check whether saddle point or not What is a \\\\\\\"Squitchen\\\\\\\"? Urysohn's Lemma with compact sets and uniformly continuous function Why does John 2:13 mention Passover as a Jewish festival? Necessity of `typename` for naming of local nested classes in function templates how to make tar stop after reading or listing a few first files from a big tarball? how to pull with the hinge How to reply to \\\\\\\"How are you?\\\\\\\" How to replace wood strip part of threshold? Bracket covers sum limits using mathclap environment Agatha Christie - Hercule Poirot short story or novel Should I kill a companion or would that be frowned upon at the table? Why do we still say \\u201cIt is gone\\u201d but not \\u201cYou are come\\u201d? Hat-trick is for three, what's the word for four consecutive successes? How do I enable File and Printer sharing in latest Windows 11 InsertOnlyHashSet in C++ What is the correct orientation of the connecting tab on a bathroom sink stopper? more hot questions Question feed Subscribe to RSS Question feed To subscribe to this RSS feed, copy and paste this URL into your RSS reader. lang-bash Stack Overflow Questions Help Chat Products Teams Advertising Talent Company About Press Work Here Legal Privacy Policy Terms of Service Contact Us Your Privacy Choices Cookie Policy Stack Exchange Network Technology Culture & recreation Life & arts Science Professional Business API Data Blog Facebook Twitter LinkedIn Instagram Site design / logo \\u00a9 2025 Stack Exchange Inc; user contributions licensed under CC BY-SA . rev 2025.11.7.36544\\\"},{\\\"url\\\":\\\"https://docs.opensearch.org/latest/dashboards/management/management-index/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Regular expression syntax Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Using UBI in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Dashboards Management Introduced 2.10 Dashboards Management is the central hub for managing and customizing OpenSearch data directly within OpenSearch Dashboards. OpenSearch and OpenSearch Dashboards permissions govern access to individual features. If you do not have the appropriate access permissions, consult your administrator. Applications You can access the following applications in Dashboards Management: Index Patterns: To access OpenSearch data, you need to create an index pattern so that you can select the data you want to use and define the properties of the fields. The Index Pattern tool gives you the ability to create an index pattern from within the UI. Index patterns point to one or more indexes, data streams, or index aliases. Data Sources: The Data Sources tool is used to configure and manage the data sources that OpenSearch uses to collect and analyze data. You can use the tool to specify the source configuration in your copy of the OpenSearch Dashboards configuration file. Saved Objects: The Saved Objects tool helps you organize and manage your saved objects. Saved objects are files that store data, such as dashboards, visualizations, and maps, for later use. Advanced Settings: The Advanced Settings tool gives you the flexibility to personalize the behavior of OpenSearch Dashboards. The tool is divided into settings sections, such as General, Accessibility, and Notifications, and you can use it to customize and optimize many of your Dashboards settings. Related documentation Index patterns Advanced settings Access control lists for saved objects Applications WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright \\u00a9 OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\\\"},{\\\"url\\\":\\\"https://docs.opensearch.org/latest/api-reference/index-apis/create-index/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Regular expression syntax Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Using UBI in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Index APIs Core index APIs Create index Create Index API Introduced 1.0 While you can create an index by using a document as a base, you can also create an empty index for later use. When creating an index, you can specify its mappings, settings, and aliases. Endpoints PUT <index>\\\\n Index naming restrictions OpenSearch indexes have the following naming restrictions: All letters must be lowercase. Index names can\\u2019t begin with underscores (_) or hyphens (-). Index names can\\u2019t contain spaces, commas, or the following characters: :, \\\\\\\", *, +, /, \\\\\\\\, |, ?, #, >, or < Path parameters Parameter Data type Description index String The index name. Must conform to the index naming restrictions. Required. Query parameters You can include the following query parameters in your request. All parameters are optional. Parameter Type Description wait_for_active_shards String Specifies the number of active shards that must be available before OpenSearch processes the request. Default is 1 (only the primary shard). Set to all or a positive integer. Values greater than 1 require replicas. For example, if you specify a value of 3, the index must have two replicas distributed across two additional nodes for the request to succeed. cluster_manager_timeout Time How long to wait for a connection to the cluster manager node. Default is 30s. timeout Time How long to wait for the request to return. Default is 30s. Request body As part of your request, you can optionally specify index settings, mappings, aliases, and index context. Example request REST Python PUT /sample-index1\\\\n{\\\\n  \\\\\\\"settings\\\\\\\": {\\\\n    \\\\\\\"index\\\\\\\": {\\\\n      \\\\\\\"number_of_shards\\\\\\\": 2,\\\\n      \\\\\\\"number_of_replicas\\\\\\\": 1\\\\n    }\\\\n  },\\\\n  \\\\\\\"mappings\\\\\\\": {\\\\n    \\\\\\\"properties\\\\\\\": {\\\\n      \\\\\\\"age\\\\\\\": {\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"integer\\\\\\\"\\\\n      }\\\\n    }\\\\n  },\\\\n  \\\\\\\"aliases\\\\\\\": {\\\\n    \\\\\\\"sample-alias1\\\\\\\": {}\\\\n  }\\\\n} Copy Copy as cURL response = client.indices.create(\\\\n  index = \\\\\\\"sample-index1\\\\\\\",\\\\n  body =   {\\\\n    \\\\\\\"settings\\\\\\\": {\\\\n      \\\\\\\"index\\\\\\\": {\\\\n        \\\\\\\"number_of_shards\\\\\\\": 2,\\\\n        \\\\\\\"number_of_replicas\\\\\\\": 1\\\\n      }\\\\n    },\\\\n    \\\\\\\"mappings\\\\\\\": {\\\\n      \\\\\\\"properties\\\\\\\": {\\\\n        \\\\\\\"age\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"integer\\\\\\\"\\\\n        }\\\\n      }\\\\n    },\\\\n    \\\\\\\"aliases\\\\\\\": {\\\\n      \\\\\\\"sample-alias1\\\\\\\": {}\\\\n    }\\\\n  }\\\\n) Copy Endpoints Index naming restrictions Path parameters Query parameters Request body Example request WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright \\u00a9 OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\\\"}]}\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Search for OpenSearch documentation\n",
    "parameters = {\n",
    "    \"question\": \"How to create an index pattern in OpenSearch?\"\n",
    "}\n",
    "\n",
    "print(\"‚ùì Question: How to create an index pattern in OpenSearch?\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "response = execute_agent(client, agent_id, parameters)\n",
    "\n",
    "print(\"\\nüåê Web Search Results:\")\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b75e24",
   "metadata": {},
   "source": [
    "## Formatting the output - Markdown\n",
    "- One result content out of many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3478713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# üìÑ OpenSearch Index Pattern Guide\n",
       "\n",
       "## Overview\n",
       "Index patterns are essential for accessing OpenSearch data. They reference one or more indexes, data streams, or index aliases.\n",
       "\n",
       "## Step 1: 1: Define the index pattern Go to OpenSearch Dashboards, and select Management > Dashboards Management > Index patterns\n",
       "Select Create index pattern. From the Create index pattern window, define the index pattern by entering a name for your index pattern in the Index pattern name field. Dashboards automatically adds a wildcard, *, once you start typing. Using a wildcard is helpful for matching an index pattern to multiple sources or indexes. A dropdown list displaying all the indexes that match your index pattern appears when you start typing. Select Next step. An example of step 1 is shown in the following image. Note that the index pattern security* matches three indexes. By defining the pattern with a wildcard *, you can query and visualize all the data in your indexes. \n",
       "\n",
       "## Step 2: 2: Configure the settings Select @timestamp from the dropdown menu to specify the time field for OpenSearch to use when filtering documents based on time\n",
       "Selecting this time filter determines which field the time filter is applied to. It can be the timestamp of a request or any relevant timestamp field. If you don‚Äôt want to use a time filter, select that option from the dropdown menu. If you select this option, OpenSearch returns all of the data in the indexes that match the pattern. Select Create index pattern. An example is shown in the following image. Once the index pattern has been created, you can view the mapping of the matching indexes. Within the table, you can see the list of fields, along with their data type and properties. An example is shown in the following image. Next steps Understand your data through visuals. Dig into your data. Get started Prerequisites Best practices Creating an index pattern \n",
       "\n",
       "## Step 4: 2: Configure the settings Next steps WAS THIS PAGE HELPFUL? ‚úî Yes ‚úñ No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum\n",
       "Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright ¬© OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import JSON, display, HTML, Markdown\n",
    "\n",
    "result1 = json.loads(response['inference_results'][0]['output'][0]['result'])['items'][0]['content']\n",
    "\n",
    "# Extract key sections from the content\n",
    "sections = result1.split('Step ')\n",
    "\n",
    "# Create formatted output\n",
    "output = \"# üìÑ OpenSearch Index Pattern Guide\\n\\n\"\n",
    "\n",
    "# Add introduction\n",
    "output += \"## Overview\\n\"\n",
    "output += \"Index patterns are essential for accessing OpenSearch data. They reference one or more indexes, data streams, or index aliases.\\n\\n\"\n",
    "\n",
    "# Parse and format the steps\n",
    "for i, section in enumerate(sections[1:], 1):\n",
    "    lines = section.split('. ', 1)\n",
    "    if len(lines) > 1:\n",
    "        output += f\"## Step {i}: {lines[0]}\\n\"\n",
    "        output += f\"{lines[1]}\\n\\n\"\n",
    "\n",
    "# Display as markdown\n",
    "display(Markdown(output))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3cb3ebc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# üåê All Web Search Results\n",
       "\n",
       "**Total Results:** 10  \n",
       "**Query:** How to create an index pattern in OpenSearch?\n",
       "\n",
       "---\n",
       "\n",
       "## Result 1: Link Search Menu Expand Document Documentation Menu\n",
       "\n",
       "**üîó Source:** [https://docs.opensearch.org/latest/dashboards/management/index-patterns/](https://docs.opensearch.org/latest/dashboards/management/index-patterns/)\n",
       "\n",
       "**Overview:**\n",
       "Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards ‚Üê Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Regular expression syntax Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Using UBI in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Dashboards Management Index patterns Index patterns Index patterns are essential for accessing OpenSearch data. An index pattern references one or more indexes, data streams, or index aliases. For example, an index pattern can point you to your log data from yesterday or all indexes that contain that data. If you store data in multiple indexes, creating an index pattern enables your visualizations to retrieve data from all indexes that match the index pattern. You need to create index patterns to define how data is retrieved and fields are formatted so that you can query, search, and display data. Get started In this tutorial, you‚Äôll learn to create index patterns. Note To create or modify index patterns, you must have create, manage, and delete permissions. Contact your administrator for support. For more information, refer to Multi-tenancy configuration. Prerequisites Before you can create an index pattern, your data must be indexed. To learn about indexing your data in OpenSearch, see Managing indexes. Best practices Consider the following best practices when creating index patterns: Make your index patterns specific. Instead of creating an index pattern that matches all indexes, create an index pattern that matches all indexes starting with a certain prefix, for example, my-index-. The more specific your index patterns, the better it will be to query and analyze your data. Use wildcards sparingly. Wildcards can be useful for matching multiple indexes, but they can also make it more difficult to manage your index patterns. Try to use wildcards as specifically as possible. Test your index patterns. Make sure to test your index patterns to ensure that they match the correct indexes. Creating an index pattern If you added sample data, you have index patterns that you can use to analyze that data. To create an index pattern for your own data, follow these steps.\n",
       "\n",
       "### Step 1: 1: Define the index pattern Go to OpenSearch Dashboards, and select Management > Dashboards Management > Index patterns\n",
       "Select Create index pattern. From the Create index pattern window, define the index pattern by entering a name for your index pattern in the Index pattern name field. Dashboards automatically adds a wildcard, *, once you start typing. Using a wildcard is helpful for matching an index pattern to multiple sources or indexes. A dropdown list displaying all the indexes that match your index pattern appears when you start typing. Select Next step. An example of step 1 is shown in the following image. Note that the index pattern security* matches three indexes. By defining the pattern with a wildcard *, you can query and visualize all the data in your indexes. \n",
       "\n",
       "### Step 2: 2: Configure the settings Select @timestamp from the dropdown menu to specify the time field for OpenSearch to use when filtering documents based on time\n",
       "Selecting this time filter determines which field the time filter is applied to. It can be the timestamp of a request or any relevant timestamp field. If you don‚Äôt want to use a time filter, select that option from the dropdown menu. If you select this option, OpenSearch returns all of the data in the indexes that match the pattern. Select Create index pattern. An example is shown in the following image. Once the index pattern has been created, you can view the mapping of the matching indexes. Within the table, you can see the list of fields, along with their data type and properties. An example is shown in the following image. Next steps Understand your data through visuals. Dig into your data. Get started Prerequisites Best practices Creating an index pattern \n",
       "\n",
       "1: Define the index pattern\n",
       "\n",
       "### Step 4: 2: Configure the settings Next steps WAS THIS PAGE HELPFUL? ‚úî Yes ‚úñ No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum\n",
       "Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright ¬© OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\n",
       "\n",
       "---\n",
       "\n",
       "## Result 2: \n",
       "\n",
       "**üîó Source:** [https://repost.aws/knowledge-center/opensearch-index-pattern](https://repost.aws/knowledge-center/opensearch-index-pattern)\n",
       "\n",
       "**Overview:**\n",
       "Skip to content By using AWS re:Post, you agree to the AWS re:Post Terms of Use re:Post Search About re:Post English EnglishDeutschEspa√±olFran√ßaisItalianoÊó•Êú¨Ë™ûÌïúÍµ≠Ïñ¥Portugu√™s‰∏≠Êñá (ÁÆÄ‰Ωì)‰∏≠Êñá (ÁπÅÈ´î) Resources Sign in Home Questions Knowledge Center Articles Selections Tags Topics Community Groups AWS Support Official AWS Trust & Safety Center Ask question / How do I create an index pattern in my OpenSearch Service cluster?lg.../ How do I create an index pattern in my OpenSearch Service cluster? 5 minute read 1 I want to create an index pattern in my Amazon OpenSearch Service cluster. Resolution Prerequisites: The AWS Identity and Access Management (IAM) user must have PUT and POST permissions to create an index pattern. Example access policy: {  \"Version\": \"2012-10-17\",\n",
       "  \"Statement\": [\n",
       "    {\n",
       "      \"Sid\": \"VisualEditor0\",\n",
       "      \"Effect\": \"Allow\",\n",
       "      \"Action\": [\n",
       "        \"es:ESHttpHead\",\n",
       "        \"es:ESHttpPost\",\n",
       "        \"es:ESHttpGet\",\n",
       "        \"es:ESHttpDelete\",\n",
       "        \"es:ESHttpPut\"\n",
       "      ],\n",
       "      \"Resource\": \"arn:aws:es:region:account-id:domain/domain-name/*\"\n",
       "    }\n",
       "  ]\n",
       "} Note: Replace region with your AWS Region, account-id with your AWS account, and domain-name with your domain name. Your cluster version must allow index patterns. Create the index pattern Use OpenSearch Dashboards You can use OpenSearch Dashboards to create an index pattern for OpenSearch Service or Elasticsearch clusters with or without fine-grained access control. For instructions, see Creating an index pattern on the OpenSearch website. Use curl commands To create an index pattern for clusters without fine-grained access control, run the following command based on the cluster type. Elasticsearch clusters: curl -X POST  https://elasticsearch-end-point/_plugin/kibana/api/saved_objects/index-pattern/ \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "\n",
       "-H \"content-type: application/json\" \\\n",
       "\n",
       "-d '{ \"attributes\": { \"title\": \"sample-index*\" } }' Note: Replace sample-index with your index name or pattern. OpenSearch Service clusters: curl -X POST  https://opensearch-end-point/_dashboards/api/saved_objects/index-pattern/ \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "\n",
       "-H \"content-type: application/json\" \\\n",
       "\n",
       "-d '{ \"attributes\": { \"title\": \"sample-index*\" } }' Note: Replace sample-index with your index name or pattern. For clusters with fine-grained access control, complete the following steps: To generate authorization cookies in the auth.txt file, run the following command based on the cluster type. Elasticsearch clusters: curl -X POST  https://elasticsearch-end-point/_plugin/kibana/auth/login  \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "-H \"content-type: application/json\" \\\n",
       "-d '{\"username\":\"usernameexample\", \"password\":\"passwordexample\"}' \\\n",
       "-c auth.txt Note: Replace usernameexample with your username and passwordexample with your password. OpenSearch Service clusters: curl -X POST  https://opensearch-end-point/_dashboards/auth/login  \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "-H \"content-type: application/json\" \\\n",
       "-d '{\"username\":\"usernameexample\", \"password\":\"passwordexample\"}' \\\n",
       "-c auth.txt Note: Replace usernameexample with your username and passwordexample with your password. To submit the index pattern creation request, run the following command based on your cluster type: Elasticsearch clusters: curl -X POST  https://elasticsearch-end-point/_plugin/kibana/api/saved_objects/index-pattern/test  \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "-H \"content-type: application/json\" \\\n",
       "-d '{ \"attributes\": { \"title\": \"sample-index*\" } }' \\\n",
       "-b auth.txt Note: Replace sample-index with your index name or pattern. OpenSearch Service clusters: curl -X POST  https://opensearch-end-point/_dashboards/api/saved_objects/index-pattern/  \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "-H \"content-type: application/json\" \\\n",
       "-d '{ \"attributes\": { \"title\": \"sample-index*\" } }' \\\n",
       "-b auth.txt Note: Replace sample-index with your index name or pattern. Use Python Prerequisites: Map the role that runs the Python code to the backend role for fine-grained access control clusters. Run the following commands to install the required dependencies: pip install boto3\n",
       "pip install opensearch-py\n",
       "pip install requests\n",
       "pip install requests-aws4auth Run the following Python command to create the index pattern for OpenSearch Service clusters: import boto3\n",
       "import requests\n",
       "from requests_aws4auth import AWS4Auth\n",
       "\n",
       "host = 'https://domain-endpoint/' # include trailing /\n",
       "region = 'aos-region' # example us-west-1\n",
       "service = 'es'\n",
       "credentials = boto3.Session().get_credentials()\n",
       "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)\n",
       "\n",
       "\n",
       "path = '_dashboards/api/saved_objects/index-pattern' # _plugin/kibana/api/saved_objects/index-pattern for es versions\n",
       "url = host + path\n",
       "payload = {\"attributes\":{\"title\":\"multi-logs-*\",\"fields\":\"[]\"}}\n",
       "headers = {\"Content-Type\": \"application/json\", \"osd-xsrf\": \"true\", \"security_tenant\": \"global\" }\n",
       "r = requests.post (url, auth=awsauth, json=payload, headers=headers)\n",
       "print(r.status_code)\n",
       "print(r.text) Note: Replace domain-endpoint with your domain endpoint, and aos-region with your Region. For Elasticsearch clusters, replace _dashboards/api/saved_objects/index-pattern with _plugin/kibana/api/saved_objects/index-pattern. Troubleshoot index pattern creation issues You use fine-grained access control with SAML 2.0 or Amazon Cognito authentication If the domain for your cluster uses SAML 2.0 or Amazon Cognito for authentication, then create an internal user to manage the index pattern. Note: For clusters where you activated fine-grained access control, the user must have ESHttpPut and ESHttpPost permissions to create an index pattern. You can't create the index pattern in the Global tenant By default, OpenSearch Dashboards creates index patterns under the Global tenant. To create an index pattern outside of the Global tenant, run the following command: curl -s -X POST https://opensearch-end-point/_dashboards/api/saved_objects/index-pattern/sample-index -d '{\"attributes\": {\"title\": \"sample-index*\"}}' \\\n",
       "-H \"osd-xsrf:true\" \\\n",
       "-H \"securitytenant: private\" \\\n",
       "-H \"content-type:application/json\" \\\n",
       "-b auth.txt Note: Replace sample-index with your index name or pattern. You didn't include the .kibana alias in the cluster To troubleshoot this issue, complete the following steps: To check whether the .kibana alias exists in the cluster, run the following command: curl -XGET https://opensearch-end-point/_cat/aliases Note: For clusters with fine-grained access control, include the -u flag with your username and password. Example command: curl -XPOST -u 'master-user:master-user-password' 'domain-endpoint/_cat/indices If the .kibana index doesn't exist, then proceed to step 4. To create a backup of .kibana index, run the following command: curl -XPOST \"https://domain-endpoint/_reindex\" -H 'Content-Type: application/json' -d'{\n",
       "  \"source\": {\n",
       "    \"index\": \".kibana\"\n",
       "  },\n",
       "  \"dest\": {\n",
       " \"index\": \".kibana_backup\"\n",
       "  }\n",
       "}' Note: Replace domain-endpoint with your domain endpoint. For clusters with fine-grained access control, include the -u flag with your username and password. To delete the .kibana index, run the following command: curl -XDELETE \"https://domain-endpoint/.kibana\" Note: Replace domain-endpoint with your domain endpoint. For clusters with fine-grained access control, include the -u flag with your username and password. To create a .kibana alias and point it to the .kibana_backup index, run the following command: curl -XPOST \"https://domain-endpoint/_aliases\" -H 'Content-Type: application/json' -d'{\n",
       "  \"actions\": [\n",
       "    {\n",
       "      \"add\": {\n",
       "        \"index\": \".kibana_backup\",\n",
       "        \"alias\": \".kibana\"\n",
       "      }\n",
       "    }\n",
       "  ]\n",
       "}' Note: Replace domain-endpoint with your domain endpoint. For clusters with fine-grained access control, include the -u flag with your username and password. Related information Export and import Kibana dashboards with OpenSearch Service Why does the rollover index action in my ISM policy keep failing in OpenSearch Service? Follow Share Topics Analytics Tags Amazon OpenSearch Service Language English Related videos Watch Sujata's video to learn more (3:59) AWS OFFICIALUpdated 3 months ago 2 Comments This can also be done using basic auth using session object without signing the request if that is the use case. [+] Session Object = https://requests.readthedocs.io/en/latest/user/advanced/#session-objects #! /bin/python3\n",
       "import requests\n",
       "host = 'https://<domain_endpoint_ending_with_slash>/'\n",
       "path = '_dashboards/auth/login'\n",
       "region = 'us-east-1'\n",
       "url = host + path;\n",
       "# Set headers as mentioned. Here we will create index pattern in global tenant hence the value is global\n",
       "headers = {\"Content-Type\": \"application/json\",\"kbn-xsrf\": \"true\",\"osd-xsrf\":\"true\",\"security_tenant\":\"global\"};\n",
       "payload = {\n",
       " \"username\":\"username\",\n",
       "    \"password\":\"password\"\n",
       "}\n",
       "\n",
       "#Creating a session because requests wont store the cookie\n",
       "\n",
       "session=requests.Session();\n",
       "\n",
       "r=session.post(url,headers=headers,json=payload);\n",
       "# You can skip these lines with print. Basically the above line will do a post request with my credentials and will create a cookie and will store it\n",
       "print(r.text);\n",
       "print(r.status_code);\n",
       "\n",
       "# title is the name of my index pattern\n",
       "\n",
       "payload={\n",
       "\"attributes\": { \"title\": \"random*\" } \n",
       "\n",
       "}\n",
       "\n",
       "path=\"_dashboards/api/saved_objects/index-pattern/random*\";\n",
       "url=host+path;\n",
       "\n",
       "#Changed the path variable to the one which is mentioned above. Notice the end of the URL, my index pattern name will be random*\n",
       "\n",
       "r=session.post(url,headers=headers,json=payload);\n",
       "\n",
       "print(r.text);\n",
       "print(r.status_code);\n",
       "session.close();\n",
       " Share rePost-User-6420587 replied 2 years ago Thank you for your comment. We'll review and update the Knowledge Center article as needed. Share MODERATOR AWS Official replied 2 years ago Comment on this article Clear Post comment Relevant content Got an error \"Request Entity Too Large\" when creating index pattern in AWS Opensearch soop_minjaeoh asked a year ago How to create and configure an Open Search Serverless index via API? Zach asked 9 months ago OpenSearch Dashboards Index Pattern and Discover issues mdkail asked 4 years ago Index is not created inside the Amazon OpenSearch cluster Accepted Answer stratosb asked 2 years ago Access denied (403) when creating an index in OpenSearch Serverless. AlwaysLearning asked 2 years ago Why does the rollover index action in my ISM policy fail in OpenSearch Service? AWS OFFICIALUpdated a month ago Why can't I delete an index or upgrade my OpenSearch Service cluster? AWS OFFICIALUpdated a year ago How do I resolve the 403 \"index_create_block_exception\" or \"cluster_block_exception\" error in OpenSearch Service? AWS OFFICIALUpdated 3 years ago How do I use ISM to manage low storage space in Amazon OpenSearch Service? AWS OFFICIALUpdated 2 months ago How to combine ISM policy actions to control shard size EXPERT Sherin Chandy published a year ago FEEDBACK Privacy| Site Terms| Cookie Preferences | Sitemap| Legal| ¬© 2025, Amazon Web Services, Inc. or its affiliates. All rights reserved. Community Guidelines\n",
       "\n",
       "---\n",
       "\n",
       "## Result 3: \n",
       "\n",
       "**üîó Source:** [https://www.youtube.com/watch?v=pbABIerUYQI](https://www.youtube.com/watch?v=pbABIerUYQI)\n",
       "\n",
       "**Overview:**\n",
       "AboutPressCopyrightContact usCreatorsAdvertiseDevelopersTermsPrivacyPolicy & SafetyHow YouTube worksTest new featuresNFL Sunday Ticket ¬© 2025 Google LLC\n",
       "\n",
       "---\n",
       "\n",
       "## Result 4: \n",
       "\n",
       "**üîó Source:** [https://github.com/fidelity-contributions/opensearch-project-opensearch-py/blob/main/guides/index_template.md](https://github.com/fidelity-contributions/opensearch-project-opensearch-py/blob/main/guides/index_template.md)\n",
       "\n",
       "**Overview:**\n",
       "Skip to content Navigation Menu Toggle navigation Sign in Appearance settings Platform AI CODE CREATION GitHub CopilotWrite better code with AI GitHub SparkBuild and deploy intelligent apps GitHub ModelsManage and compare prompts MCP RegistryNewDiscover and integrate external tools DEVELOPER WORKFLOWS ActionsAutomate any workflow CodespacesInstant dev environments IssuesPlan and track work Code ReviewManage code changes APPLICATION SECURITY GitHub Advanced SecurityFind and fix vulnerabilities Code securitySecure your code as you build Secret protectionStop leaks before they start EXPLORE Why GitHub Documentation Blog Changelog Marketplace View all features Solutions BY COMPANY SIZE Enterprises Small and medium teams Startups Nonprofits BY USE CASE App Modernization DevSecOps DevOps CI/CD View all use cases BY INDUSTRY Healthcare Financial services Manufacturing Government View all industries View all solutions Resources EXPLORE BY TOPIC AI Software Development DevOps Security View all topics EXPLORE BY TYPE Customer stories Events & webinars Ebooks & reports Business insights GitHub Skills SUPPORT & SERVICES Documentation Customer support Community forum Trust center Partners Open Source COMMUNITY GitHub SponsorsFund open source developers PROGRAMS Security Lab Maintainer Community Accelerator Archive Program REPOSITORIES Topics Trending Collections Enterprise ENTERPRISE SOLUTIONS Enterprise platformAI-powered developer platform AVAILABLE ADD-ONS GitHub Advanced SecurityEnterprise-grade security features Copilot for BusinessEnterprise-grade AI features Premium SupportEnterprise-grade 24/7 support Pricing Search or jump to... Search code, repositories, users, issues, pull requests... Search Clear Search syntax tips Provide feedback We read every piece of feedback, and take your input very seriously. Include my email address so I can be contacted Cancel Submit feedback Saved searches Use saved searches to filter your results more quickly Name Query To see all available qualifiers, see our documentation. Cancel Create saved search Sign in Sign up Appearance settings Resetting focus You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert {{ message }} fidelity-contributions / opensearch-project-opensearch-py Public forked from opensearch-project/opensearch-py Notifications You must be signed in to change notification settings Fork 0 Star 0 Code Pull requests 0 Security Uh oh! There was an error while loading. Please reload this page. Insights Additional navigation options Code Pull requests Security Insights Footer ¬© 2025 GitHub, Inc. Footer navigation Terms Privacy Security Status Community Docs Contact Manage cookies Do not share my personal information You can‚Äôt perform that action at this time.\n",
       "\n",
       "---\n",
       "\n",
       "## Result 5: \n",
       "\n",
       "**üîó Source:** [https://deepwiki.com/johnny-chivers/amazon-opensearch-service/3.1-index-patterns](https://deepwiki.com/johnny-chivers/amazon-opensearch-service/3.1-index-patterns)\n",
       "\n",
       "**Overview:**\n",
       "Index your code with Devin DeepWiki DeepWiki johnny-chivers/amazon-opensearch-service Index your code with Devin Edit Wiki Share Last indexed: 25 May 2025 (924181) Overview Getting Started Tutorial Domain Setup Data Upload and Indexing Search Operations Cleanup and Domain Deletion Index Management Index Patterns Field Configuration Security and Access Control Access Control Systems Access Policies System Architecture Data Node Architecture Network Configuration Development and Testing Menu Index Patterns Relevant source files pictures/12-define-index-pattern.png pictures/13-createe-index-pattern.png Purpose and Scope This document covers the creation and configuration of index patterns in Amazon OpenSearch Service, specifically focusing on how they enable data discovery and visualization through the OpenSearch Dashboards interface. Index patterns define how OpenSearch Dashboards connects to and interprets the data stored in your OpenSearch indices. This guide specifically covers the index pattern workflow for the movies dataset used in the tutorial. For information about the underlying index field configuration and data types, see Field Configuration. For the broader context of data upload and indexing operations, see Data Upload and Indexing. Overview of Index Patterns Index patterns in OpenSearch Dashboards serve as a bridge between raw index data and the visualization layer. They define which indices contain the data you want to explore and specify how that data should be interpreted for search and analysis operations. In the context of this tutorial, index patterns enable access to the movies index that contains the bulk movie dataset from bulk_movies.json. Sources: Based on tutorial workflow and OpenSearch Dashboards architecture patterns. Index Pattern Creation Workflow The index pattern creation process follows a specific sequence within the OpenSearch Dashboards interface, as documented in the tutorial screenshots. Sources: Tutorial workflow sequence and OpenSearch Dashboards interface patterns. Pattern Definition and Configuration Index patterns use wildcard matching to identify which indices they should include. For the movies dataset, the pattern typically follows this structure: Pattern Element Purpose Example Index Name Base index identifier movies Wildcard Pattern matching movies* Time Field Timestamp field for time-based data Not applicable for movies dataset Field Discovery Automatic field detection Enabled The pattern configuration process involves several key steps: Sources: OpenSearch Dashboards index pattern creation workflow and field detection mechanisms. Field Mapping and Data Types Once an index pattern is created, OpenSearch Dashboards automatically discovers and maps the fields from the underlying movies index. This process examines the data structure from the documents uploaded via bulk_movies.json. The field mapping process identifies several categories of data: Field Category Examples from Movies Data OpenSearch Type Text Fields title, director, genre text or keyword Numeric Fields year, rating integer or float Date Fields release_date date Boolean Fields available boolean Sources: OpenSearch field mapping documentation and movies dataset structure analysis. Integration with Discovery Interface Index patterns enable the Discover interface to provide search and exploration capabilities across the movie dataset. The integration allows for both simple and complex query operations. The discovery workflow leverages the index pattern to: Field-based Filtering: Use detected fields for creating search filters Time-based Navigation: Handle temporal data if time fields are configured Aggregation Operations: Support grouping and statistical operations Export Functionality: Enable data export based on search results Sources: OpenSearch Dashboards Discover interface capabilities and query processing architecture. Pattern Management and Maintenance Index patterns require ongoing management as data structures evolve. The tutorial demonstrates basic pattern creation, but production environments often need pattern updates and field refresh operations. Key maintenance operations include: Field Refresh: Update field mappings when new fields are added to indices Pattern Modification: Adjust pattern matching rules for new indices Performance Optimization: Configure field settings for optimal query performance Access Control: Manage pattern visibility and permissions The movies dataset provides a stable example for learning these concepts, as the data structure remains consistent throughout the tutorial workflow. Sources: OpenSearch index pattern management best practices and tutorial documentation structure. Dismiss Refresh this wiki Enter email to refresh On this page Index Patterns Purpose and Scope Overview of Index Patterns Index Pattern Creation Workflow Pattern Definition and Configuration Field Mapping and Data Types Integration with Discovery Interface Pattern Management and Maintenance\n",
       "\n",
       "---\n",
       "\n",
       "## Result 6: \n",
       "\n",
       "**üîó Source:** [https://opster.com/guides/opensearch/opensearch-data-architecture/index-templating-in-opensearch-how-to-use-composable-templates/](https://opster.com/guides/opensearch/opensearch-data-architecture/index-templating-in-opensearch-how-to-use-composable-templates/)\n",
       "\n",
       "**Overview:**\n",
       "Product BUILT FOR ELASTICSEARCH AutoOps Prevent & resolve issues, cut down administration time & hardware costs. Community Tools Tools For The Community Check-Up, Search Log Analyzer & OpsGPT Resources Guides Technical guides on Elasticsearch & Opensearch Blog Insights, Opster news, blogs and more Documentation Opster product documentation Error Messages Error Repository About About Our story & vision Login AutoOps Login Contact Login Contact Running self-managed Elasticsearch just got easier. Announcing AutoOps for your clusters. Read the announcement üéâüéâ Opensearch Guides > OpenSearch Data Architecture Elasticsearch Index Templates in OpenSearch ‚Äì How to Use Composable Templates By Opster Expert Team Updated: Jun 28, 2023 | 6 min read Quick links Overview ‚Äì mapping, settings and aliases Index templates ‚Äì composable templates and component templates How to create composable index templates Creating an index Creating component templates Template priority Precedence of templates Summary The source code for this article is available here. Overview An OpenSearch index can be configured through mapping, settings and aliases: Mapping definitions specify the data schema. Settings will set the shard sizing and refresh rates. Aliases are used to give the index alternate names. When we index a document for the first time or create an empty index using the Create Index API, the index will be created with default settings, without data schema and without aliases. These defaults work pretty well in development and testing environments, but we may need to customize our indices for production environments. Working with the default mappings and settings in production might result in poor indexing and search performance. Instantiating indices manually is a tedious and time consuming process. Recreating such indices on every environment is especially impractical if we have an elaborate mapping schema as well as customized settings and aliases. Fortunately, OpenSearch provides us with a tool to automatically apply a predefined configuration when creating indices in the form of index templates. Index templates Index templates allow us to create indices with user defined configuration. An index can pull the configuration from these templates, for example a set number of shards and replicas or field mappings, during its instantiation. A template will be defined with a name pattern and some configuration in it. If the name of the index matches the template‚Äôs naming pattern, the new index will be created with the configuration defined in the template. Types of templates Index templates can be classified into two categories: Index templates (or composabale index templates): The composable index templates can either exist on their own, or can be composed of none or more component templates (see the second category). Component templates: The component template is a reusable template on its own that defines the required configuration. Usually the component template is expected to be associated with an index template. Each of the component templates can be attached with one or many index templates. As you can see in the image below, the index templates A and B share component templates (in this case just one ‚Äì Template 3) between themselves. An index template can consist of none or many component templates and each of the component templates can be associated with none or many index templates. Both types of templates can exist on their own, however component templates are of no use unless they are attached to an index template. The general idea is to develop a catalogue of component templates for an organization to use for various needs (for example, specifying the various component templates for individual environments) and attach them to various indices via the composable index templates. How to create composable (index) templates OpenSearch provides an _index_template endpoint for managing index templates. The user provides all the required mappings, settings, and aliases along with an index name pattern in this template. Let‚Äôs run through an example of creating a template for a microservice application customer-order-service which is responsible for order generation logic. Let‚Äôs say our requirement is to create a template for customer orders, represented with a pattern having wildcards: *orders. This template is expected to have certain mappings and settings, such as the order_date field, as well as shards and replica numbers. Any index that gets matched with this template during its creation inherits the configurations defined in this template. For example a black_friday_orders index will have the order_date field, shards will be set to 5 and the replicas set to 2. In addition to this, all indices created from this template inherit a single alias name, too!Let‚Äôs create this orders_template with an index pattern defined as *orders and with a mapping schema consisting of a single oder_date field with a predefined date format dd-MM-yyyy. The code below shows how to create this index template. PUT _index_template/orders_template\n",
       "{\n",
       "  \"index_patterns\": [\"*orders\"],\n",
       "  \"priority\": 300,\n",
       "  \"template\": {\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"order_date\": {\n",
       "          \"type\": \"date\",\n",
       "          \"format\":\"dd-MM-yyyy\"\n",
       "        }\n",
       "      }\n",
       "    },\n",
       "    \"settings\":{\n",
       "      \"number_of_shards\":5,\n",
       "      \"number_of_replicas\":2\n",
       "    },\n",
       "    \"aliases\":{\n",
       "      \"all_orders\":{}\n",
       "    }\n",
       "  }\n",
       "} When you execute this query in Kibana‚Äôs DevTools, the template is created with the index pattern *orders along with the predefined mapping, settings and an alias. The index_patterns is an array of match patterns; any index matching this pattern will be deriving the template configuration. You can execute the following to retrieve the persisted template that should reiterate what we did: GET _index_template/orders_template There‚Äôs also a priority, a positive number, defined when creating the template attribute defined on the template: every template is defined with a priority so that any conflicting changes from different templates will be resolved by using this value with precedence given to the higher priority value. We‚Äôll dive more deeply into template priority below. Creating an index with the template Now we have a template ‚Äì a blueprint for creating indices ‚Äì the next step is to create an index. When the name of the index matches with the given pattern, the templated configurations are applied automatically. To prove the point, as the code below shows, let‚Äôs create a brand new index named: blackfriday_orders: PUT blackfriday_orders As the name of the index (blackfriday_orders) matches with the naming pattern defined in template (i.e. *orders), the index should get all the configuration derived from the template. Let‚Äôs retrieve this freshly created index and check if this is indeed true by executing the following code: GET blackfriday_orders This should return: {\n",
       "  \"blackfriday_orders\" : {\n",
       "    \"aliases\" : {\n",
       "      \"all_orders\" : { }\n",
       "    },\n",
       "    \"mappings\" : {\n",
       "      \"properties\" : {\n",
       "        \"order_date\" : {\n",
       "          \"type\" : \"date\",\n",
       "          \"format\" : \"dd-MM-yyyy\"\n",
       "        }\n",
       "      }\n",
       "    },\n",
       "    \"settings\" : {\n",
       "      \"index\" : {\n",
       "         ...\n",
       "        \"number_of_shards\" : \"5\",\n",
       "        \"number_of_replicas\" : \"2\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "} As the response indicates, the configuration of the blackfriday_orders has been inherited from the template. We can try with various combinations of the indices that will successfully inherit the templated configuration: PUT blackfriday_orders\n",
       "PUT americaorders\n",
       "PUT cancelled--orders\n",
       "PUT undefined101orders However, the following indices will not be inheriting the configuration as the name will not match with the pattern: PUT blackfriday_orders2\n",
       "PUT open_orders_\n",
       "PUT allorders_total One important thing to remember is that all the indices derived from a template have the same alias ‚Äì all_orders ‚Äì in this case. There is an advantage of having such alias ‚Äì we can simply query on this single alias rather than multiple indices. GET blackfriday_orders,americaorders,undefined101orders/_search\n",
       "GET all_orders/_search \n",
       "{\n",
       "  \"query\": {\n",
       "    \"range\": {\n",
       "      \"order_date\": {\n",
       "        \"gte\": \"01-12-2021\",\n",
       "        \"lte\": \"31-12-2021\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "} While we create a template for *orders, any matching index is expected to adopt the template configuration. Usually, knowingly or unknowingly, teams may create a few more templates for various reasons. This means that at times the index name may match two different template patterns! OpenSearch has to decide which of the configurations from those templates it needs to apply. Fortunately, this dilemma can be solved by using the template priority. Creating component templates We learned about index templates in the earlier part of this article. There are a couple of disadvantages of creating the templates with the configuration built in ‚Äì one such disadvantage being that the configuration is not exportable for other templates. If we wish to have similar configuration, say for customer related templates (*customers), we may have to re-create the whole template. That means, we may be creating dozens of them in a typical organization (plus you may have a few more based on the environments). As we always look forward to reusability, OpenSearch redesigned the templates keeping reusability in mind. The component templates fit that bill. If you are from a DevOps background, most likely you‚Äôd have a requirement to create indices with a preset configuration for each of the environments. Rather than tediously applying each of these configurations manually, you can create a component template for each of the environments. A component template is nothing but a reusable block of configurations that we can use to make up more index templates. Do note that the component templates are of no value unless they are clubbed with index templates. They are exposed via a _component_template endpoint. Let‚Äôs see how this all fits together. Settings template Let‚Äôs extract the settings we defined in our index template earlier and create a component template out of it. The settings_component_template is expected to have five primary shards with two replicas per primary shard. The first step, as the code listing below shows, is to declare and execute a component template with this configuration. PUT _component_template/settings_component_template\n",
       "{\n",
       "  \"template\":{\n",
       "    \"settings\":{\n",
       "      \"number_of_shards\":5,\n",
       "      \"number_of_replicas\":2\n",
       "    }\n",
       "  }\n",
       "} As the code above shows, we use the _component_template endpoint to create a component template. The body of the request holds the template information in a template object. The settings_component_template is now available for use elsewhere in the index templates. One notable difference is that this template does not define any index pattern; it‚Äôs simply a code block that configures some properties for us. Mappings template In the same way, let‚Äôs create another template. This time, let‚Äôs extract the mapping schema we had defined earlier in the standalone index templates. The code below shows the script: PUT _component_template/mappings_component_template\n",
       "{\n",
       "  \"template\": {\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"order_date\": {\n",
       "          \"type\": \"date\",\n",
       "          \"format\":\"dd-MM-yyyy\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "} Aliases template Going with the same flow, we can also have a component template with the aliases ‚Äì two aliases (all_orders and sales_orders): PUT _component_template/aliases_component_template\n",
       "{\n",
       "  \"template\": {\n",
       "    \"aliases\": {\n",
       "      \"all_orders\": {},\n",
       "      \"sales_orders\":{}\n",
       "    }\n",
       "  }\n",
       "} Composable index template Now that we have these three component templates, the next step is to put them to use. We can do this by letting an index template for, say christmas_orders, use it: PUT _index_template/composed_orders_template\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"*orders\"\n",
       "  ],\n",
       "  \"priority\": 500,\n",
       "  \"composed_of\": [\n",
       "    \"settings_component_template\",\n",
       "    \"mappings_component_template\",\n",
       "    \"aliases_component_template\"\n",
       "  ]\n",
       "} The composed_of tag is a collection of all the component templates that make up this template. In this case, we are choosing the settings, mappings and aliases component templates. We are also bumping up the priority so this template trumps any others. Once the template is ready, any indices that match the *orders pattern will inherit the configuration from these three component templates. Having said that, should we wish to create a new template, say customers, with just one of the existing (settings_component_template) and a newly created aliases (aliases_component_template ‚Äì see below) template, we can do so with: PUT _component_template/aliases_component_template2\n",
       "{\n",
       "  \"template\": {\n",
       "    \"aliases\": {\n",
       "      \"all_customers\": {}\n",
       "    }\n",
       "  }\n",
       "} The index template goes like this: PUT _index_template/composed_customers_template\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"*customers*\"\n",
       "  ],\n",
       "  \"priority\": 200,\n",
       "  \"composed_of\": [\n",
       "    \"settings_component_template\",\n",
       "    \"aliases_component_template2\"\n",
       "  ]\n",
       "} Did you see that the settings_component_template has been (re)used across two different templates? That is the power of component templates. Template priority There is a chance that developers may create multiple index templates without looking at the existing stock. It is important to set a priority on each of these templates so the one with higher priority will be used. For example, the my_orders_template_1 overrides the my_orders_template_2 in the following code snippet: PUT _index_template/my_orders_template_1\n",
       "{\n",
       "  \"index_patterns\": [\"*orders\"],\n",
       "  \"priority\": 1000,\n",
       "  \"template\": { ... }\n",
       "}\n",
       "PUT _index_template/my_orders_template2\n",
       "{\n",
       "  \"index_patterns\": [\"*orders\"],\n",
       "  \"priority\": 300,\n",
       "  \"template\": { ... }\n",
       "} When you have multiple templates matching the indices that are being created, OpenSearch applies all the configurations from all matching templates but overrides anything that has higher priority. Precedence of templates Finally, you may be wondering about the precedence of the templates ‚Äì does the configuration defined in the component template override the one defined on the main index template itself? Or the other way around? Well, there are some rules: An index created with configurations explicitly takes precedence over everything ‚Äì this means if you create an index with explicit configuration, don‚Äôt expect them to be overridden by the templates. Summary An index contains mappings, settings and aliases: the mappings define the fields schema, settings set the index parameters such as number of shards and replicas, and aliases give alternate names to the index. Templates allow us to create indices with predefined configurations. Naming an index with a name that matches the index-pattern defined in a specific template will automatically configure that index according to the template. The composable templates consist of none or more component templates. An index template can have its own configuration defined too. A component template is a reusable template with predefined configuration, just like a composable index template. However, component templates are expected to be part of an index template; They are useless if they are not ‚Äúcomposed‚Äù into an index template. Component templates have no index pattern defined in them ‚Äì which is another reason they are ‚Äúexpected‚Äù to be part of an index template. Each of the templates has a priority ‚Äì a positive number. The higher the number, the greater the precedence for that template to be applied. Related Articles 3 Pagination Techniques in Elasticsearch Elasticsearch Large Cluster State - How to Discover & Prevent Backblaze Optimized OpenSearch Back to all articles Product AutoOps for Elasticsearch Community Tools Tools for the Community Company About Our Customers info@opster.com Resources Documentation Blog Guides Elasticsearch Error Messages Elasticsearch Log Errors Taking Care of Your Entire Search Operation. Opster‚Äôs solutions reduce the time and cost of running Elasticsearch. Get Improved performance & stability with less hardware. Contact Us ¬© 2025 Opster Privacy Policy Terms of Use We use cookies to ensure that we give you the best experience on our website. By continuing to browse this site, you agree to our Privacy Policy and Terms of Use. Agree Close GDPR Cookie Settings Privacy Overview Strictly Necessary Cookies Powered by GDPR Cookie Compliance Privacy Overview This website uses cookies so that we can provide you with the best user experience possible. Cookie information is stored in your browser and performs functions such as recognising you when you return to our website and helping our team to understand which sections of the website you find most interesting and useful. Strictly Necessary Cookies Strictly Necessary Cookie should be enabled at all times so that we can save your preferences for cookie settings. Enable or Disable Cookies Enabled Disabled Enable All Save Settings\n",
       "\n",
       "---\n",
       "\n",
       "## Result 7: Link Search Menu Expand Document Documentation Menu\n",
       "\n",
       "**üîó Source:** [https://docs.opensearch.org/latest/im-plugin/index-templates/](https://docs.opensearch.org/latest/im-plugin/index-templates/)\n",
       "\n",
       "**Overview:**\n",
       "Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards ‚Üê Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Regular expression syntax Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Using UBI in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Index templates Index templates let you initialize new indexes with predefined mappings and settings. For example, if you continuously index log data, you can define an index template so that all of these indexes have the same number of shards and replicas. Create a template To create an index template, use a PUT or POST request: PUT _index_template/<template name>\n",
       "POST _index_template/<template name>\n",
       " This command creates a template named daily_logs and applies it to any new index whose name matches the pattern logs-2020-01-* and also adds it to the my_logs alias: PUT _index_template/daily_logs\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"logs-2020-01-*\"\n",
       "  ],\n",
       "  \"template\": {\n",
       "    \"aliases\": {\n",
       "      \"my_logs\": {}\n",
       "    },\n",
       "    \"settings\": {\n",
       "      \"number_of_shards\": 2,\n",
       "      \"number_of_replicas\": 1\n",
       "    },\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"timestamp\": {\n",
       "          \"type\": \"date\",\n",
       "          \"format\": \"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\"\n",
       "        },\n",
       "        \"value\": {\n",
       "          \"type\": \"double\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       " You should see the following response: {\n",
       "  \"acknowledged\": true\n",
       "}\n",
       " If you create an index named logs-2020-01-01, you can see that it has the mappings and settings from the template: PUT logs-2020-01-01\n",
       "GET logs-2020-01-01\n",
       " {\n",
       "  \"logs-2020-01-01\": {\n",
       "    \"aliases\": {\n",
       "      \"my_logs\": {}\n",
       "    },\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"timestamp\": {\n",
       "          \"type\": \"date\",\n",
       "          \"format\": \"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\"\n",
       "        },\n",
       "        \"value\": {\n",
       "          \"type\": \"double\"\n",
       "        }\n",
       "      }\n",
       "    },\n",
       "    \"settings\": {\n",
       "      \"index\": {\n",
       "        \"creation_date\": \"1578107970779\",\n",
       "        \"number_of_shards\": \"2\",\n",
       "        \"number_of_replicas\": \"1\",\n",
       "        \"uuid\": \"U1vMDMOHSAuS2IzPcPHpOA\",\n",
       "        \"version\": {\n",
       "          \"created\": \"7010199\"\n",
       "        },\n",
       "        \"provided_name\": \"logs-2020-01-01\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Any additional indexes that match this pattern‚Äîlogs-2020-01-02, logs-2020-01-03, and so on‚Äîwill inherit the same mappings and settings. Index patterns cannot contain any of the following characters: :, \", +, /, \\, |, ?, #, >, and <. Retrieve a template To list all index templates: GET _cat/templates\n",
       "GET /_index_template\n",
       " To find a template by its name: GET _index_template/daily_logs\n",
       " To get a list of all templates that match a pattern: GET _index_template/daily*\n",
       " To check if a specific template exists: HEAD _index_template/<name>\n",
       " Configure multiple templates You can create multiple index templates for your indexes. If the index name matches more than one template, OpenSearch takes the mappings and settings from the template with the highest priority and applies it to the index. For example, say you have the following two templates that both match the logs-2020-01-02 index and there‚Äôs a conflict in the number_of_shards field: Template 1 PUT _index_template/template-01\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"logs*\"\n",
       "  ],\n",
       "  \"priority\": 0,\n",
       "  \"template\": {\n",
       "    \"settings\": {\n",
       "      \"number_of_shards\": 2,\n",
       "      \"number_of_replicas\": 2\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Template 2 PUT _index_template/template-02\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"logs-2020-01-*\"\n",
       "  ],\n",
       "  \"priority\": 1,\n",
       "  \"template\": {\n",
       "    \"settings\": {\n",
       "      \"number_of_shards\": 3\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Because template-02 has a higher priority value, it takes precedence over template-01 . The logs-2020-01-02 index would have the number_of_shards value as 3 and the number_of_replicas as the default value 1. Delete a template You can delete an index template using its name: DELETE _index_template/daily_logs\n",
       " Composable index templates Managing multiple index templates has the following challenges: If you have duplication between index templates, storing these index templates results in a bigger cluster state. If you want to make a change across all your index templates, you have to manually make the change for each template. You can use composable index templates to overcome these challenges. Composable index templates let you abstract common settings, mappings, and aliases into a reusable building block called a component template. You can combine component templates to compose an index template. Settings and mappings that you specify directly in the create index request override any settings or mappings specified in an index template and its component templates. Create a component template Let‚Äôs define two component templates‚Å†‚Äîcomponent_template_1 and component_template_2: Component template 1 PUT _component_template/component_template_1\n",
       "{\n",
       "  \"template\": {\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"@timestamp\": {\n",
       "          \"type\": \"date\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Component template 2 PUT _component_template/component_template_2\n",
       "{\n",
       "  \"template\": {\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"ip_address\": {\n",
       "          \"type\": \"ip\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Use component templates to create an index template When creating index templates, you need to include the component templates in a composed_of list. OpenSearch applies the component templates in the order in which you specify them within the index template. The settings, mappings, and aliases that you specify inside the index template are applied last. PUT _index_template/daily_logs\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"logs-2020-01-*\"\n",
       "  ],\n",
       "  \"template\": {\n",
       "    \"aliases\": {\n",
       "      \"my_logs\": {}\n",
       "    },\n",
       "    \"settings\": {\n",
       "      \"number_of_shards\": 2,\n",
       "      \"number_of_replicas\": 1\n",
       "    },\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"timestamp\": {\n",
       "          \"type\": \"date\",\n",
       "          \"format\": \"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\"\n",
       "        },\n",
       "        \"value\": {\n",
       "          \"type\": \"double\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  },\n",
       "  \"priority\": 200,\n",
       "  \"composed_of\": [\n",
       "    \"component_template_1\",\n",
       "    \"component_template_2\"\n",
       "  ],\n",
       "  \"version\": 3,\n",
       "  \"_meta\": {\n",
       "    \"description\": \"using component templates\"\n",
       "  }\n",
       "}\n",
       " If you create an index named logs-2020-01-01, you can see that it derives its mappings and settings from both the component templates: PUT logs-2020-01-01\n",
       "GET logs-2020-01-01\n",
       " Example response {\n",
       "  \"logs-2020-01-01\": {\n",
       "    \"aliases\": {\n",
       "      \"my_logs\": {}\n",
       "    },\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"@timestamp\": {\n",
       "          \"type\": \"date\"\n",
       "        },\n",
       "        \"ip_address\": {\n",
       "          \"type\": \"ip\"\n",
       "        },\n",
       "        \"timestamp\": {\n",
       "          \"type\": \"date\",\n",
       "          \"format\": \"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\"\n",
       "        },\n",
       "        \"value\": {\n",
       "          \"type\": \"double\"\n",
       "        }\n",
       "      }\n",
       "    },\n",
       "    \"settings\": {\n",
       "      \"index\": {\n",
       "        \"creation_date\": \"1625382479459\",\n",
       "        \"number_of_shards\": \"2\",\n",
       "        \"number_of_replicas\": \"1\",\n",
       "        \"uuid\": \"rYUlpOXDSUSuZifQLPfa5A\",\n",
       "        \"version\": {\n",
       "          \"created\": \"7100299\"\n",
       "        },\n",
       "        \"provided_name\": \"logs-2020-01-01\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Index template options You can specify the following template options: Option Type Description Required template Object Specify index settings, mappings, and aliases. No priority Integer The priority of the index template. No composed_of String array The names of component templates applied on a new index together with the current template. No version Integer Specify a version number to simplify template management. Default is null. No _meta Object Specify meta information about the template. No Create a template Retrieve a template Configure multiple templates Delete a template Create a component template Use component templates to create an index template WAS THIS PAGE HELPFUL? ‚úî Yes ‚úñ No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright ¬© OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\n",
       "\n",
       "---\n",
       "\n",
       "## Result 8: \n",
       "\n",
       "**üîó Source:** [https://stackoverflow.com/questions/71816340/how-to-create-an-index-pattern-in-opensearch-using-api](https://stackoverflow.com/questions/71816340/how-to-create-an-index-pattern-in-opensearch-using-api)\n",
       "\n",
       "**Overview:**\n",
       "Skip to main content Stack Overflow About Products For Teams Stack Overflow for Teams Where developers & technologists share private knowledge with coworkers Advertising Reach devs & technologists worldwide about your product, service or employer brand Knowledge Solutions Data licensing offering for businesses to build and improve AI tools and models Labs The future of collective knowledge sharing About the company Visit the blog Loading‚Ä¶ current community Stack Overflow help chat Meta Stack Overflow your communities Sign up or log in to customize your list. more stack exchange communities company blog Log in Sign up Home Questions AI Assist Labs Tags Challenges Chat Articles Users Jobs Companies Collectives Communities for your favorite technologies. Explore all Collectives Teams Ask questions, find answers and collaborate at work with Stack Overflow for Teams. Try Teams for free Explore Teams Teams Ask questions, find answers and collaborate at work with Stack Overflow for Teams. Explore Teams Collectives‚Ñ¢ on Stack Overflow Find centralized, trusted content and collaborate around the technologies you use most. Learn more about Collectives Teams Q&A for work Connect and share knowledge within a single location that is structured and easy to search. Learn more about Teams How to create an index pattern in Opensearch using API? Ask Question Asked 3 years, 7 months ago Modified 11 months ago Viewed 15k times Part of AWS Collective 5 I want to create an index pattern using Opensearch API. I tried to replicate what could be made graphically in the following image window, using as index pattern name cwl-* and then as time field @timestamp. My domain has OpenSearch 1.2 installed. Using curl (directly modifiend the command in kibana doc): curl -u '****:*****' -X POST \"https://******.eu-central-1.es.amazonaws.com/api/index_patterns/index_pattern\" -H 'osd-xsrf: true' -H 'Content-Type: application/json' -d'\n",
       "{\n",
       "  \"index_pattern\": {\n",
       "     \"title\": \"cwl-*\",\n",
       "     \"timeFieldName\": \"@timestamp\"\n",
       "  }\n",
       "}'\n",
       " but I receive {\"error\":{\"root_cause\":[{\"type\":\"illegal_argument_exception\",\"reason\":\"Rejecting mapping update to [api] as the final mapping would have more than 1 type: [_doc, index_patterns]\"}],\"type\":\"illegal_argument_exception\",\"reason\":\"Rejecting mapping update to [api] as the final mapping would have more than 1 type: [_doc, index_patterns]\"},\"status\":400}\n",
       " amazon-web-services shell aws-elasticsearch opensearch Share Improve this question Follow edited Apr 10, 2022 at 17:50 asked Apr 10, 2022 at 11:54 Dresult 30311 gold badge22 silver badges1212 bronze badges 9 Are you using any sort of IAM authentication? Ermiya Eskandary ‚Äì Ermiya Eskandary 2022-04-10 15:58:49 +00:00 Commented Apr 10, 2022 at 15:58 @ErmiyaEskandary just the Fine-grained access control but it works because I don't have any problem in performing other requests... Dresult ‚Äì Dresult 2022-04-10 16:01:55 +00:00 Commented Apr 10, 2022 at 16:01 Ahhhhhh - remove saved_objects from your URL. Ermiya Eskandary ‚Äì Ermiya Eskandary 2022-04-10 16:10:33 +00:00 Commented Apr 10, 2022 at 16:10 @ErmiyaEskandary Unfortunately I had already tried, it says {\"statusCode\":404,\"error\":\"Not Found\",\"message\":\"Not Found\"} Dresult ‚Äì Dresult 2022-04-10 16:13:39 +00:00 Commented Apr 10, 2022 at 16:13 Your URL is somehow wrong - I don't have docs in front of me right now but try removing _dashboards from the URL and if that doesn't work, also remove api Ermiya Eskandary ‚Äì Ermiya Eskandary 2022-04-10 16:17:22 +00:00 Commented Apr 10, 2022 at 16:17 | Show 4 more comments 3 Answers 3 Sorted by: Reset to default Highest score (default) Trending (recent votes count more) Date modified (newest first) Date created (oldest first) 3 Tested with the latest OpenSearch version 2.18.0. To simply create an index pattern via the API, a POST request should be used:     curl -XPOST \"http://localhost:5601/api/saved_objects/index-pattern\" \\\n",
       "-u \"user:pass\" \\\n",
       "-H 'osd-xsrf: true' \\\n",
       "-H 'Content-Type: application/json' \\\n",
       "-d ' \n",
       "{\n",
       "  \"attributes\": {\n",
       "    \"title\": \"pattern-*\",\n",
       "    \"timeFieldName\": \"@timestamp\"\n",
       "  }\n",
       "}'\n",
       " If you want to create an OpenSearch index pattern with a specific ID, you can generate it or copy it from another source (in my case, I copied the ID of the missing pattern from the broken Dashboard) and include it as part of the request: curl -XPOST \"http://localhost:5601/api/saved_objects/index-pattern/90bd9a00-ad57-41a0-b16a-b134a8c51e98\" \\\n",
       "-u \"user:pass\" \\\n",
       "-H 'osd-xsrf: true' \\\n",
       "-H 'Content-Type: application/json' \\\n",
       "-d ' \n",
       "{\n",
       "  \"attributes\": {\n",
       "    \"title\": \"pattern-*\",\n",
       "    \"timeFieldName\": \"@timestamp\"\n",
       "  }\n",
       "}'\n",
       " If you need to update existing index pattern, a PUT request should be used, with existing ID: curl -XPUT \"http://localhost:5601/api/saved_objects/index-pattern/90bd9a00-ad57-41a0-b16a-b134a8c51e98\" \\\n",
       "-u \"user:pass\" \\\n",
       "-H 'osd-xsrf: true' \\\n",
       "-H 'Content-Type: application/json' \\\n",
       "-d ' \n",
       "{\n",
       "  \"attributes\": {\n",
       "    \"title\": \"pattern-*\",\n",
       "    \"timeFieldName\": \"@timestamp\"\n",
       "  }\n",
       "}'\n",
       " Share Improve this answer Follow answered Nov 26, 2024 at 21:35 nmishin 3,20255 gold badges2222 silver badges3737 bronze badges Sign up to request clarification or add additional context in comments. Comments Add a comment 1 curl -u '****:*****' -X POST \"https://******.eu-central-1.es.amazonaws.com/api/index_patterns/cwl-*\" -H 'osd-xsrf: true' -H 'Content-Type: application/json' -d'\n",
       "{\n",
       "  \"index_pattern\": {\n",
       "     \"title\": \"cwl-*\",\n",
       "     \"timeFieldName\": \"@timestamp\"\n",
       "  }\n",
       "}'\n",
       " change api/index_patterns/index_pattern to api/index_patterns/cwl-* and try again? Share Improve this answer Follow answered Apr 14, 2022 at 8:33 doge76 2122 bronze badges 4 Comments Add a comment Dresult Dresult Over a year ago It works in a sense that the command creates something but I cannot see anything among saved objects and seams that in this way only an index which name is \"api\" is created not an index pattern therefore each time I access the dashboard, once it finds data, it ask me if I want to create it. 2022-04-15T11:15:21.423Z+00:00 0 Reply Copy link doge76 doge76 Over a year ago if you want the index-pattern to be global, try to add this attribute in header: securitytenant: \"global\"? 2022-04-15T12:03:44.13Z+00:00 0 Reply Copy link Dresult Dresult Over a year ago already done, I've added -H 'securitytenant: global' to the curl string 2022-04-15T13:56:58.873Z+00:00 0 Reply Copy link Kasami Kasami Over a year ago @Dresult Did you ever manage to figure this out? I am encountering the same issue, it seems. 2022-10-10T22:50:32.3Z+00:00 2 Reply Copy link Add a comment 0 It worked for me in OpenSearch 1.3 when I added an ID in the URI and used saved_objects instead of index_patterns. So your cURL-request should work when looking like this. curl -u '****:*****' -X POST \"https://<opensearch-dashboards-host>.eu-central-1.es.amazonaws.com/api/saved_objects/index-pattern/<ID>\" \n",
       "-H 'osd-xsrf: true' \n",
       "-H 'Content-Type: application/json' \n",
       "-d \n",
       "   '{\n",
       "      \"index_pattern\": {\n",
       "         \"title\": \"cwl-*\",\n",
       "         \"timeFieldName\": \"@timestamp\"\n",
       "      }\n",
       "    }'\n",
       " Share Improve this answer Follow edited Dec 16, 2022 at 13:09 answered Aug 25, 2022 at 8:51 mgr110 111 bronze badge 3 Comments Add a comment K.Thanvi K.Thanvi Over a year ago I am getting no handler found for uri [/api/saved_objects/index-pattern/cwl-*] and method [POST] error for this.. using opensearch1.3. 2022-12-14T17:09:27.72Z+00:00 0 Reply Copy link mgr110 mgr110 Over a year ago @K.Thanvi This is probably because you are sending the request to the OpenSearch-host. The request is meant to be sent to the OpenSearch Dashboards-host (or Kibana-host if you use that). Using the Dev Tools will send the request to the OpenSearch-host. 2022-12-15T11:44:04.903Z+00:00 1 Reply Copy link K.Thanvi K.Thanvi Over a year ago Thanks! Yes that was the issue. i had to send the request to my <opensearch_domain>/_dashboards/api/saved_objects/index-pattern endpoint. 2023-01-09T17:07:40.23Z+00:00 1 Reply Copy link Add a comment Your Answer Thanks for contributing an answer to Stack Overflow! Please be sure to answer the question. Provide details and share your research! But avoid ‚Ä¶ Asking for help, clarification, or responding to other answers. Making statements based on opinion; back them up with references or personal experience. To learn more, see our tips on writing great answers. Draft saved Draft discarded Sign up or log in Sign up using Google Sign up using Email and Password Submit Post as a guest Name Email Required, but never shown Post as a guest Name Email Required, but never shown Post Your Answer Discard By clicking ‚ÄúPost Your Answer‚Äù, you agree to our terms of service and acknowledge you have read our privacy policy. Start asking to get answers Find the answer to your question by asking. Ask question Explore related questions amazon-web-services shell aws-elasticsearch opensearch See similar questions with these tags. AWS Collective See more This question is in a collective: a subcommunity defined by tags with relevant content and experts. The Overflow Blog The AI ick Revealing the unknown unknowns in your software Featured on Meta Results of the October 2025 Community Asks Sprint: copy button for code... Chat room owners can now establish room guidelines Policy: Generative AI (e.g., ChatGPT) is banned Opinion-based questions alpha experiment on Stack Overflow Related 1 Create Index - Elastic Search - Java API 14 Create index in Elastic Search by Java API 0 How to do an automated index creation at ElasticSearch? 21 How to configure index pattern in Kibana 2 How does one create an Index Pattern in Kibana? 3 Is there API based method to create an index pattern in Kibana if its index is present in ES 0 How to create new index pattern with custom pattern ID from the elastic API? 1 How to create Index pattern using API and Index Name 0 How to create an ElasticSearch Index as curl 0 How to create index pattern in elastic seach programmatically Hot Network Questions What is the earliest work of SF to mention a concern about time travel causing unintended space travel Why do we chase after things which make us happy? When did Soviet industrial planners start tooling for tank production? Shall I change my supervisor, who is nearing retirement? Sum of a sequence What is the most humane way to kill humans for meat? Is it possible to increase the rotation of a black hole without increasing the mass? Check whether saddle point or not What is a \"Squitchen\"? Urysohn's Lemma with compact sets and uniformly continuous function Why does John 2:13 mention Passover as a Jewish festival? Necessity of `typename` for naming of local nested classes in function templates how to make tar stop after reading or listing a few first files from a big tarball? how to pull with the hinge How to reply to \"How are you?\" How to replace wood strip part of threshold? Bracket covers sum limits using mathclap environment Agatha Christie - Hercule Poirot short story or novel Should I kill a companion or would that be frowned upon at the table? Why do we still say ‚ÄúIt is gone‚Äù but not ‚ÄúYou are come‚Äù? Hat-trick is for three, what's the word for four consecutive successes? How do I enable File and Printer sharing in latest Windows 11 InsertOnlyHashSet in C++ What is the correct orientation of the connecting tab on a bathroom sink stopper? more hot questions Question feed Subscribe to RSS Question feed To subscribe to this RSS feed, copy and paste this URL into your RSS reader. lang-bash Stack Overflow Questions Help Chat Products Teams Advertising Talent Company About Press Work Here Legal Privacy Policy Terms of Service Contact Us Your Privacy Choices Cookie Policy Stack Exchange Network Technology Culture & recreation Life & arts Science Professional Business API Data Blog Facebook Twitter LinkedIn Instagram Site design / logo ¬© 2025 Stack Exchange Inc; user contributions licensed under CC BY-SA . rev 2025.11.7.36544\n",
       "\n",
       "---\n",
       "\n",
       "## Result 9: Link Search Menu Expand Document Documentation Menu\n",
       "\n",
       "**üîó Source:** [https://docs.opensearch.org/latest/dashboards/management/management-index/](https://docs.opensearch.org/latest/dashboards/management/management-index/)\n",
       "\n",
       "**Overview:**\n",
       "Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards ‚Üê Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Regular expression syntax Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Using UBI in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Dashboards Management Introduced 2.10 Dashboards Management is the central hub for managing and customizing OpenSearch data directly within OpenSearch Dashboards. OpenSearch and OpenSearch Dashboards permissions govern access to individual features. If you do not have the appropriate access permissions, consult your administrator. Applications You can access the following applications in Dashboards Management: Index Patterns: To access OpenSearch data, you need to create an index pattern so that you can select the data you want to use and define the properties of the fields. The Index Pattern tool gives you the ability to create an index pattern from within the UI. Index patterns point to one or more indexes, data streams, or index aliases. Data Sources: The Data Sources tool is used to configure and manage the data sources that OpenSearch uses to collect and analyze data. You can use the tool to specify the source configuration in your copy of the OpenSearch Dashboards configuration file. Saved Objects: The Saved Objects tool helps you organize and manage your saved objects. Saved objects are files that store data, such as dashboards, visualizations, and maps, for later use. Advanced Settings: The Advanced Settings tool gives you the flexibility to personalize the behavior of OpenSearch Dashboards. The tool is divided into settings sections, such as General, Accessibility, and Notifications, and you can use it to customize and optimize many of your Dashboards settings. Related documentation Index patterns Advanced settings Access control lists for saved objects Applications WAS THIS PAGE HELPFUL? ‚úî Yes ‚úñ No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright ¬© OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\n",
       "\n",
       "---\n",
       "\n",
       "## Result 10: Link Search Menu Expand Document Documentation Menu\n",
       "\n",
       "**üîó Source:** [https://docs.opensearch.org/latest/api-reference/index-apis/create-index/](https://docs.opensearch.org/latest/api-reference/index-apis/create-index/)\n",
       "\n",
       "**Overview:**\n",
       "Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards ‚Üê Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Regular expression syntax Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Using UBI in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Index APIs Core index APIs Create index Create Index API Introduced 1.0 While you can create an index by using a document as a base, you can also create an empty index for later use. When creating an index, you can specify its mappings, settings, and aliases. Endpoints PUT <index>\n",
       " Index naming restrictions OpenSearch indexes have the following naming restrictions: All letters must be lowercase. Index names can‚Äôt begin with underscores (_) or hyphens (-). Index names can‚Äôt contain spaces, commas, or the following characters: :, \", *, +, /, \\, |, ?, #, >, or < Path parameters Parameter Data type Description index String The index name. Must conform to the index naming restrictions. Required. Query parameters You can include the following query parameters in your request. All parameters are optional. Parameter Type Description wait_for_active_shards String Specifies the number of active shards that must be available before OpenSearch processes the request. Default is 1 (only the primary shard). Set to all or a positive integer. Values greater than 1 require replicas. For example, if you specify a value of 3, the index must have two replicas distributed across two additional nodes for the request to succeed. cluster_manager_timeout Time How long to wait for a connection to the cluster manager node. Default is 30s. timeout Time How long to wait for the request to return. Default is 30s. Request body As part of your request, you can optionally specify index settings, mappings, aliases, and index context. Example request REST Python PUT /sample-index1\n",
       "{\n",
       "  \"settings\": {\n",
       "    \"index\": {\n",
       "      \"number_of_shards\": 2,\n",
       "      \"number_of_replicas\": 1\n",
       "    }\n",
       "  },\n",
       "  \"mappings\": {\n",
       "    \"properties\": {\n",
       "      \"age\": {\n",
       "        \"type\": \"integer\"\n",
       "      }\n",
       "    }\n",
       "  },\n",
       "  \"aliases\": {\n",
       "    \"sample-alias1\": {}\n",
       "  }\n",
       "} Copy Copy as cURL response = client.indices.create(\n",
       "  index = \"sample-index1\",\n",
       "  body =   {\n",
       "    \"settings\": {\n",
       "      \"index\": {\n",
       "        \"number_of_shards\": 2,\n",
       "        \"number_of_replicas\": 1\n",
       "      }\n",
       "    },\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"age\": {\n",
       "          \"type\": \"integer\"\n",
       "        }\n",
       "      }\n",
       "    },\n",
       "    \"aliases\": {\n",
       "      \"sample-alias1\": {}\n",
       "    }\n",
       "  }\n",
       ") Copy Endpoints Index naming restrictions Path parameters Query parameters Request body Example request WAS THIS PAGE HELPFUL? ‚úî Yes ‚úñ No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright ¬© OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\n",
       "\n",
       "---\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parse and display all content blocks from the entire response in Markdown format\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# Extract all items from the response\n",
    "all_items = json.loads(response['inference_results'][0]['output'][0]['result'])['items']\n",
    "\n",
    "# Create formatted markdown output\n",
    "output = f\"# üåê All Web Search Results\\n\\n\"\n",
    "output += f\"**Total Results:** {len(all_items)}  \\n\"\n",
    "output += f\"**Query:** {parameters.get('question', 'N/A')}\\n\\n\"\n",
    "output += \"---\\n\\n\"\n",
    "\n",
    "# Parse and display each result\n",
    "for idx, item in enumerate(all_items, 1):\n",
    "    title = item.get('title', 'No Title')\n",
    "    url = item.get('url', 'No URL')\n",
    "    content = item.get('content', 'No Content')\n",
    "    \n",
    "    output += f\"## Result {idx}: {title}\\n\\n\"\n",
    "    output += f\"**üîó Source:** [{url}]({url})\\n\\n\"\n",
    "    \n",
    "    # Parse content by steps (same logic as original cell)\n",
    "    sections = content.split('Step ')\n",
    "    \n",
    "    # Add first section as overview if it exists\n",
    "    if sections[0].strip():\n",
    "        output += f\"**Overview:**\\n{sections[0].strip()}\\n\\n\"\n",
    "    \n",
    "    # Parse and format remaining steps\n",
    "    for step_num, section in enumerate(sections[1:], 1):\n",
    "        lines = section.split('. ', 1)\n",
    "        if len(lines) > 1:\n",
    "            step_title = lines[0]\n",
    "            step_content = lines[1]\n",
    "            output += f\"### Step {step_num}: {step_title}\\n\"\n",
    "            output += f\"{step_content}\\n\\n\"\n",
    "        elif section.strip():\n",
    "            output += f\"{section.strip()}\\n\\n\"\n",
    "    \n",
    "    output += \"---\\n\\n\"\n",
    "\n",
    "# Display as markdown\n",
    "display(Markdown(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315a5bb2",
   "metadata": {},
   "source": [
    "## Format output - HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "204a6cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "<style>\n",
       "    * {\n",
       "        box-sizing: border-box;\n",
       "    }\n",
       "\n",
       "    .html-container {\n",
       "        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;\n",
       "        max-width: 1000px;\n",
       "        margin: 0 auto;\n",
       "        color: #333;\n",
       "        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);\n",
       "        padding: 30px 20px;\n",
       "    }\n",
       "\n",
       "    .header {\n",
       "        text-align: center;\n",
       "        margin-bottom: 40px;\n",
       "        color: #2c3e50;\n",
       "    }\n",
       "\n",
       "    .header h1 {\n",
       "        font-size: 32px;\n",
       "        margin: 0 0 10px 0;\n",
       "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
       "        -webkit-background-clip: text;\n",
       "        -webkit-text-fill-color: transparent;\n",
       "    }\n",
       "\n",
       "    .stats {\n",
       "        background: white;\n",
       "        padding: 20px;\n",
       "        border-radius: 8px;\n",
       "        margin-bottom: 30px;\n",
       "        box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n",
       "        display: flex;\n",
       "        gap: 20px;\n",
       "        flex-wrap: wrap;\n",
       "    }\n",
       "\n",
       "    .stat-item {\n",
       "        flex: 1;\n",
       "        min-width: 200px;\n",
       "    }\n",
       "\n",
       "    .stat-label {\n",
       "        font-size: 12px;\n",
       "        color: #7f8c8d;\n",
       "        text-transform: uppercase;\n",
       "        font-weight: bold;\n",
       "        margin-bottom: 5px;\n",
       "    }\n",
       "\n",
       "    .stat-value {\n",
       "        font-size: 20px;\n",
       "        color: #2c3e50;\n",
       "        font-weight: bold;\n",
       "    }\n",
       "\n",
       "    .results-container {\n",
       "        display: grid;\n",
       "        gap: 25px;\n",
       "    }\n",
       "\n",
       "    .result-card {\n",
       "        background: white;\n",
       "        border-radius: 12px;\n",
       "        overflow: hidden;\n",
       "        box-shadow: 0 4px 15px rgba(0,0,0,0.1);\n",
       "        transition: transform 0.3s ease, box-shadow 0.3s ease;\n",
       "    }\n",
       "\n",
       "    .result-card:hover {\n",
       "        transform: translateY(-5px);\n",
       "        box-shadow: 0 8px 25px rgba(0,0,0,0.15);\n",
       "    }\n",
       "\n",
       "    .result-header {\n",
       "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
       "        color: white;\n",
       "        padding: 20px;\n",
       "        display: flex;\n",
       "        align-items: center;\n",
       "        gap: 15px;\n",
       "    }\n",
       "\n",
       "    .result-number {\n",
       "        background: rgba(255,255,255,0.2);\n",
       "        width: 40px;\n",
       "        height: 40px;\n",
       "        border-radius: 50%;\n",
       "        display: flex;\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        font-weight: bold;\n",
       "        font-size: 16px;\n",
       "        flex-shrink: 0;\n",
       "    }\n",
       "\n",
       "    .result-title {\n",
       "        flex: 1;\n",
       "        font-size: 18px;\n",
       "        font-weight: bold;\n",
       "    }\n",
       "\n",
       "    .result-url {\n",
       "        background: white;\n",
       "        padding: 15px 20px;\n",
       "        border-bottom: 1px solid #ecf0f1;\n",
       "        color: #3498db;\n",
       "        text-decoration: none;\n",
       "        font-size: 12px;\n",
       "        word-break: break-all;\n",
       "        font-family: 'Courier New', monospace;\n",
       "    }\n",
       "\n",
       "    .result-url a {\n",
       "        color: #3498db;\n",
       "        text-decoration: none;\n",
       "    }\n",
       "\n",
       "    .result-url a:hover {\n",
       "        text-decoration: underline;\n",
       "    }\n",
       "\n",
       "    .result-body {\n",
       "        padding: 25px;\n",
       "    }\n",
       "\n",
       "    .overview {\n",
       "        background: #f8f9fa;\n",
       "        padding: 15px;\n",
       "        border-radius: 6px;\n",
       "        margin-bottom: 20px;\n",
       "        border-left: 4px solid #667eea;\n",
       "        font-size: 14px;\n",
       "        line-height: 1.7;\n",
       "        color: #555;\n",
       "    }\n",
       "\n",
       "    .steps-container {\n",
       "        display: grid;\n",
       "        gap: 15px;\n",
       "    }\n",
       "\n",
       "    .step {\n",
       "        border-left: 4px solid #764ba2;\n",
       "        padding-left: 15px;\n",
       "        padding-top: 10px;\n",
       "        padding-bottom: 10px;\n",
       "    }\n",
       "\n",
       "    .step-title {\n",
       "        font-weight: bold;\n",
       "        color: #764ba2;\n",
       "        font-size: 15px;\n",
       "        margin-bottom: 8px;\n",
       "        display: flex;\n",
       "        align-items: center;\n",
       "        gap: 8px;\n",
       "    }\n",
       "\n",
       "    .step-number {\n",
       "        display: inline-block;\n",
       "        background: #764ba2;\n",
       "        color: white;\n",
       "        width: 24px;\n",
       "        height: 24px;\n",
       "        border-radius: 50%;\n",
       "        display: flex;\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        font-size: 12px;\n",
       "        font-weight: bold;\n",
       "    }\n",
       "\n",
       "    .step-content {\n",
       "        color: #555;\n",
       "        font-size: 13px;\n",
       "        line-height: 1.8;\n",
       "    }\n",
       "</style>\n",
       "</head>\n",
       "<body>\n",
       "<div class=\"html-container\">\n",
       "    <div class=\"header\">\n",
       "        <h1>üåê Web Search Results</h1>\n",
       "        <p>Comprehensive detailed view of all search results</p>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"stats\">\n",
       "        <div class=\"stat-item\">\n",
       "            <div class=\"stat-label\">üìä Total Results</div>\n",
       "            <div class=\"stat-value\">10</div>\n",
       "        </div>\n",
       "        <div class=\"stat-item\">\n",
       "            <div class=\"stat-label\">‚ùì Query</div>\n",
       "            <div class=\"stat-value\">How to create an index pattern in OpenSearch?</div>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"results-container\">\n",
       "\n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\">\n",
       "                <div class=\"result-number\">1</div>\n",
       "                <div class=\"result-title\">Link Search Menu Expand Document Documentation Menu</div>\n",
       "            </div>\n",
       "            <div class=\"result-url\">\n",
       "                <strong>üîó Source:</strong> <a href=\"https://docs.opensearch.org/latest/dashboards/management/index-patterns/\" target=\"_blank\">https://docs.opensearch.org/latest/dashboards/management/index-patterns/</a>\n",
       "            </div>\n",
       "            <div class=\"result-body\">\n",
       "    \n",
       "                <div class=\"overview\">\n",
       "                    <strong>Overview:</strong><br>\n",
       "                    Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards ‚Üê Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Regular expression syntax Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Using UBI in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Dashboards Management Index patterns Index patterns Index patterns are essential for accessing OpenSearch data. An index pattern references one or more indexes, data streams, or index aliases. For example, an index pattern can point you to your log data from yesterday or all indexes that contain that data. If you store data in multiple indexes, creating an index pattern enables your visualizations to retrieve data from all indexes that match the index pattern. You need to create index patterns to define how data is retrieved and fields are formatted so that you can query, search, and display data. Get started In this tutorial, you‚Äôll learn to create index patterns. Note To create or modify index patterns, you must have create, manage, and delete permissions. Contact your administrator for support. For more information, refer to Multi-tenancy configuration. Prerequisites Before you can create an index pattern, your data must be indexed. To learn about indexing your data in OpenSearch, see Managing indexes. Best practices Consider the following best practices when creating index patterns: Make your index patterns specific. Instead of creating an index pattern that matches all indexes, create an index pattern that matches all indexes starting with a certain prefix, for example, my-index-. The more specific your index patterns, the better it will be to query and analyze your data. Use wildcards sparingly. Wildcards can be useful for matching multiple indexes, but they can also make it more difficult to manage your index patterns. Try to use wildcards as specifically as possible. Test your index patterns. Make sure to test your index patterns to ensure that they match the correct indexes. Creating an index pattern If you added sample data, you have index patterns that you can use to analyze that data. To create an index pattern for your own data, follow these steps.\n",
       "                </div>\n",
       "        \n",
       "                <div class=\"steps-container\">\n",
       "        \n",
       "                    <div class=\"step\">\n",
       "                        <div class=\"step-title\">\n",
       "                            <span class=\"step-number\">1</span>\n",
       "                            1: Define the index pattern Go to OpenSearch Dashboards, and select Management > Dashboards Management > Index patterns\n",
       "                        </div>\n",
       "                        <div class=\"step-content\">Select Create index pattern. From the Create index pattern window, define the index pattern by entering a name for your index pattern in the Index pattern name field. Dashboards automatically adds a wildcard, *, once you start typing. Using a wildcard is helpful for matching an index pattern to multiple sources or indexes. A dropdown list displaying all the indexes that match your index pattern appears when you start typing. Select Next step. An example of step 1 is shown in the following image. Note that the index pattern security* matches three indexes. By defining the pattern with a wildcard *, you can query and visualize all the data in your indexes. </div>\n",
       "                    </div>\n",
       "                \n",
       "                    <div class=\"step\">\n",
       "                        <div class=\"step-title\">\n",
       "                            <span class=\"step-number\">2</span>\n",
       "                            2: Configure the settings Select @timestamp from the dropdown menu to specify the time field for OpenSearch to use when filtering documents based on time\n",
       "                        </div>\n",
       "                        <div class=\"step-content\">Selecting this time filter determines which field the time filter is applied to. It can be the timestamp of a request or any relevant timestamp field. If you don‚Äôt want to use a time filter, select that option from the dropdown menu. If you select this option, OpenSearch returns all of the data in the indexes that match the pattern. Select Create index pattern. An example is shown in the following image. Once the index pattern has been created, you can view the mapping of the matching indexes. Within the table, you can see the list of fields, along with their data type and properties. An example is shown in the following image. Next steps Understand your data through visuals. Dig into your data. Get started Prerequisites Best practices Creating an index pattern </div>\n",
       "                    </div>\n",
       "                \n",
       "                    <div class=\"step\">\n",
       "                        <div class=\"step-content\">1: Define the index pattern</div>\n",
       "                    </div>\n",
       "                \n",
       "                    <div class=\"step\">\n",
       "                        <div class=\"step-title\">\n",
       "                            <span class=\"step-number\">4</span>\n",
       "                            2: Configure the settings Next steps WAS THIS PAGE HELPFUL? ‚úî Yes ‚úñ No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum\n",
       "                        </div>\n",
       "                        <div class=\"step-content\">Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright ¬© OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.</div>\n",
       "                    </div>\n",
       "                \n",
       "                </div>\n",
       "        \n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\">\n",
       "                <div class=\"result-number\">2</div>\n",
       "                <div class=\"result-title\"></div>\n",
       "            </div>\n",
       "            <div class=\"result-url\">\n",
       "                <strong>üîó Source:</strong> <a href=\"https://repost.aws/knowledge-center/opensearch-index-pattern\" target=\"_blank\">https://repost.aws/knowledge-center/opensearch-index-pattern</a>\n",
       "            </div>\n",
       "            <div class=\"result-body\">\n",
       "    \n",
       "                <div class=\"overview\">\n",
       "                    <strong>Overview:</strong><br>\n",
       "                    Skip to content By using AWS re:Post, you agree to the AWS re:Post Terms of Use re:Post Search About re:Post English EnglishDeutschEspa√±olFran√ßaisItalianoÊó•Êú¨Ë™ûÌïúÍµ≠Ïñ¥Portugu√™s‰∏≠Êñá (ÁÆÄ‰Ωì)‰∏≠Êñá (ÁπÅÈ´î) Resources Sign in Home Questions Knowledge Center Articles Selections Tags Topics Community Groups AWS Support Official AWS Trust & Safety Center Ask question / How do I create an index pattern in my OpenSearch Service cluster?lg.../ How do I create an index pattern in my OpenSearch Service cluster? 5 minute read 1 I want to create an index pattern in my Amazon OpenSearch Service cluster. Resolution Prerequisites: The AWS Identity and Access Management (IAM) user must have PUT and POST permissions to create an index pattern. Example access policy: {  \"Version\": \"2012-10-17\",\n",
       "  \"Statement\": [\n",
       "    {\n",
       "      \"Sid\": \"VisualEditor0\",\n",
       "      \"Effect\": \"Allow\",\n",
       "      \"Action\": [\n",
       "        \"es:ESHttpHead\",\n",
       "        \"es:ESHttpPost\",\n",
       "        \"es:ESHttpGet\",\n",
       "        \"es:ESHttpDelete\",\n",
       "        \"es:ESHttpPut\"\n",
       "      ],\n",
       "      \"Resource\": \"arn:aws:es:region:account-id:domain/domain-name/*\"\n",
       "    }\n",
       "  ]\n",
       "} Note: Replace region with your AWS Region, account-id with your AWS account, and domain-name with your domain name. Your cluster version must allow index patterns. Create the index pattern Use OpenSearch Dashboards You can use OpenSearch Dashboards to create an index pattern for OpenSearch Service or Elasticsearch clusters with or without fine-grained access control. For instructions, see Creating an index pattern on the OpenSearch website. Use curl commands To create an index pattern for clusters without fine-grained access control, run the following command based on the cluster type. Elasticsearch clusters: curl -X POST  https://elasticsearch-end-point/_plugin/kibana/api/saved_objects/index-pattern/ \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "\n",
       "-H \"content-type: application/json\" \\\n",
       "\n",
       "-d '{ \"attributes\": { \"title\": \"sample-index*\" } }' Note: Replace sample-index with your index name or pattern. OpenSearch Service clusters: curl -X POST  https://opensearch-end-point/_dashboards/api/saved_objects/index-pattern/ \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "\n",
       "-H \"content-type: application/json\" \\\n",
       "\n",
       "-d '{ \"attributes\": { \"title\": \"sample-index*\" } }' Note: Replace sample-index with your index name or pattern. For clusters with fine-grained access control, complete the following steps: To generate authorization cookies in the auth.txt file, run the following command based on the cluster type. Elasticsearch clusters: curl -X POST  https://elasticsearch-end-point/_plugin/kibana/auth/login  \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "-H \"content-type: application/json\" \\\n",
       "-d '{\"username\":\"usernameexample\", \"password\":\"passwordexample\"}' \\\n",
       "-c auth.txt Note: Replace usernameexample with your username and passwordexample with your password. OpenSearch Service clusters: curl -X POST  https://opensearch-end-point/_dashboards/auth/login  \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "-H \"content-type: application/json\" \\\n",
       "-d '{\"username\":\"usernameexample\", \"password\":\"passwordexample\"}' \\\n",
       "-c auth.txt Note: Replace usernameexample with your username and passwordexample with your password. To submit the index pattern creation request, run the following command based on your cluster type: Elasticsearch clusters: curl -X POST  https://elasticsearch-end-point/_plugin/kibana/api/saved_objects/index-pattern/test  \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "-H \"content-type: application/json\" \\\n",
       "-d '{ \"attributes\": { \"title\": \"sample-index*\" } }' \\\n",
       "-b auth.txt Note: Replace sample-index with your index name or pattern. OpenSearch Service clusters: curl -X POST  https://opensearch-end-point/_dashboards/api/saved_objects/index-pattern/  \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "-H \"content-type: application/json\" \\\n",
       "-d '{ \"attributes\": { \"title\": \"sample-index*\" } }' \\\n",
       "-b auth.txt Note: Replace sample-index with your index name or pattern. Use Python Prerequisites: Map the role that runs the Python code to the backend role for fine-grained access control clusters. Run the following commands to install the required dependencies: pip install boto3\n",
       "pip install opensearch-py\n",
       "pip install requests\n",
       "pip install requests-aws4auth Run the following Python command to create the index pattern for OpenSearch Service clusters: import boto3\n",
       "import requests\n",
       "from requests_aws4auth import AWS4Auth\n",
       "\n",
       "host = 'https://domain-endpoint/' # include trailing /\n",
       "region = 'aos-region' # example us-west-1\n",
       "service = 'es'\n",
       "credentials = boto3.Session().get_credentials()\n",
       "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)\n",
       "\n",
       "\n",
       "path = '_dashboards/api/saved_objects/index-pattern' # _plugin/kibana/api/saved_objects/index-pattern for es versions\n",
       "url = host + path\n",
       "payload = {\"attributes\":{\"title\":\"multi-logs-*\",\"fields\":\"[]\"}}\n",
       "headers = {\"Content-Type\": \"application/json\", \"osd-xsrf\": \"true\", \"security_tenant\": \"global\" }\n",
       "r = requests.post (url, auth=awsauth, json=payload, headers=headers)\n",
       "print(r.status_code)\n",
       "print(r.text) Note: Replace domain-endpoint with your domain endpoint, and aos-region with your Region. For Elasticsearch clusters, replace _dashboards/api/saved_objects/index-pattern with _plugin/kibana/api/saved_objects/index-pattern. Troubleshoot index pattern creation issues You use fine-grained access control with SAML 2.0 or Amazon Cognito authentication If the domain for your cluster uses SAML 2.0 or Amazon Cognito for authentication, then create an internal user to manage the index pattern. Note: For clusters where you activated fine-grained access control, the user must have ESHttpPut and ESHttpPost permissions to create an index pattern. You can't create the index pattern in the Global tenant By default, OpenSearch Dashboards creates index patterns under the Global tenant. To create an index pattern outside of the Global tenant, run the following command: curl -s -X POST https://opensearch-end-point/_dashboards/api/saved_objects/index-pattern/sample-index -d '{\"attributes\": {\"title\": \"sample-index*\"}}' \\\n",
       "-H \"osd-xsrf:true\" \\\n",
       "-H \"securitytenant: private\" \\\n",
       "-H \"content-type:application/json\" \\\n",
       "-b auth.txt Note: Replace sample-index with your index name or pattern. You didn't include the .kibana alias in the cluster To troubleshoot this issue, complete the following steps: To check whether the .kibana alias exists in the cluster, run the following command: curl -XGET https://opensearch-end-point/_cat/aliases Note: For clusters with fine-grained access control, include the -u flag with your username and password. Example command: curl -XPOST -u 'master-user:master-user-password' 'domain-endpoint/_cat/indices If the .kibana index doesn't exist, then proceed to step 4. To create a backup of .kibana index, run the following command: curl -XPOST \"https://domain-endpoint/_reindex\" -H 'Content-Type: application/json' -d'{\n",
       "  \"source\": {\n",
       "    \"index\": \".kibana\"\n",
       "  },\n",
       "  \"dest\": {\n",
       " \"index\": \".kibana_backup\"\n",
       "  }\n",
       "}' Note: Replace domain-endpoint with your domain endpoint. For clusters with fine-grained access control, include the -u flag with your username and password. To delete the .kibana index, run the following command: curl -XDELETE \"https://domain-endpoint/.kibana\" Note: Replace domain-endpoint with your domain endpoint. For clusters with fine-grained access control, include the -u flag with your username and password. To create a .kibana alias and point it to the .kibana_backup index, run the following command: curl -XPOST \"https://domain-endpoint/_aliases\" -H 'Content-Type: application/json' -d'{\n",
       "  \"actions\": [\n",
       "    {\n",
       "      \"add\": {\n",
       "        \"index\": \".kibana_backup\",\n",
       "        \"alias\": \".kibana\"\n",
       "      }\n",
       "    }\n",
       "  ]\n",
       "}' Note: Replace domain-endpoint with your domain endpoint. For clusters with fine-grained access control, include the -u flag with your username and password. Related information Export and import Kibana dashboards with OpenSearch Service Why does the rollover index action in my ISM policy keep failing in OpenSearch Service? Follow Share Topics Analytics Tags Amazon OpenSearch Service Language English Related videos Watch Sujata's video to learn more (3:59) AWS OFFICIALUpdated 3 months ago 2 Comments This can also be done using basic auth using session object without signing the request if that is the use case. [+] Session Object = https://requests.readthedocs.io/en/latest/user/advanced/#session-objects #! /bin/python3\n",
       "import requests\n",
       "host = 'https://<domain_endpoint_ending_with_slash>/'\n",
       "path = '_dashboards/auth/login'\n",
       "region = 'us-east-1'\n",
       "url = host + path;\n",
       "# Set headers as mentioned. Here we will create index pattern in global tenant hence the value is global\n",
       "headers = {\"Content-Type\": \"application/json\",\"kbn-xsrf\": \"true\",\"osd-xsrf\":\"true\",\"security_tenant\":\"global\"};\n",
       "payload = {\n",
       " \"username\":\"username\",\n",
       "    \"password\":\"password\"\n",
       "}\n",
       "\n",
       "#Creating a session because requests wont store the cookie\n",
       "\n",
       "session=requests.Session();\n",
       "\n",
       "r=session.post(url,headers=headers,json=payload);\n",
       "# You can skip these lines with print. Basically the above line will do a post request with my credentials and will create a cookie and will store it\n",
       "print(r.text);\n",
       "print(r.status_code);\n",
       "\n",
       "# title is the name of my index pattern\n",
       "\n",
       "payload={\n",
       "\"attributes\": { \"title\": \"random*\" } \n",
       "\n",
       "}\n",
       "\n",
       "path=\"_dashboards/api/saved_objects/index-pattern/random*\";\n",
       "url=host+path;\n",
       "\n",
       "#Changed the path variable to the one which is mentioned above. Notice the end of the URL, my index pattern name will be random*\n",
       "\n",
       "r=session.post(url,headers=headers,json=payload);\n",
       "\n",
       "print(r.text);\n",
       "print(r.status_code);\n",
       "session.close();\n",
       " Share rePost-User-6420587 replied 2 years ago Thank you for your comment. We'll review and update the Knowledge Center article as needed. Share MODERATOR AWS Official replied 2 years ago Comment on this article Clear Post comment Relevant content Got an error \"Request Entity Too Large\" when creating index pattern in AWS Opensearch soop_minjaeoh asked a year ago How to create and configure an Open Search Serverless index via API? Zach asked 9 months ago OpenSearch Dashboards Index Pattern and Discover issues mdkail asked 4 years ago Index is not created inside the Amazon OpenSearch cluster Accepted Answer stratosb asked 2 years ago Access denied (403) when creating an index in OpenSearch Serverless. AlwaysLearning asked 2 years ago Why does the rollover index action in my ISM policy fail in OpenSearch Service? AWS OFFICIALUpdated a month ago Why can't I delete an index or upgrade my OpenSearch Service cluster? AWS OFFICIALUpdated a year ago How do I resolve the 403 \"index_create_block_exception\" or \"cluster_block_exception\" error in OpenSearch Service? AWS OFFICIALUpdated 3 years ago How do I use ISM to manage low storage space in Amazon OpenSearch Service? AWS OFFICIALUpdated 2 months ago How to combine ISM policy actions to control shard size EXPERT Sherin Chandy published a year ago FEEDBACK Privacy| Site Terms| Cookie Preferences | Sitemap| Legal| ¬© 2025, Amazon Web Services, Inc. or its affiliates. All rights reserved. Community Guidelines\n",
       "                </div>\n",
       "        \n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\">\n",
       "                <div class=\"result-number\">3</div>\n",
       "                <div class=\"result-title\"></div>\n",
       "            </div>\n",
       "            <div class=\"result-url\">\n",
       "                <strong>üîó Source:</strong> <a href=\"https://www.youtube.com/watch?v=pbABIerUYQI\" target=\"_blank\">https://www.youtube.com/watch?v=pbABIerUYQI</a>\n",
       "            </div>\n",
       "            <div class=\"result-body\">\n",
       "    \n",
       "                <div class=\"overview\">\n",
       "                    <strong>Overview:</strong><br>\n",
       "                    AboutPressCopyrightContact usCreatorsAdvertiseDevelopersTermsPrivacyPolicy & SafetyHow YouTube worksTest new featuresNFL Sunday Ticket ¬© 2025 Google LLC\n",
       "                </div>\n",
       "        \n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\">\n",
       "                <div class=\"result-number\">4</div>\n",
       "                <div class=\"result-title\"></div>\n",
       "            </div>\n",
       "            <div class=\"result-url\">\n",
       "                <strong>üîó Source:</strong> <a href=\"https://github.com/fidelity-contributions/opensearch-project-opensearch-py/blob/main/guides/index_template.md\" target=\"_blank\">https://github.com/fidelity-contributions/opensearch-project-opensearch-py/blob/main/guides/index_template.md</a>\n",
       "            </div>\n",
       "            <div class=\"result-body\">\n",
       "    \n",
       "                <div class=\"overview\">\n",
       "                    <strong>Overview:</strong><br>\n",
       "                    Skip to content Navigation Menu Toggle navigation Sign in Appearance settings Platform AI CODE CREATION GitHub CopilotWrite better code with AI GitHub SparkBuild and deploy intelligent apps GitHub ModelsManage and compare prompts MCP RegistryNewDiscover and integrate external tools DEVELOPER WORKFLOWS ActionsAutomate any workflow CodespacesInstant dev environments IssuesPlan and track work Code ReviewManage code changes APPLICATION SECURITY GitHub Advanced SecurityFind and fix vulnerabilities Code securitySecure your code as you build Secret protectionStop leaks before they start EXPLORE Why GitHub Documentation Blog Changelog Marketplace View all features Solutions BY COMPANY SIZE Enterprises Small and medium teams Startups Nonprofits BY USE CASE App Modernization DevSecOps DevOps CI/CD View all use cases BY INDUSTRY Healthcare Financial services Manufacturing Government View all industries View all solutions Resources EXPLORE BY TOPIC AI Software Development DevOps Security View all topics EXPLORE BY TYPE Customer stories Events & webinars Ebooks & reports Business insights GitHub Skills SUPPORT & SERVICES Documentation Customer support Community forum Trust center Partners Open Source COMMUNITY GitHub SponsorsFund open source developers PROGRAMS Security Lab Maintainer Community Accelerator Archive Program REPOSITORIES Topics Trending Collections Enterprise ENTERPRISE SOLUTIONS Enterprise platformAI-powered developer platform AVAILABLE ADD-ONS GitHub Advanced SecurityEnterprise-grade security features Copilot for BusinessEnterprise-grade AI features Premium SupportEnterprise-grade 24/7 support Pricing Search or jump to... Search code, repositories, users, issues, pull requests... Search Clear Search syntax tips Provide feedback We read every piece of feedback, and take your input very seriously. Include my email address so I can be contacted Cancel Submit feedback Saved searches Use saved searches to filter your results more quickly Name Query To see all available qualifiers, see our documentation. Cancel Create saved search Sign in Sign up Appearance settings Resetting focus You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert {{ message }} fidelity-contributions / opensearch-project-opensearch-py Public forked from opensearch-project/opensearch-py Notifications You must be signed in to change notification settings Fork 0 Star 0 Code Pull requests 0 Security Uh oh! There was an error while loading. Please reload this page. Insights Additional navigation options Code Pull requests Security Insights Footer ¬© 2025 GitHub, Inc. Footer navigation Terms Privacy Security Status Community Docs Contact Manage cookies Do not share my personal information You can‚Äôt perform that action at this time.\n",
       "                </div>\n",
       "        \n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\">\n",
       "                <div class=\"result-number\">5</div>\n",
       "                <div class=\"result-title\"></div>\n",
       "            </div>\n",
       "            <div class=\"result-url\">\n",
       "                <strong>üîó Source:</strong> <a href=\"https://deepwiki.com/johnny-chivers/amazon-opensearch-service/3.1-index-patterns\" target=\"_blank\">https://deepwiki.com/johnny-chivers/amazon-opensearch-service/3.1-index-patterns</a>\n",
       "            </div>\n",
       "            <div class=\"result-body\">\n",
       "    \n",
       "                <div class=\"overview\">\n",
       "                    <strong>Overview:</strong><br>\n",
       "                    Index your code with Devin DeepWiki DeepWiki johnny-chivers/amazon-opensearch-service Index your code with Devin Edit Wiki Share Last indexed: 25 May 2025 (924181) Overview Getting Started Tutorial Domain Setup Data Upload and Indexing Search Operations Cleanup and Domain Deletion Index Management Index Patterns Field Configuration Security and Access Control Access Control Systems Access Policies System Architecture Data Node Architecture Network Configuration Development and Testing Menu Index Patterns Relevant source files pictures/12-define-index-pattern.png pictures/13-createe-index-pattern.png Purpose and Scope This document covers the creation and configuration of index patterns in Amazon OpenSearch Service, specifically focusing on how they enable data discovery and visualization through the OpenSearch Dashboards interface. Index patterns define how OpenSearch Dashboards connects to and interprets the data stored in your OpenSearch indices. This guide specifically covers the index pattern workflow for the movies dataset used in the tutorial. For information about the underlying index field configuration and data types, see Field Configuration. For the broader context of data upload and indexing operations, see Data Upload and Indexing. Overview of Index Patterns Index patterns in OpenSearch Dashboards serve as a bridge between raw index data and the visualization layer. They define which indices contain the data you want to explore and specify how that data should be interpreted for search and analysis operations. In the context of this tutorial, index patterns enable access to the movies index that contains the bulk movie dataset from bulk_movies.json. Sources: Based on tutorial workflow and OpenSearch Dashboards architecture patterns. Index Pattern Creation Workflow The index pattern creation process follows a specific sequence within the OpenSearch Dashboards interface, as documented in the tutorial screenshots. Sources: Tutorial workflow sequence and OpenSearch Dashboards interface patterns. Pattern Definition and Configuration Index patterns use wildcard matching to identify which indices they should include. For the movies dataset, the pattern typically follows this structure: Pattern Element Purpose Example Index Name Base index identifier movies Wildcard Pattern matching movies* Time Field Timestamp field for time-based data Not applicable for movies dataset Field Discovery Automatic field detection Enabled The pattern configuration process involves several key steps: Sources: OpenSearch Dashboards index pattern creation workflow and field detection mechanisms. Field Mapping and Data Types Once an index pattern is created, OpenSearch Dashboards automatically discovers and maps the fields from the underlying movies index. This process examines the data structure from the documents uploaded via bulk_movies.json. The field mapping process identifies several categories of data: Field Category Examples from Movies Data OpenSearch Type Text Fields title, director, genre text or keyword Numeric Fields year, rating integer or float Date Fields release_date date Boolean Fields available boolean Sources: OpenSearch field mapping documentation and movies dataset structure analysis. Integration with Discovery Interface Index patterns enable the Discover interface to provide search and exploration capabilities across the movie dataset. The integration allows for both simple and complex query operations. The discovery workflow leverages the index pattern to: Field-based Filtering: Use detected fields for creating search filters Time-based Navigation: Handle temporal data if time fields are configured Aggregation Operations: Support grouping and statistical operations Export Functionality: Enable data export based on search results Sources: OpenSearch Dashboards Discover interface capabilities and query processing architecture. Pattern Management and Maintenance Index patterns require ongoing management as data structures evolve. The tutorial demonstrates basic pattern creation, but production environments often need pattern updates and field refresh operations. Key maintenance operations include: Field Refresh: Update field mappings when new fields are added to indices Pattern Modification: Adjust pattern matching rules for new indices Performance Optimization: Configure field settings for optimal query performance Access Control: Manage pattern visibility and permissions The movies dataset provides a stable example for learning these concepts, as the data structure remains consistent throughout the tutorial workflow. Sources: OpenSearch index pattern management best practices and tutorial documentation structure. Dismiss Refresh this wiki Enter email to refresh On this page Index Patterns Purpose and Scope Overview of Index Patterns Index Pattern Creation Workflow Pattern Definition and Configuration Field Mapping and Data Types Integration with Discovery Interface Pattern Management and Maintenance\n",
       "                </div>\n",
       "        \n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\">\n",
       "                <div class=\"result-number\">6</div>\n",
       "                <div class=\"result-title\"></div>\n",
       "            </div>\n",
       "            <div class=\"result-url\">\n",
       "                <strong>üîó Source:</strong> <a href=\"https://opster.com/guides/opensearch/opensearch-data-architecture/index-templating-in-opensearch-how-to-use-composable-templates/\" target=\"_blank\">https://opster.com/guides/opensearch/opensearch-data-architecture/index-templating-in-opensearch-how-to-use-composable-templates/</a>\n",
       "            </div>\n",
       "            <div class=\"result-body\">\n",
       "    \n",
       "                <div class=\"overview\">\n",
       "                    <strong>Overview:</strong><br>\n",
       "                    Product BUILT FOR ELASTICSEARCH AutoOps Prevent & resolve issues, cut down administration time & hardware costs. Community Tools Tools For The Community Check-Up, Search Log Analyzer & OpsGPT Resources Guides Technical guides on Elasticsearch & Opensearch Blog Insights, Opster news, blogs and more Documentation Opster product documentation Error Messages Error Repository About About Our story & vision Login AutoOps Login Contact Login Contact Running self-managed Elasticsearch just got easier. Announcing AutoOps for your clusters. Read the announcement üéâüéâ Opensearch Guides > OpenSearch Data Architecture Elasticsearch Index Templates in OpenSearch ‚Äì How to Use Composable Templates By Opster Expert Team Updated: Jun 28, 2023 | 6 min read Quick links Overview ‚Äì mapping, settings and aliases Index templates ‚Äì composable templates and component templates How to create composable index templates Creating an index Creating component templates Template priority Precedence of templates Summary The source code for this article is available here. Overview An OpenSearch index can be configured through mapping, settings and aliases: Mapping definitions specify the data schema. Settings will set the shard sizing and refresh rates. Aliases are used to give the index alternate names. When we index a document for the first time or create an empty index using the Create Index API, the index will be created with default settings, without data schema and without aliases. These defaults work pretty well in development and testing environments, but we may need to customize our indices for production environments. Working with the default mappings and settings in production might result in poor indexing and search performance. Instantiating indices manually is a tedious and time consuming process. Recreating such indices on every environment is especially impractical if we have an elaborate mapping schema as well as customized settings and aliases. Fortunately, OpenSearch provides us with a tool to automatically apply a predefined configuration when creating indices in the form of index templates. Index templates Index templates allow us to create indices with user defined configuration. An index can pull the configuration from these templates, for example a set number of shards and replicas or field mappings, during its instantiation. A template will be defined with a name pattern and some configuration in it. If the name of the index matches the template‚Äôs naming pattern, the new index will be created with the configuration defined in the template. Types of templates Index templates can be classified into two categories: Index templates (or composabale index templates): The composable index templates can either exist on their own, or can be composed of none or more component templates (see the second category). Component templates: The component template is a reusable template on its own that defines the required configuration. Usually the component template is expected to be associated with an index template. Each of the component templates can be attached with one or many index templates. As you can see in the image below, the index templates A and B share component templates (in this case just one ‚Äì Template 3) between themselves. An index template can consist of none or many component templates and each of the component templates can be associated with none or many index templates. Both types of templates can exist on their own, however component templates are of no use unless they are attached to an index template. The general idea is to develop a catalogue of component templates for an organization to use for various needs (for example, specifying the various component templates for individual environments) and attach them to various indices via the composable index templates. How to create composable (index) templates OpenSearch provides an _index_template endpoint for managing index templates. The user provides all the required mappings, settings, and aliases along with an index name pattern in this template. Let‚Äôs run through an example of creating a template for a microservice application customer-order-service which is responsible for order generation logic. Let‚Äôs say our requirement is to create a template for customer orders, represented with a pattern having wildcards: *orders. This template is expected to have certain mappings and settings, such as the order_date field, as well as shards and replica numbers. Any index that gets matched with this template during its creation inherits the configurations defined in this template. For example a black_friday_orders index will have the order_date field, shards will be set to 5 and the replicas set to 2. In addition to this, all indices created from this template inherit a single alias name, too!Let‚Äôs create this orders_template with an index pattern defined as *orders and with a mapping schema consisting of a single oder_date field with a predefined date format dd-MM-yyyy. The code below shows how to create this index template. PUT _index_template/orders_template\n",
       "{\n",
       "  \"index_patterns\": [\"*orders\"],\n",
       "  \"priority\": 300,\n",
       "  \"template\": {\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"order_date\": {\n",
       "          \"type\": \"date\",\n",
       "          \"format\":\"dd-MM-yyyy\"\n",
       "        }\n",
       "      }\n",
       "    },\n",
       "    \"settings\":{\n",
       "      \"number_of_shards\":5,\n",
       "      \"number_of_replicas\":2\n",
       "    },\n",
       "    \"aliases\":{\n",
       "      \"all_orders\":{}\n",
       "    }\n",
       "  }\n",
       "} When you execute this query in Kibana‚Äôs DevTools, the template is created with the index pattern *orders along with the predefined mapping, settings and an alias. The index_patterns is an array of match patterns; any index matching this pattern will be deriving the template configuration. You can execute the following to retrieve the persisted template that should reiterate what we did: GET _index_template/orders_template There‚Äôs also a priority, a positive number, defined when creating the template attribute defined on the template: every template is defined with a priority so that any conflicting changes from different templates will be resolved by using this value with precedence given to the higher priority value. We‚Äôll dive more deeply into template priority below. Creating an index with the template Now we have a template ‚Äì a blueprint for creating indices ‚Äì the next step is to create an index. When the name of the index matches with the given pattern, the templated configurations are applied automatically. To prove the point, as the code below shows, let‚Äôs create a brand new index named: blackfriday_orders: PUT blackfriday_orders As the name of the index (blackfriday_orders) matches with the naming pattern defined in template (i.e. *orders), the index should get all the configuration derived from the template. Let‚Äôs retrieve this freshly created index and check if this is indeed true by executing the following code: GET blackfriday_orders This should return: {\n",
       "  \"blackfriday_orders\" : {\n",
       "    \"aliases\" : {\n",
       "      \"all_orders\" : { }\n",
       "    },\n",
       "    \"mappings\" : {\n",
       "      \"properties\" : {\n",
       "        \"order_date\" : {\n",
       "          \"type\" : \"date\",\n",
       "          \"format\" : \"dd-MM-yyyy\"\n",
       "        }\n",
       "      }\n",
       "    },\n",
       "    \"settings\" : {\n",
       "      \"index\" : {\n",
       "         ...\n",
       "        \"number_of_shards\" : \"5\",\n",
       "        \"number_of_replicas\" : \"2\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "} As the response indicates, the configuration of the blackfriday_orders has been inherited from the template. We can try with various combinations of the indices that will successfully inherit the templated configuration: PUT blackfriday_orders\n",
       "PUT americaorders\n",
       "PUT cancelled--orders\n",
       "PUT undefined101orders However, the following indices will not be inheriting the configuration as the name will not match with the pattern: PUT blackfriday_orders2\n",
       "PUT open_orders_\n",
       "PUT allorders_total One important thing to remember is that all the indices derived from a template have the same alias ‚Äì all_orders ‚Äì in this case. There is an advantage of having such alias ‚Äì we can simply query on this single alias rather than multiple indices. GET blackfriday_orders,americaorders,undefined101orders/_search\n",
       "GET all_orders/_search \n",
       "{\n",
       "  \"query\": {\n",
       "    \"range\": {\n",
       "      \"order_date\": {\n",
       "        \"gte\": \"01-12-2021\",\n",
       "        \"lte\": \"31-12-2021\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "} While we create a template for *orders, any matching index is expected to adopt the template configuration. Usually, knowingly or unknowingly, teams may create a few more templates for various reasons. This means that at times the index name may match two different template patterns! OpenSearch has to decide which of the configurations from those templates it needs to apply. Fortunately, this dilemma can be solved by using the template priority. Creating component templates We learned about index templates in the earlier part of this article. There are a couple of disadvantages of creating the templates with the configuration built in ‚Äì one such disadvantage being that the configuration is not exportable for other templates. If we wish to have similar configuration, say for customer related templates (*customers), we may have to re-create the whole template. That means, we may be creating dozens of them in a typical organization (plus you may have a few more based on the environments). As we always look forward to reusability, OpenSearch redesigned the templates keeping reusability in mind. The component templates fit that bill. If you are from a DevOps background, most likely you‚Äôd have a requirement to create indices with a preset configuration for each of the environments. Rather than tediously applying each of these configurations manually, you can create a component template for each of the environments. A component template is nothing but a reusable block of configurations that we can use to make up more index templates. Do note that the component templates are of no value unless they are clubbed with index templates. They are exposed via a _component_template endpoint. Let‚Äôs see how this all fits together. Settings template Let‚Äôs extract the settings we defined in our index template earlier and create a component template out of it. The settings_component_template is expected to have five primary shards with two replicas per primary shard. The first step, as the code listing below shows, is to declare and execute a component template with this configuration. PUT _component_template/settings_component_template\n",
       "{\n",
       "  \"template\":{\n",
       "    \"settings\":{\n",
       "      \"number_of_shards\":5,\n",
       "      \"number_of_replicas\":2\n",
       "    }\n",
       "  }\n",
       "} As the code above shows, we use the _component_template endpoint to create a component template. The body of the request holds the template information in a template object. The settings_component_template is now available for use elsewhere in the index templates. One notable difference is that this template does not define any index pattern; it‚Äôs simply a code block that configures some properties for us. Mappings template In the same way, let‚Äôs create another template. This time, let‚Äôs extract the mapping schema we had defined earlier in the standalone index templates. The code below shows the script: PUT _component_template/mappings_component_template\n",
       "{\n",
       "  \"template\": {\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"order_date\": {\n",
       "          \"type\": \"date\",\n",
       "          \"format\":\"dd-MM-yyyy\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "} Aliases template Going with the same flow, we can also have a component template with the aliases ‚Äì two aliases (all_orders and sales_orders): PUT _component_template/aliases_component_template\n",
       "{\n",
       "  \"template\": {\n",
       "    \"aliases\": {\n",
       "      \"all_orders\": {},\n",
       "      \"sales_orders\":{}\n",
       "    }\n",
       "  }\n",
       "} Composable index template Now that we have these three component templates, the next step is to put them to use. We can do this by letting an index template for, say christmas_orders, use it: PUT _index_template/composed_orders_template\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"*orders\"\n",
       "  ],\n",
       "  \"priority\": 500,\n",
       "  \"composed_of\": [\n",
       "    \"settings_component_template\",\n",
       "    \"mappings_component_template\",\n",
       "    \"aliases_component_template\"\n",
       "  ]\n",
       "} The composed_of tag is a collection of all the component templates that make up this template. In this case, we are choosing the settings, mappings and aliases component templates. We are also bumping up the priority so this template trumps any others. Once the template is ready, any indices that match the *orders pattern will inherit the configuration from these three component templates. Having said that, should we wish to create a new template, say customers, with just one of the existing (settings_component_template) and a newly created aliases (aliases_component_template ‚Äì see below) template, we can do so with: PUT _component_template/aliases_component_template2\n",
       "{\n",
       "  \"template\": {\n",
       "    \"aliases\": {\n",
       "      \"all_customers\": {}\n",
       "    }\n",
       "  }\n",
       "} The index template goes like this: PUT _index_template/composed_customers_template\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"*customers*\"\n",
       "  ],\n",
       "  \"priority\": 200,\n",
       "  \"composed_of\": [\n",
       "    \"settings_component_template\",\n",
       "    \"aliases_component_template2\"\n",
       "  ]\n",
       "} Did you see that the settings_component_template has been (re)used across two different templates? That is the power of component templates. Template priority There is a chance that developers may create multiple index templates without looking at the existing stock. It is important to set a priority on each of these templates so the one with higher priority will be used. For example, the my_orders_template_1 overrides the my_orders_template_2 in the following code snippet: PUT _index_template/my_orders_template_1\n",
       "{\n",
       "  \"index_patterns\": [\"*orders\"],\n",
       "  \"priority\": 1000,\n",
       "  \"template\": { ... }\n",
       "}\n",
       "PUT _index_template/my_orders_template2\n",
       "{\n",
       "  \"index_patterns\": [\"*orders\"],\n",
       "  \"priority\": 300,\n",
       "  \"template\": { ... }\n",
       "} When you have multiple templates matching the indices that are being created, OpenSearch applies all the configurations from all matching templates but overrides anything that has higher priority. Precedence of templates Finally, you may be wondering about the precedence of the templates ‚Äì does the configuration defined in the component template override the one defined on the main index template itself? Or the other way around? Well, there are some rules: An index created with configurations explicitly takes precedence over everything ‚Äì this means if you create an index with explicit configuration, don‚Äôt expect them to be overridden by the templates. Summary An index contains mappings, settings and aliases: the mappings define the fields schema, settings set the index parameters such as number of shards and replicas, and aliases give alternate names to the index. Templates allow us to create indices with predefined configurations. Naming an index with a name that matches the index-pattern defined in a specific template will automatically configure that index according to the template. The composable templates consist of none or more component templates. An index template can have its own configuration defined too. A component template is a reusable template with predefined configuration, just like a composable index template. However, component templates are expected to be part of an index template; They are useless if they are not ‚Äúcomposed‚Äù into an index template. Component templates have no index pattern defined in them ‚Äì which is another reason they are ‚Äúexpected‚Äù to be part of an index template. Each of the templates has a priority ‚Äì a positive number. The higher the number, the greater the precedence for that template to be applied. Related Articles 3 Pagination Techniques in Elasticsearch Elasticsearch Large Cluster State - How to Discover & Prevent Backblaze Optimized OpenSearch Back to all articles Product AutoOps for Elasticsearch Community Tools Tools for the Community Company About Our Customers info@opster.com Resources Documentation Blog Guides Elasticsearch Error Messages Elasticsearch Log Errors Taking Care of Your Entire Search Operation. Opster‚Äôs solutions reduce the time and cost of running Elasticsearch. Get Improved performance & stability with less hardware. Contact Us ¬© 2025 Opster Privacy Policy Terms of Use We use cookies to ensure that we give you the best experience on our website. By continuing to browse this site, you agree to our Privacy Policy and Terms of Use. Agree Close GDPR Cookie Settings Privacy Overview Strictly Necessary Cookies Powered by GDPR Cookie Compliance Privacy Overview This website uses cookies so that we can provide you with the best user experience possible. Cookie information is stored in your browser and performs functions such as recognising you when you return to our website and helping our team to understand which sections of the website you find most interesting and useful. Strictly Necessary Cookies Strictly Necessary Cookie should be enabled at all times so that we can save your preferences for cookie settings. Enable or Disable Cookies Enabled Disabled Enable All Save Settings\n",
       "                </div>\n",
       "        \n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\">\n",
       "                <div class=\"result-number\">7</div>\n",
       "                <div class=\"result-title\">Link Search Menu Expand Document Documentation Menu</div>\n",
       "            </div>\n",
       "            <div class=\"result-url\">\n",
       "                <strong>üîó Source:</strong> <a href=\"https://docs.opensearch.org/latest/im-plugin/index-templates/\" target=\"_blank\">https://docs.opensearch.org/latest/im-plugin/index-templates/</a>\n",
       "            </div>\n",
       "            <div class=\"result-body\">\n",
       "    \n",
       "                <div class=\"overview\">\n",
       "                    <strong>Overview:</strong><br>\n",
       "                    Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards ‚Üê Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Regular expression syntax Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Using UBI in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Index templates Index templates let you initialize new indexes with predefined mappings and settings. For example, if you continuously index log data, you can define an index template so that all of these indexes have the same number of shards and replicas. Create a template To create an index template, use a PUT or POST request: PUT _index_template/<template name>\n",
       "POST _index_template/<template name>\n",
       " This command creates a template named daily_logs and applies it to any new index whose name matches the pattern logs-2020-01-* and also adds it to the my_logs alias: PUT _index_template/daily_logs\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"logs-2020-01-*\"\n",
       "  ],\n",
       "  \"template\": {\n",
       "    \"aliases\": {\n",
       "      \"my_logs\": {}\n",
       "    },\n",
       "    \"settings\": {\n",
       "      \"number_of_shards\": 2,\n",
       "      \"number_of_replicas\": 1\n",
       "    },\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"timestamp\": {\n",
       "          \"type\": \"date\",\n",
       "          \"format\": \"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\"\n",
       "        },\n",
       "        \"value\": {\n",
       "          \"type\": \"double\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       " You should see the following response: {\n",
       "  \"acknowledged\": true\n",
       "}\n",
       " If you create an index named logs-2020-01-01, you can see that it has the mappings and settings from the template: PUT logs-2020-01-01\n",
       "GET logs-2020-01-01\n",
       " {\n",
       "  \"logs-2020-01-01\": {\n",
       "    \"aliases\": {\n",
       "      \"my_logs\": {}\n",
       "    },\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"timestamp\": {\n",
       "          \"type\": \"date\",\n",
       "          \"format\": \"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\"\n",
       "        },\n",
       "        \"value\": {\n",
       "          \"type\": \"double\"\n",
       "        }\n",
       "      }\n",
       "    },\n",
       "    \"settings\": {\n",
       "      \"index\": {\n",
       "        \"creation_date\": \"1578107970779\",\n",
       "        \"number_of_shards\": \"2\",\n",
       "        \"number_of_replicas\": \"1\",\n",
       "        \"uuid\": \"U1vMDMOHSAuS2IzPcPHpOA\",\n",
       "        \"version\": {\n",
       "          \"created\": \"7010199\"\n",
       "        },\n",
       "        \"provided_name\": \"logs-2020-01-01\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Any additional indexes that match this pattern‚Äîlogs-2020-01-02, logs-2020-01-03, and so on‚Äîwill inherit the same mappings and settings. Index patterns cannot contain any of the following characters: :, \", +, /, \\, |, ?, #, >, and <. Retrieve a template To list all index templates: GET _cat/templates\n",
       "GET /_index_template\n",
       " To find a template by its name: GET _index_template/daily_logs\n",
       " To get a list of all templates that match a pattern: GET _index_template/daily*\n",
       " To check if a specific template exists: HEAD _index_template/<name>\n",
       " Configure multiple templates You can create multiple index templates for your indexes. If the index name matches more than one template, OpenSearch takes the mappings and settings from the template with the highest priority and applies it to the index. For example, say you have the following two templates that both match the logs-2020-01-02 index and there‚Äôs a conflict in the number_of_shards field: Template 1 PUT _index_template/template-01\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"logs*\"\n",
       "  ],\n",
       "  \"priority\": 0,\n",
       "  \"template\": {\n",
       "    \"settings\": {\n",
       "      \"number_of_shards\": 2,\n",
       "      \"number_of_replicas\": 2\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Template 2 PUT _index_template/template-02\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"logs-2020-01-*\"\n",
       "  ],\n",
       "  \"priority\": 1,\n",
       "  \"template\": {\n",
       "    \"settings\": {\n",
       "      \"number_of_shards\": 3\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Because template-02 has a higher priority value, it takes precedence over template-01 . The logs-2020-01-02 index would have the number_of_shards value as 3 and the number_of_replicas as the default value 1. Delete a template You can delete an index template using its name: DELETE _index_template/daily_logs\n",
       " Composable index templates Managing multiple index templates has the following challenges: If you have duplication between index templates, storing these index templates results in a bigger cluster state. If you want to make a change across all your index templates, you have to manually make the change for each template. You can use composable index templates to overcome these challenges. Composable index templates let you abstract common settings, mappings, and aliases into a reusable building block called a component template. You can combine component templates to compose an index template. Settings and mappings that you specify directly in the create index request override any settings or mappings specified in an index template and its component templates. Create a component template Let‚Äôs define two component templates‚Å†‚Äîcomponent_template_1 and component_template_2: Component template 1 PUT _component_template/component_template_1\n",
       "{\n",
       "  \"template\": {\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"@timestamp\": {\n",
       "          \"type\": \"date\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Component template 2 PUT _component_template/component_template_2\n",
       "{\n",
       "  \"template\": {\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"ip_address\": {\n",
       "          \"type\": \"ip\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Use component templates to create an index template When creating index templates, you need to include the component templates in a composed_of list. OpenSearch applies the component templates in the order in which you specify them within the index template. The settings, mappings, and aliases that you specify inside the index template are applied last. PUT _index_template/daily_logs\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"logs-2020-01-*\"\n",
       "  ],\n",
       "  \"template\": {\n",
       "    \"aliases\": {\n",
       "      \"my_logs\": {}\n",
       "    },\n",
       "    \"settings\": {\n",
       "      \"number_of_shards\": 2,\n",
       "      \"number_of_replicas\": 1\n",
       "    },\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"timestamp\": {\n",
       "          \"type\": \"date\",\n",
       "          \"format\": \"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\"\n",
       "        },\n",
       "        \"value\": {\n",
       "          \"type\": \"double\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  },\n",
       "  \"priority\": 200,\n",
       "  \"composed_of\": [\n",
       "    \"component_template_1\",\n",
       "    \"component_template_2\"\n",
       "  ],\n",
       "  \"version\": 3,\n",
       "  \"_meta\": {\n",
       "    \"description\": \"using component templates\"\n",
       "  }\n",
       "}\n",
       " If you create an index named logs-2020-01-01, you can see that it derives its mappings and settings from both the component templates: PUT logs-2020-01-01\n",
       "GET logs-2020-01-01\n",
       " Example response {\n",
       "  \"logs-2020-01-01\": {\n",
       "    \"aliases\": {\n",
       "      \"my_logs\": {}\n",
       "    },\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"@timestamp\": {\n",
       "          \"type\": \"date\"\n",
       "        },\n",
       "        \"ip_address\": {\n",
       "          \"type\": \"ip\"\n",
       "        },\n",
       "        \"timestamp\": {\n",
       "          \"type\": \"date\",\n",
       "          \"format\": \"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\"\n",
       "        },\n",
       "        \"value\": {\n",
       "          \"type\": \"double\"\n",
       "        }\n",
       "      }\n",
       "    },\n",
       "    \"settings\": {\n",
       "      \"index\": {\n",
       "        \"creation_date\": \"1625382479459\",\n",
       "        \"number_of_shards\": \"2\",\n",
       "        \"number_of_replicas\": \"1\",\n",
       "        \"uuid\": \"rYUlpOXDSUSuZifQLPfa5A\",\n",
       "        \"version\": {\n",
       "          \"created\": \"7100299\"\n",
       "        },\n",
       "        \"provided_name\": \"logs-2020-01-01\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Index template options You can specify the following template options: Option Type Description Required template Object Specify index settings, mappings, and aliases. No priority Integer The priority of the index template. No composed_of String array The names of component templates applied on a new index together with the current template. No version Integer Specify a version number to simplify template management. Default is null. No _meta Object Specify meta information about the template. No Create a template Retrieve a template Configure multiple templates Delete a template Create a component template Use component templates to create an index template WAS THIS PAGE HELPFUL? ‚úî Yes ‚úñ No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright ¬© OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\n",
       "                </div>\n",
       "        \n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\">\n",
       "                <div class=\"result-number\">8</div>\n",
       "                <div class=\"result-title\"></div>\n",
       "            </div>\n",
       "            <div class=\"result-url\">\n",
       "                <strong>üîó Source:</strong> <a href=\"https://stackoverflow.com/questions/71816340/how-to-create-an-index-pattern-in-opensearch-using-api\" target=\"_blank\">https://stackoverflow.com/questions/71816340/how-to-create-an-index-pattern-in-opensearch-using-api</a>\n",
       "            </div>\n",
       "            <div class=\"result-body\">\n",
       "    \n",
       "                <div class=\"overview\">\n",
       "                    <strong>Overview:</strong><br>\n",
       "                    Skip to main content Stack Overflow About Products For Teams Stack Overflow for Teams Where developers & technologists share private knowledge with coworkers Advertising Reach devs & technologists worldwide about your product, service or employer brand Knowledge Solutions Data licensing offering for businesses to build and improve AI tools and models Labs The future of collective knowledge sharing About the company Visit the blog Loading‚Ä¶ current community Stack Overflow help chat Meta Stack Overflow your communities Sign up or log in to customize your list. more stack exchange communities company blog Log in Sign up Home Questions AI Assist Labs Tags Challenges Chat Articles Users Jobs Companies Collectives Communities for your favorite technologies. Explore all Collectives Teams Ask questions, find answers and collaborate at work with Stack Overflow for Teams. Try Teams for free Explore Teams Teams Ask questions, find answers and collaborate at work with Stack Overflow for Teams. Explore Teams Collectives‚Ñ¢ on Stack Overflow Find centralized, trusted content and collaborate around the technologies you use most. Learn more about Collectives Teams Q&A for work Connect and share knowledge within a single location that is structured and easy to search. Learn more about Teams How to create an index pattern in Opensearch using API? Ask Question Asked 3 years, 7 months ago Modified 11 months ago Viewed 15k times Part of AWS Collective 5 I want to create an index pattern using Opensearch API. I tried to replicate what could be made graphically in the following image window, using as index pattern name cwl-* and then as time field @timestamp. My domain has OpenSearch 1.2 installed. Using curl (directly modifiend the command in kibana doc): curl -u '****:*****' -X POST \"https://******.eu-central-1.es.amazonaws.com/api/index_patterns/index_pattern\" -H 'osd-xsrf: true' -H 'Content-Type: application/json' -d'\n",
       "{\n",
       "  \"index_pattern\": {\n",
       "     \"title\": \"cwl-*\",\n",
       "     \"timeFieldName\": \"@timestamp\"\n",
       "  }\n",
       "}'\n",
       " but I receive {\"error\":{\"root_cause\":[{\"type\":\"illegal_argument_exception\",\"reason\":\"Rejecting mapping update to [api] as the final mapping would have more than 1 type: [_doc, index_patterns]\"}],\"type\":\"illegal_argument_exception\",\"reason\":\"Rejecting mapping update to [api] as the final mapping would have more than 1 type: [_doc, index_patterns]\"},\"status\":400}\n",
       " amazon-web-services shell aws-elasticsearch opensearch Share Improve this question Follow edited Apr 10, 2022 at 17:50 asked Apr 10, 2022 at 11:54 Dresult 30311 gold badge22 silver badges1212 bronze badges 9 Are you using any sort of IAM authentication? Ermiya Eskandary ‚Äì Ermiya Eskandary 2022-04-10 15:58:49 +00:00 Commented Apr 10, 2022 at 15:58 @ErmiyaEskandary just the Fine-grained access control but it works because I don't have any problem in performing other requests... Dresult ‚Äì Dresult 2022-04-10 16:01:55 +00:00 Commented Apr 10, 2022 at 16:01 Ahhhhhh - remove saved_objects from your URL. Ermiya Eskandary ‚Äì Ermiya Eskandary 2022-04-10 16:10:33 +00:00 Commented Apr 10, 2022 at 16:10 @ErmiyaEskandary Unfortunately I had already tried, it says {\"statusCode\":404,\"error\":\"Not Found\",\"message\":\"Not Found\"} Dresult ‚Äì Dresult 2022-04-10 16:13:39 +00:00 Commented Apr 10, 2022 at 16:13 Your URL is somehow wrong - I don't have docs in front of me right now but try removing _dashboards from the URL and if that doesn't work, also remove api Ermiya Eskandary ‚Äì Ermiya Eskandary 2022-04-10 16:17:22 +00:00 Commented Apr 10, 2022 at 16:17 | Show 4 more comments 3 Answers 3 Sorted by: Reset to default Highest score (default) Trending (recent votes count more) Date modified (newest first) Date created (oldest first) 3 Tested with the latest OpenSearch version 2.18.0. To simply create an index pattern via the API, a POST request should be used:     curl -XPOST \"http://localhost:5601/api/saved_objects/index-pattern\" \\\n",
       "-u \"user:pass\" \\\n",
       "-H 'osd-xsrf: true' \\\n",
       "-H 'Content-Type: application/json' \\\n",
       "-d ' \n",
       "{\n",
       "  \"attributes\": {\n",
       "    \"title\": \"pattern-*\",\n",
       "    \"timeFieldName\": \"@timestamp\"\n",
       "  }\n",
       "}'\n",
       " If you want to create an OpenSearch index pattern with a specific ID, you can generate it or copy it from another source (in my case, I copied the ID of the missing pattern from the broken Dashboard) and include it as part of the request: curl -XPOST \"http://localhost:5601/api/saved_objects/index-pattern/90bd9a00-ad57-41a0-b16a-b134a8c51e98\" \\\n",
       "-u \"user:pass\" \\\n",
       "-H 'osd-xsrf: true' \\\n",
       "-H 'Content-Type: application/json' \\\n",
       "-d ' \n",
       "{\n",
       "  \"attributes\": {\n",
       "    \"title\": \"pattern-*\",\n",
       "    \"timeFieldName\": \"@timestamp\"\n",
       "  }\n",
       "}'\n",
       " If you need to update existing index pattern, a PUT request should be used, with existing ID: curl -XPUT \"http://localhost:5601/api/saved_objects/index-pattern/90bd9a00-ad57-41a0-b16a-b134a8c51e98\" \\\n",
       "-u \"user:pass\" \\\n",
       "-H 'osd-xsrf: true' \\\n",
       "-H 'Content-Type: application/json' \\\n",
       "-d ' \n",
       "{\n",
       "  \"attributes\": {\n",
       "    \"title\": \"pattern-*\",\n",
       "    \"timeFieldName\": \"@timestamp\"\n",
       "  }\n",
       "}'\n",
       " Share Improve this answer Follow answered Nov 26, 2024 at 21:35 nmishin 3,20255 gold badges2222 silver badges3737 bronze badges Sign up to request clarification or add additional context in comments. Comments Add a comment 1 curl -u '****:*****' -X POST \"https://******.eu-central-1.es.amazonaws.com/api/index_patterns/cwl-*\" -H 'osd-xsrf: true' -H 'Content-Type: application/json' -d'\n",
       "{\n",
       "  \"index_pattern\": {\n",
       "     \"title\": \"cwl-*\",\n",
       "     \"timeFieldName\": \"@timestamp\"\n",
       "  }\n",
       "}'\n",
       " change api/index_patterns/index_pattern to api/index_patterns/cwl-* and try again? Share Improve this answer Follow answered Apr 14, 2022 at 8:33 doge76 2122 bronze badges 4 Comments Add a comment Dresult Dresult Over a year ago It works in a sense that the command creates something but I cannot see anything among saved objects and seams that in this way only an index which name is \"api\" is created not an index pattern therefore each time I access the dashboard, once it finds data, it ask me if I want to create it. 2022-04-15T11:15:21.423Z+00:00 0 Reply Copy link doge76 doge76 Over a year ago if you want the index-pattern to be global, try to add this attribute in header: securitytenant: \"global\"? 2022-04-15T12:03:44.13Z+00:00 0 Reply Copy link Dresult Dresult Over a year ago already done, I've added -H 'securitytenant: global' to the curl string 2022-04-15T13:56:58.873Z+00:00 0 Reply Copy link Kasami Kasami Over a year ago @Dresult Did you ever manage to figure this out? I am encountering the same issue, it seems. 2022-10-10T22:50:32.3Z+00:00 2 Reply Copy link Add a comment 0 It worked for me in OpenSearch 1.3 when I added an ID in the URI and used saved_objects instead of index_patterns. So your cURL-request should work when looking like this. curl -u '****:*****' -X POST \"https://<opensearch-dashboards-host>.eu-central-1.es.amazonaws.com/api/saved_objects/index-pattern/<ID>\" \n",
       "-H 'osd-xsrf: true' \n",
       "-H 'Content-Type: application/json' \n",
       "-d \n",
       "   '{\n",
       "      \"index_pattern\": {\n",
       "         \"title\": \"cwl-*\",\n",
       "         \"timeFieldName\": \"@timestamp\"\n",
       "      }\n",
       "    }'\n",
       " Share Improve this answer Follow edited Dec 16, 2022 at 13:09 answered Aug 25, 2022 at 8:51 mgr110 111 bronze badge 3 Comments Add a comment K.Thanvi K.Thanvi Over a year ago I am getting no handler found for uri [/api/saved_objects/index-pattern/cwl-*] and method [POST] error for this.. using opensearch1.3. 2022-12-14T17:09:27.72Z+00:00 0 Reply Copy link mgr110 mgr110 Over a year ago @K.Thanvi This is probably because you are sending the request to the OpenSearch-host. The request is meant to be sent to the OpenSearch Dashboards-host (or Kibana-host if you use that). Using the Dev Tools will send the request to the OpenSearch-host. 2022-12-15T11:44:04.903Z+00:00 1 Reply Copy link K.Thanvi K.Thanvi Over a year ago Thanks! Yes that was the issue. i had to send the request to my <opensearch_domain>/_dashboards/api/saved_objects/index-pattern endpoint. 2023-01-09T17:07:40.23Z+00:00 1 Reply Copy link Add a comment Your Answer Thanks for contributing an answer to Stack Overflow! Please be sure to answer the question. Provide details and share your research! But avoid ‚Ä¶ Asking for help, clarification, or responding to other answers. Making statements based on opinion; back them up with references or personal experience. To learn more, see our tips on writing great answers. Draft saved Draft discarded Sign up or log in Sign up using Google Sign up using Email and Password Submit Post as a guest Name Email Required, but never shown Post as a guest Name Email Required, but never shown Post Your Answer Discard By clicking ‚ÄúPost Your Answer‚Äù, you agree to our terms of service and acknowledge you have read our privacy policy. Start asking to get answers Find the answer to your question by asking. Ask question Explore related questions amazon-web-services shell aws-elasticsearch opensearch See similar questions with these tags. AWS Collective See more This question is in a collective: a subcommunity defined by tags with relevant content and experts. The Overflow Blog The AI ick Revealing the unknown unknowns in your software Featured on Meta Results of the October 2025 Community Asks Sprint: copy button for code... Chat room owners can now establish room guidelines Policy: Generative AI (e.g., ChatGPT) is banned Opinion-based questions alpha experiment on Stack Overflow Related 1 Create Index - Elastic Search - Java API 14 Create index in Elastic Search by Java API 0 How to do an automated index creation at ElasticSearch? 21 How to configure index pattern in Kibana 2 How does one create an Index Pattern in Kibana? 3 Is there API based method to create an index pattern in Kibana if its index is present in ES 0 How to create new index pattern with custom pattern ID from the elastic API? 1 How to create Index pattern using API and Index Name 0 How to create an ElasticSearch Index as curl 0 How to create index pattern in elastic seach programmatically Hot Network Questions What is the earliest work of SF to mention a concern about time travel causing unintended space travel Why do we chase after things which make us happy? When did Soviet industrial planners start tooling for tank production? Shall I change my supervisor, who is nearing retirement? Sum of a sequence What is the most humane way to kill humans for meat? Is it possible to increase the rotation of a black hole without increasing the mass? Check whether saddle point or not What is a \"Squitchen\"? Urysohn's Lemma with compact sets and uniformly continuous function Why does John 2:13 mention Passover as a Jewish festival? Necessity of `typename` for naming of local nested classes in function templates how to make tar stop after reading or listing a few first files from a big tarball? how to pull with the hinge How to reply to \"How are you?\" How to replace wood strip part of threshold? Bracket covers sum limits using mathclap environment Agatha Christie - Hercule Poirot short story or novel Should I kill a companion or would that be frowned upon at the table? Why do we still say ‚ÄúIt is gone‚Äù but not ‚ÄúYou are come‚Äù? Hat-trick is for three, what's the word for four consecutive successes? How do I enable File and Printer sharing in latest Windows 11 InsertOnlyHashSet in C++ What is the correct orientation of the connecting tab on a bathroom sink stopper? more hot questions Question feed Subscribe to RSS Question feed To subscribe to this RSS feed, copy and paste this URL into your RSS reader. lang-bash Stack Overflow Questions Help Chat Products Teams Advertising Talent Company About Press Work Here Legal Privacy Policy Terms of Service Contact Us Your Privacy Choices Cookie Policy Stack Exchange Network Technology Culture & recreation Life & arts Science Professional Business API Data Blog Facebook Twitter LinkedIn Instagram Site design / logo ¬© 2025 Stack Exchange Inc; user contributions licensed under CC BY-SA . rev 2025.11.7.36544\n",
       "                </div>\n",
       "        \n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\">\n",
       "                <div class=\"result-number\">9</div>\n",
       "                <div class=\"result-title\">Link Search Menu Expand Document Documentation Menu</div>\n",
       "            </div>\n",
       "            <div class=\"result-url\">\n",
       "                <strong>üîó Source:</strong> <a href=\"https://docs.opensearch.org/latest/dashboards/management/management-index/\" target=\"_blank\">https://docs.opensearch.org/latest/dashboards/management/management-index/</a>\n",
       "            </div>\n",
       "            <div class=\"result-body\">\n",
       "    \n",
       "                <div class=\"overview\">\n",
       "                    <strong>Overview:</strong><br>\n",
       "                    Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards ‚Üê Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Regular expression syntax Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Using UBI in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Dashboards Management Introduced 2.10 Dashboards Management is the central hub for managing and customizing OpenSearch data directly within OpenSearch Dashboards. OpenSearch and OpenSearch Dashboards permissions govern access to individual features. If you do not have the appropriate access permissions, consult your administrator. Applications You can access the following applications in Dashboards Management: Index Patterns: To access OpenSearch data, you need to create an index pattern so that you can select the data you want to use and define the properties of the fields. The Index Pattern tool gives you the ability to create an index pattern from within the UI. Index patterns point to one or more indexes, data streams, or index aliases. Data Sources: The Data Sources tool is used to configure and manage the data sources that OpenSearch uses to collect and analyze data. You can use the tool to specify the source configuration in your copy of the OpenSearch Dashboards configuration file. Saved Objects: The Saved Objects tool helps you organize and manage your saved objects. Saved objects are files that store data, such as dashboards, visualizations, and maps, for later use. Advanced Settings: The Advanced Settings tool gives you the flexibility to personalize the behavior of OpenSearch Dashboards. The tool is divided into settings sections, such as General, Accessibility, and Notifications, and you can use it to customize and optimize many of your Dashboards settings. Related documentation Index patterns Advanced settings Access control lists for saved objects Applications WAS THIS PAGE HELPFUL? ‚úî Yes ‚úñ No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright ¬© OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\n",
       "                </div>\n",
       "        \n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\">\n",
       "                <div class=\"result-number\">10</div>\n",
       "                <div class=\"result-title\">Link Search Menu Expand Document Documentation Menu</div>\n",
       "            </div>\n",
       "            <div class=\"result-url\">\n",
       "                <strong>üîó Source:</strong> <a href=\"https://docs.opensearch.org/latest/api-reference/index-apis/create-index/\" target=\"_blank\">https://docs.opensearch.org/latest/api-reference/index-apis/create-index/</a>\n",
       "            </div>\n",
       "            <div class=\"result-body\">\n",
       "    \n",
       "                <div class=\"overview\">\n",
       "                    <strong>Overview:</strong><br>\n",
       "                    Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards ‚Üê Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Regular expression syntax Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Using UBI in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Index APIs Core index APIs Create index Create Index API Introduced 1.0 While you can create an index by using a document as a base, you can also create an empty index for later use. When creating an index, you can specify its mappings, settings, and aliases. Endpoints PUT <index>\n",
       " Index naming restrictions OpenSearch indexes have the following naming restrictions: All letters must be lowercase. Index names can‚Äôt begin with underscores (_) or hyphens (-). Index names can‚Äôt contain spaces, commas, or the following characters: :, \", *, +, /, \\, |, ?, #, >, or < Path parameters Parameter Data type Description index String The index name. Must conform to the index naming restrictions. Required. Query parameters You can include the following query parameters in your request. All parameters are optional. Parameter Type Description wait_for_active_shards String Specifies the number of active shards that must be available before OpenSearch processes the request. Default is 1 (only the primary shard). Set to all or a positive integer. Values greater than 1 require replicas. For example, if you specify a value of 3, the index must have two replicas distributed across two additional nodes for the request to succeed. cluster_manager_timeout Time How long to wait for a connection to the cluster manager node. Default is 30s. timeout Time How long to wait for the request to return. Default is 30s. Request body As part of your request, you can optionally specify index settings, mappings, aliases, and index context. Example request REST Python PUT /sample-index1\n",
       "{\n",
       "  \"settings\": {\n",
       "    \"index\": {\n",
       "      \"number_of_shards\": 2,\n",
       "      \"number_of_replicas\": 1\n",
       "    }\n",
       "  },\n",
       "  \"mappings\": {\n",
       "    \"properties\": {\n",
       "      \"age\": {\n",
       "        \"type\": \"integer\"\n",
       "      }\n",
       "    }\n",
       "  },\n",
       "  \"aliases\": {\n",
       "    \"sample-alias1\": {}\n",
       "  }\n",
       "} Copy Copy as cURL response = client.indices.create(\n",
       "  index = \"sample-index1\",\n",
       "  body =   {\n",
       "    \"settings\": {\n",
       "      \"index\": {\n",
       "        \"number_of_shards\": 2,\n",
       "        \"number_of_replicas\": 1\n",
       "      }\n",
       "    },\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"age\": {\n",
       "          \"type\": \"integer\"\n",
       "        }\n",
       "      }\n",
       "    },\n",
       "    \"aliases\": {\n",
       "      \"sample-alias1\": {}\n",
       "    }\n",
       "  }\n",
       ") Copy Endpoints Index naming restrictions Path parameters Query parameters Request body Example request WAS THIS PAGE HELPFUL? ‚úî Yes ‚úñ No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright ¬© OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\n",
       "                </div>\n",
       "        \n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "    </div>\n",
       "</div>\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parse and display all content blocks in HTML format\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Extract all items from the response\n",
    "all_items = json.loads(response['inference_results'][0]['output'][0]['result'])['items']\n",
    "\n",
    "# Prepare query text\n",
    "query_text = parameters.get('question', 'N/A')\n",
    "query_display = query_text[:50] + '...' if len(query_text) > 50 else query_text\n",
    "\n",
    "# Create comprehensive HTML output with better styling\n",
    "html_output = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "    * {\n",
    "        box-sizing: border-box;\n",
    "    }\n",
    "    \n",
    "    .html-container {\n",
    "        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;\n",
    "        max-width: 1000px;\n",
    "        margin: 0 auto;\n",
    "        color: #333;\n",
    "        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);\n",
    "        padding: 30px 20px;\n",
    "    }\n",
    "    \n",
    "    .header {\n",
    "        text-align: center;\n",
    "        margin-bottom: 40px;\n",
    "        color: #2c3e50;\n",
    "    }\n",
    "    \n",
    "    .header h1 {\n",
    "        font-size: 32px;\n",
    "        margin: 0 0 10px 0;\n",
    "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "        -webkit-background-clip: text;\n",
    "        -webkit-text-fill-color: transparent;\n",
    "    }\n",
    "    \n",
    "    .stats {\n",
    "        background: white;\n",
    "        padding: 20px;\n",
    "        border-radius: 8px;\n",
    "        margin-bottom: 30px;\n",
    "        box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n",
    "        display: flex;\n",
    "        gap: 20px;\n",
    "        flex-wrap: wrap;\n",
    "    }\n",
    "    \n",
    "    .stat-item {\n",
    "        flex: 1;\n",
    "        min-width: 200px;\n",
    "    }\n",
    "    \n",
    "    .stat-label {\n",
    "        font-size: 12px;\n",
    "        color: #7f8c8d;\n",
    "        text-transform: uppercase;\n",
    "        font-weight: bold;\n",
    "        margin-bottom: 5px;\n",
    "    }\n",
    "    \n",
    "    .stat-value {\n",
    "        font-size: 20px;\n",
    "        color: #2c3e50;\n",
    "        font-weight: bold;\n",
    "    }\n",
    "    \n",
    "    .results-container {\n",
    "        display: grid;\n",
    "        gap: 25px;\n",
    "    }\n",
    "    \n",
    "    .result-card {\n",
    "        background: white;\n",
    "        border-radius: 12px;\n",
    "        overflow: hidden;\n",
    "        box-shadow: 0 4px 15px rgba(0,0,0,0.1);\n",
    "        transition: transform 0.3s ease, box-shadow 0.3s ease;\n",
    "    }\n",
    "    \n",
    "    .result-card:hover {\n",
    "        transform: translateY(-5px);\n",
    "        box-shadow: 0 8px 25px rgba(0,0,0,0.15);\n",
    "    }\n",
    "    \n",
    "    .result-header {\n",
    "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "        color: white;\n",
    "        padding: 20px;\n",
    "        display: flex;\n",
    "        align-items: center;\n",
    "        gap: 15px;\n",
    "    }\n",
    "    \n",
    "    .result-number {\n",
    "        background: rgba(255,255,255,0.2);\n",
    "        width: 40px;\n",
    "        height: 40px;\n",
    "        border-radius: 50%;\n",
    "        display: flex;\n",
    "        align-items: center;\n",
    "        justify-content: center;\n",
    "        font-weight: bold;\n",
    "        font-size: 16px;\n",
    "        flex-shrink: 0;\n",
    "    }\n",
    "    \n",
    "    .result-title {\n",
    "        flex: 1;\n",
    "        font-size: 18px;\n",
    "        font-weight: bold;\n",
    "    }\n",
    "    \n",
    "    .result-url {\n",
    "        background: white;\n",
    "        padding: 15px 20px;\n",
    "        border-bottom: 1px solid #ecf0f1;\n",
    "        color: #3498db;\n",
    "        text-decoration: none;\n",
    "        font-size: 12px;\n",
    "        word-break: break-all;\n",
    "        font-family: 'Courier New', monospace;\n",
    "    }\n",
    "    \n",
    "    .result-url a {\n",
    "        color: #3498db;\n",
    "        text-decoration: none;\n",
    "    }\n",
    "    \n",
    "    .result-url a:hover {\n",
    "        text-decoration: underline;\n",
    "    }\n",
    "    \n",
    "    .result-body {\n",
    "        padding: 25px;\n",
    "    }\n",
    "    \n",
    "    .overview {\n",
    "        background: #f8f9fa;\n",
    "        padding: 15px;\n",
    "        border-radius: 6px;\n",
    "        margin-bottom: 20px;\n",
    "        border-left: 4px solid #667eea;\n",
    "        font-size: 14px;\n",
    "        line-height: 1.7;\n",
    "        color: #555;\n",
    "    }\n",
    "    \n",
    "    .steps-container {\n",
    "        display: grid;\n",
    "        gap: 15px;\n",
    "    }\n",
    "    \n",
    "    .step {\n",
    "        border-left: 4px solid #764ba2;\n",
    "        padding-left: 15px;\n",
    "        padding-top: 10px;\n",
    "        padding-bottom: 10px;\n",
    "    }\n",
    "    \n",
    "    .step-title {\n",
    "        font-weight: bold;\n",
    "        color: #764ba2;\n",
    "        font-size: 15px;\n",
    "        margin-bottom: 8px;\n",
    "        display: flex;\n",
    "        align-items: center;\n",
    "        gap: 8px;\n",
    "    }\n",
    "    \n",
    "    .step-number {\n",
    "        display: inline-block;\n",
    "        background: #764ba2;\n",
    "        color: white;\n",
    "        width: 24px;\n",
    "        height: 24px;\n",
    "        border-radius: 50%;\n",
    "        display: flex;\n",
    "        align-items: center;\n",
    "        justify-content: center;\n",
    "        font-size: 12px;\n",
    "        font-weight: bold;\n",
    "    }\n",
    "    \n",
    "    .step-content {\n",
    "        color: #555;\n",
    "        font-size: 13px;\n",
    "        line-height: 1.8;\n",
    "    }\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "<div class=\"html-container\">\n",
    "    <div class=\"header\">\n",
    "        <h1>üåê Web Search Results</h1>\n",
    "        <p>Comprehensive detailed view of all search results</p>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"stats\">\n",
    "        <div class=\"stat-item\">\n",
    "            <div class=\"stat-label\">üìä Total Results</div>\n",
    "            <div class=\"stat-value\">\"\"\" + str(len(all_items)) + \"\"\"</div>\n",
    "        </div>\n",
    "        <div class=\"stat-item\">\n",
    "            <div class=\"stat-label\">‚ùì Query</div>\n",
    "            <div class=\"stat-value\">\"\"\" + query_display + \"\"\"</div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"results-container\">\n",
    "\"\"\"\n",
    "\n",
    "# Parse and display each result\n",
    "for idx, item in enumerate(all_items, 1):\n",
    "    title = item.get('title', 'No Title')\n",
    "    url = item.get('url', 'No URL')\n",
    "    content = item.get('content', 'No Content')\n",
    "    \n",
    "    html_output += f\"\"\"\n",
    "        <div class=\"result-card\">\n",
    "            <div class=\"result-header\">\n",
    "                <div class=\"result-number\">{idx}</div>\n",
    "                <div class=\"result-title\">{title}</div>\n",
    "            </div>\n",
    "            <div class=\"result-url\">\n",
    "                <strong>üîó Source:</strong> <a href=\"{url}\" target=\"_blank\">{url}</a>\n",
    "            </div>\n",
    "            <div class=\"result-body\">\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parse content by steps\n",
    "    sections = content.split('Step ')\n",
    "    \n",
    "    # Add first section as overview if it exists\n",
    "    if sections[0].strip():\n",
    "        html_output += f\"\"\"\n",
    "                <div class=\"overview\">\n",
    "                    <strong>Overview:</strong><br>\n",
    "                    {sections[0].strip()}\n",
    "                </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    # Parse and format remaining steps\n",
    "    if len(sections) > 1:\n",
    "        html_output += \"\"\"\n",
    "                <div class=\"steps-container\">\n",
    "        \"\"\"\n",
    "        \n",
    "        for step_num, section in enumerate(sections[1:], 1):\n",
    "            lines = section.split('. ', 1)\n",
    "            if len(lines) > 1:\n",
    "                step_title = lines[0]\n",
    "                step_content = lines[1]\n",
    "                html_output += f\"\"\"\n",
    "                    <div class=\"step\">\n",
    "                        <div class=\"step-title\">\n",
    "                            <span class=\"step-number\">{step_num}</span>\n",
    "                            {step_title}\n",
    "                        </div>\n",
    "                        <div class=\"step-content\">{step_content}</div>\n",
    "                    </div>\n",
    "                \"\"\"\n",
    "            elif section.strip():\n",
    "                html_output += f\"\"\"\n",
    "                    <div class=\"step\">\n",
    "                        <div class=\"step-content\">{section.strip()}</div>\n",
    "                    </div>\n",
    "                \"\"\"\n",
    "        \n",
    "        html_output += \"\"\"\n",
    "                </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    html_output += \"\"\"\n",
    "            </div>\n",
    "        </div>\n",
    "    \"\"\"\n",
    "\n",
    "html_output += \"\"\"\n",
    "    </div>\n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdb82b2",
   "metadata": {},
   "source": [
    "## How do actual browsers show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7ea77f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë DeepSeek API Key loaded: ‚úÖ Yes\n",
      "   Key preview: sk-40088b7...\n",
      "Result 1: Link Search Menu Expand Document Documentation Men\n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 2: \n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 2: \n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 3: \n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 3: \n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 4: \n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 4: \n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 5: \n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 5: \n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 6: \n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 6: \n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 7: Link Search Menu Expand Document Documentation Men\n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 7: Link Search Menu Expand Document Documentation Men\n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 8: \n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 8: \n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 9: Link Search Menu Expand Document Documentation Men\n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 9: Link Search Menu Expand Document Documentation Men\n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 10: Link Search Menu Expand Document Documentation Men\n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 10: Link Search Menu Expand Document Documentation Men\n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "  üì• Response status: 200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "<meta charset=\"UTF-8\">\n",
       "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "<style>\n",
       "    * {\n",
       "        margin: 0;\n",
       "        padding: 0;\n",
       "        box-sizing: border-box;\n",
       "    }\n",
       "\n",
       "    body {\n",
       "        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;\n",
       "        background: #fff;\n",
       "        color: #202124;\n",
       "    }\n",
       "\n",
       "    .search-engine-container {\n",
       "        max-width: 600px;\n",
       "        margin: 40px auto;\n",
       "        padding: 20px;\n",
       "    }\n",
       "\n",
       "    .search-header {\n",
       "        margin-bottom: 30px;\n",
       "        padding-bottom: 20px;\n",
       "        border-bottom: 1px solid #dadce0;\n",
       "    }\n",
       "\n",
       "    .search-title {\n",
       "        font-size: 28px;\n",
       "        font-weight: 400;\n",
       "        color: #1f2937;\n",
       "        margin-bottom: 5px;\n",
       "    }\n",
       "\n",
       "    .search-query {\n",
       "        font-size: 14px;\n",
       "        color: #5f6368;\n",
       "    }\n",
       "\n",
       "    .search-stats {\n",
       "        font-size: 13px;\n",
       "        color: #70757a;\n",
       "        margin-top: 10px;\n",
       "    }\n",
       "\n",
       "    .search-results {\n",
       "        display: flex;\n",
       "        flex-direction: column;\n",
       "        gap: 30px;\n",
       "    }\n",
       "\n",
       "    .result-item {\n",
       "        display: flex;\n",
       "        flex-direction: column;\n",
       "        padding: 0;\n",
       "    }\n",
       "\n",
       "    .result-url {\n",
       "        font-size: 13px;\n",
       "        color: #006621;\n",
       "        margin-bottom: 5px;\n",
       "        word-break: break-all;\n",
       "        font-family: Arial, sans-serif;\n",
       "    }\n",
       "\n",
       "    .result-url a {\n",
       "        color: #006621;\n",
       "        text-decoration: none;\n",
       "    }\n",
       "\n",
       "    .result-url a:hover {\n",
       "        text-decoration: underline;\n",
       "    }\n",
       "\n",
       "    .result-title {\n",
       "        font-size: 20px;\n",
       "        color: #1f2937;\n",
       "        font-weight: 500;\n",
       "        margin-bottom: 8px;\n",
       "        line-height: 1.3;\n",
       "        cursor: pointer;\n",
       "        transition: color 0.2s;\n",
       "    }\n",
       "\n",
       "    .result-title:hover {\n",
       "        color: #1a73e8;\n",
       "        text-decoration: underline;\n",
       "    }\n",
       "\n",
       "    .result-title a {\n",
       "        color: inherit;\n",
       "        text-decoration: none;\n",
       "    }\n",
       "\n",
       "    .result-snippet {\n",
       "        font-size: 14px;\n",
       "        color: #545454;\n",
       "        line-height: 1.6;\n",
       "        margin-bottom: 5px;\n",
       "    }\n",
       "\n",
       "    .result-number {\n",
       "        font-size: 12px;\n",
       "        color: #9aa0a6;\n",
       "        margin-top: 5px;\n",
       "    }\n",
       "</style>\n",
       "</head>\n",
       "<body>\n",
       "<div class=\"search-engine-container\">\n",
       "    <div class=\"search-header\">\n",
       "        <div class=\"search-title\">üîç Search Results</div>\n",
       "        <div class=\"search-query\"><strong>Query:</strong> How to create an index pattern in OpenSearch?</div>\n",
       "        <div class=\"search-stats\">About 10 results</div>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"search-results\">\n",
       "\n",
       "        <div class=\"result-item\">\n",
       "            <div class=\"result-url\">\n",
       "                <a href=\"https://docs.opensearch.org/latest/dashboards/management/index-patterns/\" target=\"_blank\">https://docs.opensearch.org/latest/dashboards/management/index-patterns/</a>\n",
       "            </div>\n",
       "            <div class=\"result-title\">\n",
       "                <a href=\"https://docs.opensearch.org/latest/dashboards/management/index-patterns/\" target=\"_blank\">Link Search Menu Expand Document Documentation Menu</a>\n",
       "            </div>\n",
       "            <div class=\"result-snippet\">OpenSearch documentation for index patterns.</div>\n",
       "            <div class=\"result-number\">Result 1</div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-item\">\n",
       "            <div class=\"result-url\">\n",
       "                <a href=\"https://repost.aws/knowledge-center/opensearch-index-pattern\" target=\"_blank\">https://repost.aws/knowledge-center/opensearch-index-pattern</a>\n",
       "            </div>\n",
       "            <div class=\"result-title\">\n",
       "                <a href=\"https://repost.aws/knowledge-center/opensearch-index-pattern\" target=\"_blank\"></a>\n",
       "            </div>\n",
       "            <div class=\"result-snippet\">Creating index patterns in AWS OpenSearch.</div>\n",
       "            <div class=\"result-number\">Result 2</div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-item\">\n",
       "            <div class=\"result-url\">\n",
       "                <a href=\"https://www.youtube.com/watch?v=pbABIerUYQI\" target=\"_blank\">https://www.youtube.com/watch?v=pbABIerUYQI</a>\n",
       "            </div>\n",
       "            <div class=\"result-title\">\n",
       "                <a href=\"https://www.youtube.com/watch?v=pbABIerUYQI\" target=\"_blank\"></a>\n",
       "            </div>\n",
       "            <div class=\"result-snippet\">YouTube's copyright and policy information.</div>\n",
       "            <div class=\"result-number\">Result 3</div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-item\">\n",
       "            <div class=\"result-url\">\n",
       "                <a href=\"https://github.com/fidelity-contributions/opensearch-project-opensearch-py/blob/main/guides/index_template.md\" target=\"_blank\">https://github.com/fidelity-contributions/opensearch-project-opensearch-py/blob/main/guides/index_template.md</a>\n",
       "            </div>\n",
       "            <div class=\"result-title\">\n",
       "                <a href=\"https://github.com/fidelity-contributions/opensearch-project-opensearch-py/blob/main/guides/index_template.md\" target=\"_blank\"></a>\n",
       "            </div>\n",
       "            <div class=\"result-snippet\">GitHub's OpenSearch Python client repository.</div>\n",
       "            <div class=\"result-number\">Result 4</div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-item\">\n",
       "            <div class=\"result-url\">\n",
       "                <a href=\"https://deepwiki.com/johnny-chivers/amazon-opensearch-service/3.1-index-patterns\" target=\"_blank\">https://deepwiki.com/johnny-chivers/amazon-opensearch-service/3.1-index-patterns</a>\n",
       "            </div>\n",
       "            <div class=\"result-title\">\n",
       "                <a href=\"https://deepwiki.com/johnny-chivers/amazon-opensearch-service/3.1-index-patterns\" target=\"_blank\"></a>\n",
       "            </div>\n",
       "            <div class=\"result-snippet\">Creating index patterns for OpenSearch Dashboards.</div>\n",
       "            <div class=\"result-number\">Result 5</div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-item\">\n",
       "            <div class=\"result-url\">\n",
       "                <a href=\"https://opster.com/guides/opensearch/opensearch-data-architecture/index-templating-in-opensearch-how-to-use-composable-templates/\" target=\"_blank\">https://opster.com/guides/opensearch/opensearch-data-architecture/index-templating-in-opensearch-how-to-use-composable-templates/</a>\n",
       "            </div>\n",
       "            <div class=\"result-title\">\n",
       "                <a href=\"https://opster.com/guides/opensearch/opensearch-data-architecture/index-templating-in-opensearch-how-to-use-composable-templates/\" target=\"_blank\"></a>\n",
       "            </div>\n",
       "            <div class=\"result-snippet\">Guide to OpenSearch index templates.</div>\n",
       "            <div class=\"result-number\">Result 6</div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-item\">\n",
       "            <div class=\"result-url\">\n",
       "                <a href=\"https://docs.opensearch.org/latest/im-plugin/index-templates/\" target=\"_blank\">https://docs.opensearch.org/latest/im-plugin/index-templates/</a>\n",
       "            </div>\n",
       "            <div class=\"result-title\">\n",
       "                <a href=\"https://docs.opensearch.org/latest/im-plugin/index-templates/\" target=\"_blank\">Link Search Menu Expand Document Documentation Menu</a>\n",
       "            </div>\n",
       "            <div class=\"result-snippet\">OpenSearch documentation for index templates.</div>\n",
       "            <div class=\"result-number\">Result 7</div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-item\">\n",
       "            <div class=\"result-url\">\n",
       "                <a href=\"https://stackoverflow.com/questions/71816340/how-to-create-an-index-pattern-in-opensearch-using-api\" target=\"_blank\">https://stackoverflow.com/questions/71816340/how-to-create-an-index-pattern-in-opensearch-using-api</a>\n",
       "            </div>\n",
       "            <div class=\"result-title\">\n",
       "                <a href=\"https://stackoverflow.com/questions/71816340/how-to-create-an-index-pattern-in-opensearch-using-api\" target=\"_blank\"></a>\n",
       "            </div>\n",
       "            <div class=\"result-snippet\">Creating an OpenSearch index pattern via API.</div>\n",
       "            <div class=\"result-number\">Result 8</div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-item\">\n",
       "            <div class=\"result-url\">\n",
       "                <a href=\"https://docs.opensearch.org/latest/dashboards/management/management-index/\" target=\"_blank\">https://docs.opensearch.org/latest/dashboards/management/management-index/</a>\n",
       "            </div>\n",
       "            <div class=\"result-title\">\n",
       "                <a href=\"https://docs.opensearch.org/latest/dashboards/management/management-index/\" target=\"_blank\">Link Search Menu Expand Document Documentation Menu</a>\n",
       "            </div>\n",
       "            <div class=\"result-snippet\">OpenSearch documentation for search and analytics.</div>\n",
       "            <div class=\"result-number\">Result 9</div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-item\">\n",
       "            <div class=\"result-url\">\n",
       "                <a href=\"https://docs.opensearch.org/latest/api-reference/index-apis/create-index/\" target=\"_blank\">https://docs.opensearch.org/latest/api-reference/index-apis/create-index/</a>\n",
       "            </div>\n",
       "            <div class=\"result-title\">\n",
       "                <a href=\"https://docs.opensearch.org/latest/api-reference/index-apis/create-index/\" target=\"_blank\">Link Search Menu Expand Document Documentation Menu</a>\n",
       "            </div>\n",
       "            <div class=\"result-snippet\">OpenSearch documentation for creating indexes.</div>\n",
       "            <div class=\"result-number\">Result 10</div>\n",
       "        </div>\n",
       "    \n",
       "    </div>\n",
       "</div>\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Displayed 10 search results in search engine format\n"
     ]
    }
   ],
   "source": [
    "# Display results as a search engine with AI-powered summaries\n",
    "import requests\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "\n",
    "# Try to load from environment\n",
    "DEEPSEEK_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "\n",
    "# If not found, try loading from .env file\n",
    "if not DEEPSEEK_API_KEY:\n",
    "    try:\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv(\"../../.env\")\n",
    "        DEEPSEEK_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Debug: Check if API key is available\n",
    "print(f\"üîë DeepSeek API Key loaded: {'‚úÖ Yes' if DEEPSEEK_API_KEY else '‚ùå No'}\")\n",
    "if DEEPSEEK_API_KEY:\n",
    "    print(f\"   Key preview: {DEEPSEEK_API_KEY[:10]}...\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  WARNING: DeepSeek API key not found. Set DEEPSEEK_API_KEY environment variable.\")\n",
    "\n",
    "DEEPSEEK_API_URL = \"https://api.deepseek.com/chat/completions\"\n",
    "\n",
    "# Extract all items from the response\n",
    "all_items = json.loads(response['inference_results'][0]['output'][0]['result'])['items']\n",
    "\n",
    "def parse_content_for_summary(content):\n",
    "    \"\"\"Parse content by steps to get better structured text for summarization\"\"\"\n",
    "    sections = content.split('Step ')\n",
    "    parsed_text = []\n",
    "    \n",
    "    # Add first section as overview if it exists\n",
    "    if sections[0].strip():\n",
    "        parsed_text.append(sections[0].strip())\n",
    "    \n",
    "    # Parse and format remaining steps\n",
    "    for step_num, section in enumerate(sections[1:], 1):\n",
    "        lines = section.split('. ', 1)\n",
    "        if len(lines) > 1:\n",
    "            step_title = lines[0]\n",
    "            step_content = lines[1]\n",
    "            parsed_text.append(f\"Step {step_num}: {step_title}. {step_content}\")\n",
    "        elif section.strip():\n",
    "            parsed_text.append(section.strip())\n",
    "    \n",
    "    return ' '.join(parsed_text)\n",
    "\n",
    "def get_summary_from_deepseek(content, max_words=10):\n",
    "    \"\"\"Get a brief summary of content using DeepSeek API\"\"\"\n",
    "    if not DEEPSEEK_API_KEY:\n",
    "        print(\"  ‚ö†Ô∏è  API key missing, returning fallback summary\")\n",
    "        # Return a basic fallback summary from content\n",
    "        parsed_content = parse_content_for_summary(content)\n",
    "        words = parsed_content.split()\n",
    "        fallback = ' '.join(words[:max_words]) + '...' if len(words) > max_words else parsed_content\n",
    "        return fallback\n",
    "    \n",
    "    try:\n",
    "        # Parse content by steps first\n",
    "        parsed_content = parse_content_for_summary(content)\n",
    "        \n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {DEEPSEEK_API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": \"deepseek-chat\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Summarize this text in less than {max_words} words, focusing on the main point:\\n\\n{parsed_content}\"\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 2000,\n",
    "            \"temperature\": 0.5\n",
    "        }\n",
    "        \n",
    "        print(f\"  üì§ Calling DeepSeek API...\")\n",
    "        response = requests.post(DEEPSEEK_API_URL, json=payload, headers=headers, timeout=10)\n",
    "        \n",
    "        print(f\"  üì• Response status: {response.status_code}\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            summary = result.get('choices', [{}])[0].get('message', {}).get('content', 'No summary available').strip()\n",
    "            # Truncate if needed\n",
    "            words = summary.split()\n",
    "            if len(words) > max_words:\n",
    "                summary = ' '.join(words[:max_words]) + '...'\n",
    "            return summary\n",
    "        else:\n",
    "            print(f\"  ‚ùå API Error: {response.status_code}\")\n",
    "            print(f\"  Response: {response.text[:200]}\")\n",
    "            # Return fallback\n",
    "            parsed_content = parse_content_for_summary(content)\n",
    "            words = parsed_content.split()\n",
    "            fallback = ' '.join(words[:max_words]) + '...' if len(words) > max_words else parsed_content\n",
    "            return fallback\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error calling DeepSeek API: {str(e)}\")\n",
    "        # Return fallback\n",
    "        try:\n",
    "            parsed_content = parse_content_for_summary(content)\n",
    "            words = parsed_content.split()\n",
    "            fallback = ' '.join(words[:max_words]) + '...' if len(words) > max_words else parsed_content\n",
    "            return fallback\n",
    "        except:\n",
    "            return \"Summary unavailable\"\n",
    "\n",
    "# Create HTML output styled like Google Search Results\n",
    "html_output = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<meta charset=\"UTF-8\">\n",
    "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "<style>\n",
    "    * {\n",
    "        margin: 0;\n",
    "        padding: 0;\n",
    "        box-sizing: border-box;\n",
    "    }\n",
    "    \n",
    "    body {\n",
    "        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;\n",
    "        background: #fff;\n",
    "        color: #202124;\n",
    "    }\n",
    "    \n",
    "    .search-engine-container {\n",
    "        max-width: 600px;\n",
    "        margin: 40px auto;\n",
    "        padding: 20px;\n",
    "    }\n",
    "    \n",
    "    .search-header {\n",
    "        margin-bottom: 30px;\n",
    "        padding-bottom: 20px;\n",
    "        border-bottom: 1px solid #dadce0;\n",
    "    }\n",
    "    \n",
    "    .search-title {\n",
    "        font-size: 28px;\n",
    "        font-weight: 400;\n",
    "        color: #1f2937;\n",
    "        margin-bottom: 5px;\n",
    "    }\n",
    "    \n",
    "    .search-query {\n",
    "        font-size: 14px;\n",
    "        color: #5f6368;\n",
    "    }\n",
    "    \n",
    "    .search-stats {\n",
    "        font-size: 13px;\n",
    "        color: #70757a;\n",
    "        margin-top: 10px;\n",
    "    }\n",
    "    \n",
    "    .search-results {\n",
    "        display: flex;\n",
    "        flex-direction: column;\n",
    "        gap: 30px;\n",
    "    }\n",
    "    \n",
    "    .result-item {\n",
    "        display: flex;\n",
    "        flex-direction: column;\n",
    "        padding: 0;\n",
    "    }\n",
    "    \n",
    "    .result-url {\n",
    "        font-size: 13px;\n",
    "        color: #006621;\n",
    "        margin-bottom: 5px;\n",
    "        word-break: break-all;\n",
    "        font-family: Arial, sans-serif;\n",
    "    }\n",
    "    \n",
    "    .result-url a {\n",
    "        color: #006621;\n",
    "        text-decoration: none;\n",
    "    }\n",
    "    \n",
    "    .result-url a:hover {\n",
    "        text-decoration: underline;\n",
    "    }\n",
    "    \n",
    "    .result-title {\n",
    "        font-size: 20px;\n",
    "        color: #1f2937;\n",
    "        font-weight: 500;\n",
    "        margin-bottom: 8px;\n",
    "        line-height: 1.3;\n",
    "        cursor: pointer;\n",
    "        transition: color 0.2s;\n",
    "    }\n",
    "    \n",
    "    .result-title:hover {\n",
    "        color: #1a73e8;\n",
    "        text-decoration: underline;\n",
    "    }\n",
    "    \n",
    "    .result-title a {\n",
    "        color: inherit;\n",
    "        text-decoration: none;\n",
    "    }\n",
    "    \n",
    "    .result-snippet {\n",
    "        font-size: 14px;\n",
    "        color: #545454;\n",
    "        line-height: 1.6;\n",
    "        margin-bottom: 5px;\n",
    "    }\n",
    "    \n",
    "    .result-number {\n",
    "        font-size: 12px;\n",
    "        color: #9aa0a6;\n",
    "        margin-top: 5px;\n",
    "    }\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "<div class=\"search-engine-container\">\n",
    "    <div class=\"search-header\">\n",
    "        <div class=\"search-title\">üîç Search Results</div>\n",
    "        <div class=\"search-query\"><strong>Query:</strong> \"\"\" + parameters.get('question', 'N/A') + \"\"\"</div>\n",
    "        <div class=\"search-stats\">About \"\"\" + str(len(all_items)) + \"\"\" results</div>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"search-results\">\n",
    "\"\"\"\n",
    "\n",
    "# Process each result\n",
    "for idx, item in enumerate(all_items, 1):\n",
    "    title = item.get('title', 'No Title')\n",
    "    url = item.get('url', 'No URL')\n",
    "    content = item.get('content', 'No Content')\n",
    "    \n",
    "    # Get summary from DeepSeek with parsed content\n",
    "    print(f\"Result {idx}: {title[:50]}\")\n",
    "    summary = get_summary_from_deepseek(content, max_words=10)\n",
    "    \n",
    "    html_output += f\"\"\"\n",
    "        <div class=\"result-item\">\n",
    "            <div class=\"result-url\">\n",
    "                <a href=\"{url}\" target=\"_blank\">{url}</a>\n",
    "            </div>\n",
    "            <div class=\"result-title\">\n",
    "                <a href=\"{url}\" target=\"_blank\">{title}</a>\n",
    "            </div>\n",
    "            <div class=\"result-snippet\">{summary}</div>\n",
    "            <div class=\"result-number\">Result {idx}</div>\n",
    "        </div>\n",
    "    \"\"\"\n",
    "\n",
    "html_output += \"\"\"\n",
    "    </div>\n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html_output))\n",
    "print(f\"\\n‚úÖ Displayed {len(all_items)} search results in search engine format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d31fc5d",
   "metadata": {},
   "source": [
    "## Step 5: Test Case 2 - Search for Technical Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ea20684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì Question: What is k-NN vector search and how does it work?\n",
      "============================================================\n",
      "\n",
      "üìö Technical Information:\n",
      "{\n",
      "  \"inference_results\": [\n",
      "    {\n",
      "      \"output\": [\n",
      "        {\n",
      "          \"name\": \"response\",\n",
      "          \"result\": \"{\\\"next_page\\\":\\\"https://duckduckgo.com/html?q=What+is+k-NN+vector+search+and+how+does+it+work?&s=10&nextParams=&v=l&o=json&dc=11&api=d.js&vqd=4-323019276702527373326608110606503075675&kl=wt-wt\\\",\\\"items\\\":[{\\\"url\\\":\\\"https://docs.opensearch.org/latest/vector-search/vector-search-techniques/index/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Regular expression syntax Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Using UBI in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Vector search techniques OpenSearch implements vector search as k-nearest neighbors, or k-NN, search. k-NN search finds the k neighbors closest to a query point across an index of vectors. To determine the neighbors, you can specify the space (the distance function) you want to use to measure the distance between points. OpenSearch supports three different methods for obtaining the k-nearest neighbors from an index of vectors: Approximate search (approximate k-NN, or ANN): Returns approximate nearest neighbors to the query vector. Usually, approximate search algorithms sacrifice indexing speed and search accuracy in exchange for performance benefits such as lower latency, smaller memory footprints, and more scalable search. For most use cases, approximate search is the best option. Exact search: A brute-force, exact k-NN search of vector fields. OpenSearch supports the following types of exact search: Exact search with a scoring script: Using a scoring script, you can apply a filter to an index before executing the nearest neighbor search. Painless extensions: Adds the distance functions as Painless extensions that you can use in more complex combinations. You can use this method to perform a brute-force, exact vector search of an index, which also supports pre-filtering. In general, you should choose the ANN method for larger datasets because it scales significantly better. For smaller datasets, where you may want to apply a filter, you should choose the custom scoring approach. If you have a more complex use case in which you need to use a distance function as part of the scoring method, you should use the Painless scripting approach. Approximate search OpenSearch supports multiple backend algorithms (methods) and libraries for implementing these algorithms (engines). It automatically selects the optimal configuration based on the chosen mode and available memory. For more information, see Methods and engines. Using sparse vectors Neural sparse search offers an efficient alternative to dense vector search by using sparse embedding models and inverted indexes, providing performance similar to BM25. Unlike dense vector methods that require significant memory and CPU resources, sparse search creates a list of token-weight pairs and stores them in a rank features index. This approach combines the efficiency of traditional search with the semantic understanding of neural networks. OpenSearch supports both automatic embedding generation through ingest pipelines and direct sparse vector ingestion. For more information, see Neural sparse search. Combining multiple search techniques Hybrid search enhances search relevance by combining multiple search techniques in OpenSearch. It integrates traditional keyword search with vector-based semantic search. Through a configurable search pipeline, hybrid search normalizes and combines scores from different search methods to provide unified, relevant results. This approach is particularly effective for complex queries where both semantic understanding and exact matching are important. The search pipeline can be further customized with post-filtering operations and aggregations to meet specific search requirements. For more information, see Hybrid search. Approximate search Using sparse vectors Combining multiple search techniques WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright \\u00a9 OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\\\"},{\\\"url\\\":\\\"https://learn.microsoft.com/en-us/azure/search/vector-search-ranking\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to main content Skip to Ask Learn chat experience This browser is no longer supported. Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support. Download Microsoft Edge More info about Internet Explorer and Microsoft Edge Table of contents Exit editor mode Ask Learn Ask Learn Focus mode Table of contents Read in English Add Add to plan Edit Share via Facebook x.com LinkedIn Email Print Note Access to this page requires authorization. You can try signing in or changing directories. Access to this page requires authorization. You can try changing directories. Relevance in vector search Feedback Summarize this article for me In this article During vector query execution, the search engine looks for similar vectors to find the best candidates to return in search results. Depending on how you indexed the vector content, the search for relevant matches is either exhaustive, or constrained to nearest neighbors for faster processing. Once candidates are found, similarity metrics are used to score each result based on the strength of the match. This article explains the algorithms used to find relevant matches and the similarity metrics used for scoring. It also offers tips for improving relevance if search results don't meet expectations. Algorithms used in vector search Vector search algorithms include: Exhaustive K-Nearest Neighbors (KNN), which performs a brute-force scan of the entire vector space. Hierarchical Navigable Small World (HNSW), which performs an Approximate Nearest Neighbor (ANN) search. Only vector fields marked as searchable in the index or searchFields in the query are used for searching and scoring. About exhaustive KNN Exhaustive KNN calculates the distances between all pairs of data points and finds the exact k nearest neighbors for a query point. Because the algorithm doesn't require fast random access of data points, KNN doesn't consume vector index size quota. However, it provides the global set of nearest neighbors. Exhaustive KNN is computationally intensive, so use it for small to medium datasets or when the need for precision outweighs the need for query performance. Another use case is building a dataset to evaluate the recall of an ANN algorithm, as exhaustive KNN can be used to build the ground truth set of nearest neighbors. About HNSW HNSW is an ANN algorithm optimized for high-recall, low-latency applications with unknown or volatile data distribution. During indexing, HNSW creates extra data structures that organize data points into a hierarchical graph. During query execution, HNSW navigates through this graph to find the most relevant matches, enabling efficient nearest neighbor searches. HNSW requires all data points to reside in memory for fast random access, which consumes vector index size quota. This design balances search accuracy with computational efficiency and makes HNSW suitable for most scenarios, especially when searching over larger datasets. HNSW offers several tunable configuration parameters to optimize throughput, latency, and recall for your search application. For example, fields that specify HNSW also support exhaustive KNN using the query request parameter \\\\\\\"exhaustive\\\\\\\": true. However, fields indexed for exhaustiveKnn don't support HNSW queries because the extra data structures that enable efficient search don't exist. About ANN ANN is a class of algorithms for finding matches in vector space. This class of algorithms uses different data structures or data partitioning methods to significantly reduce the search space and accelerate query processing. ANN algorithms sacrifice some accuracy but offer scalable and faster retrieval of approximate nearest neighbors, which makes them ideal for balancing accuracy and efficiency in modern information retrieval applications. You can adjust the parameters of your algorithm to fine-tune the recall, latency, memory, and disk footprint requirements of your search application. Azure AI Search uses HNSW for its ANN algorithm. How nearest neighbor search works Vector queries execute against an embedding space consisting of vectors generated from the same embedding model. Generally, the input value within a query request is fed into the same machine learning model that generated embeddings in the vector index. The output is a vector in the same embedding space. Since similar vectors are clustered close together, finding matches is equivalent to finding the vectors that are closest to the query vector, and returning the associated documents as the search result. For example, if a query request is about hotels, the model maps the query into a vector that exists somewhere in the cluster of vectors representing documents about hotels. Identifying which vectors are the most similar to the query, based on a similarity metric, determines which documents are the most relevant. When vector fields are indexed for exhaustive KNN, the query executes against \\\\\\\"all neighbors\\\\\\\". For fields indexed for HNSW, the search engine uses an HNSW graph to search over a subset of nodes within the vector index. Creating the HNSW graph During indexing, the search service constructs the HNSW graph. The goal of indexing a new vector into an HNSW graph is to add it to the graph structure in a manner that allows for efficient nearest neighbor search. The following steps summarize the process: Initialization: Start with an empty HNSW graph, or the existing HNSW graph if it's not a new index. Entry point: This is the top-level of the hierarchical graph and serves as the starting point for indexing. Adding to the graph: Different hierarchical levels represent different granularities of the graph, with higher levels being more global, and lower levels being more granular. Each node in the graph represents a vector point. Each node is connected to up to m neighbors that are nearby. This is the m parameter. The number of data points considered as candidate connections is governed by the efConstruction parameter. This dynamic list forms the set of closest points in the existing graph for the algorithm to consider. Higher efConstruction values result in more nodes being considered, which often leads to denser local neighborhoods for each vector. These connections use the configured similarity metric to determine distance. Some connections are \\\\\\\"long-distance\\\\\\\" connections that connect across different hierarchical levels, creating shortcuts in the graph that enhance search efficiency. Graph pruning and optimization: This can happen after indexing all vectors, and it improves navigability and efficiency of the HNSW graph. Navigating the HNSW graph at query time A vector query navigates the hierarchical graph structure to scan for matches. The following summarize the steps in the process: Initialization: The algorithm initiates the search at the top-level of the hierarchical graph. This entry point contains the set of vectors that serve as starting points for search. Traversal: Next, it traverses the graph level by level, navigating from the top-level to lower levels, selecting candidate nodes that are closer to the query vector based on the configured distance metric, such as cosine similarity. Pruning: To improve efficiency, the algorithm prunes the search space by only considering nodes that are likely to contain nearest neighbors. This is achieved by maintaining a priority queue of potential candidates and updating it as the search progresses. The length of this queue is configured by the parameter efSearch. Refinement: As the algorithm moves to lower, more granular levels, HNSW considers more neighbors near the query, which allows the candidate set of vectors to be refined, improving accuracy. Completion: The search completes when the desired number of nearest neighbors have been identified, or when other stopping criteria are met. This desired number of nearest neighbors is governed by the query-time parameter k. Similarity metrics used to measure nearness The algorithm finds candidate vectors to evaluate similarity. To perform this task, a similarity metric calculation compares the candidate vector to the query vector and measures the similarity. The algorithm keeps track of the ordered set of most similar vectors that its found, which forms the ranked result set when the algorithm has reached completion. Metric Description cosine This metric measures the angle between two vectors, and isn't affected by differing vector lengths. Mathematically, it calculates the angle between two vectors. Cosine is the similarity metric used by Azure OpenAI embedding models, so if you're using Azure OpenAI, specify cosine in the vector configuration. dotProduct This metric measures both the length of each pair of two vectors, and the angle between them. Mathematically, it calculates the products of vectors' magnitudes and the angle between them. For normalized vectors, this is identical to cosine similarity, but slightly more performant. euclidean (also known as l2 norm) This metric measures the length of the vector difference between two vectors. Mathematically, it calculates the Euclidean distance between two vectors, which is the l2-norm of the difference of the two vectors. Note If you run two or more vector queries in parallel, or if you do a hybrid search that combines vector and text queries in the same request, Reciprocal Rank Fusion (RRF) is used for scoring the final search results. Scores in a vector search results Scores are calculated and assigned to each match, with the highest matches returned as k results. The @search.score property contains the score. The following table shows the range within which a score will fall. Search method Parameter Scoring metric Range vector search @search.score Cosine 0.333 - 1.00 Forcosine metric, it's important to note that the calculated @search.score isn't the cosine value between the query vector and the document vectors. Instead, Azure AI Search applies transformations such that the score function is monotonically decreasing, meaning score values will always decrease in value as the similarity becomes worse. This transformation ensures that search scores are usable for ranking purposes. There are some nuances with similarity scores: Cosine similarity is defined as the cosine of the angle between two vectors. Cosine distance is defined as 1 - cosine_similarity. To create a monotonically decreasing function, the @search.score is defined as 1 / (1 + cosine_distance). Developers who need a cosine value instead of the synthetic value can use a formula to convert the search score back to cosine distance: double ScoreToSimilarity(double score)\\\\n{\\\\n    double cosineDistance = (1 - score) / score;\\\\n    return  -cosineDistance + 1;\\\\n}\\\\n Having the original cosine value can be useful in custom solutions that set up thresholds to trim results of low quality results. Tips for relevance tuning If you aren't getting relevant results, experiment with changes to query configuration. There are no specific tuning features, such as a scoring profile or field or term boosting, for vector queries: Experiment with chunk size and overlap. Try increasing the chunk size and ensuring there's sufficient overlap to preserve context or continuity between chunks. For HNSW, try different levels of efConstruction to change the internal composition of the proximity graph. The default is 400. The range is 100 to 1,000. Increase k results to feed more search results into a chat model, if you're using one. Try hybrid queries with semantic ranking. In benchmark testing, this combination consistently produced the most relevant results. Next steps Try the quickstart Create and configure a vector index Learn more about embeddings Learn more about data chunking Feedback Was this page helpful? Yes No No Need help with this topic? Want to try using Ask Learn to clarify or guide you through this topic? Ask Learn Ask Learn Suggest a fix? Additional resources Last updated on 2025-07-09 In this article Was this page helpful? Yes No No Need help with this topic? Want to try using Ask Learn to clarify or guide you through this topic? Ask Learn Ask Learn Suggest a fix? en-us Your Privacy Choices Theme Light Dark High contrast AI Disclaimer Previous Versions Blog Contribute Privacy Terms of Use Trademarks \\u00a9 Microsoft 2025\\\"},{\\\"url\\\":\\\"https://medium.com/google-cloud/vector-search-demystifying-ann-and-knn-64bc2b24cca8\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Sitemap Open in app Sign up Sign in Medium Logo Write Search Sign up Sign in Google Cloud - Community \\u00b7 A collection of technical articles and blogs published or curated by Google Cloud Developer Advocates. The views expressed are those of the authors and don't necessarily reflect those of Google. Vector Search: Demystifying ANN and KNN Shu Zhou 4 min read \\u00b7 Oct 31, 2025 -- Listen Share Press enter or click to view image in full size In the rapidly evolving landscape of data, the ability to efficiently search and retrieve relevant information \\u2014 even as your data set explodes \\u2014 is critical. This is where vector search shines, transforming how we interact with large datasets by representing data as numerical vectors that capture semantic meaning in a high-dimensional space. This transforms the sophisticated semantic similarity problem into a mathematical vector distance problem. Vector search uses algorithms designed to find similar vectors, with K-Nearest Neighbors (KNN) and Approximate Nearest Neighbors (ANN) being two of the most prominent. Similar to the previous blog in this series, Choosing Your Vector Search Solution, I\\u2019ll continue using Cloud SQL for MySQL as the example. What Is KNN (K-Nearest Neighbors) KNN is a direct approach to finding similar data points in vector search. Given a query vector, KNN exhaustively calculates the distance (or similarity) between the query and every single vector in the database. It then returns the K vectors that are closest to the query. Key Characteristics of KNN: Accuracy: KNN is known for its accuracy because it performs an exhaustive search. It guarantees finding the true K-nearest neighbors. High Computational Cost: As the dataset size grows, the computational cost (and thus time) for each query increases linearly. It would become prohibitively slow when the number of vectors grows to millions. In Cloud SQL for MySQL, one can perform KNN queries using explicit distance measure functions such as: select id from tbl order by cosine_distance(emb, string_to_vector(\\u2018[...]\\u2019) limit 10; What is ANN (Approximate Nearest Neighbors) ANN algorithms are designed to overcome the scalability limitations of KNN. Instead of guaranteeing the absolute K-nearest neighbors, ANN aims to find a good approximation of the nearest neighbors, sacrificing some accuracy for significantly improved speed and scalability. This \\u201capproximation\\u201d is often more than sufficient for most real-world applications where near real-time performance is crucial. Key Characteristics of ANN: Speed: ANN algorithms are orders of magnitude faster than KNN for large datasets. Scalability: ANN can handle datasets with billions of vectors, making it suitable for modern large-scale applications like recommendation systems, image search, and natural language processing. Index: ANN queries are done through the help of vector indexes. Tunable Accuracy vs. Speed Trade-off: There\\u2019s an inherent trade-off. Users can often tune the vector index to prioritize higher accuracy at the cost of some speed or higher speed at the cost of some accuracy. Complexity: ANN algorithms are more complex to implement and understand than basic KNN, involving techniques like tree-based methods (e.g., ScaNN, Annoy), hashing-based methods (e.g., Locality Sensitive Hashing \\u2014 LSH), and graph-based methods (e.g., HNSW). In Cloud SQL for MySQL, ANN is signified by the approx_distance function, see below example. select id from tbl order by approx_distance(emb, string_to_vector(\\u2018[...]\\u2019), \\u2018distance_measure=cosine\\u2019) limit 10; KNN vs. ANN: A Comparison Let\\u2019s summarize the key differences between KNN and ANN: Your dataset is relatively small (low hundreds of thousands of vectors). You require 100% precision in finding the absolute nearest neighbors. Computational time is not a critical constraint. Choose ANN when: Your dataset is large (millions to billions of vectors). Speed and scalability are paramount for your application (e.g., real-time search). A slight trade-off in accuracy for significantly improved performance is acceptable. Auto Switch in Cloud SQL for MySQL Cloud SQL for MySQL includes a resilient feature where a query requesting an ANN search can automatically revert to performing an exact KNN search. This fallback is triggered when KNN is deemed more suitable for the query. The optimizer in Cloud SQL MySQL is aware of the vector index, which allows it to recognize when the conditions for an accelerated ANN search are not met. Common reasons include: Missing Vector Index: The query is against a vector column that does not have a corresponding index. In this case, the database has no choice but to perform an exhaustive, \\u201cexact\\u201d search. Unsupported Query arguments: ANN queries often have specific requirements for how they are used in a query. For instance, they might explicitly require a specific distance measure algorithm, that is not the same as what the index uses. Optimizer determines KNN search is lower cost: Certain queries (i.e. high selectivity filters) make KNN search a more efficient choice than ANN. The optimizer may intelligently use KNN in this scenario. This smart feature provides a few benefits: This automatic fallback makes the application more resilient to potential errors. Instead of failing, the query still executes and returns correct results. The application gets a valid response, although the performance will be that of a slower KNN search rather than the faster ANN search. This ensures that your application continues to function, while also implicitly signaling that the query or underlying table structure may need optimization (e.g., by creating a missing vector index). It is also a handy tool for app development and debugging. The developers can use the ANN queries as in real production when working in their dev environments. The test datasets are usually small, sometimes too small to create a vector index, but the developers can still use the prod syntax all the way through the whole application development cycle. You can always monitor the KNN/ANN switch status by consulting the dedicated status. show global status like '%cloudsql_vector_knn_fallback%'; Get Started Both KNN and ANN are vital for vector search, but they serve different needs. While KNN offers unparalleled precision for smaller scales, ANN is the clear winner for handling the massive datasets prevalent in today\\u2019s data-driven world. Understanding their differences is crucial for anyone building efficient and scalable vector search systems. If you\\u2019re interested in learning more about the broader landscape of vector search solutions and whether a specialized database is right for you, I recommend reading our previous post: Cloud SQL vs. Specialized Databases: Choosing Your Vector Search Solution. Ready to try it out and test it yourself? Follow this codelab and start building your first vector search powered app! Vector Database MySQL Google Cloud Sql Genai Rags -- -- Published in Google Cloud - Community 69K followers \\u00b7Last published 2 days ago A collection of technical articles and blogs published or curated by Google Cloud Developer Advocates. The views expressed are those of the authors and don't necessarily reflect those of Google. Written by Shu Zhou 3 followers \\u00b72 following SWE @ Google No responses yet Help Status About Careers Press Blog Privacy Rules Terms Text to speech\\\"},null,{\\\"url\\\":\\\"https://docs.aws.amazon.com/opensearch-service/latest/developerguide/knn.html\\\",\\\"title\\\":\\\"k-Nearest Neighbor (k-NN) search in Amazon OpenSearch Service - Amazon OpenSearch Service\\\",\\\"content\\\":\\\"k-Nearest Neighbor (k-NN) search in Amazon OpenSearch Service - Amazon OpenSearch Service DocumentationAmazon OpenSearch ServiceDeveloper Guide Getting started with k-NNk-NN differences, tuning, and limitations k-Nearest Neighbor (k-NN) search in Amazon OpenSearch Service Short for its associated k-nearest neighbors algorithm, k-NN for Amazon OpenSearch Service lets you search for points in a vector space and find the \\\\\\\"nearest neighbors\\\\\\\" for those points by Euclidean distance or cosine similarity. Use cases include recommendations (for example, an \\\\\\\"other songs you might like\\\\\\\" feature in a music application), image recognition, and fraud detection. Note This documentation provides a brief overview of the k-NN plugin, as well as limitations when using the plugin with managed OpenSearch Service. For comprehensive documentation of the k-NN plugin, including simple and complex examples, parameter references, and the complete API reference, see the open source OpenSearch documentation. The open source documentation also covers performance tuning and k-NN-specific cluster settings. Getting started with k-NN To use k-NN, you must create an index with the index.knn setting and add one or more fields of the knn_vector data type. PUT my-index\\\\n\\\\n{\\\\n  \\\\\\\"settings\\\\\\\": {\\\\n    \\\\\\\"index.knn\\\\\\\": true\\\\n  },\\\\n  \\\\\\\"mappings\\\\\\\": {\\\\n    \\\\\\\"properties\\\\\\\": {\\\\n      \\\\\\\"my_vector1\\\\\\\": {\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"knn_vector\\\\\\\",\\\\n        \\\\\\\"dimension\\\\\\\": 2\\\\n      },\\\\n      \\\\\\\"my_vector2\\\\\\\": {\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"knn_vector\\\\\\\",\\\\n        \\\\\\\"dimension\\\\\\\": 4\\\\n      }\\\\n    }\\\\n  }\\\\n} The knn_vector data type supports a single list of up to 10,000 floats, with the number of floats defined by the required dimension parameter. After you create the index, add some data to it. POST _bulk\\\\n\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"1\\\\\\\" } }\\\\n{ \\\\\\\"my_vector1\\\\\\\": [1.5, 2.5], \\\\\\\"price\\\\\\\": 12.2 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"2\\\\\\\" } }\\\\n{ \\\\\\\"my_vector1\\\\\\\": [2.5, 3.5], \\\\\\\"price\\\\\\\": 7.1 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"3\\\\\\\" } }\\\\n{ \\\\\\\"my_vector1\\\\\\\": [3.5, 4.5], \\\\\\\"price\\\\\\\": 12.9 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"4\\\\\\\" } }\\\\n{ \\\\\\\"my_vector1\\\\\\\": [5.5, 6.5], \\\\\\\"price\\\\\\\": 1.2 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"5\\\\\\\" } }\\\\n{ \\\\\\\"my_vector1\\\\\\\": [4.5, 5.5], \\\\\\\"price\\\\\\\": 3.7 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"6\\\\\\\" } }\\\\n{ \\\\\\\"my_vector2\\\\\\\": [1.5, 5.5, 4.5, 6.4], \\\\\\\"price\\\\\\\": 10.3 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"7\\\\\\\" } }\\\\n{ \\\\\\\"my_vector2\\\\\\\": [2.5, 3.5, 5.6, 6.7], \\\\\\\"price\\\\\\\": 5.5 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"8\\\\\\\" } }\\\\n{ \\\\\\\"my_vector2\\\\\\\": [4.5, 5.5, 6.7, 3.7], \\\\\\\"price\\\\\\\": 4.4 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"9\\\\\\\" } }\\\\n{ \\\\\\\"my_vector2\\\\\\\": [1.5, 5.5, 4.5, 6.4], \\\\\\\"price\\\\\\\": 8.9 }\\\\n Then you can search the data using the knn query type. GET my-index/_search\\\\n{\\\\n  \\\\\\\"size\\\\\\\": 2,\\\\n  \\\\\\\"query\\\\\\\": {\\\\n    \\\\\\\"knn\\\\\\\": {\\\\n      \\\\\\\"my_vector2\\\\\\\": {\\\\n        \\\\\\\"vector\\\\\\\": [2, 3, 5, 6],\\\\n        \\\\\\\"k\\\\\\\": 2\\\\n      }\\\\n    }\\\\n  }\\\\n} In this case, k is the number of neighbors you want the query to return, but you must also include the size option. Otherwise, you get k results for each shard (and each segment) rather than k results for the entire query. k-NN supports a maximum k value of 10,000. If you mix the knn query with other clauses, you might receive fewer than k results. In this example, the post_filter clause reduces the number of results from 2 to 1. GET my-index/_search\\\\n\\\\n{\\\\n  \\\\\\\"size\\\\\\\": 2,\\\\n  \\\\\\\"query\\\\\\\": {\\\\n    \\\\\\\"knn\\\\\\\": {\\\\n      \\\\\\\"my_vector2\\\\\\\": {\\\\n        \\\\\\\"vector\\\\\\\": [2, 3, 5, 6],\\\\n        \\\\\\\"k\\\\\\\": 2\\\\n      }\\\\n    }\\\\n  },\\\\n  \\\\\\\"post_filter\\\\\\\": {\\\\n    \\\\\\\"range\\\\\\\": {\\\\n      \\\\\\\"price\\\\\\\": {\\\\n        \\\\\\\"gte\\\\\\\": 6,\\\\n        \\\\\\\"lte\\\\\\\": 10\\\\n      }\\\\n    }\\\\n  }\\\\n} If you need to handle a large volume of queries while maintaining optimal performance, you can use the _msearch API to construct a bulk search with JSON and send a single request to perform multiple searches: GET _msearch\\\\n\\\\n{ \\\\\\\"index\\\\\\\": \\\\\\\"my-index\\\\\\\"}\\\\n{ \\\\\\\"query\\\\\\\": { \\\\\\\"knn\\\\\\\": {\\\\\\\"my_vector2\\\\\\\":{\\\\\\\"vector\\\\\\\": [2, 3, 5, 6],\\\\\\\"k\\\\\\\":2 }} } }\\\\n{ \\\\\\\"index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"search_type\\\\\\\": \\\\\\\"dfs_query_then_fetch\\\\\\\"}\\\\n{ \\\\\\\"query\\\\\\\": { \\\\\\\"knn\\\\\\\": {\\\\\\\"my_vector1\\\\\\\":{\\\\\\\"vector\\\\\\\": [2, 3],\\\\\\\"k\\\\\\\":2 }} } } The following video demonstrates how to set up bulk vector searches for K-NN queries. k-NN differences, tuning, and limitations OpenSearch lets you modify all k-NN settings using the _cluster/settings API. On OpenSearch Service, you can change all settings except knn.memory.circuit_breaker.enabled and knn.circuit_breaker.triggered. k-NN statistics are included as Amazon CloudWatch metrics. In particular, check the KNNGraphMemoryUsage metric on each data node against the knn.memory.circuit_breaker.limit statistic and the available RAM for the instance type. OpenSearch Service uses half of an instance's RAM for the Java heap (up to a heap size of 32 GiB). By default, k-NN uses up to 50% of the remaining half, so an instance type with 32 GiB of RAM can accommodate 8 GiB of graphs (32 * 0.5 * 0.5). Performance can suffer if graph memory usage exceeds this value. You can migrate a k-NN index created on version 2.x or later to UltraWarm or cold storage on a domain with version 2.17 or later. Clear cache api and warmup apis for k-NN indices are blocked for warm indices. When the first query is initiated for the index, it downloads the graph files from Amazon S3 and loads the graph to memory. Similarly, when TTL is expired for the graphs, the files are automatically evicted from memory. Javascript is disabled or is unavailable in your browser. To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions. Document Conventions (Preview) Advanced search capabilities with an Amazon S3 vector engine OpenSearch Dashboards Did this page help you? - Yes Thanks for letting us know we're doing a good job! If you've got a moment, please tell us what we did right so we can do more of it. Did this page help you? - No Thanks for letting us know this page needs work. We're sorry we let you down. If you've got a moment, please tell us how we can make the documentation better.\\\"},{\\\"url\\\":\\\"https://www.digitalocean.com/blog/enhancing-search-capabilities-with-k-nn-vector-search-in-opensearch\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Blog Docs Get Support Contact Sales DigitalOcean Products Featured Products Droplets Scalable virtual machines Kubernetes Scale more effectively Gradient\\u2122 AI Agentic Cloud Build and scale with AI Cloudways Managed cloud hosting App Platform Get apps to market faster Managed Databases Fully-managed database hosting Compute Droplets Kubernetes CPU-Optimized Droplets Functions App Platform Gradient\\u2122 AI Agentic Cloud GPU Droplets 1-Click Models Platform Bare Metal GPUs Backups & Snapshots Backups Snapshots SnapShooter Networking Virtual Private Cloud (VPC) Partner Network Connect Cloud Firewalls Load Balancers DNS DDoS Protection Managed Databases MongoDB Kafka MySQL PostgreSQL Valkey OpenSearch Storage Spaces Object Storage Volume Block Storage Network File Storage Developer Tools API CLI Support Plans Monitoring Uptime Identity and Access Management Marketplace Droplet 1-Click Kubernetes 1-Click AI 1-Click Models Add-Ons Cloud Website Hosting Cloudways See all products Solutions AI and Machine Learning Develop, train, and deploy AI apps GPUs Platform 1-Click Models HR Knowledge Assistant Code Copilot Support Ticket Triage Recommendation Engine Blockchain Infrastructure for decentralized apps Blogs, Forums and Content Websites Lightning-fast, reliable CMS hosting Wordpress Ghost Mastodon Data Analytics Real-time data processing at scale Data Streaming AdTech & Martech Kafka Developer Tools DevOps and CI/CD solutions CI/CD Prototyping Digital Marketing Agencies Power your clients\\u2019 websites and campaigns Freelancer IT Consulting Ecommerce Build beautiful online storefronts Dropshipping WooCommerce Magento Game Development Low-latency multiplayer servers Minecraft Hosting IoT Connect to the power of the cloud Kafka ISVs Streamlined ISV application development Secure Web Hosting Powerful protection from DDoS and more Private VPN Startup Cloud Hosting Scalable, cost-effective infrastructure Small Business Video Streaming High-bandwidth, low-latency delivery Kafka Web and Mobile Apps Simple cross-platform app hosting cPanel Docker Next.js Node.js Website Hosting Fast page loads and reliable site uptime VPS Hosting Virtual Machines Get help Migration Assistance Talk to an expert See all solutions Developers Our Community Community Home DevOps and development guides CSS-Tricks All things web design The Wave Content to level up your business. Resources Tutorials Questions and Answers Marketplace Tools Write for DOnations Cloud Chats Customer Stories DigitalOcean Blog Pricing Calculator Get Involved DigitalOcean Startups Open Source Sponsorships Hacktoberfest Deploy 2025 Wavemakers Program Documentation Quickstart Compute Gradient\\u2122 AI Platform Storage Managed Databases Containers Billing API Reference Partners DigitalOcean Partner Programs Become a Partner Partner Services Program DigitalOcean AI Partner Program Marketplace DigitalOcean Startups Connect with a Partner Partner Programs Resources Customer Stories DigitalOcean Onboarding Series Training for Agencies and Freelancers Price Estimate Calculator Featured Partner Articles Cloud cost optimization best practices Read more How to choose a cloud provider Read more DigitalOcean vs. AWS Lightsail: Which Cloud Platform is Right for You? Read more Questions? Talk to an expert Pricing Log in Sign up Blog Docs Get Support Contact Sales Log in Sign up Engineering Enhancing Search Capabilities with K-NN Vector Search in OpenSearch By Dustin Wilson and Govind Srinivasaraghavan Published: July 31, 2024 5 min read <- Back to blog home Many applications depend on the ability to deliver precise and relevant search results. Although the full-text search capabilities of traditional relational databases are sufficient in some situations, these databases can fall short in extracting semantic meaning from text or searching through less-structured data. In this blog post, we\\u2019ll explore how you can address these limitations using DigitalOcean-managed OpenSearch and a collection of techniques called K-Nearest Neighbor vector search (K-NN). K-NN makes OpenSearch a powerful and flexible solution for various search and analytics applications. Understanding K-NN Vector Search What is K-NN Vector Search? Unlike traditional search methods that rely on keyword matching, K-NN vector search involves representing each record in a dataset as a vector that encapsulates the attributes of the record. Machine learning models are often used to embed data into a vector representation. When a query is made, the search engine computes the distance between the query vector and the data vectors and returns the nearest neighbors based on a predefined distance metric, such as Euclidean distance or cosine similarity. Why Use OpenSearch for K-NN Vector Search? Introduction to OpenSearch OpenSearch is a highly scalable open-source search and analytics engine. It builds upon the strengths of Elasticsearch, providing robust features for full-text search, log analytics, and more. With the introduction of vector search capabilities, OpenSearch extends its utility to more advanced use cases such as natural language processing, recommendation systems, and image retrieval. Benefits of Using OpenSearch for Vector Search Scalability: OpenSearch can handle large volumes of data and queries efficiently. Using approximate nearest neighbor algorithms, OpenSearch can provide relevant search results much faster and with a lower memory footprint. Flexibility: It supports various types of data and search functionalities, making it suitable for diverse applications. Community and Support: Being open-source, it benefits from a vibrant community and regular updates. Setting Up OpenSearch for K-NN Vector Search Installing OpenSearch To get started, you need to install OpenSearch. Here\\u2019s a basic command to pull and run the latest version of the OpenSearch Docker image: docker pull opensearchproject/opensearch:latest\\\\n\\\\n\\\\ndocker run -d --name opensearch -p 9200:9200 -e \\\\\\\"discovery.type=single-node\\\\\\\" -e \\\\\\\"OPENSEARCH_INITIAL_ADMIN_PASSWORD=<your-strong-password>\\u201d opensearchproject/opensearch:latest\\\\n Note: You need to set an initial admin password when you try to run the opensearch docker container. It should be a minimum of 8 characters and must contain at least one uppercase letter, one lowercase letter, one digit, and one special character that is strong. Alternatively, DigitalOcean supports Managed OpenSearch, which makes configuring and managing OpenSearch clusters a breeze. Configuring OpenSearch for Vector Search After installing OpenSearch, the next step is to enable the K-NN plugin. On self-managed clusters, this involves modifying the cluster\\u2019s configuration file. On DigitalOcean Managed Opensearch The K-NN plugin is enabled by default and no additional configuration is required. Implementing K-NN Vector Search To use K-NN vector search, you must first create an index with vector fields. You can do so by navigating to the Opensearch development console at https://${CLUSTER_HOST}/app/dev_tools#/console and submitting the following request. Alternatively, you can send these commands as HTTP requests to https://${CLUSTER_HOST}:9200. PUT /my_vector_index\\\\n\\\\n{\\\\n\\\\n  \\\\\\\"mappings\\\\\\\": {\\\\n\\\\n    \\\\\\\"properties\\\\\\\": {\\\\n\\\\n      \\\\\\\"my_vector\\\\\\\": {\\\\n\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"K-NN_vector\\\\\\\",\\\\n\\\\n        \\\\\\\"dimension\\\\\\\": 128\\\\n\\\\n      }\\\\n\\\\n    }\\\\n\\\\n  }\\\\n\\\\n}\\\\n With this request you\\u2019ve created an index, my_vector_index, which you can use to store and query data using 128-dimension embeddings. You can now begin adding documents along with their vector representations to the index with the following request. PUT /my_vector_index/_doc/1\\\\n\\\\n{\\\\n\\\\n  \\\\\\\"my_vector\\\\\\\": [0.1, 0.2, ... , 0.128],\\\\n\\\\n  \\\\\\\"description\\\\\\\": \\\\\\\"Sample document\\\\\\\"\\\\n\\\\n}\\\\n Finally, to perform a K-NN search over these documents, you can use the following query. POST /my_vector_index/_search\\\\n\\\\n{\\\\n\\\\n  \\\\\\\"size\\\\\\\": 5,\\\\n\\\\n  \\\\\\\"query\\\\\\\": {\\\\n\\\\n    \\\\\\\"K-NN\\\\\\\": {\\\\n\\\\n      \\\\\\\"my_vector\\\\\\\": {\\\\n\\\\n        \\\\\\\"vector\\\\\\\": [0.1, 0.2, ... , 0.128],\\\\n\\\\n        \\\\\\\"k\\\\\\\": 5\\\\n\\\\n      }\\\\n\\\\n    }\\\\n\\\\n  }\\\\n\\\\n}\\\\n Use Cases and Applications Let\\u2019s cover a few end-to-end applications that could make use of Opensearch\\u2019s K-NN capabilities. Customer Support Chatbot: Vector search is often used to find semantically similar texts. A chatbot service might use a machine-learning model to embed an incoming query (e.g. \\u201cHow can I reset my password?\\u201d) into a vector and then use K-NN vector search to find similar queries in the knowledge base, such as \\u201cI forgot my password, how do I reset it?\\u201d. The chatbot can use this information to provide the user a more helpful response based on these similar queries. E-commerce Platform: K-NN vector search can enhance recommendation systems by finding items similar to a user\\u2019s preferences based on vector representations. For example, a user who buys a book from an online store might be recommended other books by the same author, books from the same genre, or even books that other users with similar preferences have bought. In this example, the vector representation of a book may include attributes like author, genre, ratings, and keywords from reviews. Fashion Retailer: By converting images into vectors using deep learning models, K-NN vector search can be used to retrieve visually similar images from a database. A user may upload a photo of a red dress. The system processes the image to create a vector representing the dress\\u2019s visual features. Using K-NN vector search, the platform retrieves and displays similar dresses in various shades of red, with similar cuts and designs, helping the user find exactly what they\\u2019re looking for. Challenges and Considerations using K-NN with OpenSearch 1. Vector Dimensionality High-dimensional vectors can lead to increased computational complexity. It\\u2019s important to balance vector dimensions with performance requirements. Luckily, OpenSearch has multiple K-NN methods with their own performance characteristics. While each method aims to return vectors with the minimal distance to an incoming vector, some can be tuned to prioritize memory use, response time or accuracy. 2. Data Normalization Ensuring that data is normalized and consistent is crucial for the accuracy of K-NN search results. 3. Performance Tuning Optimizing OpenSearch settings and hardware resources is essential for handling large-scale vector searches efficiently. See this article for more details on performance tuning. Conclusion K-NN vector search opens up new possibilities for delivering highly relevant search results across various domains. By leveraging OpenSearch\\u2019s powerful capabilities, developers can implement advanced search functionalities with relative ease. Whether it\\u2019s for recommendation systems, image retrieval, or NLP applications, K-NN vector search with OpenSearch is a valuable tool in the search technology landscape. About the author(s) Dustin Wilson Author See author profile See author profile Govind Srinivasaraghavan Author See author profile See author profile Share Engineering Try DigitalOcean for free Click below to sign up and get $200 of credit to try our products over 60 days! Sign up Related Articles Engineering How startups scale on DigitalOcean Kubernetes: Best Practices Part VI - Security Kunju Perath October 8, 2024 12 min read Read more Engineering Introducing new GitHub Actions for App Platform Markus Th\\u00f6mmes September 26, 2024 8 min read Read more Engineering How SMBs and startups scale on DigitalOcean Kubernetes: Best Practices Part V - Disaster Recovery David Hwang August 14, 2024 7 min read Read more Company About Leadership Blog Careers Customers Partners Referral Program Affiliate Program Press Legal Privacy Policy Security Investor Relations Products Overview Droplets Kubernetes Functions App Platform Gradient\\u2122 AI GPU Droplets Gradient\\u2122 AI Bare Metal GPUs Gradient\\u2122 AI 1-Click Models Gradient\\u2122 AI Platform Load Balancers Managed Databases Spaces Block Storage Network File Storage API Uptime Identity and Access Management Cloudways Resources Community Tutorials Community Q&A CSS-Tricks Write for DOnations Currents Research DigitalOcean Startups Wavemakers Program Compass Council Open Source Newsletter Signup Marketplace Pricing Pricing Calculator Documentation Release Notes Code of Conduct Shop Swag Solutions Website Hosting VPS Hosting Web & Mobile Apps Game Development Streaming VPN SaaS Platforms Cloud Hosting for Blockchain Startup Resources Migration Assistance Contact Support Sales Report Abuse System Status Share your ideas Company About Leadership Blog Careers Customers Partners Referral Program Affiliate Program Press Legal Privacy Policy Security Investor Relations Products Overview Droplets Kubernetes Functions App Platform Gradient\\u2122 AI GPU Droplets Gradient\\u2122 AI Bare Metal GPUs Gradient\\u2122 AI 1-Click Models Gradient\\u2122 AI Platform Load Balancers Managed Databases Spaces Block Storage Network File Storage API Uptime Identity and Access Management Cloudways Resources Community Tutorials Community Q&A CSS-Tricks Write for DOnations Currents Research DigitalOcean Startups Wavemakers Program Compass Council Open Source Newsletter Signup Marketplace Pricing Pricing Calculator Documentation Release Notes Code of Conduct Shop Swag Solutions Website Hosting VPS Hosting Web & Mobile Apps Game Development Streaming VPN SaaS Platforms Cloud Hosting for Blockchain Startup Resources Migration Assistance Contact Support Sales Report Abuse System Status Share your ideas \\u00a9 2025 DigitalOcean, LLC.Sitemap.\\\"},{\\\"url\\\":\\\"https://learncodecamp.net/vector-databases-knn-hnsw/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to content Learn Code Camp Menu Menu Home Java AI System Design JavaScript Kafka Exploring the Power of Vector Databases: Leveraging KNN and HNSW for Efficient Data Retrieval 6 March 2024 by Nitin What are vector databases? Key techniques employed in vector databases Approximate Nearest Neighbors Search (K-ANNS) Examples of ANN algorithms HNSW Summary What are vector databases? A Vector Database is a type of database that stores information in a structured way using vectors. Now, what are vectors? Think of them as mathematical representations of data that capture its meaning and context. Let\\u2019s say you have a photo of a cat. Instead of just storing the image file, a Vector Database will convert this photo into a vector, which is essentially a set of numbers that represent various features of the cat, like its color, shape, and size. This vector will contain information about the cat in a way that a computer can understand. Now, the cool thing about vector databases is that they allow you to search for similar items easily. For instance, if you upload a photo of a dog, the database can quickly find other photos with similar features to that dog by comparing their vectors. This is like when you search for similar images on your smartphone\\u2014except it\\u2019s done using mathematical calculations rather than just looking for file names or tags. So, in simple terms, a Vector Database helps organize and search for different types of data by converting them into mathematical representations called vectors, making it easier to find similar items or information. Check Understanding Embeddings: https://learncodecamp.net/embeddings/ Vector databases are specialized databases tailored for high-dimensional data points represented as vectors, offering efficient storage and retrieval capabilities. They excel at performing nearest-neighbor searches, swiftly retrieving data points closest to a given point in multi-dimensional space. Key techniques employed in vector databases k-Nearest Neighbor (k-NN) Index: This technique enables rapid identification of the k nearest neighbors of a given vector. It aids in efficiently narrowing down the search space, improving retrieval speed. Hierarchical Navigable Small World (HNSW): HNSW algorithm efficiently organizes data points to facilitate faster nearest-neighbor searches. It constructs a hierarchical graph structure that optimizes the search process. In summary, vector databases leverage advanced methods such as k-NN indexes and algorithms like HNSW to ensure efficient storage and retrieval of high-dimensional vectors, enabling rapid lookup of nearest neighbors in multi-dimensional spaces. # Function to find K Nearest Neighbors\\\\ndef find_k_nearest_neighbors(query_vector, vectors, k=5, threshold=0.8):\\\\n    nearest_neighbors = []\\\\n    for vector in vectors:\\\\n        similarity = cosine_similarity(query_vector, vector)\\\\n        if similarity >= threshold:\\\\n            nearest_neighbors.append((vector, similarity))\\\\n    nearest_neighbors.sort(key=lambda x: x[1], reverse=True)\\\\n    return nearest_neighbors[:k]\\\\n Simple pseudocode for finding k nearest neighbors, query_vector is the embedding vector of the search term, and k is the number of the items to retrieve, threshold is minimum match % The brute force of a kNN search is computationally very expensive \\u2013 and depending on the size of your database, a single query could take anything from several seconds to even mins. Number of computations = Number of dimensions \\u00d7 Vector size Given: Number of dimensions (d) = 1536 Vector size (n) = 1 million = 1\\u00d710^6 Number of computations=1536\\u00d71\\u00d710^6 = 1.536\\u00d710^9 approximately 1.536 billion it would take approximately 1.536 seconds to perform all the computations needed for your kNN search on a system capable of performing 1 billion computations per second. Let\\u2019s explore Approximate Nearest Neighbors Algorithms. Approximate Nearest Neighbors Search (K-ANNS) This is used to efficiently find approximate nearest neighbors for a given query point in a large dataset. It\\u2019s particularly useful when dealing with high-dimensional data where traditional exact nearest neighbor search methods become computationally expensive. The quality of an inexact search (the recall) is defined as the ratio between the number of found true nearest neighbors and K To elaborate: True Nearest Neighbors: These are the actual nearest neighbors of the query point in the dataset, determined by some distance metric. For example, if we\\u2019re searching for the 5 nearest neighbors (K=5) of a given point, the true nearest neighbors are those 5 points in the dataset that are closest to the query point. Found Nearest Neighbors: These are the points that the approximate search algorithm returns as the nearest neighbors of the query point. Due to the approximate nature of the search, they may not be exactly the same as the true nearest neighbors. Recall: The recall of the search is then defined as the ratio of the number of found true nearest neighbors to the total number of nearest neighbors desired (K). It\\u2019s calculated using the formula: Recall = (Number of Found True Nearest Neighbors) / K For example, if a search algorithm returns 3 out of the 5 true nearest neighbors for a query with K=5, the recall would be 3/5, or 0.6. This means that the algorithm successfully retrieved 60% of the true nearest neighbors. High recall is desirable in many applications because it indicates that the algorithm is effectively capturing the most relevant points in the dataset. Examples of ANN algorithms Examples of ANN methods are: trees \\u2013 e.g. ANNOY (Figure 1), proximity graphs \\u2013 e.g. HNSW (Figure 2), clustering \\u2013 e.g. FAISS, hashing \\u2013 e.g. LSH, vector compression \\u2013 e.g. PQ or SCANN. Figure 1 Annoy is used at Spotify for music recommendations. Redis Search supports\\u2002FLAT \\u2013 Brute-force index and HNSW HNSW Probabilistic Skip List: A skip list is a data structure that allows for fast search, insertion, and deletion operations in a sorted list. It achieves this by adding multiple layers of pointers, allowing for \\u201cskipping\\u201d over some elements during traversal. In HNSW, the probabilistic skip list is used to organize the data points within each layer of the hierarchical structure. Probabilistic skip list The \\u201cNavigable Small World\\u201d (NSW) part of Hierarchical Navigable Small World (HNSW) refers to a graph structure designed to maintain both local connectivity and global exploration capabilities. Let\\u2019s break down the NSW component: Navigability: NSW aims to create a graph structure where each data point (or node) is connected to its neighbors in a way that facilitates efficient navigation through the dataset. This means that similar points are likely to be connected, allowing for quick traversal between them. Small World Property: The small-world property refers to the idea that even though the graph may be large and sparsely connected, it\\u2019s still possible to navigate from one point to another through a relatively small number of connections. This property is essential for efficient search and exploration in large datasets. Connection Strategy: In NSW, connections between points are established based on their proximity in the data space. Typically, points that are closer together in the data space are more likely to be connected. However, NSW also incorporates randomness into the connection strategy to balance local connectivity with global exploration. Efficient Search: By creating a graph structure with the small-world property, NSW enables efficient search for nearest neighbors. During the search process, the algorithm can navigate through the graph using a combination of local connections to quickly find nearby points and occasional long-range connections to explore distant regions of the dataset. Summary Vector databases rely on Machine Learning models to generate vector embeddings for all data objects. Vector embeddings represent the meaning and context of data, enabling efficient analysis and retrieval. Vector databases provide rapid query capabilities due to Approximate Nearest Neighbors (ANN) algorithms. ANN algorithms sacrifice some accuracy in exchange for significant performance improvements. Categories AI Building a RESTful API with Node.js, Express, and MongoDB Revolutionizing AI: LLMs Without GPUs? The Promise of BitNet B1.58 Leave a comment Cancel reply Comment Name Email Save my name, email, and website in this browser for the next time I comment. \\u0394 Search for: Recent Posts Debugging HTTP Traffic Like a Pro: HTTP Toolkit and Terminal Interception How to Stop Hallucinations in RAG Chatbots: A Complete Guide Agentic Context Engineering (ACE): Turning Context Into a Self-Improving Playbook for LLMs Search for: Categories AI Blog Java JavaScript Kafka Spring Boot System Design Recent Posts Debugging HTTP Traffic Like a Pro: HTTP Toolkit and Terminal Interception How to Stop Hallucinations in RAG Chatbots: A Complete Guide Agentic Context Engineering (ACE): Turning Context Into a Self-Improving Playbook for LLMs Loss functions for llm \\u2014 a practical, hands-on guide Q K V : Query (Q), Key (K), and Value (V) Vectors in the Attention Mechanism Tags AI aop beans command line embeddings eol java java8 javascript kafka maven microservices mvn spring boot system design Quick Links Home Contact Us Privacy Policy About Us \\u00a9 2025 Learn Code Camp \\u2022 Built with GeneratePress\\\"},{\\\"url\\\":\\\"https://generativeai.pub/how-i-use-knn-and-ann-to-power-fast-scalable-vector-search-206fd9fb21f3\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Sitemap Open in app Sign up Sign in Medium Logo Write Search Sign up Sign in Generative AI \\u00b7 Follow publication Stay updated with the latest news, research, and developments in the world of generative AI. We cover everything from AI model updates, comprehensive tutorials, and real-world applications to the broader impact of AI on society. Work with us: jimclydegm@gmail.com Follow publication How I Use KNN and ANN to Power Fast, Scalable Vector Search Alex Chen 5 min read \\u00b7 Jul 16, 2025 -- Listen Share Press enter or click to view image in full size As I\\u2019ve been building a semantic search engine over a growing corpus of multimodal data, I\\u2019ve had to answer a deceptively simple question: What\\u2019s the fastest way to find similar vectors at scale \\u2014 without burning memory or sacrificing recall? That question led me deep into the internals of vector search algorithms, especially the trade-offs between exact and approximate methods like K-Nearest Neighbors (KNN) and Approximate Nearest Neighbors (ANN). In this post, I\\u2019ll walk through how these algorithms work, why they matter, and where each fits in real-world deployments. Vector Search in Practice Imagine you\\u2019re running facial recognition in a high-traffic airport. Each detected face becomes a high-dimensional vector. Your system must search millions of stored vectors \\u2014 quickly \\u2014 to find the top few that resemble the input. This is vector search: efficient retrieval based on similarity in high-dimensional space. Under the hood, this process relies on distance metrics like Euclidean or cosine similarity. The core challenge is performance: brute-force comparisons don\\u2019t scale, especially when latency budgets are tight. That\\u2019s where machine learning-based search methods come into play. Method 1: K-Nearest Neighbors (KNN) KNN is the most intuitive approach: Take your query vector Compare it to every vector in the dataset Pick the K closest ones based on a distance metric It\\u2019s dead simple and perfectly accurate \\u2014 but it doesn\\u2019t scale. Let\\u2019s say you have 10 million vectors, each with 512 dimensions. A brute-force KNN search means computing 10 million distances for every query. That\\u2019s CPU-intensive, cache-unfriendly, and slow under real-time constraints. KNN is best suited for: Small datasets (<100K vectors) Tasks where precision is non-negotiable (e.g., forensics or compliance) Offline or batch inference pipelines Press enter or click to view image in full size Method 2: Approximate Nearest Neighbors (ANN) To make vector search scalable, we approximate. ANN algorithms build clever index structures \\u2014 think of them as spatial shortcuts. They don\\u2019t guarantee the exact nearest neighbors, but they can find very close ones much faster. Instead of comparing to every vector, ANN searches through select regions likely to contain similar vectors. You can tune the trade-off between speed and accuracy depending on the use case. Common ANN algorithms: HNSW (Hierarchical Navigable Small Worlds): Graph-based, fast and high-recall IVF (Inverted File) + PQ (Product Quantization): Partition-based, memory-efficient LSH (Locality-Sensitive Hashing): Fast but lower recall, best for sparse or binary vectors KNN vs ANN: Trade-off Table Here\\u2019s a quick summary from my benchmarking: In one of my tests on a 1M vector dataset (768 dims), HNSW reduced average query time from 230ms (brute force) to 12ms, with a recall of ~94%. When K Isn\\u2019t Enough: Range Search KNN and ANN return exactly K results \\u2014 but what if that includes duplicates or irrelevant hits? Take a streaming recommender that shows \\u201ctop 5 similar songs.\\u201d If all 5 are near-identical variants of one genre, you\\u2019re not delivering diversity. Range search solves this by retrieving all vectors within a given distance threshold instead of a fixed count. Here\\u2019s a Python example using a Milvus-compatible API to set distance bounds: search_params = {     \\\\\\\"params\\\\\\\": {         \\\\\\\"nprobe\\\\\\\": 10,         \\\\\\\"radius\\\\\\\": 10,         \\\\\\\"range_filter\\\\\\\": 20     } } res = collection.search(     vectors, \\\\\\\"float_vector\\\\\\\", search_params, topK,     \\\\\\\"int64 > 100\\\\\\\", output_fields=[\\\\\\\"int64\\\\\\\", \\\\\\\"float\\\\\\\"] ) This approach shines in: Data deduplication Copyright detection (finding \\u201ctoo-similar\\u201d content) Use cases needing semantic filtering, not just top-K \\ud83d\\udccc Reference: unlock advanced recommendation engines with Milvus\\u2019s new range search Indexing Considerations Choosing ANN also means choosing an index type. My rule of thumb: Press enter or click to view image in full size Use CaseIndex TypeNotesLow-latency web appHNSWFastest; low memory if tuned wellMulti-billion vector archiveIVF_PQScalable; great for cold queriesSparse or binary embeddingsLSHQuick setup; less accurateMultilingual searchOPQ + IVFImproves vector alignment pre-PQ Some vector DBs\\uff08like Milvus\\uff09let you plug these in easily. Just remember that index building time and size can vary a lot \\u2014 I\\u2019ve seen HNSW index builds take 3x longer than IVF on the same dataset. Deployment Notes When rolling out ANN in production, consider: Index warm-up: Preload into memory to avoid cold-start penalties Batch vs real-time: Some ANN types are better suited for offline queries (e.g., IVF_PQ) Recall monitoring: Approximation means drift \\u2014 log sample queries and validate outputs periodically For large-scale deployments, hardware also matters. In my tests, running ANN on CPU with AVX2 SIMD saw 3\\u20135x gains in speed. If your DB supports GPU (e.g., Faiss GPU backend), you might see even more. What I\\u2019m Exploring Next Lately, I\\u2019ve been digging into hybrid search \\u2014 combining vector and keyword filtering for more nuanced results. I\\u2019m also curious about how adaptive indexing could optimize ANN over time as data evolves. Vector search is no longer a toy problem. Whether it\\u2019s recommendations, semantic retrieval, or surveillance, scalable search is now a core infrastructure need \\u2014 and choosing the right algorithm is step one. If you\\u2019re hitting latency ceilings or drowning in embeddings, don\\u2019t default to brute-force. Take the time to understand your data shape and use case \\u2014 and consider ANN where it fits. Let me know if you\\u2019d like a follow-up post on comparing HNSW and IVF_PQ head-to-head. I\\u2019ve got some fun benchmarks on that. This story is published on Generative AI. Connect with us on LinkedIn and follow Zeniteq to stay in the loop with the latest AI stories. Subscribe to our newsletter and YouTube channel to stay updated with the latest news and updates on generative AI. Let\\u2019s shape the future of AI together! Machine Learning Artificial Intelligence Data Science Vector Database -- -- Follow Published in Generative AI 68K followers \\u00b7Last published 1 day ago Stay updated with the latest news, research, and developments in the world of generative AI. We cover everything from AI model updates, comprehensive tutorials, and real-world applications to the broader impact of AI on society. Work with us: jimclydegm@gmail.com Follow Written by Alex Chen 11 followers \\u00b74 following Passionate open\\u2011source contributor and database tinkerer sharing insights on ANN algorithm implementations and vector indexing techniques. No responses yet Help Status About Careers Press Blog Privacy Rules Terms Text to speech\\\"},{\\\"url\\\":\\\"https://www.elastic.co/search-labs/tutorials/search-tutorial/vector-search/nearest-neighbor-search\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Explore Elastic: elastic.co Security Labs Observability Labs Tutorials Examples Integrations Blogs Start free trial Tutorials/Search Tutorial k-Nearest Neighbor (kNN) Search In this series Welcome Requirements Project Setup Full-Text Search Python Client Setup Create an Index Search Basics Pagination Filters Faceted Search Vector Search Embeddings Intro Generating Embeddings Storing Embeddings k-Nearest Neighbor Search Hybrid Search Semantic Search ELSER Model Semantic Queries Hybrid Search Conclusion Copy Share The k-nearest neighbor (kNN) algorithm performs a similarity search on fields of dense_vector type. This type of search, which is more appropriately called \\\\\\\"approximate kNN\\\\\\\", accepts a vector or embedding as a search term, and finds entries in the index that are close. In this section you are going to learn how to run a kNN search using the document embeddings created in the previous section. The knn Query In the full-text search section of the tutorial you learned about the query option passed to the search() method of the Elasticsearch client. When searching vectors, the knn option is used instead. Below you can see a new version of the handle_search() function in app.py that runs a kNN search for the query entered by the user in the search form. In this version of the function, the query option was replaced with knn. The size and from_ options for pagination remain the same, and everything else in the function and the index.html template are also the same as before. The knn search option accepts a number of parameters that configure the search: field: the field in the index to search. The field must have a dense_vector type. query_vector: the embedding to search for. This should be an embedding generated from the search text. num_candidates: the number of candidate documents to consider from each shard. Elasticsearch retrieves this many candidates from each shard, combines them into a single list and then finds the closest \\\\\\\"k\\\\\\\" to return as results. k: the number of results to return. This number has a direct effect on performance, so it should be kept as small as possible. The value passed in this option must be less than num_candidates. With the settings used in the code above, the 10 best matching results will be returned. You are welcome to experiment with this new version of the application. Here are a pair of good examples to appreciate how useful this type of search: Searching for \\\\\\\"holiday\\\\\\\", which is the British English equivalent to \\\\\\\"vacation\\\\\\\" in American English, kNN search returns the document \\\\\\\"Vacation Policy\\\\\\\" as top result, even though the word holiday itself does not appear in the document. Searching for \\\\\\\"cats and dogs\\\\\\\" or any other term related to pets brings the \\\\\\\"Office Pet Policy\\\\\\\" document as top result, even though the document summary does not mention any specific pets. Using Filters in kNN Queries The search query, as defined in the full-text section of this tutorial, allowed the user to request a specific category to be used, using the syntax category:<category-name> in any place of the search text. The extract_filters() function in app.py is in charge of finding and separating these filter expressions from the search query. In the version of the handle_search() function from the previous section the filters variable is not used, so the category filters are ignored. Luckily, the knn option also supports filtering. The filter option actually accepts the same type of filters, so the filters can be inserted directly into the knn query, exactly as they are returned by the extract_filters() function: Aggregations also work well in kNN queries, so they can also be added back: This version of the handle_search() function has the same functionality as the full-text search version, implemented using vector search instead of keyword-based search. In the next section, you'll learn how to combine results from these two different search methods. Previously Storing Embeddings Next Hybrid Search Report an issue Ready to build state of the art search experiences? Sufficiently advanced search isn\\u2019t achieved with the efforts of one. Elasticsearch is powered by data scientists, ML ops, engineers, and many more who are just as passionate about search as you are. Let\\u2019s connect and work together to build the magical search experience that will get you the results you want. Try it yourself Subscribe to newsletter Elasticsearch Labs is the one-stop destination for developers to learn how to easily utilize Elasticsearch to build advanced search experiences including generative AI, embedding models, reranking capabilities and more. Let's connect Menu Tutorials Examples Integrations Blogs Search Additional Resources Elasticsearch API Reference Elastic.co Sitemap RSS 2025. Elasticsearch B.V. All Rights Reserved.\\\"},{\\\"url\\\":\\\"https://www.ibm.com/think/topics/vector-search\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Artificial Intelligence What is vector search? Authors Meredith Syed Technical Content, Editorial Lead IBM Erika Russi Data Scientist IBM What is vector search? Vector search is a search technique used to find similar items or data points, typically represented as vectors, in large collections. Vectors, or embeddings, are numerical representations of words, entities, documents, images or videos. Vectors capture the semantic relationships between elements, enabling effective processing by machine learning models and artificial intelligence applications. Vector search vs. traditional search In contrast to traditional search, which typically uses keyword search, vector search relies on vector similarity search techniques like k-nearest neighbor search (knn) to retrieve data points similar to a query vector based on some distance metric. Vectors capture semantic relationships and similarities between data points, enabling semantic search instead of simple keyword search. To illustrate the difference between traditional keyword and vector search, let\\u2019s go through an example. Say you are looking for information on the best pizza restaurant and you search for \\u201cbest pizza restaurant\\u201d in a traditional keyword search engine. The keyword search looks for pages that contain the exact words \\u201cbest\\u201d, \\u201cpizza\\u201d and \\u201crestaurant\\u201d and only returns results like \\u201cBest Pizza Restaurant\\u201d or \\u201cPizza restaurant near me\\u201d. Traditional keyword search focuses on matching the keywords rather than understanding the context or intent behind the search. By contrast, in a semantic vector search, the search engine understands the intent behind the query. Semantic, by definition, means relating to meaning in language, that is, semantic search understands the meaning and context of a query. In this case, it would look for content that talks about top-rated or highly recommended pizza places, even if the exact words \\\\\\\"best pizza restaurant\\\\\\\" are not used in the content. The results are more contextually relevant and might include articles or guides that discuss high quality pizza places in various locations. Traditional search methods typically represent data using discrete tokens or features, such as keywords, tags or metadata. As shown in our example above, these methods rely on exact matches to retrieve relevant results. By contrast, vector search represents data as dense vectors (a vector in which most or all of the elements are non-zero) in a continuous vector space, the mathematical space in which data is represented as vectors. Each dimension of the dense vector corresponds to a latent feature or aspect of the data, an underlying characteristic or attribute that is not directly observed but is inferred from the data through mathematical models or algorithms. These latent features capture the hidden patterns and relationships in the data, enabling more meaningful and accurate representations of items as vectors in a high-dimensional space. Traditional search methods may struggle with scalability for large datasets or high-dimensional data due to computational and memory constraints. By contrast, vector embeddings are easier to scale to larger datasets and more complex models. Unlike sparse representations of data where most of the values are zeros across dimensions, embeddings are dense vector representations having non-zero values in most dimensions. This allows vector embeddings to store more information in a smaller, lower-dimensional space, requiring less memory.1 As a result, machine learning algorithms and models can use embeddings more efficiently with fewer compute resources. Vectorization process For this explainer, we will focus on the vector representations applicable under natural language processing (NLP), that is, vectors that represent words, entities or documents. We will illustrate the vectorization process by vectorizing a small corpus of sentences: \\u201cthe cat sat on the mat\\u201d, \\u201cthe dog played in the yard\\u201d and \\u201cbirds chirped in the trees\\u201d. The first step to building vector embeddings is to clean and process the raw dataset. This may involve the removal of noise and standardization of the text. For our example, we won\\u2019t do any cleaning since the text is already cleaned and standardized. Next, an embedding model is chosen to be trained on the dataset. The trained embedding model is used to generate embeddings for each data point in the dataset. For text data, popular open-source embedding models include Word2Vec, GloVe, FastText or pre-trained transformer-based models like BERT or RoBERTa2. For our example, we\\u2019ll use Word2Vec to generate our embeddings. Next, the embeddings are stored in a vector database or a vector search plugin for a search engine, like Elasticsearch, is used. In vector search, relevance of a search result is established by assessing the similarity between the query vector, which is generated by vectorizing the query, and the document vector, which is a representation of the data being queried. Indexes need to be created in the vector database to enable fast and efficient retrieval of embeddings based on similar queries. Techniques such as hierarchical navigable small world (HNSW) can be used to index the embeddings and facilitate similarity search at query time. HNSW organizes the dataset and enables rapid search for nearest neighbors by clustering similar vectors together during the index construction process. Finally, a mechanism or procedure to generate vectors for new queries must be established. This typically involves creating an API or service that takes user search queries as input in real-time, processes it using the same vector model and generates a corresponding vector representation. This vector can then be used to search on the database to get the most relevant results. Finding similarity with distance measurements and ANN algorithms In vector search, relevance is determined by measuring the similarity between query and document vectors. To compare two vectors against each other and determine their similarity, some distance measurement may be used, such as Euclidean distance or cosine similarity3. Euclidean distance Euclidean distance is a measure of the straight-line distance between two points. It is calculated as the square root of the sum of the squared differences between the corresponding coordinates of the two points. This formula can be extended to higher-dimensional spaces by adding more terms to account for additional dimensions. Cosine similarity Cosine similarity is a measure of similarity between two vectors in a multi-dimensional space. It calculates the cosine of the angle between the two vectors, indicating how closely the vectors align with each other. Mathematically, the cosine similarity, cos(\\u03b8), between two vectors is calculated as the dot product of the two vectors divided by the product of their magnitudes. Cosine similarity ranges from -1 to 1, where: 1 indicates that the vectors are perfectly aligned (pointing in the same direction), 0 indicates that the vectors are orthogonal (perpendicular to each other) and -1 indicates that the vectors are pointing in opposite directions. Cosine similarity is particularly useful when dealing with vectors, as it focuses on the directional relationship between vectors rather than their magnitudes. Approximate-nearest neighbor (ANN) Although the distance metrics mentioned previously can be used to measure vector similarity, it becomes inefficient and slow to compare all possible vectors against the query vector at query time for similarity search. To solve for this, we can use an approximate-nearest neighbor (ANN) search. Instead of finding an exact match, ANN algorithms efficiently search for the vectors that are approximately closest to a given query based on some distance metric like Euclidean distance or cosine similarity. By allowing for some level of approximation, these algorithms can significantly reduce the computational cost of nearest neighbor search without the need to compute embedding similarities across an entire corpus. One of the most popular ANN algorithms is HNSW graphs. The hierarchical navigable small world graph structure indexes the dataset and facilitates fast search for nearest neighbors by grouping similar vectors together as it builds the index. HNSW organizes data into neighborhoods, linking them with probable connections. When indexing a dense vector, it identifies the suitable neighborhood and its potential connections, storing them in a graph structure. During an HNSW search with a dense vector query, it locates the optimal neighborhood entry point and returns the nearest neighbors. Applications of vector search Vector search has numerous use cases across domains due to its ability to efficiently retrieve similar items based on their vector representations. Some common applications of vector search include: Information retrieval Vector search is used in search engines to retrieve documents, articles, web pages or other textual content based on their similarity to a query. It enables users to find relevant information even if the exact terms used in the query are not present in the documents. Retrieval Augmented Generation (RAG) Vector search is instrumental in the Retrieval Augmented Generation (RAG) framework for retrieving relevant context from a large corpus of text. RAG is a framework for generative AI that combines vector search with generative language models to generate responses. In traditional language generation tasks, large language models (LLMs) like OpenAI\\u2019s GPT (Generative Pre-trained Transformer) or IBM\\u2019s Granite Models are used to construct responses based on the input prompt. However, these models may struggle to produce responses that are contextually relevant, factually accurate or up to date. RAG addresses this limitation by incorporating a retrieval step before response generation. During retrieval, vector search can be used to identify contextually pertinent information, such as relevant passages or documents from a large corpus of text, typically stored in a vector database. Next, an LLM is used to generate a response based on the retrieved context. Beyond language generation, RAG and vector search have further applications in various other NLP tasks, including question answering, chatbots, summarization and content generation. Hybrid search Vector search can be integrated into hybrid search approaches to enhance the effectiveness and flexibility of the search process. Hybrid search combines vector search with other search techniques, such as keyword-based search or metadata-based search. Vector search may be used to retrieve items based on their similarity to a query, while other search methods may be used to retrieve items based on exact matches or specific criteria. Video and image search Vector stores are used in image and video search engines to index and retrieve visual content based on similarity. Image and video embeddings are stored as vectors, enabling users to search for visually similar images or videos across large datasets. Recommendation systems Recommendation engines in streaming services as well as e-commerce, social media and visual media platforms can be powered by vector search. Vector search allows for the recommendation of products, movies, music or other items based on their similarity to items that users have interacted with or liked previously. Geospatial analysis Vector search is used in geospatial data applications to to retrieve spatial data such as points of interest, geographic features or spatial trajectories based on their proximity or similarity to a query location or pattern. It enables efficient spatial search and analysis in geographic information systems and location-based services. The latest AI News + Insights \\\\u2028 Discover expertly curated insights and news on AI, cloud and more in the weekly Think Newsletter. Subscribe today Mixture of Experts | 7 November, episode 80 Decoding AI: Weekly News Roundup Join our world-class panel of engineers, researchers, product leaders and more as they cut through the AI noise to bring you the latest in AI news and insights. Watch all episodes of Mixture of Experts Ebook How to choose the right foundation model Learn how to choose the right approach in preparing datasets and employing foundation models. Read the ebook Resources Upcoming Webinar | November 20 Fact or Fiction? Top Misconceptions About AI Agents Join experts from IBM and MINT.ai as they break down the most common misconceptions about AI agents and share the truth behind the technology. Register now Ebook Start realizing ROI: A practical guide to agentic AI Discover ways to get ahead, successfully scaling AI across your business with real results. Read the ebook 2025 AI Agents buyer's guide How AI agents and assistants can benefit your organization Dive into this comprehensive guide that breaks down key use cases, core capabilities, and step-by-step recommendations to help you choose the right solutions for your business. Read the guide Report Top strategic technology trends for 2025: Agentic AI Download this Gartner\\u00ae research to learn the potential opportunities and risks of agentic AI for IT leaders and how to prepare for this next wave of AI innovation. Read the report Training Level up your AI expertise Access our full catalog of over 100 online courses by purchasing an individual or multi-user subscription today, enabling you to expand your skills across a range of our products at a low price. Start learning Report From AI projects to profits: How agentic AI can sustain financial returns Learn how organizations are shifting from launching AI in disparate pilots to using it to drive transformation at the core. Read the report AI models Explore IBM Granite IBM\\u00ae Granite\\u00ae is a family of open, performant and trusted AI models tailored for business and optimized to scale your AI applications. Explore language, code, time series and guardrail options. Meet Granite Report IBM is named a Leader in Data Science & Machine Learning Learn why IBM has been recognized as a Leader in the 2025 Gartner\\u00ae Magic Quadrant\\u2122 for Data Science and Machine Learning Platforms. Read the report Video IBM AI Academy Led by top IBM thought leaders, the curriculum is designed to help business leaders gain the knowledge needed to prioritize the AI investments that can drive growth. Explore the series Report The 2025 CEO\\u2019s guide: 5 mindshifts to supercharge business growth Activate these five mindshifts to cut through the uncertainty, spur business reinvention, and supercharge growth with agentic AI. Read the report Ebook Unlock the power of generative AI and ML Learn how to confidently incorporate generative AI and machine learning into your business. Read the ebook Guide How to thrive in this new era of AI with trust and confidence Dive into the three critical elements of a strong AI strategy: creating a competitive edge, scaling AI across the business and advancing trustworthy AI. Read the guide Related solutions IBM\\u00ae watsonx Orchestrate\\u2122 Easily design scalable AI assistants and agents, automate repetitive tasks and simplify complex processes with IBM\\u00ae watsonx Orchestrate\\u2122. Explore watsonx Orchestrate Artificial intelligence solutions Put AI to work in your business with IBM\\u2019s industry-leading AI expertise and portfolio of solutions at your side. Explore AI solutions Artificial intelligence consulting and services IBM Consulting AI services help reimagine how businesses work with AI for transformation. Explore AI services Take the next step Whether you choose to customize pre-built apps and skills or build and deploy custom agentic services using an AI studio, the IBM watsonx platform has you covered. Explore watsonx Orchestrate Explore watsonx.ai Footnotes 1 Bahaaldine Azarmi and Jeff Vestal, Vector Search for Practitioners with Elastic, Packt Publishing, 2023 2 Vicki Boykis, \\u201cWhat are embeddings,\\u201d 2023, https://vickiboykis.com/what_are_embeddings 3 Trey Grainger, Doug Turnbull and Max Irwin, AI Powered Search, Manning Publications, 2024\\\"}]}\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "üìö Technical Information:\n",
      "{\n",
      "  \"inference_results\": [\n",
      "    {\n",
      "      \"output\": [\n",
      "        {\n",
      "          \"name\": \"response\",\n",
      "          \"result\": \"{\\\"next_page\\\":\\\"https://duckduckgo.com/html?q=What+is+k-NN+vector+search+and+how+does+it+work?&s=10&nextParams=&v=l&o=json&dc=11&api=d.js&vqd=4-323019276702527373326608110606503075675&kl=wt-wt\\\",\\\"items\\\":[{\\\"url\\\":\\\"https://docs.opensearch.org/latest/vector-search/vector-search-techniques/index/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Regular expression syntax Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Using UBI in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Vector search techniques OpenSearch implements vector search as k-nearest neighbors, or k-NN, search. k-NN search finds the k neighbors closest to a query point across an index of vectors. To determine the neighbors, you can specify the space (the distance function) you want to use to measure the distance between points. OpenSearch supports three different methods for obtaining the k-nearest neighbors from an index of vectors: Approximate search (approximate k-NN, or ANN): Returns approximate nearest neighbors to the query vector. Usually, approximate search algorithms sacrifice indexing speed and search accuracy in exchange for performance benefits such as lower latency, smaller memory footprints, and more scalable search. For most use cases, approximate search is the best option. Exact search: A brute-force, exact k-NN search of vector fields. OpenSearch supports the following types of exact search: Exact search with a scoring script: Using a scoring script, you can apply a filter to an index before executing the nearest neighbor search. Painless extensions: Adds the distance functions as Painless extensions that you can use in more complex combinations. You can use this method to perform a brute-force, exact vector search of an index, which also supports pre-filtering. In general, you should choose the ANN method for larger datasets because it scales significantly better. For smaller datasets, where you may want to apply a filter, you should choose the custom scoring approach. If you have a more complex use case in which you need to use a distance function as part of the scoring method, you should use the Painless scripting approach. Approximate search OpenSearch supports multiple backend algorithms (methods) and libraries for implementing these algorithms (engines). It automatically selects the optimal configuration based on the chosen mode and available memory. For more information, see Methods and engines. Using sparse vectors Neural sparse search offers an efficient alternative to dense vector search by using sparse embedding models and inverted indexes, providing performance similar to BM25. Unlike dense vector methods that require significant memory and CPU resources, sparse search creates a list of token-weight pairs and stores them in a rank features index. This approach combines the efficiency of traditional search with the semantic understanding of neural networks. OpenSearch supports both automatic embedding generation through ingest pipelines and direct sparse vector ingestion. For more information, see Neural sparse search. Combining multiple search techniques Hybrid search enhances search relevance by combining multiple search techniques in OpenSearch. It integrates traditional keyword search with vector-based semantic search. Through a configurable search pipeline, hybrid search normalizes and combines scores from different search methods to provide unified, relevant results. This approach is particularly effective for complex queries where both semantic understanding and exact matching are important. The search pipeline can be further customized with post-filtering operations and aggregations to meet specific search requirements. For more information, see Hybrid search. Approximate search Using sparse vectors Combining multiple search techniques WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright \\u00a9 OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\\\"},{\\\"url\\\":\\\"https://learn.microsoft.com/en-us/azure/search/vector-search-ranking\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to main content Skip to Ask Learn chat experience This browser is no longer supported. Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support. Download Microsoft Edge More info about Internet Explorer and Microsoft Edge Table of contents Exit editor mode Ask Learn Ask Learn Focus mode Table of contents Read in English Add Add to plan Edit Share via Facebook x.com LinkedIn Email Print Note Access to this page requires authorization. You can try signing in or changing directories. Access to this page requires authorization. You can try changing directories. Relevance in vector search Feedback Summarize this article for me In this article During vector query execution, the search engine looks for similar vectors to find the best candidates to return in search results. Depending on how you indexed the vector content, the search for relevant matches is either exhaustive, or constrained to nearest neighbors for faster processing. Once candidates are found, similarity metrics are used to score each result based on the strength of the match. This article explains the algorithms used to find relevant matches and the similarity metrics used for scoring. It also offers tips for improving relevance if search results don't meet expectations. Algorithms used in vector search Vector search algorithms include: Exhaustive K-Nearest Neighbors (KNN), which performs a brute-force scan of the entire vector space. Hierarchical Navigable Small World (HNSW), which performs an Approximate Nearest Neighbor (ANN) search. Only vector fields marked as searchable in the index or searchFields in the query are used for searching and scoring. About exhaustive KNN Exhaustive KNN calculates the distances between all pairs of data points and finds the exact k nearest neighbors for a query point. Because the algorithm doesn't require fast random access of data points, KNN doesn't consume vector index size quota. However, it provides the global set of nearest neighbors. Exhaustive KNN is computationally intensive, so use it for small to medium datasets or when the need for precision outweighs the need for query performance. Another use case is building a dataset to evaluate the recall of an ANN algorithm, as exhaustive KNN can be used to build the ground truth set of nearest neighbors. About HNSW HNSW is an ANN algorithm optimized for high-recall, low-latency applications with unknown or volatile data distribution. During indexing, HNSW creates extra data structures that organize data points into a hierarchical graph. During query execution, HNSW navigates through this graph to find the most relevant matches, enabling efficient nearest neighbor searches. HNSW requires all data points to reside in memory for fast random access, which consumes vector index size quota. This design balances search accuracy with computational efficiency and makes HNSW suitable for most scenarios, especially when searching over larger datasets. HNSW offers several tunable configuration parameters to optimize throughput, latency, and recall for your search application. For example, fields that specify HNSW also support exhaustive KNN using the query request parameter \\\\\\\"exhaustive\\\\\\\": true. However, fields indexed for exhaustiveKnn don't support HNSW queries because the extra data structures that enable efficient search don't exist. About ANN ANN is a class of algorithms for finding matches in vector space. This class of algorithms uses different data structures or data partitioning methods to significantly reduce the search space and accelerate query processing. ANN algorithms sacrifice some accuracy but offer scalable and faster retrieval of approximate nearest neighbors, which makes them ideal for balancing accuracy and efficiency in modern information retrieval applications. You can adjust the parameters of your algorithm to fine-tune the recall, latency, memory, and disk footprint requirements of your search application. Azure AI Search uses HNSW for its ANN algorithm. How nearest neighbor search works Vector queries execute against an embedding space consisting of vectors generated from the same embedding model. Generally, the input value within a query request is fed into the same machine learning model that generated embeddings in the vector index. The output is a vector in the same embedding space. Since similar vectors are clustered close together, finding matches is equivalent to finding the vectors that are closest to the query vector, and returning the associated documents as the search result. For example, if a query request is about hotels, the model maps the query into a vector that exists somewhere in the cluster of vectors representing documents about hotels. Identifying which vectors are the most similar to the query, based on a similarity metric, determines which documents are the most relevant. When vector fields are indexed for exhaustive KNN, the query executes against \\\\\\\"all neighbors\\\\\\\". For fields indexed for HNSW, the search engine uses an HNSW graph to search over a subset of nodes within the vector index. Creating the HNSW graph During indexing, the search service constructs the HNSW graph. The goal of indexing a new vector into an HNSW graph is to add it to the graph structure in a manner that allows for efficient nearest neighbor search. The following steps summarize the process: Initialization: Start with an empty HNSW graph, or the existing HNSW graph if it's not a new index. Entry point: This is the top-level of the hierarchical graph and serves as the starting point for indexing. Adding to the graph: Different hierarchical levels represent different granularities of the graph, with higher levels being more global, and lower levels being more granular. Each node in the graph represents a vector point. Each node is connected to up to m neighbors that are nearby. This is the m parameter. The number of data points considered as candidate connections is governed by the efConstruction parameter. This dynamic list forms the set of closest points in the existing graph for the algorithm to consider. Higher efConstruction values result in more nodes being considered, which often leads to denser local neighborhoods for each vector. These connections use the configured similarity metric to determine distance. Some connections are \\\\\\\"long-distance\\\\\\\" connections that connect across different hierarchical levels, creating shortcuts in the graph that enhance search efficiency. Graph pruning and optimization: This can happen after indexing all vectors, and it improves navigability and efficiency of the HNSW graph. Navigating the HNSW graph at query time A vector query navigates the hierarchical graph structure to scan for matches. The following summarize the steps in the process: Initialization: The algorithm initiates the search at the top-level of the hierarchical graph. This entry point contains the set of vectors that serve as starting points for search. Traversal: Next, it traverses the graph level by level, navigating from the top-level to lower levels, selecting candidate nodes that are closer to the query vector based on the configured distance metric, such as cosine similarity. Pruning: To improve efficiency, the algorithm prunes the search space by only considering nodes that are likely to contain nearest neighbors. This is achieved by maintaining a priority queue of potential candidates and updating it as the search progresses. The length of this queue is configured by the parameter efSearch. Refinement: As the algorithm moves to lower, more granular levels, HNSW considers more neighbors near the query, which allows the candidate set of vectors to be refined, improving accuracy. Completion: The search completes when the desired number of nearest neighbors have been identified, or when other stopping criteria are met. This desired number of nearest neighbors is governed by the query-time parameter k. Similarity metrics used to measure nearness The algorithm finds candidate vectors to evaluate similarity. To perform this task, a similarity metric calculation compares the candidate vector to the query vector and measures the similarity. The algorithm keeps track of the ordered set of most similar vectors that its found, which forms the ranked result set when the algorithm has reached completion. Metric Description cosine This metric measures the angle between two vectors, and isn't affected by differing vector lengths. Mathematically, it calculates the angle between two vectors. Cosine is the similarity metric used by Azure OpenAI embedding models, so if you're using Azure OpenAI, specify cosine in the vector configuration. dotProduct This metric measures both the length of each pair of two vectors, and the angle between them. Mathematically, it calculates the products of vectors' magnitudes and the angle between them. For normalized vectors, this is identical to cosine similarity, but slightly more performant. euclidean (also known as l2 norm) This metric measures the length of the vector difference between two vectors. Mathematically, it calculates the Euclidean distance between two vectors, which is the l2-norm of the difference of the two vectors. Note If you run two or more vector queries in parallel, or if you do a hybrid search that combines vector and text queries in the same request, Reciprocal Rank Fusion (RRF) is used for scoring the final search results. Scores in a vector search results Scores are calculated and assigned to each match, with the highest matches returned as k results. The @search.score property contains the score. The following table shows the range within which a score will fall. Search method Parameter Scoring metric Range vector search @search.score Cosine 0.333 - 1.00 Forcosine metric, it's important to note that the calculated @search.score isn't the cosine value between the query vector and the document vectors. Instead, Azure AI Search applies transformations such that the score function is monotonically decreasing, meaning score values will always decrease in value as the similarity becomes worse. This transformation ensures that search scores are usable for ranking purposes. There are some nuances with similarity scores: Cosine similarity is defined as the cosine of the angle between two vectors. Cosine distance is defined as 1 - cosine_similarity. To create a monotonically decreasing function, the @search.score is defined as 1 / (1 + cosine_distance). Developers who need a cosine value instead of the synthetic value can use a formula to convert the search score back to cosine distance: double ScoreToSimilarity(double score)\\\\n{\\\\n    double cosineDistance = (1 - score) / score;\\\\n    return  -cosineDistance + 1;\\\\n}\\\\n Having the original cosine value can be useful in custom solutions that set up thresholds to trim results of low quality results. Tips for relevance tuning If you aren't getting relevant results, experiment with changes to query configuration. There are no specific tuning features, such as a scoring profile or field or term boosting, for vector queries: Experiment with chunk size and overlap. Try increasing the chunk size and ensuring there's sufficient overlap to preserve context or continuity between chunks. For HNSW, try different levels of efConstruction to change the internal composition of the proximity graph. The default is 400. The range is 100 to 1,000. Increase k results to feed more search results into a chat model, if you're using one. Try hybrid queries with semantic ranking. In benchmark testing, this combination consistently produced the most relevant results. Next steps Try the quickstart Create and configure a vector index Learn more about embeddings Learn more about data chunking Feedback Was this page helpful? Yes No No Need help with this topic? Want to try using Ask Learn to clarify or guide you through this topic? Ask Learn Ask Learn Suggest a fix? Additional resources Last updated on 2025-07-09 In this article Was this page helpful? Yes No No Need help with this topic? Want to try using Ask Learn to clarify or guide you through this topic? Ask Learn Ask Learn Suggest a fix? en-us Your Privacy Choices Theme Light Dark High contrast AI Disclaimer Previous Versions Blog Contribute Privacy Terms of Use Trademarks \\u00a9 Microsoft 2025\\\"},{\\\"url\\\":\\\"https://medium.com/google-cloud/vector-search-demystifying-ann-and-knn-64bc2b24cca8\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Sitemap Open in app Sign up Sign in Medium Logo Write Search Sign up Sign in Google Cloud - Community \\u00b7 A collection of technical articles and blogs published or curated by Google Cloud Developer Advocates. The views expressed are those of the authors and don't necessarily reflect those of Google. Vector Search: Demystifying ANN and KNN Shu Zhou 4 min read \\u00b7 Oct 31, 2025 -- Listen Share Press enter or click to view image in full size In the rapidly evolving landscape of data, the ability to efficiently search and retrieve relevant information \\u2014 even as your data set explodes \\u2014 is critical. This is where vector search shines, transforming how we interact with large datasets by representing data as numerical vectors that capture semantic meaning in a high-dimensional space. This transforms the sophisticated semantic similarity problem into a mathematical vector distance problem. Vector search uses algorithms designed to find similar vectors, with K-Nearest Neighbors (KNN) and Approximate Nearest Neighbors (ANN) being two of the most prominent. Similar to the previous blog in this series, Choosing Your Vector Search Solution, I\\u2019ll continue using Cloud SQL for MySQL as the example. What Is KNN (K-Nearest Neighbors) KNN is a direct approach to finding similar data points in vector search. Given a query vector, KNN exhaustively calculates the distance (or similarity) between the query and every single vector in the database. It then returns the K vectors that are closest to the query. Key Characteristics of KNN: Accuracy: KNN is known for its accuracy because it performs an exhaustive search. It guarantees finding the true K-nearest neighbors. High Computational Cost: As the dataset size grows, the computational cost (and thus time) for each query increases linearly. It would become prohibitively slow when the number of vectors grows to millions. In Cloud SQL for MySQL, one can perform KNN queries using explicit distance measure functions such as: select id from tbl order by cosine_distance(emb, string_to_vector(\\u2018[...]\\u2019) limit 10; What is ANN (Approximate Nearest Neighbors) ANN algorithms are designed to overcome the scalability limitations of KNN. Instead of guaranteeing the absolute K-nearest neighbors, ANN aims to find a good approximation of the nearest neighbors, sacrificing some accuracy for significantly improved speed and scalability. This \\u201capproximation\\u201d is often more than sufficient for most real-world applications where near real-time performance is crucial. Key Characteristics of ANN: Speed: ANN algorithms are orders of magnitude faster than KNN for large datasets. Scalability: ANN can handle datasets with billions of vectors, making it suitable for modern large-scale applications like recommendation systems, image search, and natural language processing. Index: ANN queries are done through the help of vector indexes. Tunable Accuracy vs. Speed Trade-off: There\\u2019s an inherent trade-off. Users can often tune the vector index to prioritize higher accuracy at the cost of some speed or higher speed at the cost of some accuracy. Complexity: ANN algorithms are more complex to implement and understand than basic KNN, involving techniques like tree-based methods (e.g., ScaNN, Annoy), hashing-based methods (e.g., Locality Sensitive Hashing \\u2014 LSH), and graph-based methods (e.g., HNSW). In Cloud SQL for MySQL, ANN is signified by the approx_distance function, see below example. select id from tbl order by approx_distance(emb, string_to_vector(\\u2018[...]\\u2019), \\u2018distance_measure=cosine\\u2019) limit 10; KNN vs. ANN: A Comparison Let\\u2019s summarize the key differences between KNN and ANN: Your dataset is relatively small (low hundreds of thousands of vectors). You require 100% precision in finding the absolute nearest neighbors. Computational time is not a critical constraint. Choose ANN when: Your dataset is large (millions to billions of vectors). Speed and scalability are paramount for your application (e.g., real-time search). A slight trade-off in accuracy for significantly improved performance is acceptable. Auto Switch in Cloud SQL for MySQL Cloud SQL for MySQL includes a resilient feature where a query requesting an ANN search can automatically revert to performing an exact KNN search. This fallback is triggered when KNN is deemed more suitable for the query. The optimizer in Cloud SQL MySQL is aware of the vector index, which allows it to recognize when the conditions for an accelerated ANN search are not met. Common reasons include: Missing Vector Index: The query is against a vector column that does not have a corresponding index. In this case, the database has no choice but to perform an exhaustive, \\u201cexact\\u201d search. Unsupported Query arguments: ANN queries often have specific requirements for how they are used in a query. For instance, they might explicitly require a specific distance measure algorithm, that is not the same as what the index uses. Optimizer determines KNN search is lower cost: Certain queries (i.e. high selectivity filters) make KNN search a more efficient choice than ANN. The optimizer may intelligently use KNN in this scenario. This smart feature provides a few benefits: This automatic fallback makes the application more resilient to potential errors. Instead of failing, the query still executes and returns correct results. The application gets a valid response, although the performance will be that of a slower KNN search rather than the faster ANN search. This ensures that your application continues to function, while also implicitly signaling that the query or underlying table structure may need optimization (e.g., by creating a missing vector index). It is also a handy tool for app development and debugging. The developers can use the ANN queries as in real production when working in their dev environments. The test datasets are usually small, sometimes too small to create a vector index, but the developers can still use the prod syntax all the way through the whole application development cycle. You can always monitor the KNN/ANN switch status by consulting the dedicated status. show global status like '%cloudsql_vector_knn_fallback%'; Get Started Both KNN and ANN are vital for vector search, but they serve different needs. While KNN offers unparalleled precision for smaller scales, ANN is the clear winner for handling the massive datasets prevalent in today\\u2019s data-driven world. Understanding their differences is crucial for anyone building efficient and scalable vector search systems. If you\\u2019re interested in learning more about the broader landscape of vector search solutions and whether a specialized database is right for you, I recommend reading our previous post: Cloud SQL vs. Specialized Databases: Choosing Your Vector Search Solution. Ready to try it out and test it yourself? Follow this codelab and start building your first vector search powered app! Vector Database MySQL Google Cloud Sql Genai Rags -- -- Published in Google Cloud - Community 69K followers \\u00b7Last published 2 days ago A collection of technical articles and blogs published or curated by Google Cloud Developer Advocates. The views expressed are those of the authors and don't necessarily reflect those of Google. Written by Shu Zhou 3 followers \\u00b72 following SWE @ Google No responses yet Help Status About Careers Press Blog Privacy Rules Terms Text to speech\\\"},null,{\\\"url\\\":\\\"https://docs.aws.amazon.com/opensearch-service/latest/developerguide/knn.html\\\",\\\"title\\\":\\\"k-Nearest Neighbor (k-NN) search in Amazon OpenSearch Service - Amazon OpenSearch Service\\\",\\\"content\\\":\\\"k-Nearest Neighbor (k-NN) search in Amazon OpenSearch Service - Amazon OpenSearch Service DocumentationAmazon OpenSearch ServiceDeveloper Guide Getting started with k-NNk-NN differences, tuning, and limitations k-Nearest Neighbor (k-NN) search in Amazon OpenSearch Service Short for its associated k-nearest neighbors algorithm, k-NN for Amazon OpenSearch Service lets you search for points in a vector space and find the \\\\\\\"nearest neighbors\\\\\\\" for those points by Euclidean distance or cosine similarity. Use cases include recommendations (for example, an \\\\\\\"other songs you might like\\\\\\\" feature in a music application), image recognition, and fraud detection. Note This documentation provides a brief overview of the k-NN plugin, as well as limitations when using the plugin with managed OpenSearch Service. For comprehensive documentation of the k-NN plugin, including simple and complex examples, parameter references, and the complete API reference, see the open source OpenSearch documentation. The open source documentation also covers performance tuning and k-NN-specific cluster settings. Getting started with k-NN To use k-NN, you must create an index with the index.knn setting and add one or more fields of the knn_vector data type. PUT my-index\\\\n\\\\n{\\\\n  \\\\\\\"settings\\\\\\\": {\\\\n    \\\\\\\"index.knn\\\\\\\": true\\\\n  },\\\\n  \\\\\\\"mappings\\\\\\\": {\\\\n    \\\\\\\"properties\\\\\\\": {\\\\n      \\\\\\\"my_vector1\\\\\\\": {\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"knn_vector\\\\\\\",\\\\n        \\\\\\\"dimension\\\\\\\": 2\\\\n      },\\\\n      \\\\\\\"my_vector2\\\\\\\": {\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"knn_vector\\\\\\\",\\\\n        \\\\\\\"dimension\\\\\\\": 4\\\\n      }\\\\n    }\\\\n  }\\\\n} The knn_vector data type supports a single list of up to 10,000 floats, with the number of floats defined by the required dimension parameter. After you create the index, add some data to it. POST _bulk\\\\n\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"1\\\\\\\" } }\\\\n{ \\\\\\\"my_vector1\\\\\\\": [1.5, 2.5], \\\\\\\"price\\\\\\\": 12.2 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"2\\\\\\\" } }\\\\n{ \\\\\\\"my_vector1\\\\\\\": [2.5, 3.5], \\\\\\\"price\\\\\\\": 7.1 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"3\\\\\\\" } }\\\\n{ \\\\\\\"my_vector1\\\\\\\": [3.5, 4.5], \\\\\\\"price\\\\\\\": 12.9 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"4\\\\\\\" } }\\\\n{ \\\\\\\"my_vector1\\\\\\\": [5.5, 6.5], \\\\\\\"price\\\\\\\": 1.2 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"5\\\\\\\" } }\\\\n{ \\\\\\\"my_vector1\\\\\\\": [4.5, 5.5], \\\\\\\"price\\\\\\\": 3.7 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"6\\\\\\\" } }\\\\n{ \\\\\\\"my_vector2\\\\\\\": [1.5, 5.5, 4.5, 6.4], \\\\\\\"price\\\\\\\": 10.3 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"7\\\\\\\" } }\\\\n{ \\\\\\\"my_vector2\\\\\\\": [2.5, 3.5, 5.6, 6.7], \\\\\\\"price\\\\\\\": 5.5 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"8\\\\\\\" } }\\\\n{ \\\\\\\"my_vector2\\\\\\\": [4.5, 5.5, 6.7, 3.7], \\\\\\\"price\\\\\\\": 4.4 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"9\\\\\\\" } }\\\\n{ \\\\\\\"my_vector2\\\\\\\": [1.5, 5.5, 4.5, 6.4], \\\\\\\"price\\\\\\\": 8.9 }\\\\n Then you can search the data using the knn query type. GET my-index/_search\\\\n{\\\\n  \\\\\\\"size\\\\\\\": 2,\\\\n  \\\\\\\"query\\\\\\\": {\\\\n    \\\\\\\"knn\\\\\\\": {\\\\n      \\\\\\\"my_vector2\\\\\\\": {\\\\n        \\\\\\\"vector\\\\\\\": [2, 3, 5, 6],\\\\n        \\\\\\\"k\\\\\\\": 2\\\\n      }\\\\n    }\\\\n  }\\\\n} In this case, k is the number of neighbors you want the query to return, but you must also include the size option. Otherwise, you get k results for each shard (and each segment) rather than k results for the entire query. k-NN supports a maximum k value of 10,000. If you mix the knn query with other clauses, you might receive fewer than k results. In this example, the post_filter clause reduces the number of results from 2 to 1. GET my-index/_search\\\\n\\\\n{\\\\n  \\\\\\\"size\\\\\\\": 2,\\\\n  \\\\\\\"query\\\\\\\": {\\\\n    \\\\\\\"knn\\\\\\\": {\\\\n      \\\\\\\"my_vector2\\\\\\\": {\\\\n        \\\\\\\"vector\\\\\\\": [2, 3, 5, 6],\\\\n        \\\\\\\"k\\\\\\\": 2\\\\n      }\\\\n    }\\\\n  },\\\\n  \\\\\\\"post_filter\\\\\\\": {\\\\n    \\\\\\\"range\\\\\\\": {\\\\n      \\\\\\\"price\\\\\\\": {\\\\n        \\\\\\\"gte\\\\\\\": 6,\\\\n        \\\\\\\"lte\\\\\\\": 10\\\\n      }\\\\n    }\\\\n  }\\\\n} If you need to handle a large volume of queries while maintaining optimal performance, you can use the _msearch API to construct a bulk search with JSON and send a single request to perform multiple searches: GET _msearch\\\\n\\\\n{ \\\\\\\"index\\\\\\\": \\\\\\\"my-index\\\\\\\"}\\\\n{ \\\\\\\"query\\\\\\\": { \\\\\\\"knn\\\\\\\": {\\\\\\\"my_vector2\\\\\\\":{\\\\\\\"vector\\\\\\\": [2, 3, 5, 6],\\\\\\\"k\\\\\\\":2 }} } }\\\\n{ \\\\\\\"index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"search_type\\\\\\\": \\\\\\\"dfs_query_then_fetch\\\\\\\"}\\\\n{ \\\\\\\"query\\\\\\\": { \\\\\\\"knn\\\\\\\": {\\\\\\\"my_vector1\\\\\\\":{\\\\\\\"vector\\\\\\\": [2, 3],\\\\\\\"k\\\\\\\":2 }} } } The following video demonstrates how to set up bulk vector searches for K-NN queries. k-NN differences, tuning, and limitations OpenSearch lets you modify all k-NN settings using the _cluster/settings API. On OpenSearch Service, you can change all settings except knn.memory.circuit_breaker.enabled and knn.circuit_breaker.triggered. k-NN statistics are included as Amazon CloudWatch metrics. In particular, check the KNNGraphMemoryUsage metric on each data node against the knn.memory.circuit_breaker.limit statistic and the available RAM for the instance type. OpenSearch Service uses half of an instance's RAM for the Java heap (up to a heap size of 32 GiB). By default, k-NN uses up to 50% of the remaining half, so an instance type with 32 GiB of RAM can accommodate 8 GiB of graphs (32 * 0.5 * 0.5). Performance can suffer if graph memory usage exceeds this value. You can migrate a k-NN index created on version 2.x or later to UltraWarm or cold storage on a domain with version 2.17 or later. Clear cache api and warmup apis for k-NN indices are blocked for warm indices. When the first query is initiated for the index, it downloads the graph files from Amazon S3 and loads the graph to memory. Similarly, when TTL is expired for the graphs, the files are automatically evicted from memory. Javascript is disabled or is unavailable in your browser. To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions. Document Conventions (Preview) Advanced search capabilities with an Amazon S3 vector engine OpenSearch Dashboards Did this page help you? - Yes Thanks for letting us know we're doing a good job! If you've got a moment, please tell us what we did right so we can do more of it. Did this page help you? - No Thanks for letting us know this page needs work. We're sorry we let you down. If you've got a moment, please tell us how we can make the documentation better.\\\"},{\\\"url\\\":\\\"https://www.digitalocean.com/blog/enhancing-search-capabilities-with-k-nn-vector-search-in-opensearch\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Blog Docs Get Support Contact Sales DigitalOcean Products Featured Products Droplets Scalable virtual machines Kubernetes Scale more effectively Gradient\\u2122 AI Agentic Cloud Build and scale with AI Cloudways Managed cloud hosting App Platform Get apps to market faster Managed Databases Fully-managed database hosting Compute Droplets Kubernetes CPU-Optimized Droplets Functions App Platform Gradient\\u2122 AI Agentic Cloud GPU Droplets 1-Click Models Platform Bare Metal GPUs Backups & Snapshots Backups Snapshots SnapShooter Networking Virtual Private Cloud (VPC) Partner Network Connect Cloud Firewalls Load Balancers DNS DDoS Protection Managed Databases MongoDB Kafka MySQL PostgreSQL Valkey OpenSearch Storage Spaces Object Storage Volume Block Storage Network File Storage Developer Tools API CLI Support Plans Monitoring Uptime Identity and Access Management Marketplace Droplet 1-Click Kubernetes 1-Click AI 1-Click Models Add-Ons Cloud Website Hosting Cloudways See all products Solutions AI and Machine Learning Develop, train, and deploy AI apps GPUs Platform 1-Click Models HR Knowledge Assistant Code Copilot Support Ticket Triage Recommendation Engine Blockchain Infrastructure for decentralized apps Blogs, Forums and Content Websites Lightning-fast, reliable CMS hosting Wordpress Ghost Mastodon Data Analytics Real-time data processing at scale Data Streaming AdTech & Martech Kafka Developer Tools DevOps and CI/CD solutions CI/CD Prototyping Digital Marketing Agencies Power your clients\\u2019 websites and campaigns Freelancer IT Consulting Ecommerce Build beautiful online storefronts Dropshipping WooCommerce Magento Game Development Low-latency multiplayer servers Minecraft Hosting IoT Connect to the power of the cloud Kafka ISVs Streamlined ISV application development Secure Web Hosting Powerful protection from DDoS and more Private VPN Startup Cloud Hosting Scalable, cost-effective infrastructure Small Business Video Streaming High-bandwidth, low-latency delivery Kafka Web and Mobile Apps Simple cross-platform app hosting cPanel Docker Next.js Node.js Website Hosting Fast page loads and reliable site uptime VPS Hosting Virtual Machines Get help Migration Assistance Talk to an expert See all solutions Developers Our Community Community Home DevOps and development guides CSS-Tricks All things web design The Wave Content to level up your business. Resources Tutorials Questions and Answers Marketplace Tools Write for DOnations Cloud Chats Customer Stories DigitalOcean Blog Pricing Calculator Get Involved DigitalOcean Startups Open Source Sponsorships Hacktoberfest Deploy 2025 Wavemakers Program Documentation Quickstart Compute Gradient\\u2122 AI Platform Storage Managed Databases Containers Billing API Reference Partners DigitalOcean Partner Programs Become a Partner Partner Services Program DigitalOcean AI Partner Program Marketplace DigitalOcean Startups Connect with a Partner Partner Programs Resources Customer Stories DigitalOcean Onboarding Series Training for Agencies and Freelancers Price Estimate Calculator Featured Partner Articles Cloud cost optimization best practices Read more How to choose a cloud provider Read more DigitalOcean vs. AWS Lightsail: Which Cloud Platform is Right for You? Read more Questions? Talk to an expert Pricing Log in Sign up Blog Docs Get Support Contact Sales Log in Sign up Engineering Enhancing Search Capabilities with K-NN Vector Search in OpenSearch By Dustin Wilson and Govind Srinivasaraghavan Published: July 31, 2024 5 min read <- Back to blog home Many applications depend on the ability to deliver precise and relevant search results. Although the full-text search capabilities of traditional relational databases are sufficient in some situations, these databases can fall short in extracting semantic meaning from text or searching through less-structured data. In this blog post, we\\u2019ll explore how you can address these limitations using DigitalOcean-managed OpenSearch and a collection of techniques called K-Nearest Neighbor vector search (K-NN). K-NN makes OpenSearch a powerful and flexible solution for various search and analytics applications. Understanding K-NN Vector Search What is K-NN Vector Search? Unlike traditional search methods that rely on keyword matching, K-NN vector search involves representing each record in a dataset as a vector that encapsulates the attributes of the record. Machine learning models are often used to embed data into a vector representation. When a query is made, the search engine computes the distance between the query vector and the data vectors and returns the nearest neighbors based on a predefined distance metric, such as Euclidean distance or cosine similarity. Why Use OpenSearch for K-NN Vector Search? Introduction to OpenSearch OpenSearch is a highly scalable open-source search and analytics engine. It builds upon the strengths of Elasticsearch, providing robust features for full-text search, log analytics, and more. With the introduction of vector search capabilities, OpenSearch extends its utility to more advanced use cases such as natural language processing, recommendation systems, and image retrieval. Benefits of Using OpenSearch for Vector Search Scalability: OpenSearch can handle large volumes of data and queries efficiently. Using approximate nearest neighbor algorithms, OpenSearch can provide relevant search results much faster and with a lower memory footprint. Flexibility: It supports various types of data and search functionalities, making it suitable for diverse applications. Community and Support: Being open-source, it benefits from a vibrant community and regular updates. Setting Up OpenSearch for K-NN Vector Search Installing OpenSearch To get started, you need to install OpenSearch. Here\\u2019s a basic command to pull and run the latest version of the OpenSearch Docker image: docker pull opensearchproject/opensearch:latest\\\\n\\\\n\\\\ndocker run -d --name opensearch -p 9200:9200 -e \\\\\\\"discovery.type=single-node\\\\\\\" -e \\\\\\\"OPENSEARCH_INITIAL_ADMIN_PASSWORD=<your-strong-password>\\u201d opensearchproject/opensearch:latest\\\\n Note: You need to set an initial admin password when you try to run the opensearch docker container. It should be a minimum of 8 characters and must contain at least one uppercase letter, one lowercase letter, one digit, and one special character that is strong. Alternatively, DigitalOcean supports Managed OpenSearch, which makes configuring and managing OpenSearch clusters a breeze. Configuring OpenSearch for Vector Search After installing OpenSearch, the next step is to enable the K-NN plugin. On self-managed clusters, this involves modifying the cluster\\u2019s configuration file. On DigitalOcean Managed Opensearch The K-NN plugin is enabled by default and no additional configuration is required. Implementing K-NN Vector Search To use K-NN vector search, you must first create an index with vector fields. You can do so by navigating to the Opensearch development console at https://${CLUSTER_HOST}/app/dev_tools#/console and submitting the following request. Alternatively, you can send these commands as HTTP requests to https://${CLUSTER_HOST}:9200. PUT /my_vector_index\\\\n\\\\n{\\\\n\\\\n  \\\\\\\"mappings\\\\\\\": {\\\\n\\\\n    \\\\\\\"properties\\\\\\\": {\\\\n\\\\n      \\\\\\\"my_vector\\\\\\\": {\\\\n\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"K-NN_vector\\\\\\\",\\\\n\\\\n        \\\\\\\"dimension\\\\\\\": 128\\\\n\\\\n      }\\\\n\\\\n    }\\\\n\\\\n  }\\\\n\\\\n}\\\\n With this request you\\u2019ve created an index, my_vector_index, which you can use to store and query data using 128-dimension embeddings. You can now begin adding documents along with their vector representations to the index with the following request. PUT /my_vector_index/_doc/1\\\\n\\\\n{\\\\n\\\\n  \\\\\\\"my_vector\\\\\\\": [0.1, 0.2, ... , 0.128],\\\\n\\\\n  \\\\\\\"description\\\\\\\": \\\\\\\"Sample document\\\\\\\"\\\\n\\\\n}\\\\n Finally, to perform a K-NN search over these documents, you can use the following query. POST /my_vector_index/_search\\\\n\\\\n{\\\\n\\\\n  \\\\\\\"size\\\\\\\": 5,\\\\n\\\\n  \\\\\\\"query\\\\\\\": {\\\\n\\\\n    \\\\\\\"K-NN\\\\\\\": {\\\\n\\\\n      \\\\\\\"my_vector\\\\\\\": {\\\\n\\\\n        \\\\\\\"vector\\\\\\\": [0.1, 0.2, ... , 0.128],\\\\n\\\\n        \\\\\\\"k\\\\\\\": 5\\\\n\\\\n      }\\\\n\\\\n    }\\\\n\\\\n  }\\\\n\\\\n}\\\\n Use Cases and Applications Let\\u2019s cover a few end-to-end applications that could make use of Opensearch\\u2019s K-NN capabilities. Customer Support Chatbot: Vector search is often used to find semantically similar texts. A chatbot service might use a machine-learning model to embed an incoming query (e.g. \\u201cHow can I reset my password?\\u201d) into a vector and then use K-NN vector search to find similar queries in the knowledge base, such as \\u201cI forgot my password, how do I reset it?\\u201d. The chatbot can use this information to provide the user a more helpful response based on these similar queries. E-commerce Platform: K-NN vector search can enhance recommendation systems by finding items similar to a user\\u2019s preferences based on vector representations. For example, a user who buys a book from an online store might be recommended other books by the same author, books from the same genre, or even books that other users with similar preferences have bought. In this example, the vector representation of a book may include attributes like author, genre, ratings, and keywords from reviews. Fashion Retailer: By converting images into vectors using deep learning models, K-NN vector search can be used to retrieve visually similar images from a database. A user may upload a photo of a red dress. The system processes the image to create a vector representing the dress\\u2019s visual features. Using K-NN vector search, the platform retrieves and displays similar dresses in various shades of red, with similar cuts and designs, helping the user find exactly what they\\u2019re looking for. Challenges and Considerations using K-NN with OpenSearch 1. Vector Dimensionality High-dimensional vectors can lead to increased computational complexity. It\\u2019s important to balance vector dimensions with performance requirements. Luckily, OpenSearch has multiple K-NN methods with their own performance characteristics. While each method aims to return vectors with the minimal distance to an incoming vector, some can be tuned to prioritize memory use, response time or accuracy. 2. Data Normalization Ensuring that data is normalized and consistent is crucial for the accuracy of K-NN search results. 3. Performance Tuning Optimizing OpenSearch settings and hardware resources is essential for handling large-scale vector searches efficiently. See this article for more details on performance tuning. Conclusion K-NN vector search opens up new possibilities for delivering highly relevant search results across various domains. By leveraging OpenSearch\\u2019s powerful capabilities, developers can implement advanced search functionalities with relative ease. Whether it\\u2019s for recommendation systems, image retrieval, or NLP applications, K-NN vector search with OpenSearch is a valuable tool in the search technology landscape. About the author(s) Dustin Wilson Author See author profile See author profile Govind Srinivasaraghavan Author See author profile See author profile Share Engineering Try DigitalOcean for free Click below to sign up and get $200 of credit to try our products over 60 days! Sign up Related Articles Engineering How startups scale on DigitalOcean Kubernetes: Best Practices Part VI - Security Kunju Perath October 8, 2024 12 min read Read more Engineering Introducing new GitHub Actions for App Platform Markus Th\\u00f6mmes September 26, 2024 8 min read Read more Engineering How SMBs and startups scale on DigitalOcean Kubernetes: Best Practices Part V - Disaster Recovery David Hwang August 14, 2024 7 min read Read more Company About Leadership Blog Careers Customers Partners Referral Program Affiliate Program Press Legal Privacy Policy Security Investor Relations Products Overview Droplets Kubernetes Functions App Platform Gradient\\u2122 AI GPU Droplets Gradient\\u2122 AI Bare Metal GPUs Gradient\\u2122 AI 1-Click Models Gradient\\u2122 AI Platform Load Balancers Managed Databases Spaces Block Storage Network File Storage API Uptime Identity and Access Management Cloudways Resources Community Tutorials Community Q&A CSS-Tricks Write for DOnations Currents Research DigitalOcean Startups Wavemakers Program Compass Council Open Source Newsletter Signup Marketplace Pricing Pricing Calculator Documentation Release Notes Code of Conduct Shop Swag Solutions Website Hosting VPS Hosting Web & Mobile Apps Game Development Streaming VPN SaaS Platforms Cloud Hosting for Blockchain Startup Resources Migration Assistance Contact Support Sales Report Abuse System Status Share your ideas Company About Leadership Blog Careers Customers Partners Referral Program Affiliate Program Press Legal Privacy Policy Security Investor Relations Products Overview Droplets Kubernetes Functions App Platform Gradient\\u2122 AI GPU Droplets Gradient\\u2122 AI Bare Metal GPUs Gradient\\u2122 AI 1-Click Models Gradient\\u2122 AI Platform Load Balancers Managed Databases Spaces Block Storage Network File Storage API Uptime Identity and Access Management Cloudways Resources Community Tutorials Community Q&A CSS-Tricks Write for DOnations Currents Research DigitalOcean Startups Wavemakers Program Compass Council Open Source Newsletter Signup Marketplace Pricing Pricing Calculator Documentation Release Notes Code of Conduct Shop Swag Solutions Website Hosting VPS Hosting Web & Mobile Apps Game Development Streaming VPN SaaS Platforms Cloud Hosting for Blockchain Startup Resources Migration Assistance Contact Support Sales Report Abuse System Status Share your ideas \\u00a9 2025 DigitalOcean, LLC.Sitemap.\\\"},{\\\"url\\\":\\\"https://learncodecamp.net/vector-databases-knn-hnsw/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to content Learn Code Camp Menu Menu Home Java AI System Design JavaScript Kafka Exploring the Power of Vector Databases: Leveraging KNN and HNSW for Efficient Data Retrieval 6 March 2024 by Nitin What are vector databases? Key techniques employed in vector databases Approximate Nearest Neighbors Search (K-ANNS) Examples of ANN algorithms HNSW Summary What are vector databases? A Vector Database is a type of database that stores information in a structured way using vectors. Now, what are vectors? Think of them as mathematical representations of data that capture its meaning and context. Let\\u2019s say you have a photo of a cat. Instead of just storing the image file, a Vector Database will convert this photo into a vector, which is essentially a set of numbers that represent various features of the cat, like its color, shape, and size. This vector will contain information about the cat in a way that a computer can understand. Now, the cool thing about vector databases is that they allow you to search for similar items easily. For instance, if you upload a photo of a dog, the database can quickly find other photos with similar features to that dog by comparing their vectors. This is like when you search for similar images on your smartphone\\u2014except it\\u2019s done using mathematical calculations rather than just looking for file names or tags. So, in simple terms, a Vector Database helps organize and search for different types of data by converting them into mathematical representations called vectors, making it easier to find similar items or information. Check Understanding Embeddings: https://learncodecamp.net/embeddings/ Vector databases are specialized databases tailored for high-dimensional data points represented as vectors, offering efficient storage and retrieval capabilities. They excel at performing nearest-neighbor searches, swiftly retrieving data points closest to a given point in multi-dimensional space. Key techniques employed in vector databases k-Nearest Neighbor (k-NN) Index: This technique enables rapid identification of the k nearest neighbors of a given vector. It aids in efficiently narrowing down the search space, improving retrieval speed. Hierarchical Navigable Small World (HNSW): HNSW algorithm efficiently organizes data points to facilitate faster nearest-neighbor searches. It constructs a hierarchical graph structure that optimizes the search process. In summary, vector databases leverage advanced methods such as k-NN indexes and algorithms like HNSW to ensure efficient storage and retrieval of high-dimensional vectors, enabling rapid lookup of nearest neighbors in multi-dimensional spaces. # Function to find K Nearest Neighbors\\\\ndef find_k_nearest_neighbors(query_vector, vectors, k=5, threshold=0.8):\\\\n    nearest_neighbors = []\\\\n    for vector in vectors:\\\\n        similarity = cosine_similarity(query_vector, vector)\\\\n        if similarity >= threshold:\\\\n            nearest_neighbors.append((vector, similarity))\\\\n    nearest_neighbors.sort(key=lambda x: x[1], reverse=True)\\\\n    return nearest_neighbors[:k]\\\\n Simple pseudocode for finding k nearest neighbors, query_vector is the embedding vector of the search term, and k is the number of the items to retrieve, threshold is minimum match % The brute force of a kNN search is computationally very expensive \\u2013 and depending on the size of your database, a single query could take anything from several seconds to even mins. Number of computations = Number of dimensions \\u00d7 Vector size Given: Number of dimensions (d) = 1536 Vector size (n) = 1 million = 1\\u00d710^6 Number of computations=1536\\u00d71\\u00d710^6 = 1.536\\u00d710^9 approximately 1.536 billion it would take approximately 1.536 seconds to perform all the computations needed for your kNN search on a system capable of performing 1 billion computations per second. Let\\u2019s explore Approximate Nearest Neighbors Algorithms. Approximate Nearest Neighbors Search (K-ANNS) This is used to efficiently find approximate nearest neighbors for a given query point in a large dataset. It\\u2019s particularly useful when dealing with high-dimensional data where traditional exact nearest neighbor search methods become computationally expensive. The quality of an inexact search (the recall) is defined as the ratio between the number of found true nearest neighbors and K To elaborate: True Nearest Neighbors: These are the actual nearest neighbors of the query point in the dataset, determined by some distance metric. For example, if we\\u2019re searching for the 5 nearest neighbors (K=5) of a given point, the true nearest neighbors are those 5 points in the dataset that are closest to the query point. Found Nearest Neighbors: These are the points that the approximate search algorithm returns as the nearest neighbors of the query point. Due to the approximate nature of the search, they may not be exactly the same as the true nearest neighbors. Recall: The recall of the search is then defined as the ratio of the number of found true nearest neighbors to the total number of nearest neighbors desired (K). It\\u2019s calculated using the formula: Recall = (Number of Found True Nearest Neighbors) / K For example, if a search algorithm returns 3 out of the 5 true nearest neighbors for a query with K=5, the recall would be 3/5, or 0.6. This means that the algorithm successfully retrieved 60% of the true nearest neighbors. High recall is desirable in many applications because it indicates that the algorithm is effectively capturing the most relevant points in the dataset. Examples of ANN algorithms Examples of ANN methods are: trees \\u2013 e.g. ANNOY (Figure 1), proximity graphs \\u2013 e.g. HNSW (Figure 2), clustering \\u2013 e.g. FAISS, hashing \\u2013 e.g. LSH, vector compression \\u2013 e.g. PQ or SCANN. Figure 1 Annoy is used at Spotify for music recommendations. Redis Search supports\\u2002FLAT \\u2013 Brute-force index and HNSW HNSW Probabilistic Skip List: A skip list is a data structure that allows for fast search, insertion, and deletion operations in a sorted list. It achieves this by adding multiple layers of pointers, allowing for \\u201cskipping\\u201d over some elements during traversal. In HNSW, the probabilistic skip list is used to organize the data points within each layer of the hierarchical structure. Probabilistic skip list The \\u201cNavigable Small World\\u201d (NSW) part of Hierarchical Navigable Small World (HNSW) refers to a graph structure designed to maintain both local connectivity and global exploration capabilities. Let\\u2019s break down the NSW component: Navigability: NSW aims to create a graph structure where each data point (or node) is connected to its neighbors in a way that facilitates efficient navigation through the dataset. This means that similar points are likely to be connected, allowing for quick traversal between them. Small World Property: The small-world property refers to the idea that even though the graph may be large and sparsely connected, it\\u2019s still possible to navigate from one point to another through a relatively small number of connections. This property is essential for efficient search and exploration in large datasets. Connection Strategy: In NSW, connections between points are established based on their proximity in the data space. Typically, points that are closer together in the data space are more likely to be connected. However, NSW also incorporates randomness into the connection strategy to balance local connectivity with global exploration. Efficient Search: By creating a graph structure with the small-world property, NSW enables efficient search for nearest neighbors. During the search process, the algorithm can navigate through the graph using a combination of local connections to quickly find nearby points and occasional long-range connections to explore distant regions of the dataset. Summary Vector databases rely on Machine Learning models to generate vector embeddings for all data objects. Vector embeddings represent the meaning and context of data, enabling efficient analysis and retrieval. Vector databases provide rapid query capabilities due to Approximate Nearest Neighbors (ANN) algorithms. ANN algorithms sacrifice some accuracy in exchange for significant performance improvements. Categories AI Building a RESTful API with Node.js, Express, and MongoDB Revolutionizing AI: LLMs Without GPUs? The Promise of BitNet B1.58 Leave a comment Cancel reply Comment Name Email Save my name, email, and website in this browser for the next time I comment. \\u0394 Search for: Recent Posts Debugging HTTP Traffic Like a Pro: HTTP Toolkit and Terminal Interception How to Stop Hallucinations in RAG Chatbots: A Complete Guide Agentic Context Engineering (ACE): Turning Context Into a Self-Improving Playbook for LLMs Search for: Categories AI Blog Java JavaScript Kafka Spring Boot System Design Recent Posts Debugging HTTP Traffic Like a Pro: HTTP Toolkit and Terminal Interception How to Stop Hallucinations in RAG Chatbots: A Complete Guide Agentic Context Engineering (ACE): Turning Context Into a Self-Improving Playbook for LLMs Loss functions for llm \\u2014 a practical, hands-on guide Q K V : Query (Q), Key (K), and Value (V) Vectors in the Attention Mechanism Tags AI aop beans command line embeddings eol java java8 javascript kafka maven microservices mvn spring boot system design Quick Links Home Contact Us Privacy Policy About Us \\u00a9 2025 Learn Code Camp \\u2022 Built with GeneratePress\\\"},{\\\"url\\\":\\\"https://generativeai.pub/how-i-use-knn-and-ann-to-power-fast-scalable-vector-search-206fd9fb21f3\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Sitemap Open in app Sign up Sign in Medium Logo Write Search Sign up Sign in Generative AI \\u00b7 Follow publication Stay updated with the latest news, research, and developments in the world of generative AI. We cover everything from AI model updates, comprehensive tutorials, and real-world applications to the broader impact of AI on society. Work with us: jimclydegm@gmail.com Follow publication How I Use KNN and ANN to Power Fast, Scalable Vector Search Alex Chen 5 min read \\u00b7 Jul 16, 2025 -- Listen Share Press enter or click to view image in full size As I\\u2019ve been building a semantic search engine over a growing corpus of multimodal data, I\\u2019ve had to answer a deceptively simple question: What\\u2019s the fastest way to find similar vectors at scale \\u2014 without burning memory or sacrificing recall? That question led me deep into the internals of vector search algorithms, especially the trade-offs between exact and approximate methods like K-Nearest Neighbors (KNN) and Approximate Nearest Neighbors (ANN). In this post, I\\u2019ll walk through how these algorithms work, why they matter, and where each fits in real-world deployments. Vector Search in Practice Imagine you\\u2019re running facial recognition in a high-traffic airport. Each detected face becomes a high-dimensional vector. Your system must search millions of stored vectors \\u2014 quickly \\u2014 to find the top few that resemble the input. This is vector search: efficient retrieval based on similarity in high-dimensional space. Under the hood, this process relies on distance metrics like Euclidean or cosine similarity. The core challenge is performance: brute-force comparisons don\\u2019t scale, especially when latency budgets are tight. That\\u2019s where machine learning-based search methods come into play. Method 1: K-Nearest Neighbors (KNN) KNN is the most intuitive approach: Take your query vector Compare it to every vector in the dataset Pick the K closest ones based on a distance metric It\\u2019s dead simple and perfectly accurate \\u2014 but it doesn\\u2019t scale. Let\\u2019s say you have 10 million vectors, each with 512 dimensions. A brute-force KNN search means computing 10 million distances for every query. That\\u2019s CPU-intensive, cache-unfriendly, and slow under real-time constraints. KNN is best suited for: Small datasets (<100K vectors) Tasks where precision is non-negotiable (e.g., forensics or compliance) Offline or batch inference pipelines Press enter or click to view image in full size Method 2: Approximate Nearest Neighbors (ANN) To make vector search scalable, we approximate. ANN algorithms build clever index structures \\u2014 think of them as spatial shortcuts. They don\\u2019t guarantee the exact nearest neighbors, but they can find very close ones much faster. Instead of comparing to every vector, ANN searches through select regions likely to contain similar vectors. You can tune the trade-off between speed and accuracy depending on the use case. Common ANN algorithms: HNSW (Hierarchical Navigable Small Worlds): Graph-based, fast and high-recall IVF (Inverted File) + PQ (Product Quantization): Partition-based, memory-efficient LSH (Locality-Sensitive Hashing): Fast but lower recall, best for sparse or binary vectors KNN vs ANN: Trade-off Table Here\\u2019s a quick summary from my benchmarking: In one of my tests on a 1M vector dataset (768 dims), HNSW reduced average query time from 230ms (brute force) to 12ms, with a recall of ~94%. When K Isn\\u2019t Enough: Range Search KNN and ANN return exactly K results \\u2014 but what if that includes duplicates or irrelevant hits? Take a streaming recommender that shows \\u201ctop 5 similar songs.\\u201d If all 5 are near-identical variants of one genre, you\\u2019re not delivering diversity. Range search solves this by retrieving all vectors within a given distance threshold instead of a fixed count. Here\\u2019s a Python example using a Milvus-compatible API to set distance bounds: search_params = {     \\\\\\\"params\\\\\\\": {         \\\\\\\"nprobe\\\\\\\": 10,         \\\\\\\"radius\\\\\\\": 10,         \\\\\\\"range_filter\\\\\\\": 20     } } res = collection.search(     vectors, \\\\\\\"float_vector\\\\\\\", search_params, topK,     \\\\\\\"int64 > 100\\\\\\\", output_fields=[\\\\\\\"int64\\\\\\\", \\\\\\\"float\\\\\\\"] ) This approach shines in: Data deduplication Copyright detection (finding \\u201ctoo-similar\\u201d content) Use cases needing semantic filtering, not just top-K \\ud83d\\udccc Reference: unlock advanced recommendation engines with Milvus\\u2019s new range search Indexing Considerations Choosing ANN also means choosing an index type. My rule of thumb: Press enter or click to view image in full size Use CaseIndex TypeNotesLow-latency web appHNSWFastest; low memory if tuned wellMulti-billion vector archiveIVF_PQScalable; great for cold queriesSparse or binary embeddingsLSHQuick setup; less accurateMultilingual searchOPQ + IVFImproves vector alignment pre-PQ Some vector DBs\\uff08like Milvus\\uff09let you plug these in easily. Just remember that index building time and size can vary a lot \\u2014 I\\u2019ve seen HNSW index builds take 3x longer than IVF on the same dataset. Deployment Notes When rolling out ANN in production, consider: Index warm-up: Preload into memory to avoid cold-start penalties Batch vs real-time: Some ANN types are better suited for offline queries (e.g., IVF_PQ) Recall monitoring: Approximation means drift \\u2014 log sample queries and validate outputs periodically For large-scale deployments, hardware also matters. In my tests, running ANN on CPU with AVX2 SIMD saw 3\\u20135x gains in speed. If your DB supports GPU (e.g., Faiss GPU backend), you might see even more. What I\\u2019m Exploring Next Lately, I\\u2019ve been digging into hybrid search \\u2014 combining vector and keyword filtering for more nuanced results. I\\u2019m also curious about how adaptive indexing could optimize ANN over time as data evolves. Vector search is no longer a toy problem. Whether it\\u2019s recommendations, semantic retrieval, or surveillance, scalable search is now a core infrastructure need \\u2014 and choosing the right algorithm is step one. If you\\u2019re hitting latency ceilings or drowning in embeddings, don\\u2019t default to brute-force. Take the time to understand your data shape and use case \\u2014 and consider ANN where it fits. Let me know if you\\u2019d like a follow-up post on comparing HNSW and IVF_PQ head-to-head. I\\u2019ve got some fun benchmarks on that. This story is published on Generative AI. Connect with us on LinkedIn and follow Zeniteq to stay in the loop with the latest AI stories. Subscribe to our newsletter and YouTube channel to stay updated with the latest news and updates on generative AI. Let\\u2019s shape the future of AI together! Machine Learning Artificial Intelligence Data Science Vector Database -- -- Follow Published in Generative AI 68K followers \\u00b7Last published 1 day ago Stay updated with the latest news, research, and developments in the world of generative AI. We cover everything from AI model updates, comprehensive tutorials, and real-world applications to the broader impact of AI on society. Work with us: jimclydegm@gmail.com Follow Written by Alex Chen 11 followers \\u00b74 following Passionate open\\u2011source contributor and database tinkerer sharing insights on ANN algorithm implementations and vector indexing techniques. No responses yet Help Status About Careers Press Blog Privacy Rules Terms Text to speech\\\"},{\\\"url\\\":\\\"https://www.elastic.co/search-labs/tutorials/search-tutorial/vector-search/nearest-neighbor-search\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Explore Elastic: elastic.co Security Labs Observability Labs Tutorials Examples Integrations Blogs Start free trial Tutorials/Search Tutorial k-Nearest Neighbor (kNN) Search In this series Welcome Requirements Project Setup Full-Text Search Python Client Setup Create an Index Search Basics Pagination Filters Faceted Search Vector Search Embeddings Intro Generating Embeddings Storing Embeddings k-Nearest Neighbor Search Hybrid Search Semantic Search ELSER Model Semantic Queries Hybrid Search Conclusion Copy Share The k-nearest neighbor (kNN) algorithm performs a similarity search on fields of dense_vector type. This type of search, which is more appropriately called \\\\\\\"approximate kNN\\\\\\\", accepts a vector or embedding as a search term, and finds entries in the index that are close. In this section you are going to learn how to run a kNN search using the document embeddings created in the previous section. The knn Query In the full-text search section of the tutorial you learned about the query option passed to the search() method of the Elasticsearch client. When searching vectors, the knn option is used instead. Below you can see a new version of the handle_search() function in app.py that runs a kNN search for the query entered by the user in the search form. In this version of the function, the query option was replaced with knn. The size and from_ options for pagination remain the same, and everything else in the function and the index.html template are also the same as before. The knn search option accepts a number of parameters that configure the search: field: the field in the index to search. The field must have a dense_vector type. query_vector: the embedding to search for. This should be an embedding generated from the search text. num_candidates: the number of candidate documents to consider from each shard. Elasticsearch retrieves this many candidates from each shard, combines them into a single list and then finds the closest \\\\\\\"k\\\\\\\" to return as results. k: the number of results to return. This number has a direct effect on performance, so it should be kept as small as possible. The value passed in this option must be less than num_candidates. With the settings used in the code above, the 10 best matching results will be returned. You are welcome to experiment with this new version of the application. Here are a pair of good examples to appreciate how useful this type of search: Searching for \\\\\\\"holiday\\\\\\\", which is the British English equivalent to \\\\\\\"vacation\\\\\\\" in American English, kNN search returns the document \\\\\\\"Vacation Policy\\\\\\\" as top result, even though the word holiday itself does not appear in the document. Searching for \\\\\\\"cats and dogs\\\\\\\" or any other term related to pets brings the \\\\\\\"Office Pet Policy\\\\\\\" document as top result, even though the document summary does not mention any specific pets. Using Filters in kNN Queries The search query, as defined in the full-text section of this tutorial, allowed the user to request a specific category to be used, using the syntax category:<category-name> in any place of the search text. The extract_filters() function in app.py is in charge of finding and separating these filter expressions from the search query. In the version of the handle_search() function from the previous section the filters variable is not used, so the category filters are ignored. Luckily, the knn option also supports filtering. The filter option actually accepts the same type of filters, so the filters can be inserted directly into the knn query, exactly as they are returned by the extract_filters() function: Aggregations also work well in kNN queries, so they can also be added back: This version of the handle_search() function has the same functionality as the full-text search version, implemented using vector search instead of keyword-based search. In the next section, you'll learn how to combine results from these two different search methods. Previously Storing Embeddings Next Hybrid Search Report an issue Ready to build state of the art search experiences? Sufficiently advanced search isn\\u2019t achieved with the efforts of one. Elasticsearch is powered by data scientists, ML ops, engineers, and many more who are just as passionate about search as you are. Let\\u2019s connect and work together to build the magical search experience that will get you the results you want. Try it yourself Subscribe to newsletter Elasticsearch Labs is the one-stop destination for developers to learn how to easily utilize Elasticsearch to build advanced search experiences including generative AI, embedding models, reranking capabilities and more. Let's connect Menu Tutorials Examples Integrations Blogs Search Additional Resources Elasticsearch API Reference Elastic.co Sitemap RSS 2025. Elasticsearch B.V. All Rights Reserved.\\\"},{\\\"url\\\":\\\"https://www.ibm.com/think/topics/vector-search\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Artificial Intelligence What is vector search? Authors Meredith Syed Technical Content, Editorial Lead IBM Erika Russi Data Scientist IBM What is vector search? Vector search is a search technique used to find similar items or data points, typically represented as vectors, in large collections. Vectors, or embeddings, are numerical representations of words, entities, documents, images or videos. Vectors capture the semantic relationships between elements, enabling effective processing by machine learning models and artificial intelligence applications. Vector search vs. traditional search In contrast to traditional search, which typically uses keyword search, vector search relies on vector similarity search techniques like k-nearest neighbor search (knn) to retrieve data points similar to a query vector based on some distance metric. Vectors capture semantic relationships and similarities between data points, enabling semantic search instead of simple keyword search. To illustrate the difference between traditional keyword and vector search, let\\u2019s go through an example. Say you are looking for information on the best pizza restaurant and you search for \\u201cbest pizza restaurant\\u201d in a traditional keyword search engine. The keyword search looks for pages that contain the exact words \\u201cbest\\u201d, \\u201cpizza\\u201d and \\u201crestaurant\\u201d and only returns results like \\u201cBest Pizza Restaurant\\u201d or \\u201cPizza restaurant near me\\u201d. Traditional keyword search focuses on matching the keywords rather than understanding the context or intent behind the search. By contrast, in a semantic vector search, the search engine understands the intent behind the query. Semantic, by definition, means relating to meaning in language, that is, semantic search understands the meaning and context of a query. In this case, it would look for content that talks about top-rated or highly recommended pizza places, even if the exact words \\\\\\\"best pizza restaurant\\\\\\\" are not used in the content. The results are more contextually relevant and might include articles or guides that discuss high quality pizza places in various locations. Traditional search methods typically represent data using discrete tokens or features, such as keywords, tags or metadata. As shown in our example above, these methods rely on exact matches to retrieve relevant results. By contrast, vector search represents data as dense vectors (a vector in which most or all of the elements are non-zero) in a continuous vector space, the mathematical space in which data is represented as vectors. Each dimension of the dense vector corresponds to a latent feature or aspect of the data, an underlying characteristic or attribute that is not directly observed but is inferred from the data through mathematical models or algorithms. These latent features capture the hidden patterns and relationships in the data, enabling more meaningful and accurate representations of items as vectors in a high-dimensional space. Traditional search methods may struggle with scalability for large datasets or high-dimensional data due to computational and memory constraints. By contrast, vector embeddings are easier to scale to larger datasets and more complex models. Unlike sparse representations of data where most of the values are zeros across dimensions, embeddings are dense vector representations having non-zero values in most dimensions. This allows vector embeddings to store more information in a smaller, lower-dimensional space, requiring less memory.1 As a result, machine learning algorithms and models can use embeddings more efficiently with fewer compute resources. Vectorization process For this explainer, we will focus on the vector representations applicable under natural language processing (NLP), that is, vectors that represent words, entities or documents. We will illustrate the vectorization process by vectorizing a small corpus of sentences: \\u201cthe cat sat on the mat\\u201d, \\u201cthe dog played in the yard\\u201d and \\u201cbirds chirped in the trees\\u201d. The first step to building vector embeddings is to clean and process the raw dataset. This may involve the removal of noise and standardization of the text. For our example, we won\\u2019t do any cleaning since the text is already cleaned and standardized. Next, an embedding model is chosen to be trained on the dataset. The trained embedding model is used to generate embeddings for each data point in the dataset. For text data, popular open-source embedding models include Word2Vec, GloVe, FastText or pre-trained transformer-based models like BERT or RoBERTa2. For our example, we\\u2019ll use Word2Vec to generate our embeddings. Next, the embeddings are stored in a vector database or a vector search plugin for a search engine, like Elasticsearch, is used. In vector search, relevance of a search result is established by assessing the similarity between the query vector, which is generated by vectorizing the query, and the document vector, which is a representation of the data being queried. Indexes need to be created in the vector database to enable fast and efficient retrieval of embeddings based on similar queries. Techniques such as hierarchical navigable small world (HNSW) can be used to index the embeddings and facilitate similarity search at query time. HNSW organizes the dataset and enables rapid search for nearest neighbors by clustering similar vectors together during the index construction process. Finally, a mechanism or procedure to generate vectors for new queries must be established. This typically involves creating an API or service that takes user search queries as input in real-time, processes it using the same vector model and generates a corresponding vector representation. This vector can then be used to search on the database to get the most relevant results. Finding similarity with distance measurements and ANN algorithms In vector search, relevance is determined by measuring the similarity between query and document vectors. To compare two vectors against each other and determine their similarity, some distance measurement may be used, such as Euclidean distance or cosine similarity3. Euclidean distance Euclidean distance is a measure of the straight-line distance between two points. It is calculated as the square root of the sum of the squared differences between the corresponding coordinates of the two points. This formula can be extended to higher-dimensional spaces by adding more terms to account for additional dimensions. Cosine similarity Cosine similarity is a measure of similarity between two vectors in a multi-dimensional space. It calculates the cosine of the angle between the two vectors, indicating how closely the vectors align with each other. Mathematically, the cosine similarity, cos(\\u03b8), between two vectors is calculated as the dot product of the two vectors divided by the product of their magnitudes. Cosine similarity ranges from -1 to 1, where: 1 indicates that the vectors are perfectly aligned (pointing in the same direction), 0 indicates that the vectors are orthogonal (perpendicular to each other) and -1 indicates that the vectors are pointing in opposite directions. Cosine similarity is particularly useful when dealing with vectors, as it focuses on the directional relationship between vectors rather than their magnitudes. Approximate-nearest neighbor (ANN) Although the distance metrics mentioned previously can be used to measure vector similarity, it becomes inefficient and slow to compare all possible vectors against the query vector at query time for similarity search. To solve for this, we can use an approximate-nearest neighbor (ANN) search. Instead of finding an exact match, ANN algorithms efficiently search for the vectors that are approximately closest to a given query based on some distance metric like Euclidean distance or cosine similarity. By allowing for some level of approximation, these algorithms can significantly reduce the computational cost of nearest neighbor search without the need to compute embedding similarities across an entire corpus. One of the most popular ANN algorithms is HNSW graphs. The hierarchical navigable small world graph structure indexes the dataset and facilitates fast search for nearest neighbors by grouping similar vectors together as it builds the index. HNSW organizes data into neighborhoods, linking them with probable connections. When indexing a dense vector, it identifies the suitable neighborhood and its potential connections, storing them in a graph structure. During an HNSW search with a dense vector query, it locates the optimal neighborhood entry point and returns the nearest neighbors. Applications of vector search Vector search has numerous use cases across domains due to its ability to efficiently retrieve similar items based on their vector representations. Some common applications of vector search include: Information retrieval Vector search is used in search engines to retrieve documents, articles, web pages or other textual content based on their similarity to a query. It enables users to find relevant information even if the exact terms used in the query are not present in the documents. Retrieval Augmented Generation (RAG) Vector search is instrumental in the Retrieval Augmented Generation (RAG) framework for retrieving relevant context from a large corpus of text. RAG is a framework for generative AI that combines vector search with generative language models to generate responses. In traditional language generation tasks, large language models (LLMs) like OpenAI\\u2019s GPT (Generative Pre-trained Transformer) or IBM\\u2019s Granite Models are used to construct responses based on the input prompt. However, these models may struggle to produce responses that are contextually relevant, factually accurate or up to date. RAG addresses this limitation by incorporating a retrieval step before response generation. During retrieval, vector search can be used to identify contextually pertinent information, such as relevant passages or documents from a large corpus of text, typically stored in a vector database. Next, an LLM is used to generate a response based on the retrieved context. Beyond language generation, RAG and vector search have further applications in various other NLP tasks, including question answering, chatbots, summarization and content generation. Hybrid search Vector search can be integrated into hybrid search approaches to enhance the effectiveness and flexibility of the search process. Hybrid search combines vector search with other search techniques, such as keyword-based search or metadata-based search. Vector search may be used to retrieve items based on their similarity to a query, while other search methods may be used to retrieve items based on exact matches or specific criteria. Video and image search Vector stores are used in image and video search engines to index and retrieve visual content based on similarity. Image and video embeddings are stored as vectors, enabling users to search for visually similar images or videos across large datasets. Recommendation systems Recommendation engines in streaming services as well as e-commerce, social media and visual media platforms can be powered by vector search. Vector search allows for the recommendation of products, movies, music or other items based on their similarity to items that users have interacted with or liked previously. Geospatial analysis Vector search is used in geospatial data applications to to retrieve spatial data such as points of interest, geographic features or spatial trajectories based on their proximity or similarity to a query location or pattern. It enables efficient spatial search and analysis in geographic information systems and location-based services. The latest AI News + Insights \\\\u2028 Discover expertly curated insights and news on AI, cloud and more in the weekly Think Newsletter. Subscribe today Mixture of Experts | 7 November, episode 80 Decoding AI: Weekly News Roundup Join our world-class panel of engineers, researchers, product leaders and more as they cut through the AI noise to bring you the latest in AI news and insights. Watch all episodes of Mixture of Experts Ebook How to choose the right foundation model Learn how to choose the right approach in preparing datasets and employing foundation models. Read the ebook Resources Upcoming Webinar | November 20 Fact or Fiction? Top Misconceptions About AI Agents Join experts from IBM and MINT.ai as they break down the most common misconceptions about AI agents and share the truth behind the technology. Register now Ebook Start realizing ROI: A practical guide to agentic AI Discover ways to get ahead, successfully scaling AI across your business with real results. Read the ebook 2025 AI Agents buyer's guide How AI agents and assistants can benefit your organization Dive into this comprehensive guide that breaks down key use cases, core capabilities, and step-by-step recommendations to help you choose the right solutions for your business. Read the guide Report Top strategic technology trends for 2025: Agentic AI Download this Gartner\\u00ae research to learn the potential opportunities and risks of agentic AI for IT leaders and how to prepare for this next wave of AI innovation. Read the report Training Level up your AI expertise Access our full catalog of over 100 online courses by purchasing an individual or multi-user subscription today, enabling you to expand your skills across a range of our products at a low price. Start learning Report From AI projects to profits: How agentic AI can sustain financial returns Learn how organizations are shifting from launching AI in disparate pilots to using it to drive transformation at the core. Read the report AI models Explore IBM Granite IBM\\u00ae Granite\\u00ae is a family of open, performant and trusted AI models tailored for business and optimized to scale your AI applications. Explore language, code, time series and guardrail options. Meet Granite Report IBM is named a Leader in Data Science & Machine Learning Learn why IBM has been recognized as a Leader in the 2025 Gartner\\u00ae Magic Quadrant\\u2122 for Data Science and Machine Learning Platforms. Read the report Video IBM AI Academy Led by top IBM thought leaders, the curriculum is designed to help business leaders gain the knowledge needed to prioritize the AI investments that can drive growth. Explore the series Report The 2025 CEO\\u2019s guide: 5 mindshifts to supercharge business growth Activate these five mindshifts to cut through the uncertainty, spur business reinvention, and supercharge growth with agentic AI. Read the report Ebook Unlock the power of generative AI and ML Learn how to confidently incorporate generative AI and machine learning into your business. Read the ebook Guide How to thrive in this new era of AI with trust and confidence Dive into the three critical elements of a strong AI strategy: creating a competitive edge, scaling AI across the business and advancing trustworthy AI. Read the guide Related solutions IBM\\u00ae watsonx Orchestrate\\u2122 Easily design scalable AI assistants and agents, automate repetitive tasks and simplify complex processes with IBM\\u00ae watsonx Orchestrate\\u2122. Explore watsonx Orchestrate Artificial intelligence solutions Put AI to work in your business with IBM\\u2019s industry-leading AI expertise and portfolio of solutions at your side. Explore AI solutions Artificial intelligence consulting and services IBM Consulting AI services help reimagine how businesses work with AI for transformation. Explore AI services Take the next step Whether you choose to customize pre-built apps and skills or build and deploy custom agentic services using an AI studio, the IBM watsonx platform has you covered. Explore watsonx Orchestrate Explore watsonx.ai Footnotes 1 Bahaaldine Azarmi and Jeff Vestal, Vector Search for Practitioners with Elastic, Packt Publishing, 2023 2 Vicki Boykis, \\u201cWhat are embeddings,\\u201d 2023, https://vickiboykis.com/what_are_embeddings 3 Trey Grainger, Doug Turnbull and Max Irwin, AI Powered Search, Manning Publications, 2024\\\"}]}\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Search for ML and vector search concepts\n",
    "parameters = {\n",
    "    \"question\": \"What is k-NN vector search and how does it work?\"\n",
    "}\n",
    "\n",
    "print(\"‚ùì Question: What is k-NN vector search and how does it work?\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "response = execute_agent(client, agent_id, parameters)\n",
    "\n",
    "print(\"\\nüìö Technical Information:\")\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade91ea6",
   "metadata": {},
   "source": [
    "## Step 6: Test Case 3 - Search for Current News/Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b05fd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì Question: Latest features in OpenSearch 2.11\n",
      "============================================================\n",
      "\n",
      "üì∞ Current Information:\n",
      "{\n",
      "  \"inference_results\": [\n",
      "    {\n",
      "      \"output\": [\n",
      "        {\n",
      "          \"name\": \"response\",\n",
      "          \"result\": \"{\\\"next_page\\\":\\\"https://duckduckgo.com/html?q=Latest+features+in+OpenSearch+2.11&s=10&nextParams=&v=l&o=json&dc=11&api=d.js&vqd=4-231681247467792853657446391222187685099&kl=wt-wt\\\",\\\"items\\\":[{\\\"url\\\":\\\"https://opensearch.org/blog/get-started-opensearch-2-11/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to main content Search Close Search search Menu About Foundation Governing Board Charter Meeting Calendar Platform Platform OpenSearch CoreOpenSearch is a powerful search and analytics engine built on Apache Lucene. OpenSearch DashboardsOur data visualization toolset is a flexible, fully integrated solution for visually exploring and querying your data. OpenSearch Data PrepperA server-side data collector designed to enrich, transform, and aggregate data for downstream analytics with Opensearch. OpenSearch Vector EnginePower machine learning and generative AI applications with a high-performance database designed for the way AI understands data. Capabilities Machine learning and AI Vector Search Anomaly Detection Search E-Commerce Document Search Search Relevance Observability Performance Monitoring Log Analysis Security Analytics Threat Intelligence Event Correlation Performance Benchmarks View key performance metrics across different workloads View Data Roadmap Image OpenSearch Project RoadmapExplore our official project roadmap on GitHub Community OpenSearch Community ForumFind answers to your questions, help others in the community, and join the conversation. EventsCommunity Meetings, Development Backlog & Triage, in-person, and virtual events. AmbassadorsAmbassadors Community leaders who share knowledge and grow OpenSearch. Solutions ProvidersFind open-source providers offering solutions and services. ProjectsHighlights of projects built by the community. User GroupsJoin the OpenSearch Project Meetup Network Community Resources SlackSpeak with other developers. GitHub Project OrganizationJoin us for in-person and virtual events to learn the latest about the project. OpenSearchCon Image OpenSearchCon North AmericaSeptember 8-10, 2025 | San Jose, CA OpenSearchCon India3-4 June 2025 | Bengaluru, India OpenSearchCon Korea2025 November 4 | Seoul, South Korea OpenSearchCon EuropeView Videos & Slides Documentation Documentation Library OpenSearch and DashboardsBuild your OpenSearch solution using core tooling and visualizations. OpenSearch Data PrepperFilter, mutate, and sample your data for ingestion into OpenSearch. Migration AssistantBegin your transition to OpenSearch with our migration toolkit Documentation Library II OpenSearch BenchmarkMeasure performance metrics for your OpenSearch cluster. ClientsInteract with OpenSearch from your application using language APIs. Blog & News Blog Announcements Case Studies News Authors Downloads search Blog Get started with OpenSearch 2.11 By James McIntyreOctober 16, 2023June 18th, 2025No Comments OpenSearch 2.11 is now available, with exciting new capabilities for observability applications, an expanded selection of search tools, enhancements to data durability, and more, along with new experimental functionality to explore. For a complete view of what\\u2019s new in this release, see the release notes, and you can give OpenSearch Dashboards a try on OpenSearch Playground. An easier way to infuse multimodal search into your applications This release introduces text and image multimodal search using neural search. This functionality allows users to search image and text pairs, like product catalog items (product image and description), based on visual and semantic similarity. This enables new search experiences that can deliver more relevant results. For instance, users can search for \\u201cwhite blouse\\u201d to retrieve product images\\u2014the machine learning (ML) model that powers this experience is able to associate semantics and visual characteristics. Users can also search by image to retrieve visually similar products or search by both text and image to find the products most similar to a particular product catalog item. You can now build these capabilities into your application to connect directly to multimodal models and run multimodal search queries without having to build custom middleware. See the multimodal search documentation for guidance on how to get started with multimodal semantic search, and look out for more input types to be added to this functionality in future releases. Choose the best retrieval method for semantic search applications Previously, OpenSearch offered only a dense retrieval approach for text-based vector search. With this release, search practitioners can now choose between sparse retrieval or dense retrieval methods for semantic search applications. Each method presents tradeoffs for users, depending on their application; for example, dense retrieval typically delivers high search relevance while consuming more memory and compute resources and has higher latencies. In comparison, the new sparse retrieval functionality offers two modes with different advantages: a document-only mode can deliver low-latency performance more comparable to BM25 search, with limitations for advanced syntax as compared to dense methods, and a bi-encoder mode can maximize search relevance while performing at higher latencies. With this update, users can now choose the method that works best for their performance, accuracy, and cost requirements. For an in-depth exploration of each method and their advantages for different workloads, stay tuned for an upcoming blog post. Compare and tune your search results Introduced in OpenSearch 2.4 as experimental functionality, this release makes the search comparison tool generally available for production workloads. This tool lets you compare the results of two different search queries side by side in OpenSearch Dashboards, as shown in the following example UI. As an example, you can compare the results of a lexical search against the results from a semantic search query so that you can view both rankings and tune your results accordingly. Protect data efficiently with interoperability between snapshots and remote-backed storage Today, OpenSearch offers two built-in ways to enhance data durability: remote-backed storage, which gives you the option to automatically store all transactions on a per-index basis using your choice of cloud storage services, and snapshots, which let you create an on-demand snapshot of a cluster\\u2019s indexes and metadata in a configured repository. With this feature, you have the option to use snapshots more efficiently, with less demand on compute resources, by taking snapshots that refer to data in your remote-backed repository rather than duplicating the data in full. Usability improvements for Security Analytics Following from the results of a recent usability study, this release brings updates to the user experience designed to make it easier to get started with Security Analytics. A new workflow simplifies the process of creating threat detectors and setting up alerts within OpenSearch Dashboards, reducing the number of steps and clarifying certain form fields. Another change adds categories to log types, organizing prepackaged and custom logs into predefined categories for easier filtering and sorting. Improving the security posture of OpenSearch Dashboards OpenSearch 2.11 marks the culmination of a long-term project with the goal of removing dependencies on AngularJS from OpenSearch Dashboards. With AngularJS having reached end-of-life, this step will help to modernize and improve the security posture of OpenSearch Dashboards. For a detailed view of what has changed and how it may affect users, please review this recently published notice in GitHub. Bringing authorization to the REST layer for plugin development REST layer authorization empowers plugin developers to establish secure access controls for REST endpoints in addition to transport layer authorization. Previously, OpenSearch exclusively enforced authorization checks at the transport layer. Given that extensions solely interact with the OpenSearch cluster through the REST layer, the introduction of extensions necessitated the implementation of authorization checks at that layer. Now offered as an independent feature, this enables plugin developers to incorporate routes with an additional layer of security. Integration of this functionality with the extension framework is currently under development. Experimental features OpenSearch 2.11 includes experimental features designed to allow users to preview new tools before they are generally available. Experimental features should not be used in a production environment. Track OpenSearch requests with traces OpenSearch 2.11 introduces the ability to trace OpenSearch requests and tasks as an experimental functionality. With this release, OpenSearch introduces a new framework that allows developers to follow OpenSearch requests and tasks as they traverse components and services across the distributed architecture. Users can also enable this functionality in order to trace their requests and monitor their paths through the system, measure request latencies, and more. This release enables this functionality at the network layer, REST layer, and transport layer. As development of the feature continues, additional capabilities will address collecting trace and span data at different levels of granularity and with different code paths. Refer to the documentation to learn more and see how you can explore these capabilities. To share feedback, please see our request for comments. Customize pipelines for retrieval augmented generation Enhancing the conversational search functionality introduced in OpenSearch 2.10 as an experimental toolkit, this release introduces several new parameters that can be used to customize retrieval augmented generation (RAG) pipelines. These optional parameters provide core logic that allows you to adapt the way OpenSearch interacts with large language models (LLMs) as part of generative artificial intelligence (GenAI) applications. See the documentation for this feature to explore the available parameters. The latest version of OpenSearch is ready for download! You can find out more about these features and many others in the release notes and the documentation release notes as well as the documentation. OpenSearch Playground offers a turnkey option for exploring the visualization toolkit before downloading it. Look for upcoming blog posts that dive deeper into the new functionality delivered in OpenSearch 2.11. Author James McIntyre James McIntyre is a senior product marketing manager with AWS serving the OpenSearch Project and chair of the OpenSearch Software Foundation Marketing Outreach Committee. View all posts Share Subscribe for updates, event info, and the latest community news OpenSearch is a community-driven, Apache 2.0-licensed open source search and analytics suite that makes it easy to ingest, search, visualize, and analyze data. linkedin github slack youtube mastodon bluesky x-twitter Participate Code of Conduct Forum Project Repo Community Repo Meetup Connect Providers Become a Provider Find a Provider Resources About FAQ Release Schedule Maintenance Policy Documentation Getting Started Testimonials Trademark & Brand Privacy \\u00a9 Copyright The Linux Foundation. The OpenSearch Project is a project of The Linux Foundation. For web site terms of use, trademark policy and other policies applicable to The OpenSearch Project please see Linux Foundation Policies. The OpenSearch Project supports the OpenSearch open source project, which has been established as OpenSearch Project a Series of LF Projects, LLC. For policies applicable to the OpenSearch Project a Series of LF Projects, LLC, please see LF Projects, LLC Policies, Privacy Policy, Terms of Use and the OpenSearch Trademark Policy. Close Menu About Foundation Governing Board Charter Meeting Calendar Platform Platform OpenSearch CoreOpenSearch is a powerful search and analytics engine built on Apache Lucene. OpenSearch DashboardsOur data visualization toolset is a flexible, fully integrated solution for visually exploring and querying your data. OpenSearch Data PrepperA server-side data collector designed to enrich, transform, and aggregate data for downstream analytics with Opensearch. OpenSearch Vector EnginePower machine learning and generative AI applications with a high-performance database designed for the way AI understands data. Capabilities Machine learning and AI Vector Search Anomaly Detection Search E-Commerce Document Search Search Relevance Observability Performance Monitoring Log Analysis Security Analytics Threat Intelligence Event Correlation Performance Benchmarks View key performance metrics across different workloads View Data Roadmap Image OpenSearch Project RoadmapExplore our official project roadmap on GitHub Community OpenSearch Community ForumFind answers to your questions, help others in the community, and join the conversation. EventsCommunity Meetings, Development Backlog & Triage, in-person, and virtual events. AmbassadorsAmbassadors Community leaders who share knowledge and grow OpenSearch. Solutions ProvidersFind open-source providers offering solutions and services. ProjectsHighlights of projects built by the community. User GroupsJoin the OpenSearch Project Meetup Network Community Resources SlackSpeak with other developers. GitHub Project OrganizationJoin us for in-person and virtual events to learn the latest about the project. OpenSearchCon Image OpenSearchCon North AmericaSeptember 8-10, 2025 | San Jose, CA OpenSearchCon India3-4 June 2025 | Bengaluru, India OpenSearchCon Korea2025 November 4 | Seoul, South Korea OpenSearchCon EuropeView Videos & Slides Documentation Documentation Library OpenSearch and DashboardsBuild your OpenSearch solution using core tooling and visualizations. OpenSearch Data PrepperFilter, mutate, and sample your data for ingestion into OpenSearch. Migration AssistantBegin your transition to OpenSearch with our migration toolkit Documentation Library II OpenSearch BenchmarkMeasure performance metrics for your OpenSearch cluster. ClientsInteract with OpenSearch from your application using language APIs. Blog & News Blog Announcements Case Studies News Authors Downloads\\\"},{\\\"url\\\":\\\"https://github.com/opensearch-project/opensearch-build/blob/main/release-notes/opensearch-release-notes-2.11.0.md\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to content Navigation Menu Toggle navigation Sign in Appearance settings Platform AI CODE CREATION GitHub CopilotWrite better code with AI GitHub SparkBuild and deploy intelligent apps GitHub ModelsManage and compare prompts MCP RegistryNewDiscover and integrate external tools DEVELOPER WORKFLOWS ActionsAutomate any workflow CodespacesInstant dev environments IssuesPlan and track work Code ReviewManage code changes APPLICATION SECURITY GitHub Advanced SecurityFind and fix vulnerabilities Code securitySecure your code as you build Secret protectionStop leaks before they start EXPLORE Why GitHub Documentation Blog Changelog Marketplace View all features Solutions BY COMPANY SIZE Enterprises Small and medium teams Startups Nonprofits BY USE CASE App Modernization DevSecOps DevOps CI/CD View all use cases BY INDUSTRY Healthcare Financial services Manufacturing Government View all industries View all solutions Resources EXPLORE BY TOPIC AI Software Development DevOps Security View all topics EXPLORE BY TYPE Customer stories Events & webinars Ebooks & reports Business insights GitHub Skills SUPPORT & SERVICES Documentation Customer support Community forum Trust center Partners Open Source COMMUNITY GitHub SponsorsFund open source developers PROGRAMS Security Lab Maintainer Community Accelerator Archive Program REPOSITORIES Topics Trending Collections Enterprise ENTERPRISE SOLUTIONS Enterprise platformAI-powered developer platform AVAILABLE ADD-ONS GitHub Advanced SecurityEnterprise-grade security features Copilot for BusinessEnterprise-grade AI features Premium SupportEnterprise-grade 24/7 support Pricing Search or jump to... Search code, repositories, users, issues, pull requests... Search Clear Search syntax tips Provide feedback We read every piece of feedback, and take your input very seriously. Include my email address so I can be contacted Cancel Submit feedback Saved searches Use saved searches to filter your results more quickly Name Query To see all available qualifiers, see our documentation. Cancel Create saved search Sign in Sign up Appearance settings Resetting focus You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert {{ message }} opensearch-project / opensearch-build Public generated from amazon-archives/__template_Apache-2.0 Notifications You must be signed in to change notification settings Fork 314 Star 180 Code Issues 178 Pull requests 19 Discussions Actions Projects 3 Wiki Security Uh oh! There was an error while loading. Please reload this page. Insights Additional navigation options Code Issues Pull requests Discussions Actions Projects Wiki Security Insights Footer \\u00a9 2025 GitHub, Inc. Footer navigation Terms Privacy Security Status Community Docs Contact Manage cookies Do not share my personal information You can\\u2019t perform that action at this time.\\\"},{\\\"url\\\":\\\"https://aws.amazon.com/about-aws/whats-new/2023/11/amazon-opensearch-supports-version-2-11/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to main content Click here to return to Amazon Web Services homepage About AWS Contact Us Support English My Account Sign In Create an AWS Account Close Profile Your profile helps improve your interactions with select AWS experiences. Login Close Profile Your profile helps improve your interactions with select AWS experiences. View profile Log out Amazon Q Products Solutions Pricing Documentation Learn Partner Network AWS Marketplace Customer Enablement Events Explore More Close \\u0639\\u0631\\u0628\\u064a Bahasa Indonesia Deutsch English Espa\\u00f1ol Fran\\u00e7ais Italiano Portugu\\u00eas Ti\\u1ebfng Vi\\u1ec7t T\\u00fcrk\\u00e7e \\u03a1\\u0443\\u0441\\u0441\\u043a\\u0438\\u0439 \\u0e44\\u0e17\\u0e22 \\u65e5\\u672c\\u8a9e \\ud55c\\uad6d\\uc5b4 \\u4e2d\\u6587 (\\u7b80\\u4f53) \\u4e2d\\u6587 (\\u7e41\\u9ad4) Close My Profile Sign out of AWS Builder ID AWS Management Console Account Settings Billing & Cost Management Security Credentials AWS Personal Health Dashboard Close Support Center Expert Help Knowledge Center AWS Support Overview AWS re:Post Click here to return to Amazon Web Services homepage Get Started for Free Contact Us Products Solutions Pricing Introduction to AWS Getting Started Documentation Training and Certification Developer Center Customer Success Partner Network AWS Marketplace Support AWS re:Post Log into Console Download the Mobile App Amazon OpenSearch Service now supports OpenSearch version 2.11 Posted On: Nov 20, 2023 You can now run OpenSearch version 2.11 in Amazon OpenSearch Service. With OpenSearch 2.11, we have made several improvements to search, observability, security analytics, and OpenSearch Dashboards. This version includes features that were launched as part of open source OpenSearch versions 2.10 and 2.11. This launch includes the introduction of hybrid search queries, which uses normalization processors to improve search relevance, by combining relevance scores of lexical queries with natural language-based k-NN vector search queries. It also includes multimodal search, which allows users to search image and text pairs like product catalog items, and the introduction of neural sparse retrieval in addition to existing dense retrieval for semantic search applications. Search practitioners can test out these new search methods with the new search comparison tool which lets you compare the results of two different search queries side by side in OpenSearch Dashboards. Security Analytics now provides threat detection capabilities to detect malicious activity and adds custom log categories for easier filtering and sorting. Other improvements include a new visual theme and a discover tool for a more user-friendly Dashboards environment, and a new IP2Geo processor that allows users to retrieve the geographical location of an IPv4 or IPv6 address, and add that information to incoming data during ingest or at a later time, as required. For information on upgrading to OpenSearch 2.11, please see this documentation. OpenSearch 2.11 is now available in all AWS Regions where Amazon OpenSearch Service is available. \\u00bb Sign In to the Console Learn About AWS What Is AWS? What Is Cloud Computing? AWS Accessibility What Is DevOps? What Is a Container? What Is a Data Lake? What is Artificial Intelligence (AI)? What is Generative AI? What is Machine Learning (ML)? AWS Cloud Security What's New Blogs Press Releases Resources for AWS Getting Started Training and Certification AWS Trust Center AWS Solutions Library Architecture Center Product and Technical FAQs Analyst Reports AWS Partners Developers on AWS Developer Center SDKs & Tools .NET on AWS Python on AWS Java on AWS PHP on AWS JavaScript on AWS Help Contact Us Get Expert Help File a Support Ticket AWS re:Post Knowledge Center AWS Support Overview Legal AWS Careers Create an AWS Account Amazon is an Equal Opportunity Employer: Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age. Language \\u0639\\u0631\\u0628\\u064a Bahasa Indonesia Deutsch English Espa\\u00f1ol Fran\\u00e7ais Italiano Portugu\\u00eas Ti\\u1ebfng Vi\\u1ec7t T\\u00fcrk\\u00e7e \\u03a1\\u0443\\u0441\\u0441\\u043a\\u0438\\u0439 \\u0e44\\u0e17\\u0e22 \\u65e5\\u672c\\u8a9e \\ud55c\\uad6d\\uc5b4 \\u4e2d\\u6587 (\\u7b80\\u4f53) \\u4e2d\\u6587 (\\u7e41\\u9ad4) Privacy | Accessibility | Site Terms | Cookie Preferences | \\u00a9 2025, Amazon Web Services, Inc. or its affiliates. All rights reserved. Ending Support for Internet Explorer Got it AWS support for Internet Explorer ends on 07/31/2022. Supported browsers are Chrome, Firefox, Edge, and Safari. Learn more \\u00bb Got it\\\"},{\\\"url\\\":\\\"https://opensearch.isharkfly.com/release-notes/opensearch-documentation-release-notes-2.11.0/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu OpenSearchCon 2024 - Stay Informed Sessions Speakers Exhibitors Workshops Unconference CFP is closed Download About Releases Roadmap FAQ Community Blog Forum Slack Events Partners Projects Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home API Style Guide Formatting Guide OpenSearch Documentation Website 2.10.0 Release Notes OpenSearch Documentation Website 2.11.0 Release Notes OpenSearch Documentation Website 2.12.0 Release Notes OpenSearch Documentation Website 2.4.0 Release Notes OpenSearch Documentation Website 2.5.0 Release Notes OpenSearch Documentation Website 2.6.0 Release Notes OpenSearch Documentation Website 2.7.0 Release Notes OpenSearch Documentation Website 2.8.0 Release Notes OpenSearch Documentation Website 2.9.0 Release Notes OpenSearch Project Style Guidelines OpenSearch terms Overview About OpenSearch Intro to OpenSearch Quickstart Version history Breaking changes Install and upgrade Installing OpenSearch Docker Helm Tarball RPM Debian Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Circuit breaker settings Cluster settings Index settings Search settings Availability and recovery settings Plugin settings Experimental feature flags Logs Configuring OpenSearch Dashboards Upgrading OpenSearch Rolling Upgrade Upgrades appendix Rolling upgrade lab Installing plugins Managing OpenSearch Dashboards plugins Migrate to OpenSearch Using snapshots to migrate data Migrating from Elasticsearch OSS to OpenSearch Migrating Docker clusters to OpenSearch Migrating from Kibana OSS to OpenSearch Dashboards Managing Indexes Index templates Index aliases Data streams Reindex data Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings Index management security Refresh search analyzer ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Ingest Pipelines Create pipeline Simulate pipeline Get pipeline Delete pipeline Handling pipeline failures Ingest processors Append Bytes Convert Copy CSV Date Date index name Dissect Dot expander Drop IP2Geo Grok KV Lowercase Remove_by_pattern Remove Sparse encoding Text embedding Text/image embedding Uppercase OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Analyzing data Time filter Creating dashboards Building data visualizations Using area charts Using coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using the self-host maps server Using Gantt charts Using VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimize query performance using OpenSearch indexing Dev Tools Running queries in the Dev Tools console Query Workbench Custom branding Dashboards Query Language (DQL) Search telemetry OpenSearch Integrations Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Tuning for indexing speed Security in OpenSearch Configuration Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files API rate limiting Configuring sign-in options Disabling security OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Access control REST layer authorization Document-level security Users and roles Field-level security Field masking User impersonation Cross-cluster search Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Creating detectors Supported log types Creating correlation rules Creating custom log types Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Security Analytics settings Mappings and field types Supported field types Alias Binary Numeric field types Unsigned long Boolean Date field types Date Date nanoseconds IP address Range field types Object field types Object Nested Flat object Join String field types Keyword Text Match-only text Token count Autocomplete field types Completion Search as you type Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape k-NN vector Rank field types Percolator Text analysis Language analyzers Index analyzers Search analyzers Tokenizers Token filters Delimited term frequency Normalizers Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Exists Fuzzy IDs Prefix Range Regexp Term Terms Terms set Wildcard Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box xy Span queries Match all queries Specialized queries Neural Neural sparse Script score Minimum should match Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Matrix stats Maximum Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Bucket aggregations Adjacency matrix Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Range Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Search Searching data Paginate results Point in Time Point in Time API Sort results Highlight query matches Autocomplete Did-you-mean Keyword search k-NN search k-NN index Exact k-NN with scoring script Approximate k-NN search k-NN search with filters k-NN search with nested fields k-NN Painless extensions API JNI libraries Settings Performance tuning Neural search Neural search tutorial Semantic search Multimodal search Neural sparse search Hybrid search Conversational search Search relevance Comparing search results Reranking search results Querqy Search pipelines Creating a search pipeline Using a search pipeline Retrieving search pipelines Search processors Collapse Filter query Neural query enricher Normalization Oversample Personalize search ranking Retrieval-augmented generation Rename field Rerank Script Truncate hits Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Identifiers Data Types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Machine learning ML Commons cluster settings Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Connector blueprints Agents and tools Agents and tools tutorial Tools Agent tool CAT Index tool Index Mapping tool ML Model tool Neural Sparse Search tool PPL tool RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool OpenSearch Assistant Toolkit Managing ML models in OpenSearch Dashboards Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Model group APIs Register model group Update model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Execute agent Get agent Search agent Delete agent Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Execute algorithm Tasks APIs Get task Search task Delete task Train and Predict APIs Train and predict Train Predict Profile Stats Automating configurations Workflow steps Workflow tutorial Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Monitoring your cluster Job Scheduler Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metrics analytics Query insights Top N queries Trace Analytics Getting Started OpenSearch Dashboards plugin Analyzing Jaeger trace data Distrbuted tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI OpenSearch Kubernetes Operator Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana API reference Analyze API Analysis API Terminology CAT API CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices operation CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster routing and awareness Cluster decommission Cluster health Cluster settings Cluster stats Count Document APIs Index document Get document Update document Delete document Bulk Multi-get document Delete by query Update by query Reindex document Explain Index APIs Alias Clear cache Clone index Close index Create index Create or update mappings Dangling indexes Delete index Force merge Get index Get settings Index exists Open index Shrink index Split index Stats Update settings Ingest APIs Multi-search Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Profile Ranking evaluation Remote cluster information Script APIs Create or Update Stored Script Execute Painless stored script Get Stored Script Delete Script Get Stored Script Contexts Get Script Language Execute Painless script Scroll Search Search templates Snapshot APIs Register Snapshot Repository Get Snapshot Repository Delete Snapshot Repository Verify Snaphot Repository Create Snapshot Get Snapshot Delete Snapshot Get Snapshot Status Restore Snapshot Tasks Supported units Common REST Parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Extensions OpenSearch Documentation Website 2.11.0 Release Notes The OpenSearch 2.11.0 documentation includes the following additions and updates. New documentation for 2.11.0 Add Conversational Search changes for 2.11 #5195 Remove warning about alerting and segment replication compatibility #5191 Add documentation for log type categories #5181 Add updates to creating a detector UX #5176 Add multimodal search/sparse search/pre- and post-processing function documentation #5168 Add documentation for new recovery setting #5162 Add terminate after behavior to concurrent segment search #5143 Add documentation for configurable merge policy #5137 Remove experimental header from search comparison tool #5124 Add documentation about setting a default model for neural search #5121 Add total wait time to thread pool in nodes stats #5120 Add new documentation for distributed tracing #4964 Add documentation for authorization on the REST layer #4544 New documentation for 2.11.0 WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links \\u53c2\\u4e0e\\u9879\\u76ee\\uff08Get Involved\\uff09 Code of Conduct OpenSearch \\u4e2d\\u6587\\u8bba\\u575b \\u5b98\\u65b9\\u8bba\\u575b \\u4e2d\\u6587\\u6587\\u6863\\u4ee3\\u7801\\u4ed3\\u5e93 \\u5b98\\u65b9 Github Slack \\u793e\\u533a\\u9879\\u76ee \\u8d44\\u6e90\\uff08Resources\\uff09 About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy \\u8054\\u7cfb\\u6211\\u4eec\\uff08Contact Us\\uff09 \\u8054\\u7cfb\\uff08Connect\\uff09 Twitter LinkedIn YouTube Meetup Facebook \\u00a9 OpenSearch contributors, 2024. OpenSearch is a registered trademark of Amazon Web Services. \\u00a9 2005-2021 Django Software Foundation and individual contributors. Django is a registered trademark of the Django Software Foundation. This website was forked from the BSD-licensed djangoproject.com originally designed by Threespot & andrevv.\\\"},{\\\"url\\\":\\\"https://docs.opensearch.org/latest/version-history/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Regular expression syntax Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Using UBI in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Version history OpenSearch version Release highlights Release date 3.3.2 Includes maintenance changes and bug fixes for the OpenSearch core engine and ML Commons, Neural Search, Skills, k-NN and Security plugins. For a full list of release highlights, see the Release Notes. 30 October 2025 3.3.1 Fixes backward compatibility handling of date fields while maintaining performance optimizations. The skip_list parameter is now automatically set to true for new @timestamp fields created since 3.3.0, while preserving skip_list=false for existing indexes with @timestamp or index sort date fields. This approach ensures date histogram aggregation performance benefits for new indexes while maintaining compatibility with existing workloads. For a full list of release highlights, see the Release Notes. 22 October 2025 3.3.0 Introduces redesigned Discover interface with log analytics and distributed tracing capabilities, and Apache Calcite as default PPL query engine with expanded functions. Makes agentic search and agentic memory APIs generally available for AI applications. Implements Seismic algorithm for neural sparse search performance improvements and processor chains for data transformation pipelines. Expands gRPC support for additional query types and adds experimental streaming with Apache Arrow Flight. Includes workload management enhancements with rule-based auto-tagging and query monitoring capabilities. For a full list of release highlights, see the Release Notes. 14 October 2025 3.2.0 Updates Search Relevance Workbench. Makes gRPC APIs generally available. Introduces derived source, updates workload management, semantic field, and star tree functionality. Adds experimental Agentic Memory APIs and Job Scheduler APIs. For a full list of release highlights, see the Release Notes. 19 August 2025 3.1.0 Makes GPU acceleration for vector index builds generally available. Introduces memory-optimized search for Faiss indexes using Lucene HNSW, semantic field type for streamlined semantic search, and Search Relevance Workbench for search quality optimization. Makes star-tree indexes generally available with support for comprehensive query types. Enhances observability with ML Commons metrics integration, custom index support for OpenTelemetry data, and new PPL commands for JSON manipulation. Improves agent management with Update Agent API and persistent MCP tools. Includes security enhancements with immutable user objects and new resource sharing framework. For a full list of release highlights, see the Release Notes. 24 June 2025 3.0.0 Upgrades to Lucene 10 for improved indexing and vector search. Adds experimental gRPC support and pull-based ingestion from Kafka and Kinesis. Introduces GPU acceleration for vector operations and semantic sentence highlighting. Improves range query performance and hybrid search with z-score normalization. Adds plan-execute-reflect agents and native MCP protocol support for agentic workflows. Enhances security with a new Java agent replacing the Security Manager. Includes PPL query improvements with lookup, join, and subsearch commands. For a full list of release highlights, see the Release Notes. 06 May 2025 2.19.3 Improves Flow Framework with enhanced memory handling and workflow step processing. Fixes several Query Insights and Query Insights Dashboards issues. Implements security updates across multiple components. Updates infrastructure components and documentation across multiple plugins. For a full list of release highlights, see the Release Notes. 22 July 2025 2.19.2 Improves query insights with better index handling, a new verbose API parameter, and a default index template. Fixes bugs across Query Insights, Observability, Flow Framework, and Dashboards. Includes multiple CVE fixes, test enhancements, and a new PGP key for artifact verification. For a full list of release highlights, see the Release Notes. 29 April 2025 2.19.1 Adds execution hint for cardinality aggregator. Includes bug fixes for ML Commons, Query Insights Dashboards, and Remote Metadata SDK. Contains maintenance updates for several components. For a full list of release highlights, see the Release Notes. 27 February 2025 2.19.0 Adds workload management, additional query insights, and template queries. Introduces a query insights page to OpenSearch Dashboards. Includes improvements and bug fixes to snapshots, search statistics, star-tree search, and index management. For a full list of release highlights, see the Release Notes. 11 February 2025 2.18.0 Adds a redesigned home page, updated Discover interface, and collaborative workspaces to OpenSearch Dashboards. Includes improvements to ML inference processor and query grouping. Introduces reranking by field and paginated CAT APIs. Includes experimental OpenSearch Dashboards Assistant capabilities. For a full list of release highlights, see the Release Notes. 05 November 2024 2.17.1 Includes bug fixes for ML Commons, anomaly detection, k-NN, and security analytics. Adds various infrastructure and maintenance updates. For a full list of release highlights, see the Release Notes. 1 October 2024 2.17.0 Includes disk-optimized vector search, binary quantization, and byte vector encoding in k-NN. Adds asynchronous batch ingestion for ML tasks. Provides search and query performance enhancements and a new custom trace source in trace analytics. Includes application-based configuration templates. For a full list of release highlights, see the Release Notes. 17 September 2024 2.16.0 Includes built-in byte vector quantization and binary vector support in k-NN. Adds new sort, split, and ML inference search processors for search pipelines. Provides application-based configuration templates and additional plugins to integrate multiple data sources in OpenSearch Dashboards. Includes an experimental Batch Predict ML Commons API. For a full list of release highlights, see the Release Notes. 06 August 2024 2.15.0 Includes parallel ingestion processing, SIMD support for exact search, and the ability to disable doc values for the k-NN field. Adds wildcard and derived field types. Improves performance for single-cardinality aggregations, rolling upgrades to remote-backed clusters, and more metrics for top N queries. For a full list of release highlights, see the Release Notes. 25 June 2024 2.14.0 Includes performance improvements to hybrid search and date histogram queries with multi-range traversal, ML model integration within the Ingest API, semantic cache for LangChain applications, low-level vector query interface for neural sparse queries, and improved k-NN search filtering. Provides an experimental tiered cache feature. For a full list of release highlights, see the Release Notes. 14 May 2024 2.13.0 Makes agents and tools and the OpenSearch Assistant Toolkit generally available. Introduces vector quantization within OpenSearch. Adds LLM guardrails and hybrid search with aggregations. Adds the Bloom filter skipping index for Apache Spark data sources, I/O-based admission control, and the ability to add an alerting cluster that manages all alerting tasks. For a full list of release highlights, see the Release Notes. 2 April 2024 2.12.0 Makes concurrent segment search and conversational search generally available. Provides an experimental OpenSearch Assistant Toolkit, including agents and tools, workflow automation, and OpenSearch Assistant for OpenSearch Dashboards UI. Adds a new match-only text field, query insights to monitor top N queries, and k-NN search on nested fields. For a full list of release highlights, see the Release Notes. 20 February 2024 2.11.1 Includes maintenance changes and bug fixes for cross-cluster replication, alerting, observability, OpenSearch Dashboards, index management, machine learning, security, and security analytics. For a full list of release highlights, see the Release Notes. 30 November 2023 2.11.0 Adds multimodal and sparse neural search capability and the ability to take shallow snapshots that refer to data stored in remote-backed storage. Makes the search comparison tool generally available. Includes a simplified workflow to create threat detectors in Security Analytics and improved security in OpenSearch Dashboards. Experimental features include a new framework and toolset for distributed tracing and updates to conversational search. For a full list of release highlights, see the Release Notes. 16 October 2023 2.10.0 Makes remote-backed storage generally available. Adds hybrid search capability, custom log types for Security Analytics, IP2Geo ingest processor, and delimited term frequency token filter. Includes a new look and feel for OpenSearch Dashboards and updates the Discover tool. Adds Microsoft Teams webhook support for notifications. Experimental features include concurrent segment search and conversational search. For a full list of release highlights, see the Release Notes. 25 September 2023 2.9.0 Makes search pipelines and the Neural Search plugin generally available. Adds ML model access control and integration with external ML tools. Implements k-NN byte vectors and efficient filtering with the Faiss engine. Integrates alerting and anomaly detection with OpenSearch Dashboards and adds composite monitors. Adds two new index codec algorithm options. Includes a new ingestion schema for Security Analytics, geoshape aggregations, and extensions\\u2014a new mechanism for extending OpenSearch functionality. For a full list of release highlights, see the Release Notes. 24 July 2023 2.8.0 Adds cross-cluster query with PPL, search pipelines, an option to turn on segment replication as the default replication type, improved searchable snapshot performance, and Amazon OpenSearch Serverless support with SigV4 authentication for multiple data sources. Includes the UI for the flush, refresh, and clear cache operations in OpenSearch Dashboards. For a full list of release highlights, see the Release Notes. 06 June 2023 2.7.0 Includes searchable snapshots and segment replication, which are now generally available. Adds multiple data sources, observability features, dynamic tenant management, component templates, and shape-based map filters in OpenSearch Dashboards. Includes the flat object field type, hot shard identification, and a new automatic reloading mechanism for ML models. For a full list of release highlights, see the Release Notes. 02 May 2023 2.6.0 Includes simple schema for observability, index management UI enhancements, Security Analytics enhancements, search backpressure at the coordinator node level, and the ability to add maps to dashboards. Experimental features include a new ML model health dashboard, new text embedding models in ML, and SigV4 authentication in Dashboards. For a full list of release highlights, see the Release Notes. 28 February 2023 2.5.0 Includes index management UI enhancements, multi-layer maps, Jaeger support for observability, Debian distributions, returning cluster health by awareness attribute, cluster manager task throttling, weighted zonal search request routing policy, and query string support in index rollups. Experimental features include request-level durability in remote-backed storage and GPU acceleration for ML nodes. For a full list of release highlights, see the Release Notes. 24 January 2023 2.4.1 Includes maintenance changes and bug fixes for gradle check and indexing pressure tests. Adds support for skipping changelog. For a full list of release highlights, see the Release Notes. 13 December 2022 2.4.0 Includes Windows support, Point-in-time search, custom k-NN filtering, xy_point and xy_shape field types for Cartesian coordinates, GeoHex grid aggregation, and resilience enhancements, including search backpressure. In OpenSearch Dashboards, this release adds snapshot restore functionality, multiple authentication, and aggregate view of saved objects. This release includes the following experimental features: searchable snapshots, Compare Search Results, multiple data sources in OpenSearch Dashboards, a new Model Serving Framework in ML Commons, a new Neural Search plugin that supports semantic search, and a new Security Analytics plugin to analyze security logs. For a full list of release highlights, see the Release Notes. 15 November 2022 2.3.0 This release includes the following experimental features: segment replication, remote-backed storage, and drag and drop for OpenSearch Dashboards. Experimental features allow you to test new functionality in OpenSearch. Because these features are still being developed, your testing and feedback can help shape the development of the feature before it\\u2019s official released. We do not recommend use of experimental features in production. Additionally, this release adds maketime and makedate datetime functions for the SQL plugin. Creates a new OpenSearch Playground demo site for OpenSearch Dashboards. For a full list of release highlights, see the Release Notes. 14 September 2022 2.2.1 Includes gradle updates and bug fixes for gradle check. For a full list of release highlights, see the Release Notes. 01 September 2022 2.2.0 Includes support for Logistic Regression and RCF Summarize machine learning algorithms in ML Commons, Lucene or C-based Nmslib and Faiss libraries for approximate k-NN search, search by relevance using SQL and PPL queries, custom region maps for visualizations, and rollup enhancements. For a full list of release highlights, see the Release Notes. 11 August 2022 2.1.0 Includes support for dedicated ML node in the ML Commons plugin, relevance search and other features in SQL, multi-terms aggregation, and Snapshot Management. For a full list of release highlights, see the Release Notes. 07 July 2022 2.0.1 Includes bug fixes and maintenance updates for Alerting and Anomaly Detection. For a full list of release highlights, see the Release Notes. 16 June 2022 2.0.0 Includes document-level monitors for alerting, OpenSearch Notifications plugins, and Geo Map Tiles in OpenSearch Dashboards. Also adds support for Lucene 9 and bug fixes for all OpenSearch plugins. For a full list of release highlights, see the Release Notes. 26 May 2022 2.0.0-rc1 The Release Candidate for 2.0.0. This version allows you to preview the upcoming 2.0.0 release before the GA release. The preview release adds document-level alerting, support for Lucene 9, and the ability to use term lookup queries in document level security. For a full list of release highlights, see the Release Notes. 03 May 2022 1.3.20 Includes enhancements to Anomaly Detection Dashboards, bug fixes for Alerting and Dashboards Reports, and maintenance updates for several OpenSearch components. For a full list of release highlights, see the Release Notes. 11 December 2024 1.3.19 Includes bug fixes and maintenance updates for OpenSearch security, OpenSearch security Dashboards, and anomaly detection. For a full list of release highlights, see the Release Notes. 27 August 2024 1.3.18 Includes maintenance updates for OpenSearch security. For a full list of release highlights, see the Release Notes. 16 July 2024 1.3.17 Includes maintenance updates for OpenSearch security and OpenSearch Dashboards security. For a full list of release highlights, see the Release Notes. 06 June 2024 1.3.16 Includes bug fixes and maintenance updates for OpenSearch security, index management, performance analyzer, and reporting. For a full list of release highlights, see the Release Notes. 23 April 2024 1.3.15 Includes bug fixes and maintenance updates for cross-cluster replication, SQL, OpenSearch Dashboards reporting, and alerting. For a full list of release highlights, see the Release Notes. 05 March 2024 1.3.14 Includes bug fixes and maintenance updates for OpenSearch security and OpenSearch Dashboards security. For a full list of release highlights, see the Release Notes. 12 December 2023 1.3.13 Includes bug fixes for Anomaly Detection, adds maintenance updates and infrastructure enhancements. For a full list of release highlights, see the Release Notes. 21 September 2023 1.3.12 Adds maintenance updates for OpenSearch security and OpenSearch Dashboards observability. Includes bug fixes for observability, OpenSearch Dashboards visualizations, and OpenSearch security. For a full list of release highlights, see the Release Notes. 10 August 2023 1.3.11 Adds maintenance updates for OpenSearch security, OpenSearch Dashboards security, and ML Commons. For a full list of release highlights, see the Release Notes. 29 June 2023 1.3.10 Adds infrastructure enhancements and maintenance updates for anomaly detection, observability, and security. Includes bug fixes for index management and OpenSearch security. For a full list of release highlights, see the Release Notes. 18 May 2023 1.3.9 Adds Debian support. Includes upgrades, enhancements, and maintenance updates for OpenSearch core, k-NN, and OpenSearch security. For a full list of release highlights, see the Release Notes. 16 March 2023 1.3.8 Adds OpenSearch security enhancements. Updates tool scripts to run on Windows. Includes maintenance updates and bug fixes for Anomaly Detection and OpenSearch security. For a full list of release highlights, see the Release Notes. 02 February 2023 1.3.7 Adds Windows support. Includes maintenance updates and bug fixes for error handling. For a full list of release highlights, see the Release Notes. 13 December 2022 1.3.6 Includes maintenance updates and bug fixes for tenancy in the OpenSearch Security Dashboards plugin. For a full list of release highlights, see the Release Notes. 06 October 2022 1.3.5 Includes maintenance updates and bug fixes for gradle check and OpenSearch security. For a full list of release highlights, see the Release Notes. 01 September 2022 1.3.4 Includes maintenance updates and bug fixes for OpenSearch and OpenSearch Dashboards. For a full list of release highlights, see the Release Notes. 14 July 2022 1.3.3 Adds enhancements to Anomaly Detection and ML Commons. Bug fixes for Anomaly Detection, Observability, and k-NN. For a full list of release highlights, see the Release Notes. 09 June 2022 1.3.2 Bug fixes for Anomaly Detection and the Security Dashboards Plugin, adds the option to install OpenSearch using RPM, as well as enhancements to the ML Commons execute task, and the removal of the job-scheduler zip in Anomaly Detection. For a full list of release highlights, see the Release Notes. 05 May 2022 1.3.1 Bug fixes when using document-level security, and adjusted ML Commons to use the latest RCF jar and protostuff to RCF model serialization. For a full list of release highlights, see the Release Notes. 30 March 2022 1.3.0 Adds Model Type Validation to Validate Detector API, continuous transforms, custom actions, applied policy parameter to Explain API, default action retries, and new rollover and transition conditions to Index Management, new ML Commons plugin, parse command to SQL, Application Analytics, Live Tail, Correlation, and Events Flyout to Observability, and auto backport and support for OPENSEARCH_JAVA_HOME to Performance Analyzer. Bug fixes. For a full list of release highlights, see the Release Notes. 17 March 2022 1.2.4 Updates Performance Analyzer, SQL, and Security plugins to Log4j 2.17.1, Alerting and Job Scheduler to cron-utils 9.1.6, and gson in Anomaly Detection and SQL. For a full list of release highlights, see the Release Notes. 18 January 2022 1.2.3 Updates the version of Log4j used in OpenSearch to Log4j 2.17.0 as recommended by the advisory in CVE-2021-45105. For a full list of release highlights, see the Release Notes. 22 December 2021 1.2.0 Adds observability, new validation API for Anomaly Detection, shard-level indexing back-pressure, new \\u201cmatch\\u201d query type for SQL and PPL, support for Faiss libraries in k-NN, and custom Dashboards branding. For a full list of release highlights, see the Release Notes. 23 November 2021 1.1.0 Adds cross-cluster replication, security for Index Management, bucket-level alerting, a CLI to help with upgrading from Elasticsearch OSS to OpenSearch, and enhancements to high cardinality data in the anomaly detection plugin. For a full list of release highlights, see the Release Notes. 05 October 2021 1.0.1 Bug fixes. For a full list of release highlights, see the Release Notes. 01 September 2021 1.0.0 General availability release. Adds compatibility setting for clients that require a version check before connecting. For a full list of release highlights, see the Release Notes. 12 July 2021 1.0.0-rc1 First release candidate. For a full list of release highlights, see the Release Notes. 07 June 2021 1.0.0-beta1 Initial beta release. Refactors plugins to work with OpenSearch. For a full list of release highlights, see the Release Notes. 13 May 2021 WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright \\u00a9 OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\\\"},null,{\\\"url\\\":\\\"https://aws.amazon.com/blogs/big-data/amazon-opensearch-service-announces-standard-and-extended-support-dates-for-elasticsearch-and-opensearch-versions/\\\",\\\"title\\\":\\\"facebook linkedin instagram twitch youtube podcasts email\\\",\\\"content\\\":\\\"Skip to Main Content Filter: All English Contact us Support My account Search Filter: All Sign in to console Create Account AWS Blogs Home Blogs Editions AWS Big Data Blog Amazon OpenSearch Service announces Standard and Extended Support dates for Elasticsearch and OpenSearch versions by Arvind Mahesh, Kuldeep Yadav, and Jon Handler on 07 NOV 2024 in Amazon OpenSearch Service, Analytics, Announcements Permalink Comments Share Amazon OpenSearch Service supports 19 versions of Elasticsearch opensource, and 11 versions of OpenSearch. Over the years, we have added several stability, resiliency, and security features to recent engine versions, helping customers derive better value from OpenSearch Service. As software versions grow older, we need to make sure that these versions continue to meet high security and compliance standards. Many of the legacy versions supported on OpenSearch Service, such as Elasticsearch versions 1.5 and 2.3, depend on third-party dependencies that are no longer actively supported. By moving to the latest engine versions, customers can derive maximum benefit from the new features, improved price-performance, and security improvements we make to OpenSearch. Today, we\\u2019re announcing timelines for end of Standard Support and Extended Support for legacy Elasticsearch versions up to 6.7, Elasticsearch versions 7.1 through 7.8, OpenSearch versions from 1.0 through 1.2, and OpenSearch versions 2.3 through 2.9 available on Amazon OpenSearch Service. Versions that are under Standard Support receive regular bug fixes and security fixes, and versions in Extended Support receive critical security fixes and operating system patches for an additional flat fee per normalized instance hour. With Extended Support, we want to make sure that our customers continue to receive critical security fixes for an adequate time, while they plan to upgrade to more recent engine versions. For more details on Extended Support please see the FAQs. End of Standard Support and Extended Support for Elasticsearch versions See Table 1 that follows for end of Standard Support and Extended Support dates for legacy Elasticsearch versions available on OpenSearch Service. We recommend that customers running Elasticsearch versions upgrade to the latest OpenSearch versions. All Elasticsearch versions will receive at least 12 months of Extended Support, and version 5.6 will receive 36 months of Extended Support. After Extended Support ends for a version, domains running the specific version will not receive bug fixes or security updates. Software version End of Standard Support End of Extended Support Elasticsearch versions 1.5 and 2.3 November 7, 2025 November 7, 2026 Elasticsearch versions 5.1 to 5.5 November 7, 2025 November 7, 2026 Elasticsearch version 5.6 November 7, 2025 November 7, 2028 Elasticsearch versions 6.0 to 6.7 November 7, 2025 November 7, 2026 Elasticsearch version 6.8 Not announced Not announced Elasticsearch versions 7.1 to 7.8 November 7, 2025 November 7, 2026 Elasticsearch version 7.9 Not announced Not announced Elasticsearch version 7.10 Not announced Not announced End of Standard Support and Extended Support for OpenSearch versions For OpenSearch versions running on Amazon OpenSearch Service, we will provide at least 12 months of Standard Support after the end of support date for the corresponding upstream open source OpenSearch version, or 12 months of Standard Support after the release of the next minor version on OpenSearch Service, whichever is longer. All OpenSearch versions will receive at least 12 months of Extended Support after the end of Standard Support date. For more details, check the open source OpenSearch maintenance policy. See Table 2 that follows for end of Standard Support and Extended Support dates for various OpenSearch versions available on OpenSearch Service. For future updates on versions in Standard Support and Extended Support, follow supported versions. Software Version End of Standard Support End of Extended Support OpenSearch versions 1.0 to 1.2 November 7, 2025 November 7, 2026 OpenSearch version 1.3 Not announced Not announced OpenSearch versions 2.3 to 2.9 November 7, 2025 November 7, 2026 OpenSearch versions 2.11 and higher versions Not announced Not announced Upgrading OpenSearch Service domains: We recommend that you update your domains to the latest available OpenSearch version to derive maximum value out of OpenSearch Service. Minor version upgrades on OpenSearch tend to be seamless because they don\\u2019t contain breaking changes, and we recommend moving to the latest minor version, or a version for which end of support has not yet been announced. For example, if you are on OpenSearch version 1.2, you can move to OpenSearch version 1.3, because it\\u2019s the last minor version of the 1.x series and because presently it continues to be supported by the open source community and AWS. If you want to choose an Elasticsearch version, and you are running an older 6.x or 7.x version, you can move to version 6.8, or 7.10. There are various ways to upgrade your cluster to a newer version, and the steps vary depending on the version your domain is running and the version you want to upgrade to. See Upgrading OpenSearch Service domains for detailed instructions on upgrading your domain to a new version. You can also use the Migration Assistant for Amazon OpenSearch Service for upgrading to newer versions Calculating Extended Support charges: Domains running versions under Extended Support will be charged a flat additional fee per normalized instance hour (NIH). For example, $0.0065 per NIH in the US East (North Virginia) AWS Region. See the pricing page for exact pricing by Region. NIH is computed as a factor of the instance size (for example, medium or large), and the number of instance hours. For example, if you\\u2019re running an m7g.medium.search instance for 24 hours in the US EAST (North Virginia) Region, which is priced at $0.068 per instance hour (on-demand), you will typically pay $1.632 ($0.068\\u00d724). If you\\u2019re running a version that is in Extended Support, you will pay an additional $0.0065 per NIH, which is computed as $0.0065 x 24 (number of instance hours) x 2 (size normalization factor, which is 2 for medium-sized instances), which comes to $0.312 for Extended Support for 24 hours. The total amount that you will pay for 24 hours will be a sum of the standard instance usage cost and the Extended Support cost, which is $1.944 ($1.632+$0.312, excluding storage cost). The following table shows the normalization factor for various instance sizes in OpenSearch Service. Instance size Normalization Factor nano 0.25 micro 0.5 small 1 medium 2 large 4 xlarge 8 2xlarge 16 4xlarge 32 8xlarge 64 9xlarge 72 10xlarge 80 12xlarge 96 16xlarge 128 18xlarge 144 24xlarge 192 32xlarge 256 Summary We add new capabilities across various vectors to the latest OpenSearch versions, which include new features, performance and resiliency improvements, and security improvements. We recommend that you update to recent OpenSearch versions to get the most benefit out of OpenSearch Service. For any questions on Standard and Extended Support options, see the FAQs. For further questions, contact AWS Support. About the authors Arvind Mahesh is a Senior Manager-Product at Amazon Web Services for Amazon OpenSearch Service. He has close to two decades of technology experience across a variety of domains such as Analytics, Search, Cloud, Network Security, and Telecom. Kuldeep Yadav is a Senior Technical Program Manager at Amazon Web Services who is passionate about driving innovation and complex problem solving. He works closely with teams and customers in ensuring operational excellence and achieving more with less. Outside of work he enjoys trekking and all sports Jon Handler is a Senior Principal Solutions Architect at Amazon Web Services based in Palo Alto, CA. Jon works closely with OpenSearch and Amazon OpenSearch Service, providing help and guidance to a broad range of customers who have search and log analytics workloads that they want to move to the AWS Cloud. Prior to joining AWS, Jon\\u2019s career as a software developer included 4 years of coding a large-scale, ecommerce search engine. Jon holds a Bachelor of the Arts from the University of Pennsylvania, and a Master of Science and a PhD in Computer Science and Artificial Intelligence from Northwestern University. Loading comments\\u2026 Resources Amazon Athena Amazon EMR Amazon Kinesis Amazon MSK Amazon QuickSight Amazon Redshift AWS Glue Follow Twitter Facebook LinkedIn Twitch Email Updates Create an AWS account Learn What Is AWS? What Is Cloud Computing? What Is Generative AI? Cloud Computing Concepts Hub AWS Cloud Security What's New Blogs Press Releases Resources Getting Started Training AWS Solutions Library Architecture Center Product and Technical FAQs Analyst Reports AWS Partners AWS Inclusion, Diversity & Equity Developers Developer Center SDKs & Tools .NET on AWS Python on AWS Java on AWS PHP on AWS JavaScript on AWS Help Contact Us File a Support Ticket AWS re:Post Knowledge Center AWS Support Overview Get Expert Help AWS Accessibility Legal English Back to top Amazon is an Equal Opportunity Employer: Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age. facebook linkedin instagram twitch youtube podcasts email Privacy Site terms Cookie Preferences \\u00a9 2025, Amazon Web Services, Inc. or its affiliates. All rights reserved.\\\"},{\\\"url\\\":\\\"https://www.instaclustr.com/blog/opensearch-2-11-is-now-available-on-the-instaclustr-managed-platform/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Search Search Search Contact us Support Sign in Platform + Left Column PlatformIntelligent, open source application data infrastructure Explore our platform Security and trustEnterprise-grade security Learn more HostingData infrastructure management in the cloud and on-prem Learn more AIPower RAG with open source data infrastructure Read more Right Column Store PostgreSQL\\u00ae Apache Cassandra\\u00ae Stream Apache Kafka\\u00ae Kafka\\u00ae Connect Orchestrate Cadence Analyze ClickHouse\\u00ae Search OpenSearch Pricing Services + Support Training Professional services About + About us Customers Our commitment to open source Resources + Getting started Sign up Documentation Quick start videos Integrations Support portal Discover Blog Events Content library Glossary Education hub Stream + Apache Kafka\\u00ae Real-time streaming Search + OpenSearch Store + PostgreSQL\\u00ae Apache Cassandra\\u00ae Analyze + ClickHouse\\u00ae Orchestrate + Cadence Workflow Open source + Open source AI Data infrastructure + Vector search Data streaming Data architecture Managed databases + Best practices NoSQL databases Vector databases Get a demo Try for free Free trial Sign in Platform + Left Column PlatformIntelligent, open source application data infrastructure Explore our platform Security and trustEnterprise-grade security Learn more HostingData infrastructure management in the cloud and on-prem Learn more AIPower RAG with open source data infrastructure Read more Right Column Store PostgreSQL\\u00ae Apache Cassandra\\u00ae Stream Apache Kafka\\u00ae Kafka\\u00ae Connect Orchestrate Cadence Analyze ClickHouse\\u00ae Search OpenSearch Pricing Services + Support Training Professional services About + About us Customers Our commitment to open source Resources + Getting started Sign up Documentation Quick start videos Integrations Support portal Discover Blog Events Content library Glossary Education hub Stream + Apache Kafka\\u00ae Real-time streaming Search + OpenSearch Store + PostgreSQL\\u00ae Apache Cassandra\\u00ae Analyze + ClickHouse\\u00ae Orchestrate + Cadence Workflow Open source + Open source AI Data infrastructure + Vector search Data streaming Data architecture Managed databases + Best practices NoSQL databases Vector databases Search Search Search Support Contact us Blog>Technology>OpenSearch\\u00ae 2.11 Is Now Available on the Instaclustr Managed Platform\\u202f OpenSearch\\u00ae 2.11 Is Now Available on the Instaclustr Managed Platform\\u202f January 12, 2024 | By Alex Bunday OpenSearch\\u00ae version 2.11 has now been released to the Instaclustr Managed Platform! This release brings a number of enhancements and improvements to OpenSearch. OpenSearch 2.11 resolves two vulnerabilities, CVE-2023-45807 and GHSA-8wx3-324g-w4qq. CVE-2023-45807 relates to a vulnerability found in multi-tenanted OpenSearch Dashboard deployments. GHSA-8wx3-324g-w4qq relates to an issue with how OpenSearch handled requests on the HTTP layer. You can find out more about these vulnerabilities, how we assessed them, and mitigation approaches on our security advisory blog post. One of the key highlights of this new release is the update to OpenSearch Dashboards. An entirely new user interface has been implemented, providing the same functionality but with improved usability and an updated look and feel. You can find out more about what has been changed here. Looking under the hood, this new release brings some solid enhancements. The OpenSearch Index Management Plugin now provides a unique ID to each rollup job to help with debugging, and users of the k-NN tool can flush k-NN indices out of the cache via the API. The OpenSearch Security Plugin has also been improved with added authorization in the REST layer, making queries more secure. And lastly, customers can now send OpenSearch notifications to Microsoft Teams. This latest version of OpenSearch also comes with new and experimental features that we are actively testing for future use on the Instaclustr Managed Platform. These features include the Neural Search Plugin (which turns text into vectors that can be stored and searched), and remote backed indices (which automatically creates backups of all index transactions and sends them to remote storage, providing a cost-effective solution for reducing the risk of data loss). We will have more news for you on these features in future updates. Customers of the Instaclustr Managed Platform can now begin deploying OpenSearch 2.11 on new clusters through the Console, API, or Terraform. For existing clusters, customers can contact our Support team to upgrade at [email protected]. For new customers, you can spin up an OpenSearch cluster for free through our customer console now. If you have any questions about this update or OpenSearch in general, please contact our friendly team at any time. About the author Alex Bunday | Product Manager Alex Bunday is a Product Manager with a strong focus on security and search within the Instaclustr Managed Platform, driving value through innovative solutions in the open source community. With expertise in managing product lifecycles and engaging stakeholders, Alex leverages data-driven insights to continuously improve and deliver impactful results. His collaborative approach empowers teams to develop and ship enhancements that meet customer needs and strengthen product offerings. Get the latest articles for open source In your inbox Sign up now Related content Zero Downtime Migration to Instaclustr Yes, we can migrate existing Cassandra clusters to Instaclustr without any downtime. Here's what to expect from the process... Read more Workflow Comparison: Uber Cadence vs Netflix Conductor When choosing what\\u2019s right for your company\\u2019s opensource workflow needs it is important to know the difference and similarities ... Read more Will Your Cassandra Database Project Succeed?: The New Stack Open source Apache Cassandra\\u00ae continues to stand out as an enterprise-proven solution for organizations seeking high availability... Read more \\u00d7 Sign up to our Newsletter Platform + Explore our platform Security and trust Hosting AI Stream Apache Kafka\\u00ae Kafka\\u00ae Connect Store PostgreSQL\\u00ae Apache Cassandra\\u00ae Analyze ClickHouse\\u00ae Search OpenSearch Orchestrate Cadence Column 2 Pricing + Explore our pricing Services + Support Professional services Training About + About us Customers Careers Our commitment to open source Resources + Sign up Documentation Quick start videos Integrations Support portal Blog Events Content library Glossary Stream Apache Kafka\\u00ae Store PostgreSQL\\u00ae Apache Cassandra\\u00ae Valkey\\u2122 Analyze ClickHouse\\u00ae Apache Spark\\u2122 Search OpenSearch Data infrastructure Vector search Data streaming Policies + Terms of service Security and trust Security policy Support inclusions Subscription specifications Service-level agreements Cookie settings Privacy policy Platform + Explore our platform Security and trust Hosting AI Stream Apache Kafka\\u00ae Kafka\\u00ae Connect Store PostgreSQL\\u00ae Apache Cassandra\\u00ae Analyze ClickHouse\\u00ae Search OpenSearch Orchestrate Cadence Pricing Explore our pricing Services + Support Professional services Training About + About us Customers Careers Our commitment to open source Resources + Sign up Documentation Quick start videos Integrations Support portal Blog Events Content library Glossary Stream Apache Kafka\\u00ae Store PostgreSQL\\u00ae Apache Cassandra\\u00ae Valkey\\u2122 Analyze ClickHouse\\u00ae Apache Spark\\u2122 Search OpenSearch Data infrastructure Vector search Data streaming Policies + Terms of service Security and trust Security policy Support inclusions Subscription specifications Service-level agreements Cookie settings Privacy policy \\u00a92025 NetApp Copyright. NETAPP, the NETAPP logo, Instaclustr and the marks listed at https://www.netapp.com/TM are trademarks of NetApp, Inc. Other company and product names may be trademarks of their respective owners. Apache\\u00ae, Apache Cassandra\\u00ae, Apache Kafka\\u00ae, Apache Spark\\u2122, and Apache ZooKeeper\\u2122 are trademarks of The Apache Software Foundation.\\\"},{\\\"url\\\":\\\"https://opensearch.org/blog/opensearch-performance-improvements/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to main content Search Close Search search Menu About Foundation Governing Board Charter Meeting Calendar Platform Platform OpenSearch CoreOpenSearch is a powerful search and analytics engine built on Apache Lucene. OpenSearch DashboardsOur data visualization toolset is a flexible, fully integrated solution for visually exploring and querying your data. OpenSearch Data PrepperA server-side data collector designed to enrich, transform, and aggregate data for downstream analytics with Opensearch. OpenSearch Vector EnginePower machine learning and generative AI applications with a high-performance database designed for the way AI understands data. Capabilities Machine learning and AI Vector Search Anomaly Detection Search E-Commerce Document Search Search Relevance Observability Performance Monitoring Log Analysis Security Analytics Threat Intelligence Event Correlation Performance Benchmarks View key performance metrics across different workloads View Data Roadmap Image OpenSearch Project RoadmapExplore our official project roadmap on GitHub Community OpenSearch Community ForumFind answers to your questions, help others in the community, and join the conversation. EventsCommunity Meetings, Development Backlog & Triage, in-person, and virtual events. AmbassadorsAmbassadors Community leaders who share knowledge and grow OpenSearch. Solutions ProvidersFind open-source providers offering solutions and services. ProjectsHighlights of projects built by the community. User GroupsJoin the OpenSearch Project Meetup Network Community Resources SlackSpeak with other developers. GitHub Project OrganizationJoin us for in-person and virtual events to learn the latest about the project. OpenSearchCon Image OpenSearchCon North AmericaSeptember 8-10, 2025 | San Jose, CA OpenSearchCon India3-4 June 2025 | Bengaluru, India OpenSearchCon Korea2025 November 4 | Seoul, South Korea OpenSearchCon EuropeView Videos & Slides Documentation Documentation Library OpenSearch and DashboardsBuild your OpenSearch solution using core tooling and visualizations. OpenSearch Data PrepperFilter, mutate, and sample your data for ingestion into OpenSearch. Migration AssistantBegin your transition to OpenSearch with our migration toolkit Documentation Library II OpenSearch BenchmarkMeasure performance metrics for your OpenSearch cluster. ClientsInteract with OpenSearch from your application using language APIs. Blog & News Blog Announcements Case Studies News Authors Downloads search Blog An update on the OpenSearch Project\\u2019s continued performance progress through version 2.11 By Saurabh Singh, Pallavi Priyadarshini, Dagney Braun, Rishabh SinghJanuary 10, 2024June 18th, 2025No Comments OpenSearch is a community-driven, open-source search and analytics suite used by developers to ingest, search, visualize, and analyze data. Introduced in January 2021, the OpenSearch Project originated as an open-source fork of Elasticsearch 7.10.2. OpenSearch 1.0 was released for production use in July 2021 and is licensed under the Apache License, Version 2.0 (ALv2), with the complete codebase published to GitHub. The project has consistently focused on improving the performance of its core open-source engine for high-volume indexing and low-latency search operations. OpenSearch aims to provide the best experience for every user by reducing latency and improving efficiency. In this blog post, we\\u2019ll share a comprehensive view of strategic enhancements and performance features that OpenSearch has delivered to date. Additionally, we\\u2019ll provide a look forward at the Performance Roadmap. We\\u2019ll compare the core engine performance of the latest OpenSearch version (OpenSearch 2.11) to the state just before the OpenSearch fork, with a specific focus on the advancements made since then. With this goal in mind, we have chosen Elasticsearch 7.10.2 to represent the baseline from which OpenSearch was forked, allowing us to measure all changes that have been delivered after the fork (in OpenSearch 1.0\\u20132.11). These improvements were made in collaboration with the community; thus, the OpenSearch Project is actively seeking to enhance community engagement, specifically in the area of performance improvement. Performance improvements to date OpenSearch performance improvements can be categorized into three high-level buckets: Indexing performance Query performance Storage The following image summarizes OpenSearch performance improvements since launch. Log analytics workloads are typically indexing heavy, often relying on specific resource-intensive queries. In contrast, search workloads have a more balanced distribution between indexing and query operations. Based on the analysis we\\u2019ll detail below comparing Elasticsearch 7.10.2 to OpenSearch 2.11, we have seen a 25% improvement in indexing throughput, a 15\\u201398% decrease in query latencies among some of the most popular query types, and, now with Zstandard compression, a 15\\u201330% reduction in on-disk data size. Indexing performance investments Some of the key OpenSearch features launched this year delivered efficiency improvements in indexing performance. OpenSearch rearchitected the way indexing operations are performed in order to deliver segment replication\\u2014a physical replication method that replicates index segments rather than source documents. Segment replication, a new replication strategy built on Lucene\\u2019s Near-Real-Time (NRT) Segment Index Replication API, was released as generally available in OpenSearch 2.7. Segment replication showed increased ingestion rate throughput of up to 25% when compared to default document replication. You can find a more detailed look at segment replication in this blog post. In version 2.10, OpenSearch introduced remote-backed storage, allowing users to directly write segments to object storage, such as Amazon Simple Storage Service (Amazon S3) or Oracle Cloud Infrastructure (OCI) Object Storage, to improve data durability. With remote-backed storage, in addition to storing data on a local disk, all the ingested data is stored in the configured remote store. At every refresh, the remote store also automatically becomes a point-in-time recovery point, helping users achieve a recovery point objective (RPO) of zero with the same durability properties of the configured remote store. To learn more, see this blog post. Query performance investments OpenSearch supports an extensive array of query types for different use cases, from comprehensive search capabilities to a broad spectrum of aggregations, filtering options, and sorting functionalities. One of the major query performance areas in which OpenSearch has improved is in helping vector queries perform at scale, given the rise in vector search popularity. OpenSearch\\u2019s vector engine offers fast, billion-scale vector searches with efficient latency and recall. Recent additions like scalar and product quantization reduced the cluster memory footprint by up to 80%. The incorporation of native libraries (nmslib and faiss) and HNSW with SIMD instructions has expedited vector indexing and search queries. At a large scale, tested with billions of documents, OpenSearch delivered a roughly 30% lower latency compared to Lucene ANN searches. For more information, see this partner highlight. We\\u2019ve also continued to invest broadly in core query performance for popular query types used for log analytics, time-series data, and search. OpenSearch has demonstrated significant improvement since the fork from Elasticsearch 7.10.2 for many query types. The benchmarking we performed showed a 15%\\u201398% increase in performance across popular query operations such as match all, range queries, aggregation queries, and full-text queries. You can review key benchmarking findings in the following sections. Storage investments Storage is another major factor that affects the overall efficiency of log analytics and search workloads. In OpenSearch 2.9 and later, customers can use Zstandard compression, resulting in a 30% reduction in on-disk data size while maintaining a near-identical CPU utilization pattern compared to the default compression. Some of the ongoing work, such as the addition of a match_only_text field (see #11039), has shown a promising reduction of about 25% in data on disk, primarily with text data field optimization, and should be available to users in the upcoming OpenSearch 2.12 release. Measured performance improvements To compare performance between Elasticsearch 7.10.2 and OpenSearch 2.11, we ran query operations for widely used scenarios in log analytics, time series, and search. We ran the queries across clusters running each version and documented the resulting performance. The following subsections provide the key findings from this exercise. Log analytics For log analytics use cases, we used the http_logs workload from OpenSearch Benchmark\\u2014a macro-benchmark utility within the OpenSearch Project\\u2014to replicate some of the common query operations. Here are the key highlights: match_all queries with sorting showed a more than 20x performance boost across the board because of multiple improvements made in the area (see #6321 and #7244) and other Lucene enhancements. Queries for ascending and descending sort-after-timestamp saw a significant performance improvement of up to 70x overall. The optimizations introduced (such as #6424 and #8167) extend across various numeric types, including int, short, float, double, date, and others. Other popular queries, such as search_after, saw about a 60x reduction in latency, attributed to the improvements made in the area involving optimally skipping segments during search (see #7453). The search_after queries can be used as the recommended alternative to scroll queries for a better search experience. Implementation support for match_only_text field optimization on storage and indexing/search latency for text queries is in progress (see #11039). Time series In the context of aggregations over range and time-series data, we used the nyc_taxis and http_logs workloads from OpenSearch Benchmark to benchmark various popular use cases. Here are the key highlights: Range queries, popular for aggregation use cases, exhibited about a 50%\\u201375% improvement, attributed to system upgrades such as Lucene (from v8.8 in Elasticsearch 7.10.2 to v9.7 in OpenSearch 2.11) and JDK (from JDK15 in Elasticsearch 7.10.2 to JDK17 in OpenSearch 2.11). Hourly aggregations and multi-term aggregations also demonstrated improvement, varying from 5% to 35%, attributed to the time-series improvements discussed previously. date_histograms and date_histogram_agg queries exhibited either comparable or slightly decreased performance, ranging from 5% to around 20% in multi-node environments. These issues are actively being addressed as part of ongoing project efforts (see #11083). For date histogram aggregations, there are upcoming changes aiming to improve performance by rounding down dates to the nearest interval (such as year, quarter, month, week, or day) using SIMD (see #11194). Search In the realm of text queries, we used pmc workloads from OpenSearch Benchmark to emulate various common use cases. Here are the noteworthy highlights: Phrase and term queries for text search showed improved latency, with a 25% to 65% reduction, underscoring their improved effectiveness. Popular queries related to scrolling exhibited about 15% lower latency, further improving the overall user experience. Additional optional performance-enhancing features available in version 2.11 The core engine optimizations discussed in the previous sections are available by default. Additionally, OpenSearch 2.11 includes a few key performance-enhancing features that can be optionally enabled by users. These features were not available in prior versions, so we separately benchmarked performance with those features individually enabled, resulting in the following findings: LogByteSize merge policy: Showed a 40\\u201370% improvement in ascending and descending sort queries, which is advantageous for time-series data with timestamp sorting and minimal timestamp overlap between segments. Zstandard compression: This addition empowers OpenSearch users with the new Zstandard compression codecs for their data, resulting in a 30% reduction in on-disk data size while maintaining a near-identical CPU utilization pattern compared to the default compression. Concurrent segment search: Enabling every shard-level request to concurrently search across segments during the query phase resulted in latency reduction across multiple query types. Aggregate queries showed a 50%\\u201370% improvement, range queries showed a 65% improvement, and aggregation queries with hourly data aggregations showed a 50% improvement. Future roadmap The OpenSearch Project remains steadfast in its commitment to continuously improving the core engine performance in search, ingestion, and storage operations. The OpenSearch Project roadmap on GitHub is constantly evolving, and we are excited to share it with you. This roadmap places a special emphasis on the core engine advancements while also encompassing critical areas like benchmarking and query visibility. As part of our ongoing commitment, we plan to consistently update this roadmap with both short- and long-term improvement plans. We\\u2019re keeping performance excellence at the forefront of our investments, and OpenSearch users can anticipate a series of impactful improvements in new releases in 2024, starting with OpenSearch 2.12. In the upcoming releases, we will continue to improve the core engine by targeting specific query types. We will also undertake broad strategic initiatives to further enhance the core engine through Protobuf integration, query rewrites, tiered caching, and SIMD and RUST implementations. In addition to improving the core engine, we are committed to improving OpenSearch tooling capabilities. One such improvement that we\\u2019re currently working on is the query insights functionality, which helps identify the top N queries that impact performance. Additionally, OpenSearch is working on making benchmarks easier for community members to use. For a comprehensive list of investments and additional improvements, or to provide feedback, please check out the OpenSearch Performance Roadmap on GitHub. This concludes the main summary of OpenSearch performance improvements to date. The following appendix sections provide the benchmarking details for readers interested in replicating any run. Appendix: Detailed execution and results If you\\u2019re interested in the details of the performance benchmarks we used, exploring the methodologies behind their execution, or examining the comprehensive results, keep reading. For OpenSearch users interested in establishing benchmarks and replicating these runs, we\\u2019ve provided comprehensive setup details alongside each result. This section provides the core engine performance comparison between the latest OpenSearch version (OpenSearch 2.11) and the state just before the OpenSearch fork, Elasticsearch 7.10.2, with a mid-point performance measurement on OpenSearch 2.3. OpenSearch Benchmark and workloads OpenSearch Benchmark serves as a macro-benchmark utility within the OpenSearch Project. With the help of this tool, OpenSearch users and developers can generate and visualize performance metrics from an OpenSearch cluster for various purposes, including: Monitoring the overall performance of an OpenSearch cluster. Evaluating the benefits of and making decisions about upgrading the cluster to a new version. Assessing the potential impact on the cluster resulting from changes to the workflows, such as modifications to the index mappings or changes in queries. The OpenSearch Benchmark workloads are comprised of one or multiple benchmarking scenarios. A workload typically includes the ingestion of one or more data corpora into indexes and a collection of queries and operations that are executed as a part of the benchmark. We used the following workloads for performance evaluation, encompassing aspects such as text/term queries, sorting, aggregations, histograms, and ranges: HTTP logs workload: This workload is based on web server logs from the 1998 Football World Cup. It is used for evaluating the performance of (web) server logs, which is most in line with the OpenSearch log analytics use case. NYC taxis workload: This workload contains the rides taken in yellow taxis in New York in 2015. It is used for evaluating the performance of highly structured data. It is useful for aggregation and date histogram use cases for time-series data. PMC workload: This workload contains data retrieved from PubMed Central (PMC). It is used for evaluating the performance of full-text search, in line with the OpenSearch search use case. The configurations specific to the setup for each evaluation are provided along with the results in the following sections. Comparative baseline analysis: Elasticsearch 7.10.2 vs. OpenSearch 2.3 vs. OpenSearch 2.11 We compared the performance of Elasticsearch 7.10.2 (pre-fork), OpenSearch 2.3 (an interim release), and OpenSearch 2.11 (latest version at the time of testing). This analysis covers three workloads (http-logs, nyc-taxis, and pmc) used to assess performance across different use cases. The goal is to provide comparable core engine performance metrics since the Elasticsearch 7.10.2 fork. The benchmarks in the following sections show averages from 7 days of data, generated during nightly runs using OpenSearch Benchmark, intentionally excluding outliers. In the detailed results section, each table contains a percentage improvement column. This column emphasizes the improvements to OpenSearch 2.11 over the previous releases, with positive values indicating improvement and negative values indicating regression. Detailed results: Elasticsearch 7.10.2 vs. OpenSearch 2.3 vs. OpenSearch 2.11\\u2014deep dive into single-shard performance Objective: To eliminate variables introduced at the coordination level and concentrate on data node query performance. Setup: 1 data node (r5.xlarge) with 32 GB RAM and 16 GB heap. Index settings: 1 shard and 0 replicas. http_logs workload results: The following table provides a benchmark comparison for the http_logs workload between Elasticsearch 7.10.2, OpenSearch 2.3, and OpenSearch 2.11. It includes the 90th percentile of took time latency measurements for each (p90) and the observed percentage improvements. Operations ES 7.10.2 (p90_value) OS 2.3.0 (p90_value) OS 2.11.0 (p90_value) OS 2.11.0 improvement (vs. OS 2.3.0) OS 2.11.0 improvement (vs. ES 7.10.2) 200s-in-range 13 5 5.33 -7% 59% 400s-in-range 2.73 2 2.53 -26% 7% asc_sort_size 4,262.2 4,471 4.6 100% 100% asc_sort_timestamp 10.73 785 6.47 99% 40% asc_sort_with_after_timestamp 4,576 5,368 34.47 99% 99% default 2.91 3 3 0% -3% desc_sort_size 3,800.4 3,994 9.53 100% 100% desc_sort_timestamp 39.18 5,228 58.8 99% -50% desc_sort_with_after_timestamp 5,824.27 6,925 87.8 99% 98% hourly_agg 9,387.55 9,640 9,112.4 5% 3% multi_term_agg N/A 14,703 9,669.8 34% N/A range 28.18 12 13.4 -12% 52% scroll 213.91 173 197.4 -14% 8% term 3.45 3 3.4 -13% 1% nyc_taxis workload results: The following table provides a benchmark comparison for the nyc_taxis workload between Elasticsearch 7.10.2, OpenSearch 2.3, and OpenSearch 2.11. It includes the 90th percentile of took time latency measurements for each (p90) and the observed percentage improvements. Operations ES 7.10.2 (p90_value) OS 2.3.0 (p90_value) OS 2.11.0 (p90_value) OS 2.11.0 improvement (vs. OS 2.3.0) OS 2.11.0 improvement (vs. ES 7.10.2) autohisto_agg 559.13 596 554.6 7% 1% date_histogram_agg 562.4 584 545.07 7% 3% default 4.73 6 5.07 15% -7% distance_amount_agg 13181 12796 15285 -19% -16% range 654.67 213 213.4 0% 67% pmc workload results: The following table provides a benchmark comparison for the pmc workload between Elasticsearch 7.10.2, OpenSearch 2.3, and OpenSearch 2.11. It includes the 90th percentile of took time latency measurements for each (p90) and the observed percentage improvements. Operations ES 7.10.2 (p90_value) OS 2.3.0 (p90_value) OS 2.11.0 (p90_value) OS 2.11.0 improvement (vs. OS 2.3.0) OS 2.11.0 improvement (vs. ES 7.10.2) articles_monthly_agg_cached 2 2 2.4 -20% -20% articles_monthly_agg_uncached 26.5 27 27.8 -3% -5% default 6.5 6 5.2 13% 20% phrase 8.25 6 6.4 -7% 22% scroll 894.5 857 753.8 12% 16% term 9 5 5.6 -12% 38% Detailed results: Elasticsearch 7.10.2 vs. OpenSearch 2.3 vs. OpenSearch 2.11\\u2014deep dive into multiple-shard performance Objective: To introduce the coordination layer with parallel search operations extending across multiple nodes with primary shards. Setup: 3 data nodes (r5.xlarge) with 32 GB RAM and 16 GB heap. 3 cluster manager nodes (c5.xlarge) with 8 GB RAM and 4 GB heap. Index settings: 3 shards and 0 replicas. http_logs workload results: The following table provides a benchmark comparison for the http_logs workload between Elasticsearch 7.10.2, OpenSearch 2.3, and OpenSearch 2.11. It includes the 90th percentile of took time latency measurements for each (p90) and the observed percentage improvements. Operations ES 7.10.2 (p90_value) OS 2.3.0 (p90_value) OS 2.11.0 (p90_value) OS 2.11.0 improvement (vs. OS 2.3.0) OS 2.11.0 Improvement (vs. ES 7.10.2) 200s-in-range 9.8 6 6.85 -14% 30% 400s-in-range 5.8 5 5.5 -10% 5% asc_sort_size 1,451.13 1,602 8.35 99% 99% asc_sort_timestamp 10.4 291.5 10.58 96% -2% asc_sort_with_after_timestamp 1,488.25 1,910.5 25.38 99% 98% default 6 6 6.3 -5% -5% desc_sort_size 1,281.3 1,431 13.91 99% 99% desc_sort_timestamp 34.4 1,878.5 91.9 95% -167% desc_sort_with_after_timestamp 1,887.7 2,480 85.78 97% 95% hourly_agg 2,566.9 3,115 2,937 6% -14% multi_term_agg N/A 5205 3603 31% N/A range 18.1 9 8.95 1% 51% scroll 340.1 267 323.85 -21% 5% term 5.8 6 6.45 -8% -11% nyc_taxis workload results: The following table provides a benchmark comparison for the nyc_taxis workload between Elasticsearch 7.10.2, OpenSearch 2.3, and OpenSearch 2.11. It includes the 90th percentile of took time latency measurements for each (p90) and the observed percentage improvements. Operations ES 7.10.2 (p90_value) OS 2.3.0 (p90_value) OS 2.11.0 (p90_value) OS 2.11.0 Improvement (vs. OS 2.3.0) OS 2.11.0 Improvement (vs. ES 7.10.2) autohisto_agg 208.92 217 212.93 2% -2% date_histogram_agg 198.77 218 209.4 4% -5% default 8.46 7 9.67 -38% -14% distance_amount_agg 4,131 4,696 5,067.4 -8% -23% range 281.62 73 79.53 -9% 72% pmc workload results: The following table provides a benchmark comparison for the pmc workload between Elasticsearch 7.10.2, OpenSearch 2.3, and OpenSearch 2.11. It includes the 90th percentile of took time latency measurements for each (p90) and the observed percentage improvements. Operations ES 7.10.2 (p90_value) OS 2.3.0 (p90_value) OS 2.11.0 (p90_value) OS 2.11.0 improvement (vs. OS 2.3.0) OS 2.11.0 improvement (vs. ES 7.10.2) articles_monthly_agg_cached 3.55 3 3.71 -24% -5% articles_monthly_agg_uncached 12 12 12.43 -4% -4% default 9 6 6.79 -13% 25% phrase 8.18 7 7.14 -2% 13% scroll 755.18 593 642.79 -8% 15% term 9 7 7.14 -2% 21% Elevating performance with new features available in OpenSearch 2.11 The following sections present OpenSearch 2.11 features that improve performance. LogByteSize merge policy In the realm of log analytics, the Tiered merge policy has been a cornerstone of efficient shard merges. In OpenSearch 2.11 we introduced the LogByteSize merge policy. This new approach consistently merges adjacent segments, proving especially advantageous for time-series data characterized by timestamp sorting and minimal timestamp overlap between segments. The following are the key findings from this exercise. Timestamp queries with ascending sort had an improvement of over 75%. This transformation is attributable to the impactful contribution of enhancement #9241. About a 40% enhancement in descending sort timestamp queries, surpassing the Tiered merge policy. Use cases around ascending and descending sort with an after timestamp saw regression, which is a known case for smaller workloads with this merge policy. Other common use cases for log analytics, such as multi-term aggregation, hourly_agg, range, and scroll queries exhibited comparable performance, with a subtle improvement of less than 5% attributed to the new segment merge policy. Detailed results: OS 2.11 Tiered merge policy vs OS 2.11 LogByteSize merge policy Setup: 3 data nodes (r5.xlarge) with 32 GB RAM and 16 GB heap. 3 cluster manager nodes (c5.xlarge) with 8 GB RAM and 4 GB heap. Index settings: 3 shards and 0 replicas, max_segment_size: 500 MB, refresh_interval: 1 s. http_logs workload results: The following table provides a benchmark comparison for the http_logs workload for OpenSearch 2.11 with the Tiered merge policy vs. the LogByteSize merge policy. It includes the 90th percentile of took time latency measurements for each (p90) and the observed percentage improvements. Operations OS 2.11\\u2014Tiered (p90_value) OS 2.11\\u2014LogByteSize (p90_value) % improvement (vs. Tiered merge policy) 200s-in-range 6 6 0% 400s-in-range 5 6 -20% asc_sort_size 9 8 11% asc_sort_timestamp 34 8 76% asc_sort_with_after_timestamp 13 68 -423% default 7 6 14% desc_sort_size 11 10 9% desc_sort_timestamp 29 17 41% desc_sort_with_after_timestamp 35 130 -271% hourly_agg 2816 2809 0% multi_term_agg 2739 2800 -2% range 7 8 -14% scroll 349 344 1% term 7 6 14% Zstandard codec compression This addition empowers OpenSearch users with the new Zstandard compression codecs for their data. Users can specify zstd or zstd_no_dict in the index.codec setting during index creation or modify the codecs for existing indexes. OpenSearch will continue to support the existing zlib and lz4 codecs, with the default as lz4. The following sections contain benchmarking results representing the average of 5 days of data from nightly runs using OpenSearch Benchmark. Highlights Here are the key highlights: A notable increase in the ingestion throughput, ranging from 5% to 8%, attributed to the new zstd codec. This enhancement owes its success to codec-related pull requests (#7908, #7805, and #7555). About a 30% reduction in on-disk data size, surpassing the default lz4 codec for unparalleled efficiency, all while maintaining a near-identical CPU utilization pattern compared to the default compression. The search p90 latencies remained virtually unchanged, with negligible differences of less than 2% in a few areas. Detailed results: OpenSearch 2.11 default (lz4) compression vs. OpenSearch 2.11 zstd compression using multiple shards Setup: 3 data nodes (r5.xlarge) with 32 GB RAM and 16 GB heap. 3 cluster manager nodes (c5.xlarge) with 8 GB RAM and 4 G heap. Index settings: 3 shards and 0 replicas. Indexing throughput results (docs/sec): The following table provides an indexing throughput comparison of the http_logs and nyc_taxis workloads for OpenSearch 2.11 with the default codec vs. the zstd codec enabled and includes the percentage improvement observed when using zstd. Workload OS 2.11\\u2014default codec (mean_value) OS 2.11\\u2014zstd codec (mean_value) % improvement (vs. default codec) http_logs 209,959.75 220,948 5% nyc_taxis 118,123.5 127,131 8% nyc_taxis search workload results: The following table illustrates a benchmark comparison for the nyc_taxis workload for OpenSearch 2.11 with default codec vs. zstd codec enabled, including percentage improvement. Operations OS 2.11\\u2014default codec (p90_value) OS 2.11\\u2014zstd codec (p90_value) % improvement (vs. default codec) autohisto_agg 216.75 208 4% date_histogram_agg 211.25 205.5 3% default 8 7.5 6% distance_amount_agg 5,012 4,980 1% range 74.5 77.5 -4% Detailed results: Index data size on disk (bytes) with zstd compression using a single shard Setup: OpenSearch 2.11.0, single node (r5.xlarge) with 32 GB RAM and 16 GB heap. Index settings: 1 shard and 0 replicas. Data size of disk results (bytes): The following table illustrates a benchmark comparison of the on-disk data size for the http_logs and pmc workloads for OpenSearch 2.11 with default vs. zstd codec enabled, including percentage improvement. Default compression (bytes) ZSTD (bytes) ZSTD_NO_DICT (bytes) ZSTD improvement (vs. default codec) ZSTD_NO_DICT improvement (vs. default codec) http_logs 20,056,770,878.5 15,800,734,037 16,203,187,551 21% 19% pmc 20,701,211,614.5 15,608,881,718.5 15,822,040,185 25% 24% Concurrent search improvements (Experimental in 2.11) OpenSearch users can now achieve better execution speed with concurrent segment search, launched as experimental in OpenSearch 2.11. By default, OpenSearch processes a request sequentially across all the data segments on each shard during the query phase of a search request execution. With concurrent search, every shard-level request can concurrently search across segments during the query phase. Each shard divides its segments into multiple slices, where each slice serves as a unit of work executed in parallel on a separate thread. Therefore, the slice count governs the maximum degree of parallelism for a shard-level request. After all the slices finish their tasks, OpenSearch executes a reduce operation on the slices, merging them to generate the final result for the shard-level request. The following benchmarking results show the benefits of concurrent search in action. These are the averages of data generated from over 4 days of nightly runs using OpenSearch Benchmark. Highlights Here are the key highlights: An increase in performance with aggregate queries on workloads such as the nyc_taxis workload, showcasing an improvement ranging between 50% and 70% over the default configuration. The log analytics use cases for range queries demonstrated an improvement of around 65%. Aggregation queries with hourly data aggregations, such as those for the http_logs workload, demonstrated a boost of up to 50% in performance. Comparable latencies for auto or date histogram queries, with no noteworthy improvement or regression in performance. multi_term_agg, asc_sort_size, dec_sort_size, and scroll queries showed regression. To delve deeper into the intricacies, the concurrent search contributors are proactively addressing this in the upcoming OpenSearch 2.12 GA release. Detailed results: OpenSearch 2.11 with concurrent search enabled vs. disabled Setup: OpenSearch 2.11.0 single node (r5.2xlarge) with 64 GB RAM and 32 GB heap. Index settings: 1 shard and 0 replicas. nyc_taxis workload results: The following table provides a benchmark comparison of the nyc_taxis workload for OpenSearch 2.11 with concurrent search disabled and enabled (with 0 slices and with 4 slices). It includes the 90th percentile of took time latency measurements for each (p90) and the observed percentage improvements. Operations CS disabled (p90_value) CS enabled\\u20140-slice (p90_value) CS enabled\\u20144-slice (p90_value) % improvement (with 0 slices) % improvement (with 4 slices) autohisto_agg 575 295 287 49% 50% date_histogram_agg 563 292 288 48% 49% default 6 6 5 0% 17% distance_amount_agg 15,043 4,691 4744 69% 68% range 201 73 77 64% 62% http_logs workload results: The following table provides a benchmark comparison of the http_logs workload for OpenSearch 2.11 with concurrent search disabled and enabled (with 0 slices and with 4 slices). It includes the 90th percentile of latency measurements for each (p90) and the observed percentage improvements. Operations CS disabled (p90_value) CS enabled\\u20140-slice (p90_value) CS enabled\\u20144-slice (p90_value) % improvement (with 0 slices) % improvement (with 4 slices) 200s-in-range 6 4 4 33% 33% 400s-in-range 2 2 2 0% 0% asc-sort-timestamp-after-force-merge-1-seg 20 20 22 0% -10% asc-sort-with-after-timestamp-after-force-merge-1-seg 85 86 86 -1% -1% asc_sort_size 3 5 5 -67% -67% asc_sort_timestamp 4 4 4 0% 0% asc_sort_with_after_timestamp 34 33 34 3% 0% default 4 4 3 0% 25% desc-sort-timestamp-after-force-merge-1-seg 64 62 67 3% -5% desc-sort-with-after-timestamp-after-force-merge-1-seg 67 66 68 1% -1% desc_sort_size 6 91 9 -1417% -50% desc_sort_timestamp 26 34 28 -31% -8% desc_sort_with_after_timestamp 63 61 63 3% 0% hourly_agg 8180 3832 4034 53% 51% multi_term_agg 9818 40015 54107 -308% -451% range 15 12 13 20% 13% scroll 179 375 212 -109% -18% term 3 3 3 0% 0% We would like to take this opportunity to thank the OpenSearch core developers for their contributions to the technical roadmap. We sincerely appreciate all the suggestions from Michael Froh, Andriy Redko, Jonah Kowall, Amitai Stern, Jon Handler, Prabhakar Sithanandam, Mike McCandless, Anandhi Bumstead, Eli Fisher, Carl Meadows, and Mukul Karnik in writing this blog post. Credits to Fanit Kolchina and Nathan Bower for editing and Carlos Canas for creating the graphics. Authors Saurabh Singh Saurabh is a Software Development Manager at AWS leading the core search, release, and benchmarking areas of the OpenSearch Project. His passion lies in finding solutions for intricate challenges within large-scale distributed systems. View all posts Pallavi Priyadarshini Pallavi Priyadarshini is a Senior Engineering Manager at the OpenSearch Project leading the development of high-performing and scalable technologies for search, security, releases, and dashboards. View all posts Dagney Braun Dagney Braun is a Principal Product Manager at AWS working on the OpenSearch Project. View all posts Rishabh Singh Rishabh Singh is a Systems Development Engineer at AWS working on the OpenSearch Project. He is passionate about infrastructure automation, platform development, and improving the developer experience. View all posts Share Subscribe for updates, event info, and the latest community news OpenSearch is a community-driven, Apache 2.0-licensed open source search and analytics suite that makes it easy to ingest, search, visualize, and analyze data. linkedin github slack youtube mastodon bluesky x-twitter Participate Code of Conduct Forum Project Repo Community Repo Meetup Connect Providers Become a Provider Find a Provider Resources About FAQ Release Schedule Maintenance Policy Documentation Getting Started Testimonials Trademark & Brand Privacy \\u00a9 Copyright The Linux Foundation. The OpenSearch Project is a project of The Linux Foundation. For web site terms of use, trademark policy and other policies applicable to The OpenSearch Project please see Linux Foundation Policies. The OpenSearch Project supports the OpenSearch open source project, which has been established as OpenSearch Project a Series of LF Projects, LLC. For policies applicable to the OpenSearch Project a Series of LF Projects, LLC, please see LF Projects, LLC Policies, Privacy Policy, Terms of Use and the OpenSearch Trademark Policy. Close Menu About Foundation Governing Board Charter Meeting Calendar Platform Platform OpenSearch CoreOpenSearch is a powerful search and analytics engine built on Apache Lucene. OpenSearch DashboardsOur data visualization toolset is a flexible, fully integrated solution for visually exploring and querying your data. OpenSearch Data PrepperA server-side data collector designed to enrich, transform, and aggregate data for downstream analytics with Opensearch. OpenSearch Vector EnginePower machine learning and generative AI applications with a high-performance database designed for the way AI understands data. Capabilities Machine learning and AI Vector Search Anomaly Detection Search E-Commerce Document Search Search Relevance Observability Performance Monitoring Log Analysis Security Analytics Threat Intelligence Event Correlation Performance Benchmarks View key performance metrics across different workloads View Data Roadmap Image OpenSearch Project RoadmapExplore our official project roadmap on GitHub Community OpenSearch Community ForumFind answers to your questions, help others in the community, and join the conversation. EventsCommunity Meetings, Development Backlog & Triage, in-person, and virtual events. AmbassadorsAmbassadors Community leaders who share knowledge and grow OpenSearch. Solutions ProvidersFind open-source providers offering solutions and services. ProjectsHighlights of projects built by the community. User GroupsJoin the OpenSearch Project Meetup Network Community Resources SlackSpeak with other developers. GitHub Project OrganizationJoin us for in-person and virtual events to learn the latest about the project. OpenSearchCon Image OpenSearchCon North AmericaSeptember 8-10, 2025 | San Jose, CA OpenSearchCon India3-4 June 2025 | Bengaluru, India OpenSearchCon Korea2025 November 4 | Seoul, South Korea OpenSearchCon EuropeView Videos & Slides Documentation Documentation Library OpenSearch and DashboardsBuild your OpenSearch solution using core tooling and visualizations. OpenSearch Data PrepperFilter, mutate, and sample your data for ingestion into OpenSearch. Migration AssistantBegin your transition to OpenSearch with our migration toolkit Documentation Library II OpenSearch BenchmarkMeasure performance metrics for your OpenSearch cluster. ClientsInteract with OpenSearch from your application using language APIs. Blog & News Blog Announcements Case Studies News Authors Downloads\\\"},{\\\"url\\\":\\\"https://docs.oracle.com/en-us/iaas/releasenotes/changes/69cff0e5-0db2-4f97-83d9-809559f0f141/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Oracle Cloud Infrastructure Documentation / Release Notes All Pages Skip to main content Search with OpenSearch now supports OpenSearch version 2.11 Services: Oracle Cloud Infrastructure Government Cloud, Search with OpenSearch Release Date: March 13, 2024 OCI Search with OpenSearch now supports OpenSearch version 2.11. The upgrade to OpenSearch version 2.11 comes with several improvements, including: Semantic search with custom models. Conversational search with external connectors to OCI Generative AI-hosted LLM models. Inline upgrade for minor version upgrades. Support for additional plugins, including reporting, query workbench, enhanced table. New clusters are created by default as OpenSearch 2.11 clusters. Existing clusters will still use previous version of OpenSearch, however you can upgrade them to version 2.11 using one of the following approaches: For OpenSearch 2.3 clusters, see Performing a Minor Build Version Upgrade for an OpenSearch Cluster For OpenSearch 1.2.4 clusters, see Upgrading an OpenSearch Cluster For more information: Search Service with OpenSearch OpenSearch Search with OpenSearch documentation Copyright \\u00a9 2025, Oracle and/or its affiliates. About Oracle Contact Us Legal Notices Terms of Use & Privacy Document Conventions\\\"}]}\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "üì∞ Current Information:\n",
      "{\n",
      "  \"inference_results\": [\n",
      "    {\n",
      "      \"output\": [\n",
      "        {\n",
      "          \"name\": \"response\",\n",
      "          \"result\": \"{\\\"next_page\\\":\\\"https://duckduckgo.com/html?q=Latest+features+in+OpenSearch+2.11&s=10&nextParams=&v=l&o=json&dc=11&api=d.js&vqd=4-231681247467792853657446391222187685099&kl=wt-wt\\\",\\\"items\\\":[{\\\"url\\\":\\\"https://opensearch.org/blog/get-started-opensearch-2-11/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to main content Search Close Search search Menu About Foundation Governing Board Charter Meeting Calendar Platform Platform OpenSearch CoreOpenSearch is a powerful search and analytics engine built on Apache Lucene. OpenSearch DashboardsOur data visualization toolset is a flexible, fully integrated solution for visually exploring and querying your data. OpenSearch Data PrepperA server-side data collector designed to enrich, transform, and aggregate data for downstream analytics with Opensearch. OpenSearch Vector EnginePower machine learning and generative AI applications with a high-performance database designed for the way AI understands data. Capabilities Machine learning and AI Vector Search Anomaly Detection Search E-Commerce Document Search Search Relevance Observability Performance Monitoring Log Analysis Security Analytics Threat Intelligence Event Correlation Performance Benchmarks View key performance metrics across different workloads View Data Roadmap Image OpenSearch Project RoadmapExplore our official project roadmap on GitHub Community OpenSearch Community ForumFind answers to your questions, help others in the community, and join the conversation. EventsCommunity Meetings, Development Backlog & Triage, in-person, and virtual events. AmbassadorsAmbassadors Community leaders who share knowledge and grow OpenSearch. Solutions ProvidersFind open-source providers offering solutions and services. ProjectsHighlights of projects built by the community. User GroupsJoin the OpenSearch Project Meetup Network Community Resources SlackSpeak with other developers. GitHub Project OrganizationJoin us for in-person and virtual events to learn the latest about the project. OpenSearchCon Image OpenSearchCon North AmericaSeptember 8-10, 2025 | San Jose, CA OpenSearchCon India3-4 June 2025 | Bengaluru, India OpenSearchCon Korea2025 November 4 | Seoul, South Korea OpenSearchCon EuropeView Videos & Slides Documentation Documentation Library OpenSearch and DashboardsBuild your OpenSearch solution using core tooling and visualizations. OpenSearch Data PrepperFilter, mutate, and sample your data for ingestion into OpenSearch. Migration AssistantBegin your transition to OpenSearch with our migration toolkit Documentation Library II OpenSearch BenchmarkMeasure performance metrics for your OpenSearch cluster. ClientsInteract with OpenSearch from your application using language APIs. Blog & News Blog Announcements Case Studies News Authors Downloads search Blog Get started with OpenSearch 2.11 By James McIntyreOctober 16, 2023June 18th, 2025No Comments OpenSearch 2.11 is now available, with exciting new capabilities for observability applications, an expanded selection of search tools, enhancements to data durability, and more, along with new experimental functionality to explore. For a complete view of what\\u2019s new in this release, see the release notes, and you can give OpenSearch Dashboards a try on OpenSearch Playground. An easier way to infuse multimodal search into your applications This release introduces text and image multimodal search using neural search. This functionality allows users to search image and text pairs, like product catalog items (product image and description), based on visual and semantic similarity. This enables new search experiences that can deliver more relevant results. For instance, users can search for \\u201cwhite blouse\\u201d to retrieve product images\\u2014the machine learning (ML) model that powers this experience is able to associate semantics and visual characteristics. Users can also search by image to retrieve visually similar products or search by both text and image to find the products most similar to a particular product catalog item. You can now build these capabilities into your application to connect directly to multimodal models and run multimodal search queries without having to build custom middleware. See the multimodal search documentation for guidance on how to get started with multimodal semantic search, and look out for more input types to be added to this functionality in future releases. Choose the best retrieval method for semantic search applications Previously, OpenSearch offered only a dense retrieval approach for text-based vector search. With this release, search practitioners can now choose between sparse retrieval or dense retrieval methods for semantic search applications. Each method presents tradeoffs for users, depending on their application; for example, dense retrieval typically delivers high search relevance while consuming more memory and compute resources and has higher latencies. In comparison, the new sparse retrieval functionality offers two modes with different advantages: a document-only mode can deliver low-latency performance more comparable to BM25 search, with limitations for advanced syntax as compared to dense methods, and a bi-encoder mode can maximize search relevance while performing at higher latencies. With this update, users can now choose the method that works best for their performance, accuracy, and cost requirements. For an in-depth exploration of each method and their advantages for different workloads, stay tuned for an upcoming blog post. Compare and tune your search results Introduced in OpenSearch 2.4 as experimental functionality, this release makes the search comparison tool generally available for production workloads. This tool lets you compare the results of two different search queries side by side in OpenSearch Dashboards, as shown in the following example UI. As an example, you can compare the results of a lexical search against the results from a semantic search query so that you can view both rankings and tune your results accordingly. Protect data efficiently with interoperability between snapshots and remote-backed storage Today, OpenSearch offers two built-in ways to enhance data durability: remote-backed storage, which gives you the option to automatically store all transactions on a per-index basis using your choice of cloud storage services, and snapshots, which let you create an on-demand snapshot of a cluster\\u2019s indexes and metadata in a configured repository. With this feature, you have the option to use snapshots more efficiently, with less demand on compute resources, by taking snapshots that refer to data in your remote-backed repository rather than duplicating the data in full. Usability improvements for Security Analytics Following from the results of a recent usability study, this release brings updates to the user experience designed to make it easier to get started with Security Analytics. A new workflow simplifies the process of creating threat detectors and setting up alerts within OpenSearch Dashboards, reducing the number of steps and clarifying certain form fields. Another change adds categories to log types, organizing prepackaged and custom logs into predefined categories for easier filtering and sorting. Improving the security posture of OpenSearch Dashboards OpenSearch 2.11 marks the culmination of a long-term project with the goal of removing dependencies on AngularJS from OpenSearch Dashboards. With AngularJS having reached end-of-life, this step will help to modernize and improve the security posture of OpenSearch Dashboards. For a detailed view of what has changed and how it may affect users, please review this recently published notice in GitHub. Bringing authorization to the REST layer for plugin development REST layer authorization empowers plugin developers to establish secure access controls for REST endpoints in addition to transport layer authorization. Previously, OpenSearch exclusively enforced authorization checks at the transport layer. Given that extensions solely interact with the OpenSearch cluster through the REST layer, the introduction of extensions necessitated the implementation of authorization checks at that layer. Now offered as an independent feature, this enables plugin developers to incorporate routes with an additional layer of security. Integration of this functionality with the extension framework is currently under development. Experimental features OpenSearch 2.11 includes experimental features designed to allow users to preview new tools before they are generally available. Experimental features should not be used in a production environment. Track OpenSearch requests with traces OpenSearch 2.11 introduces the ability to trace OpenSearch requests and tasks as an experimental functionality. With this release, OpenSearch introduces a new framework that allows developers to follow OpenSearch requests and tasks as they traverse components and services across the distributed architecture. Users can also enable this functionality in order to trace their requests and monitor their paths through the system, measure request latencies, and more. This release enables this functionality at the network layer, REST layer, and transport layer. As development of the feature continues, additional capabilities will address collecting trace and span data at different levels of granularity and with different code paths. Refer to the documentation to learn more and see how you can explore these capabilities. To share feedback, please see our request for comments. Customize pipelines for retrieval augmented generation Enhancing the conversational search functionality introduced in OpenSearch 2.10 as an experimental toolkit, this release introduces several new parameters that can be used to customize retrieval augmented generation (RAG) pipelines. These optional parameters provide core logic that allows you to adapt the way OpenSearch interacts with large language models (LLMs) as part of generative artificial intelligence (GenAI) applications. See the documentation for this feature to explore the available parameters. The latest version of OpenSearch is ready for download! You can find out more about these features and many others in the release notes and the documentation release notes as well as the documentation. OpenSearch Playground offers a turnkey option for exploring the visualization toolkit before downloading it. Look for upcoming blog posts that dive deeper into the new functionality delivered in OpenSearch 2.11. Author James McIntyre James McIntyre is a senior product marketing manager with AWS serving the OpenSearch Project and chair of the OpenSearch Software Foundation Marketing Outreach Committee. View all posts Share Subscribe for updates, event info, and the latest community news OpenSearch is a community-driven, Apache 2.0-licensed open source search and analytics suite that makes it easy to ingest, search, visualize, and analyze data. linkedin github slack youtube mastodon bluesky x-twitter Participate Code of Conduct Forum Project Repo Community Repo Meetup Connect Providers Become a Provider Find a Provider Resources About FAQ Release Schedule Maintenance Policy Documentation Getting Started Testimonials Trademark & Brand Privacy \\u00a9 Copyright The Linux Foundation. The OpenSearch Project is a project of The Linux Foundation. For web site terms of use, trademark policy and other policies applicable to The OpenSearch Project please see Linux Foundation Policies. The OpenSearch Project supports the OpenSearch open source project, which has been established as OpenSearch Project a Series of LF Projects, LLC. For policies applicable to the OpenSearch Project a Series of LF Projects, LLC, please see LF Projects, LLC Policies, Privacy Policy, Terms of Use and the OpenSearch Trademark Policy. Close Menu About Foundation Governing Board Charter Meeting Calendar Platform Platform OpenSearch CoreOpenSearch is a powerful search and analytics engine built on Apache Lucene. OpenSearch DashboardsOur data visualization toolset is a flexible, fully integrated solution for visually exploring and querying your data. OpenSearch Data PrepperA server-side data collector designed to enrich, transform, and aggregate data for downstream analytics with Opensearch. OpenSearch Vector EnginePower machine learning and generative AI applications with a high-performance database designed for the way AI understands data. Capabilities Machine learning and AI Vector Search Anomaly Detection Search E-Commerce Document Search Search Relevance Observability Performance Monitoring Log Analysis Security Analytics Threat Intelligence Event Correlation Performance Benchmarks View key performance metrics across different workloads View Data Roadmap Image OpenSearch Project RoadmapExplore our official project roadmap on GitHub Community OpenSearch Community ForumFind answers to your questions, help others in the community, and join the conversation. EventsCommunity Meetings, Development Backlog & Triage, in-person, and virtual events. AmbassadorsAmbassadors Community leaders who share knowledge and grow OpenSearch. Solutions ProvidersFind open-source providers offering solutions and services. ProjectsHighlights of projects built by the community. User GroupsJoin the OpenSearch Project Meetup Network Community Resources SlackSpeak with other developers. GitHub Project OrganizationJoin us for in-person and virtual events to learn the latest about the project. OpenSearchCon Image OpenSearchCon North AmericaSeptember 8-10, 2025 | San Jose, CA OpenSearchCon India3-4 June 2025 | Bengaluru, India OpenSearchCon Korea2025 November 4 | Seoul, South Korea OpenSearchCon EuropeView Videos & Slides Documentation Documentation Library OpenSearch and DashboardsBuild your OpenSearch solution using core tooling and visualizations. OpenSearch Data PrepperFilter, mutate, and sample your data for ingestion into OpenSearch. Migration AssistantBegin your transition to OpenSearch with our migration toolkit Documentation Library II OpenSearch BenchmarkMeasure performance metrics for your OpenSearch cluster. ClientsInteract with OpenSearch from your application using language APIs. Blog & News Blog Announcements Case Studies News Authors Downloads\\\"},{\\\"url\\\":\\\"https://github.com/opensearch-project/opensearch-build/blob/main/release-notes/opensearch-release-notes-2.11.0.md\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to content Navigation Menu Toggle navigation Sign in Appearance settings Platform AI CODE CREATION GitHub CopilotWrite better code with AI GitHub SparkBuild and deploy intelligent apps GitHub ModelsManage and compare prompts MCP RegistryNewDiscover and integrate external tools DEVELOPER WORKFLOWS ActionsAutomate any workflow CodespacesInstant dev environments IssuesPlan and track work Code ReviewManage code changes APPLICATION SECURITY GitHub Advanced SecurityFind and fix vulnerabilities Code securitySecure your code as you build Secret protectionStop leaks before they start EXPLORE Why GitHub Documentation Blog Changelog Marketplace View all features Solutions BY COMPANY SIZE Enterprises Small and medium teams Startups Nonprofits BY USE CASE App Modernization DevSecOps DevOps CI/CD View all use cases BY INDUSTRY Healthcare Financial services Manufacturing Government View all industries View all solutions Resources EXPLORE BY TOPIC AI Software Development DevOps Security View all topics EXPLORE BY TYPE Customer stories Events & webinars Ebooks & reports Business insights GitHub Skills SUPPORT & SERVICES Documentation Customer support Community forum Trust center Partners Open Source COMMUNITY GitHub SponsorsFund open source developers PROGRAMS Security Lab Maintainer Community Accelerator Archive Program REPOSITORIES Topics Trending Collections Enterprise ENTERPRISE SOLUTIONS Enterprise platformAI-powered developer platform AVAILABLE ADD-ONS GitHub Advanced SecurityEnterprise-grade security features Copilot for BusinessEnterprise-grade AI features Premium SupportEnterprise-grade 24/7 support Pricing Search or jump to... Search code, repositories, users, issues, pull requests... Search Clear Search syntax tips Provide feedback We read every piece of feedback, and take your input very seriously. Include my email address so I can be contacted Cancel Submit feedback Saved searches Use saved searches to filter your results more quickly Name Query To see all available qualifiers, see our documentation. Cancel Create saved search Sign in Sign up Appearance settings Resetting focus You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert {{ message }} opensearch-project / opensearch-build Public generated from amazon-archives/__template_Apache-2.0 Notifications You must be signed in to change notification settings Fork 314 Star 180 Code Issues 178 Pull requests 19 Discussions Actions Projects 3 Wiki Security Uh oh! There was an error while loading. Please reload this page. Insights Additional navigation options Code Issues Pull requests Discussions Actions Projects Wiki Security Insights Footer \\u00a9 2025 GitHub, Inc. Footer navigation Terms Privacy Security Status Community Docs Contact Manage cookies Do not share my personal information You can\\u2019t perform that action at this time.\\\"},{\\\"url\\\":\\\"https://aws.amazon.com/about-aws/whats-new/2023/11/amazon-opensearch-supports-version-2-11/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to main content Click here to return to Amazon Web Services homepage About AWS Contact Us Support English My Account Sign In Create an AWS Account Close Profile Your profile helps improve your interactions with select AWS experiences. Login Close Profile Your profile helps improve your interactions with select AWS experiences. View profile Log out Amazon Q Products Solutions Pricing Documentation Learn Partner Network AWS Marketplace Customer Enablement Events Explore More Close \\u0639\\u0631\\u0628\\u064a Bahasa Indonesia Deutsch English Espa\\u00f1ol Fran\\u00e7ais Italiano Portugu\\u00eas Ti\\u1ebfng Vi\\u1ec7t T\\u00fcrk\\u00e7e \\u03a1\\u0443\\u0441\\u0441\\u043a\\u0438\\u0439 \\u0e44\\u0e17\\u0e22 \\u65e5\\u672c\\u8a9e \\ud55c\\uad6d\\uc5b4 \\u4e2d\\u6587 (\\u7b80\\u4f53) \\u4e2d\\u6587 (\\u7e41\\u9ad4) Close My Profile Sign out of AWS Builder ID AWS Management Console Account Settings Billing & Cost Management Security Credentials AWS Personal Health Dashboard Close Support Center Expert Help Knowledge Center AWS Support Overview AWS re:Post Click here to return to Amazon Web Services homepage Get Started for Free Contact Us Products Solutions Pricing Introduction to AWS Getting Started Documentation Training and Certification Developer Center Customer Success Partner Network AWS Marketplace Support AWS re:Post Log into Console Download the Mobile App Amazon OpenSearch Service now supports OpenSearch version 2.11 Posted On: Nov 20, 2023 You can now run OpenSearch version 2.11 in Amazon OpenSearch Service. With OpenSearch 2.11, we have made several improvements to search, observability, security analytics, and OpenSearch Dashboards. This version includes features that were launched as part of open source OpenSearch versions 2.10 and 2.11. This launch includes the introduction of hybrid search queries, which uses normalization processors to improve search relevance, by combining relevance scores of lexical queries with natural language-based k-NN vector search queries. It also includes multimodal search, which allows users to search image and text pairs like product catalog items, and the introduction of neural sparse retrieval in addition to existing dense retrieval for semantic search applications. Search practitioners can test out these new search methods with the new search comparison tool which lets you compare the results of two different search queries side by side in OpenSearch Dashboards. Security Analytics now provides threat detection capabilities to detect malicious activity and adds custom log categories for easier filtering and sorting. Other improvements include a new visual theme and a discover tool for a more user-friendly Dashboards environment, and a new IP2Geo processor that allows users to retrieve the geographical location of an IPv4 or IPv6 address, and add that information to incoming data during ingest or at a later time, as required. For information on upgrading to OpenSearch 2.11, please see this documentation. OpenSearch 2.11 is now available in all AWS Regions where Amazon OpenSearch Service is available. \\u00bb Sign In to the Console Learn About AWS What Is AWS? What Is Cloud Computing? AWS Accessibility What Is DevOps? What Is a Container? What Is a Data Lake? What is Artificial Intelligence (AI)? What is Generative AI? What is Machine Learning (ML)? AWS Cloud Security What's New Blogs Press Releases Resources for AWS Getting Started Training and Certification AWS Trust Center AWS Solutions Library Architecture Center Product and Technical FAQs Analyst Reports AWS Partners Developers on AWS Developer Center SDKs & Tools .NET on AWS Python on AWS Java on AWS PHP on AWS JavaScript on AWS Help Contact Us Get Expert Help File a Support Ticket AWS re:Post Knowledge Center AWS Support Overview Legal AWS Careers Create an AWS Account Amazon is an Equal Opportunity Employer: Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age. Language \\u0639\\u0631\\u0628\\u064a Bahasa Indonesia Deutsch English Espa\\u00f1ol Fran\\u00e7ais Italiano Portugu\\u00eas Ti\\u1ebfng Vi\\u1ec7t T\\u00fcrk\\u00e7e \\u03a1\\u0443\\u0441\\u0441\\u043a\\u0438\\u0439 \\u0e44\\u0e17\\u0e22 \\u65e5\\u672c\\u8a9e \\ud55c\\uad6d\\uc5b4 \\u4e2d\\u6587 (\\u7b80\\u4f53) \\u4e2d\\u6587 (\\u7e41\\u9ad4) Privacy | Accessibility | Site Terms | Cookie Preferences | \\u00a9 2025, Amazon Web Services, Inc. or its affiliates. All rights reserved. Ending Support for Internet Explorer Got it AWS support for Internet Explorer ends on 07/31/2022. Supported browsers are Chrome, Firefox, Edge, and Safari. Learn more \\u00bb Got it\\\"},{\\\"url\\\":\\\"https://opensearch.isharkfly.com/release-notes/opensearch-documentation-release-notes-2.11.0/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu OpenSearchCon 2024 - Stay Informed Sessions Speakers Exhibitors Workshops Unconference CFP is closed Download About Releases Roadmap FAQ Community Blog Forum Slack Events Partners Projects Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home API Style Guide Formatting Guide OpenSearch Documentation Website 2.10.0 Release Notes OpenSearch Documentation Website 2.11.0 Release Notes OpenSearch Documentation Website 2.12.0 Release Notes OpenSearch Documentation Website 2.4.0 Release Notes OpenSearch Documentation Website 2.5.0 Release Notes OpenSearch Documentation Website 2.6.0 Release Notes OpenSearch Documentation Website 2.7.0 Release Notes OpenSearch Documentation Website 2.8.0 Release Notes OpenSearch Documentation Website 2.9.0 Release Notes OpenSearch Project Style Guidelines OpenSearch terms Overview About OpenSearch Intro to OpenSearch Quickstart Version history Breaking changes Install and upgrade Installing OpenSearch Docker Helm Tarball RPM Debian Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Circuit breaker settings Cluster settings Index settings Search settings Availability and recovery settings Plugin settings Experimental feature flags Logs Configuring OpenSearch Dashboards Upgrading OpenSearch Rolling Upgrade Upgrades appendix Rolling upgrade lab Installing plugins Managing OpenSearch Dashboards plugins Migrate to OpenSearch Using snapshots to migrate data Migrating from Elasticsearch OSS to OpenSearch Migrating Docker clusters to OpenSearch Migrating from Kibana OSS to OpenSearch Dashboards Managing Indexes Index templates Index aliases Data streams Reindex data Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings Index management security Refresh search analyzer ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Ingest Pipelines Create pipeline Simulate pipeline Get pipeline Delete pipeline Handling pipeline failures Ingest processors Append Bytes Convert Copy CSV Date Date index name Dissect Dot expander Drop IP2Geo Grok KV Lowercase Remove_by_pattern Remove Sparse encoding Text embedding Text/image embedding Uppercase OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Analyzing data Time filter Creating dashboards Building data visualizations Using area charts Using coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using the self-host maps server Using Gantt charts Using VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimize query performance using OpenSearch indexing Dev Tools Running queries in the Dev Tools console Query Workbench Custom branding Dashboards Query Language (DQL) Search telemetry OpenSearch Integrations Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Tuning for indexing speed Security in OpenSearch Configuration Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files API rate limiting Configuring sign-in options Disabling security OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Access control REST layer authorization Document-level security Users and roles Field-level security Field masking User impersonation Cross-cluster search Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Creating detectors Supported log types Creating correlation rules Creating custom log types Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Security Analytics settings Mappings and field types Supported field types Alias Binary Numeric field types Unsigned long Boolean Date field types Date Date nanoseconds IP address Range field types Object field types Object Nested Flat object Join String field types Keyword Text Match-only text Token count Autocomplete field types Completion Search as you type Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape k-NN vector Rank field types Percolator Text analysis Language analyzers Index analyzers Search analyzers Tokenizers Token filters Delimited term frequency Normalizers Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Exists Fuzzy IDs Prefix Range Regexp Term Terms Terms set Wildcard Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box xy Span queries Match all queries Specialized queries Neural Neural sparse Script score Minimum should match Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Matrix stats Maximum Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Bucket aggregations Adjacency matrix Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Range Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Search Searching data Paginate results Point in Time Point in Time API Sort results Highlight query matches Autocomplete Did-you-mean Keyword search k-NN search k-NN index Exact k-NN with scoring script Approximate k-NN search k-NN search with filters k-NN search with nested fields k-NN Painless extensions API JNI libraries Settings Performance tuning Neural search Neural search tutorial Semantic search Multimodal search Neural sparse search Hybrid search Conversational search Search relevance Comparing search results Reranking search results Querqy Search pipelines Creating a search pipeline Using a search pipeline Retrieving search pipelines Search processors Collapse Filter query Neural query enricher Normalization Oversample Personalize search ranking Retrieval-augmented generation Rename field Rerank Script Truncate hits Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Identifiers Data Types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Machine learning ML Commons cluster settings Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Connector blueprints Agents and tools Agents and tools tutorial Tools Agent tool CAT Index tool Index Mapping tool ML Model tool Neural Sparse Search tool PPL tool RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool OpenSearch Assistant Toolkit Managing ML models in OpenSearch Dashboards Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Model group APIs Register model group Update model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Execute agent Get agent Search agent Delete agent Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Execute algorithm Tasks APIs Get task Search task Delete task Train and Predict APIs Train and predict Train Predict Profile Stats Automating configurations Workflow steps Workflow tutorial Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Monitoring your cluster Job Scheduler Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metrics analytics Query insights Top N queries Trace Analytics Getting Started OpenSearch Dashboards plugin Analyzing Jaeger trace data Distrbuted tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI OpenSearch Kubernetes Operator Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana API reference Analyze API Analysis API Terminology CAT API CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices operation CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster routing and awareness Cluster decommission Cluster health Cluster settings Cluster stats Count Document APIs Index document Get document Update document Delete document Bulk Multi-get document Delete by query Update by query Reindex document Explain Index APIs Alias Clear cache Clone index Close index Create index Create or update mappings Dangling indexes Delete index Force merge Get index Get settings Index exists Open index Shrink index Split index Stats Update settings Ingest APIs Multi-search Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Profile Ranking evaluation Remote cluster information Script APIs Create or Update Stored Script Execute Painless stored script Get Stored Script Delete Script Get Stored Script Contexts Get Script Language Execute Painless script Scroll Search Search templates Snapshot APIs Register Snapshot Repository Get Snapshot Repository Delete Snapshot Repository Verify Snaphot Repository Create Snapshot Get Snapshot Delete Snapshot Get Snapshot Status Restore Snapshot Tasks Supported units Common REST Parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Extensions OpenSearch Documentation Website 2.11.0 Release Notes The OpenSearch 2.11.0 documentation includes the following additions and updates. New documentation for 2.11.0 Add Conversational Search changes for 2.11 #5195 Remove warning about alerting and segment replication compatibility #5191 Add documentation for log type categories #5181 Add updates to creating a detector UX #5176 Add multimodal search/sparse search/pre- and post-processing function documentation #5168 Add documentation for new recovery setting #5162 Add terminate after behavior to concurrent segment search #5143 Add documentation for configurable merge policy #5137 Remove experimental header from search comparison tool #5124 Add documentation about setting a default model for neural search #5121 Add total wait time to thread pool in nodes stats #5120 Add new documentation for distributed tracing #4964 Add documentation for authorization on the REST layer #4544 New documentation for 2.11.0 WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links \\u53c2\\u4e0e\\u9879\\u76ee\\uff08Get Involved\\uff09 Code of Conduct OpenSearch \\u4e2d\\u6587\\u8bba\\u575b \\u5b98\\u65b9\\u8bba\\u575b \\u4e2d\\u6587\\u6587\\u6863\\u4ee3\\u7801\\u4ed3\\u5e93 \\u5b98\\u65b9 Github Slack \\u793e\\u533a\\u9879\\u76ee \\u8d44\\u6e90\\uff08Resources\\uff09 About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy \\u8054\\u7cfb\\u6211\\u4eec\\uff08Contact Us\\uff09 \\u8054\\u7cfb\\uff08Connect\\uff09 Twitter LinkedIn YouTube Meetup Facebook \\u00a9 OpenSearch contributors, 2024. OpenSearch is a registered trademark of Amazon Web Services. \\u00a9 2005-2021 Django Software Foundation and individual contributors. Django is a registered trademark of the Django Software Foundation. This website was forked from the BSD-licensed djangoproject.com originally designed by Threespot & andrevv.\\\"},{\\\"url\\\":\\\"https://docs.opensearch.org/latest/version-history/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Regular expression syntax Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Using UBI in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Version history OpenSearch version Release highlights Release date 3.3.2 Includes maintenance changes and bug fixes for the OpenSearch core engine and ML Commons, Neural Search, Skills, k-NN and Security plugins. For a full list of release highlights, see the Release Notes. 30 October 2025 3.3.1 Fixes backward compatibility handling of date fields while maintaining performance optimizations. The skip_list parameter is now automatically set to true for new @timestamp fields created since 3.3.0, while preserving skip_list=false for existing indexes with @timestamp or index sort date fields. This approach ensures date histogram aggregation performance benefits for new indexes while maintaining compatibility with existing workloads. For a full list of release highlights, see the Release Notes. 22 October 2025 3.3.0 Introduces redesigned Discover interface with log analytics and distributed tracing capabilities, and Apache Calcite as default PPL query engine with expanded functions. Makes agentic search and agentic memory APIs generally available for AI applications. Implements Seismic algorithm for neural sparse search performance improvements and processor chains for data transformation pipelines. Expands gRPC support for additional query types and adds experimental streaming with Apache Arrow Flight. Includes workload management enhancements with rule-based auto-tagging and query monitoring capabilities. For a full list of release highlights, see the Release Notes. 14 October 2025 3.2.0 Updates Search Relevance Workbench. Makes gRPC APIs generally available. Introduces derived source, updates workload management, semantic field, and star tree functionality. Adds experimental Agentic Memory APIs and Job Scheduler APIs. For a full list of release highlights, see the Release Notes. 19 August 2025 3.1.0 Makes GPU acceleration for vector index builds generally available. Introduces memory-optimized search for Faiss indexes using Lucene HNSW, semantic field type for streamlined semantic search, and Search Relevance Workbench for search quality optimization. Makes star-tree indexes generally available with support for comprehensive query types. Enhances observability with ML Commons metrics integration, custom index support for OpenTelemetry data, and new PPL commands for JSON manipulation. Improves agent management with Update Agent API and persistent MCP tools. Includes security enhancements with immutable user objects and new resource sharing framework. For a full list of release highlights, see the Release Notes. 24 June 2025 3.0.0 Upgrades to Lucene 10 for improved indexing and vector search. Adds experimental gRPC support and pull-based ingestion from Kafka and Kinesis. Introduces GPU acceleration for vector operations and semantic sentence highlighting. Improves range query performance and hybrid search with z-score normalization. Adds plan-execute-reflect agents and native MCP protocol support for agentic workflows. Enhances security with a new Java agent replacing the Security Manager. Includes PPL query improvements with lookup, join, and subsearch commands. For a full list of release highlights, see the Release Notes. 06 May 2025 2.19.3 Improves Flow Framework with enhanced memory handling and workflow step processing. Fixes several Query Insights and Query Insights Dashboards issues. Implements security updates across multiple components. Updates infrastructure components and documentation across multiple plugins. For a full list of release highlights, see the Release Notes. 22 July 2025 2.19.2 Improves query insights with better index handling, a new verbose API parameter, and a default index template. Fixes bugs across Query Insights, Observability, Flow Framework, and Dashboards. Includes multiple CVE fixes, test enhancements, and a new PGP key for artifact verification. For a full list of release highlights, see the Release Notes. 29 April 2025 2.19.1 Adds execution hint for cardinality aggregator. Includes bug fixes for ML Commons, Query Insights Dashboards, and Remote Metadata SDK. Contains maintenance updates for several components. For a full list of release highlights, see the Release Notes. 27 February 2025 2.19.0 Adds workload management, additional query insights, and template queries. Introduces a query insights page to OpenSearch Dashboards. Includes improvements and bug fixes to snapshots, search statistics, star-tree search, and index management. For a full list of release highlights, see the Release Notes. 11 February 2025 2.18.0 Adds a redesigned home page, updated Discover interface, and collaborative workspaces to OpenSearch Dashboards. Includes improvements to ML inference processor and query grouping. Introduces reranking by field and paginated CAT APIs. Includes experimental OpenSearch Dashboards Assistant capabilities. For a full list of release highlights, see the Release Notes. 05 November 2024 2.17.1 Includes bug fixes for ML Commons, anomaly detection, k-NN, and security analytics. Adds various infrastructure and maintenance updates. For a full list of release highlights, see the Release Notes. 1 October 2024 2.17.0 Includes disk-optimized vector search, binary quantization, and byte vector encoding in k-NN. Adds asynchronous batch ingestion for ML tasks. Provides search and query performance enhancements and a new custom trace source in trace analytics. Includes application-based configuration templates. For a full list of release highlights, see the Release Notes. 17 September 2024 2.16.0 Includes built-in byte vector quantization and binary vector support in k-NN. Adds new sort, split, and ML inference search processors for search pipelines. Provides application-based configuration templates and additional plugins to integrate multiple data sources in OpenSearch Dashboards. Includes an experimental Batch Predict ML Commons API. For a full list of release highlights, see the Release Notes. 06 August 2024 2.15.0 Includes parallel ingestion processing, SIMD support for exact search, and the ability to disable doc values for the k-NN field. Adds wildcard and derived field types. Improves performance for single-cardinality aggregations, rolling upgrades to remote-backed clusters, and more metrics for top N queries. For a full list of release highlights, see the Release Notes. 25 June 2024 2.14.0 Includes performance improvements to hybrid search and date histogram queries with multi-range traversal, ML model integration within the Ingest API, semantic cache for LangChain applications, low-level vector query interface for neural sparse queries, and improved k-NN search filtering. Provides an experimental tiered cache feature. For a full list of release highlights, see the Release Notes. 14 May 2024 2.13.0 Makes agents and tools and the OpenSearch Assistant Toolkit generally available. Introduces vector quantization within OpenSearch. Adds LLM guardrails and hybrid search with aggregations. Adds the Bloom filter skipping index for Apache Spark data sources, I/O-based admission control, and the ability to add an alerting cluster that manages all alerting tasks. For a full list of release highlights, see the Release Notes. 2 April 2024 2.12.0 Makes concurrent segment search and conversational search generally available. Provides an experimental OpenSearch Assistant Toolkit, including agents and tools, workflow automation, and OpenSearch Assistant for OpenSearch Dashboards UI. Adds a new match-only text field, query insights to monitor top N queries, and k-NN search on nested fields. For a full list of release highlights, see the Release Notes. 20 February 2024 2.11.1 Includes maintenance changes and bug fixes for cross-cluster replication, alerting, observability, OpenSearch Dashboards, index management, machine learning, security, and security analytics. For a full list of release highlights, see the Release Notes. 30 November 2023 2.11.0 Adds multimodal and sparse neural search capability and the ability to take shallow snapshots that refer to data stored in remote-backed storage. Makes the search comparison tool generally available. Includes a simplified workflow to create threat detectors in Security Analytics and improved security in OpenSearch Dashboards. Experimental features include a new framework and toolset for distributed tracing and updates to conversational search. For a full list of release highlights, see the Release Notes. 16 October 2023 2.10.0 Makes remote-backed storage generally available. Adds hybrid search capability, custom log types for Security Analytics, IP2Geo ingest processor, and delimited term frequency token filter. Includes a new look and feel for OpenSearch Dashboards and updates the Discover tool. Adds Microsoft Teams webhook support for notifications. Experimental features include concurrent segment search and conversational search. For a full list of release highlights, see the Release Notes. 25 September 2023 2.9.0 Makes search pipelines and the Neural Search plugin generally available. Adds ML model access control and integration with external ML tools. Implements k-NN byte vectors and efficient filtering with the Faiss engine. Integrates alerting and anomaly detection with OpenSearch Dashboards and adds composite monitors. Adds two new index codec algorithm options. Includes a new ingestion schema for Security Analytics, geoshape aggregations, and extensions\\u2014a new mechanism for extending OpenSearch functionality. For a full list of release highlights, see the Release Notes. 24 July 2023 2.8.0 Adds cross-cluster query with PPL, search pipelines, an option to turn on segment replication as the default replication type, improved searchable snapshot performance, and Amazon OpenSearch Serverless support with SigV4 authentication for multiple data sources. Includes the UI for the flush, refresh, and clear cache operations in OpenSearch Dashboards. For a full list of release highlights, see the Release Notes. 06 June 2023 2.7.0 Includes searchable snapshots and segment replication, which are now generally available. Adds multiple data sources, observability features, dynamic tenant management, component templates, and shape-based map filters in OpenSearch Dashboards. Includes the flat object field type, hot shard identification, and a new automatic reloading mechanism for ML models. For a full list of release highlights, see the Release Notes. 02 May 2023 2.6.0 Includes simple schema for observability, index management UI enhancements, Security Analytics enhancements, search backpressure at the coordinator node level, and the ability to add maps to dashboards. Experimental features include a new ML model health dashboard, new text embedding models in ML, and SigV4 authentication in Dashboards. For a full list of release highlights, see the Release Notes. 28 February 2023 2.5.0 Includes index management UI enhancements, multi-layer maps, Jaeger support for observability, Debian distributions, returning cluster health by awareness attribute, cluster manager task throttling, weighted zonal search request routing policy, and query string support in index rollups. Experimental features include request-level durability in remote-backed storage and GPU acceleration for ML nodes. For a full list of release highlights, see the Release Notes. 24 January 2023 2.4.1 Includes maintenance changes and bug fixes for gradle check and indexing pressure tests. Adds support for skipping changelog. For a full list of release highlights, see the Release Notes. 13 December 2022 2.4.0 Includes Windows support, Point-in-time search, custom k-NN filtering, xy_point and xy_shape field types for Cartesian coordinates, GeoHex grid aggregation, and resilience enhancements, including search backpressure. In OpenSearch Dashboards, this release adds snapshot restore functionality, multiple authentication, and aggregate view of saved objects. This release includes the following experimental features: searchable snapshots, Compare Search Results, multiple data sources in OpenSearch Dashboards, a new Model Serving Framework in ML Commons, a new Neural Search plugin that supports semantic search, and a new Security Analytics plugin to analyze security logs. For a full list of release highlights, see the Release Notes. 15 November 2022 2.3.0 This release includes the following experimental features: segment replication, remote-backed storage, and drag and drop for OpenSearch Dashboards. Experimental features allow you to test new functionality in OpenSearch. Because these features are still being developed, your testing and feedback can help shape the development of the feature before it\\u2019s official released. We do not recommend use of experimental features in production. Additionally, this release adds maketime and makedate datetime functions for the SQL plugin. Creates a new OpenSearch Playground demo site for OpenSearch Dashboards. For a full list of release highlights, see the Release Notes. 14 September 2022 2.2.1 Includes gradle updates and bug fixes for gradle check. For a full list of release highlights, see the Release Notes. 01 September 2022 2.2.0 Includes support for Logistic Regression and RCF Summarize machine learning algorithms in ML Commons, Lucene or C-based Nmslib and Faiss libraries for approximate k-NN search, search by relevance using SQL and PPL queries, custom region maps for visualizations, and rollup enhancements. For a full list of release highlights, see the Release Notes. 11 August 2022 2.1.0 Includes support for dedicated ML node in the ML Commons plugin, relevance search and other features in SQL, multi-terms aggregation, and Snapshot Management. For a full list of release highlights, see the Release Notes. 07 July 2022 2.0.1 Includes bug fixes and maintenance updates for Alerting and Anomaly Detection. For a full list of release highlights, see the Release Notes. 16 June 2022 2.0.0 Includes document-level monitors for alerting, OpenSearch Notifications plugins, and Geo Map Tiles in OpenSearch Dashboards. Also adds support for Lucene 9 and bug fixes for all OpenSearch plugins. For a full list of release highlights, see the Release Notes. 26 May 2022 2.0.0-rc1 The Release Candidate for 2.0.0. This version allows you to preview the upcoming 2.0.0 release before the GA release. The preview release adds document-level alerting, support for Lucene 9, and the ability to use term lookup queries in document level security. For a full list of release highlights, see the Release Notes. 03 May 2022 1.3.20 Includes enhancements to Anomaly Detection Dashboards, bug fixes for Alerting and Dashboards Reports, and maintenance updates for several OpenSearch components. For a full list of release highlights, see the Release Notes. 11 December 2024 1.3.19 Includes bug fixes and maintenance updates for OpenSearch security, OpenSearch security Dashboards, and anomaly detection. For a full list of release highlights, see the Release Notes. 27 August 2024 1.3.18 Includes maintenance updates for OpenSearch security. For a full list of release highlights, see the Release Notes. 16 July 2024 1.3.17 Includes maintenance updates for OpenSearch security and OpenSearch Dashboards security. For a full list of release highlights, see the Release Notes. 06 June 2024 1.3.16 Includes bug fixes and maintenance updates for OpenSearch security, index management, performance analyzer, and reporting. For a full list of release highlights, see the Release Notes. 23 April 2024 1.3.15 Includes bug fixes and maintenance updates for cross-cluster replication, SQL, OpenSearch Dashboards reporting, and alerting. For a full list of release highlights, see the Release Notes. 05 March 2024 1.3.14 Includes bug fixes and maintenance updates for OpenSearch security and OpenSearch Dashboards security. For a full list of release highlights, see the Release Notes. 12 December 2023 1.3.13 Includes bug fixes for Anomaly Detection, adds maintenance updates and infrastructure enhancements. For a full list of release highlights, see the Release Notes. 21 September 2023 1.3.12 Adds maintenance updates for OpenSearch security and OpenSearch Dashboards observability. Includes bug fixes for observability, OpenSearch Dashboards visualizations, and OpenSearch security. For a full list of release highlights, see the Release Notes. 10 August 2023 1.3.11 Adds maintenance updates for OpenSearch security, OpenSearch Dashboards security, and ML Commons. For a full list of release highlights, see the Release Notes. 29 June 2023 1.3.10 Adds infrastructure enhancements and maintenance updates for anomaly detection, observability, and security. Includes bug fixes for index management and OpenSearch security. For a full list of release highlights, see the Release Notes. 18 May 2023 1.3.9 Adds Debian support. Includes upgrades, enhancements, and maintenance updates for OpenSearch core, k-NN, and OpenSearch security. For a full list of release highlights, see the Release Notes. 16 March 2023 1.3.8 Adds OpenSearch security enhancements. Updates tool scripts to run on Windows. Includes maintenance updates and bug fixes for Anomaly Detection and OpenSearch security. For a full list of release highlights, see the Release Notes. 02 February 2023 1.3.7 Adds Windows support. Includes maintenance updates and bug fixes for error handling. For a full list of release highlights, see the Release Notes. 13 December 2022 1.3.6 Includes maintenance updates and bug fixes for tenancy in the OpenSearch Security Dashboards plugin. For a full list of release highlights, see the Release Notes. 06 October 2022 1.3.5 Includes maintenance updates and bug fixes for gradle check and OpenSearch security. For a full list of release highlights, see the Release Notes. 01 September 2022 1.3.4 Includes maintenance updates and bug fixes for OpenSearch and OpenSearch Dashboards. For a full list of release highlights, see the Release Notes. 14 July 2022 1.3.3 Adds enhancements to Anomaly Detection and ML Commons. Bug fixes for Anomaly Detection, Observability, and k-NN. For a full list of release highlights, see the Release Notes. 09 June 2022 1.3.2 Bug fixes for Anomaly Detection and the Security Dashboards Plugin, adds the option to install OpenSearch using RPM, as well as enhancements to the ML Commons execute task, and the removal of the job-scheduler zip in Anomaly Detection. For a full list of release highlights, see the Release Notes. 05 May 2022 1.3.1 Bug fixes when using document-level security, and adjusted ML Commons to use the latest RCF jar and protostuff to RCF model serialization. For a full list of release highlights, see the Release Notes. 30 March 2022 1.3.0 Adds Model Type Validation to Validate Detector API, continuous transforms, custom actions, applied policy parameter to Explain API, default action retries, and new rollover and transition conditions to Index Management, new ML Commons plugin, parse command to SQL, Application Analytics, Live Tail, Correlation, and Events Flyout to Observability, and auto backport and support for OPENSEARCH_JAVA_HOME to Performance Analyzer. Bug fixes. For a full list of release highlights, see the Release Notes. 17 March 2022 1.2.4 Updates Performance Analyzer, SQL, and Security plugins to Log4j 2.17.1, Alerting and Job Scheduler to cron-utils 9.1.6, and gson in Anomaly Detection and SQL. For a full list of release highlights, see the Release Notes. 18 January 2022 1.2.3 Updates the version of Log4j used in OpenSearch to Log4j 2.17.0 as recommended by the advisory in CVE-2021-45105. For a full list of release highlights, see the Release Notes. 22 December 2021 1.2.0 Adds observability, new validation API for Anomaly Detection, shard-level indexing back-pressure, new \\u201cmatch\\u201d query type for SQL and PPL, support for Faiss libraries in k-NN, and custom Dashboards branding. For a full list of release highlights, see the Release Notes. 23 November 2021 1.1.0 Adds cross-cluster replication, security for Index Management, bucket-level alerting, a CLI to help with upgrading from Elasticsearch OSS to OpenSearch, and enhancements to high cardinality data in the anomaly detection plugin. For a full list of release highlights, see the Release Notes. 05 October 2021 1.0.1 Bug fixes. For a full list of release highlights, see the Release Notes. 01 September 2021 1.0.0 General availability release. Adds compatibility setting for clients that require a version check before connecting. For a full list of release highlights, see the Release Notes. 12 July 2021 1.0.0-rc1 First release candidate. For a full list of release highlights, see the Release Notes. 07 June 2021 1.0.0-beta1 Initial beta release. Refactors plugins to work with OpenSearch. For a full list of release highlights, see the Release Notes. 13 May 2021 WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright \\u00a9 OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\\\"},null,{\\\"url\\\":\\\"https://aws.amazon.com/blogs/big-data/amazon-opensearch-service-announces-standard-and-extended-support-dates-for-elasticsearch-and-opensearch-versions/\\\",\\\"title\\\":\\\"facebook linkedin instagram twitch youtube podcasts email\\\",\\\"content\\\":\\\"Skip to Main Content Filter: All English Contact us Support My account Search Filter: All Sign in to console Create Account AWS Blogs Home Blogs Editions AWS Big Data Blog Amazon OpenSearch Service announces Standard and Extended Support dates for Elasticsearch and OpenSearch versions by Arvind Mahesh, Kuldeep Yadav, and Jon Handler on 07 NOV 2024 in Amazon OpenSearch Service, Analytics, Announcements Permalink Comments Share Amazon OpenSearch Service supports 19 versions of Elasticsearch opensource, and 11 versions of OpenSearch. Over the years, we have added several stability, resiliency, and security features to recent engine versions, helping customers derive better value from OpenSearch Service. As software versions grow older, we need to make sure that these versions continue to meet high security and compliance standards. Many of the legacy versions supported on OpenSearch Service, such as Elasticsearch versions 1.5 and 2.3, depend on third-party dependencies that are no longer actively supported. By moving to the latest engine versions, customers can derive maximum benefit from the new features, improved price-performance, and security improvements we make to OpenSearch. Today, we\\u2019re announcing timelines for end of Standard Support and Extended Support for legacy Elasticsearch versions up to 6.7, Elasticsearch versions 7.1 through 7.8, OpenSearch versions from 1.0 through 1.2, and OpenSearch versions 2.3 through 2.9 available on Amazon OpenSearch Service. Versions that are under Standard Support receive regular bug fixes and security fixes, and versions in Extended Support receive critical security fixes and operating system patches for an additional flat fee per normalized instance hour. With Extended Support, we want to make sure that our customers continue to receive critical security fixes for an adequate time, while they plan to upgrade to more recent engine versions. For more details on Extended Support please see the FAQs. End of Standard Support and Extended Support for Elasticsearch versions See Table 1 that follows for end of Standard Support and Extended Support dates for legacy Elasticsearch versions available on OpenSearch Service. We recommend that customers running Elasticsearch versions upgrade to the latest OpenSearch versions. All Elasticsearch versions will receive at least 12 months of Extended Support, and version 5.6 will receive 36 months of Extended Support. After Extended Support ends for a version, domains running the specific version will not receive bug fixes or security updates. Software version End of Standard Support End of Extended Support Elasticsearch versions 1.5 and 2.3 November 7, 2025 November 7, 2026 Elasticsearch versions 5.1 to 5.5 November 7, 2025 November 7, 2026 Elasticsearch version 5.6 November 7, 2025 November 7, 2028 Elasticsearch versions 6.0 to 6.7 November 7, 2025 November 7, 2026 Elasticsearch version 6.8 Not announced Not announced Elasticsearch versions 7.1 to 7.8 November 7, 2025 November 7, 2026 Elasticsearch version 7.9 Not announced Not announced Elasticsearch version 7.10 Not announced Not announced End of Standard Support and Extended Support for OpenSearch versions For OpenSearch versions running on Amazon OpenSearch Service, we will provide at least 12 months of Standard Support after the end of support date for the corresponding upstream open source OpenSearch version, or 12 months of Standard Support after the release of the next minor version on OpenSearch Service, whichever is longer. All OpenSearch versions will receive at least 12 months of Extended Support after the end of Standard Support date. For more details, check the open source OpenSearch maintenance policy. See Table 2 that follows for end of Standard Support and Extended Support dates for various OpenSearch versions available on OpenSearch Service. For future updates on versions in Standard Support and Extended Support, follow supported versions. Software Version End of Standard Support End of Extended Support OpenSearch versions 1.0 to 1.2 November 7, 2025 November 7, 2026 OpenSearch version 1.3 Not announced Not announced OpenSearch versions 2.3 to 2.9 November 7, 2025 November 7, 2026 OpenSearch versions 2.11 and higher versions Not announced Not announced Upgrading OpenSearch Service domains: We recommend that you update your domains to the latest available OpenSearch version to derive maximum value out of OpenSearch Service. Minor version upgrades on OpenSearch tend to be seamless because they don\\u2019t contain breaking changes, and we recommend moving to the latest minor version, or a version for which end of support has not yet been announced. For example, if you are on OpenSearch version 1.2, you can move to OpenSearch version 1.3, because it\\u2019s the last minor version of the 1.x series and because presently it continues to be supported by the open source community and AWS. If you want to choose an Elasticsearch version, and you are running an older 6.x or 7.x version, you can move to version 6.8, or 7.10. There are various ways to upgrade your cluster to a newer version, and the steps vary depending on the version your domain is running and the version you want to upgrade to. See Upgrading OpenSearch Service domains for detailed instructions on upgrading your domain to a new version. You can also use the Migration Assistant for Amazon OpenSearch Service for upgrading to newer versions Calculating Extended Support charges: Domains running versions under Extended Support will be charged a flat additional fee per normalized instance hour (NIH). For example, $0.0065 per NIH in the US East (North Virginia) AWS Region. See the pricing page for exact pricing by Region. NIH is computed as a factor of the instance size (for example, medium or large), and the number of instance hours. For example, if you\\u2019re running an m7g.medium.search instance for 24 hours in the US EAST (North Virginia) Region, which is priced at $0.068 per instance hour (on-demand), you will typically pay $1.632 ($0.068\\u00d724). If you\\u2019re running a version that is in Extended Support, you will pay an additional $0.0065 per NIH, which is computed as $0.0065 x 24 (number of instance hours) x 2 (size normalization factor, which is 2 for medium-sized instances), which comes to $0.312 for Extended Support for 24 hours. The total amount that you will pay for 24 hours will be a sum of the standard instance usage cost and the Extended Support cost, which is $1.944 ($1.632+$0.312, excluding storage cost). The following table shows the normalization factor for various instance sizes in OpenSearch Service. Instance size Normalization Factor nano 0.25 micro 0.5 small 1 medium 2 large 4 xlarge 8 2xlarge 16 4xlarge 32 8xlarge 64 9xlarge 72 10xlarge 80 12xlarge 96 16xlarge 128 18xlarge 144 24xlarge 192 32xlarge 256 Summary We add new capabilities across various vectors to the latest OpenSearch versions, which include new features, performance and resiliency improvements, and security improvements. We recommend that you update to recent OpenSearch versions to get the most benefit out of OpenSearch Service. For any questions on Standard and Extended Support options, see the FAQs. For further questions, contact AWS Support. About the authors Arvind Mahesh is a Senior Manager-Product at Amazon Web Services for Amazon OpenSearch Service. He has close to two decades of technology experience across a variety of domains such as Analytics, Search, Cloud, Network Security, and Telecom. Kuldeep Yadav is a Senior Technical Program Manager at Amazon Web Services who is passionate about driving innovation and complex problem solving. He works closely with teams and customers in ensuring operational excellence and achieving more with less. Outside of work he enjoys trekking and all sports Jon Handler is a Senior Principal Solutions Architect at Amazon Web Services based in Palo Alto, CA. Jon works closely with OpenSearch and Amazon OpenSearch Service, providing help and guidance to a broad range of customers who have search and log analytics workloads that they want to move to the AWS Cloud. Prior to joining AWS, Jon\\u2019s career as a software developer included 4 years of coding a large-scale, ecommerce search engine. Jon holds a Bachelor of the Arts from the University of Pennsylvania, and a Master of Science and a PhD in Computer Science and Artificial Intelligence from Northwestern University. Loading comments\\u2026 Resources Amazon Athena Amazon EMR Amazon Kinesis Amazon MSK Amazon QuickSight Amazon Redshift AWS Glue Follow Twitter Facebook LinkedIn Twitch Email Updates Create an AWS account Learn What Is AWS? What Is Cloud Computing? What Is Generative AI? Cloud Computing Concepts Hub AWS Cloud Security What's New Blogs Press Releases Resources Getting Started Training AWS Solutions Library Architecture Center Product and Technical FAQs Analyst Reports AWS Partners AWS Inclusion, Diversity & Equity Developers Developer Center SDKs & Tools .NET on AWS Python on AWS Java on AWS PHP on AWS JavaScript on AWS Help Contact Us File a Support Ticket AWS re:Post Knowledge Center AWS Support Overview Get Expert Help AWS Accessibility Legal English Back to top Amazon is an Equal Opportunity Employer: Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age. facebook linkedin instagram twitch youtube podcasts email Privacy Site terms Cookie Preferences \\u00a9 2025, Amazon Web Services, Inc. or its affiliates. All rights reserved.\\\"},{\\\"url\\\":\\\"https://www.instaclustr.com/blog/opensearch-2-11-is-now-available-on-the-instaclustr-managed-platform/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Search Search Search Contact us Support Sign in Platform + Left Column PlatformIntelligent, open source application data infrastructure Explore our platform Security and trustEnterprise-grade security Learn more HostingData infrastructure management in the cloud and on-prem Learn more AIPower RAG with open source data infrastructure Read more Right Column Store PostgreSQL\\u00ae Apache Cassandra\\u00ae Stream Apache Kafka\\u00ae Kafka\\u00ae Connect Orchestrate Cadence Analyze ClickHouse\\u00ae Search OpenSearch Pricing Services + Support Training Professional services About + About us Customers Our commitment to open source Resources + Getting started Sign up Documentation Quick start videos Integrations Support portal Discover Blog Events Content library Glossary Education hub Stream + Apache Kafka\\u00ae Real-time streaming Search + OpenSearch Store + PostgreSQL\\u00ae Apache Cassandra\\u00ae Analyze + ClickHouse\\u00ae Orchestrate + Cadence Workflow Open source + Open source AI Data infrastructure + Vector search Data streaming Data architecture Managed databases + Best practices NoSQL databases Vector databases Get a demo Try for free Free trial Sign in Platform + Left Column PlatformIntelligent, open source application data infrastructure Explore our platform Security and trustEnterprise-grade security Learn more HostingData infrastructure management in the cloud and on-prem Learn more AIPower RAG with open source data infrastructure Read more Right Column Store PostgreSQL\\u00ae Apache Cassandra\\u00ae Stream Apache Kafka\\u00ae Kafka\\u00ae Connect Orchestrate Cadence Analyze ClickHouse\\u00ae Search OpenSearch Pricing Services + Support Training Professional services About + About us Customers Our commitment to open source Resources + Getting started Sign up Documentation Quick start videos Integrations Support portal Discover Blog Events Content library Glossary Education hub Stream + Apache Kafka\\u00ae Real-time streaming Search + OpenSearch Store + PostgreSQL\\u00ae Apache Cassandra\\u00ae Analyze + ClickHouse\\u00ae Orchestrate + Cadence Workflow Open source + Open source AI Data infrastructure + Vector search Data streaming Data architecture Managed databases + Best practices NoSQL databases Vector databases Search Search Search Support Contact us Blog>Technology>OpenSearch\\u00ae 2.11 Is Now Available on the Instaclustr Managed Platform\\u202f OpenSearch\\u00ae 2.11 Is Now Available on the Instaclustr Managed Platform\\u202f January 12, 2024 | By Alex Bunday OpenSearch\\u00ae version 2.11 has now been released to the Instaclustr Managed Platform! This release brings a number of enhancements and improvements to OpenSearch. OpenSearch 2.11 resolves two vulnerabilities, CVE-2023-45807 and GHSA-8wx3-324g-w4qq. CVE-2023-45807 relates to a vulnerability found in multi-tenanted OpenSearch Dashboard deployments. GHSA-8wx3-324g-w4qq relates to an issue with how OpenSearch handled requests on the HTTP layer. You can find out more about these vulnerabilities, how we assessed them, and mitigation approaches on our security advisory blog post. One of the key highlights of this new release is the update to OpenSearch Dashboards. An entirely new user interface has been implemented, providing the same functionality but with improved usability and an updated look and feel. You can find out more about what has been changed here. Looking under the hood, this new release brings some solid enhancements. The OpenSearch Index Management Plugin now provides a unique ID to each rollup job to help with debugging, and users of the k-NN tool can flush k-NN indices out of the cache via the API. The OpenSearch Security Plugin has also been improved with added authorization in the REST layer, making queries more secure. And lastly, customers can now send OpenSearch notifications to Microsoft Teams. This latest version of OpenSearch also comes with new and experimental features that we are actively testing for future use on the Instaclustr Managed Platform. These features include the Neural Search Plugin (which turns text into vectors that can be stored and searched), and remote backed indices (which automatically creates backups of all index transactions and sends them to remote storage, providing a cost-effective solution for reducing the risk of data loss). We will have more news for you on these features in future updates. Customers of the Instaclustr Managed Platform can now begin deploying OpenSearch 2.11 on new clusters through the Console, API, or Terraform. For existing clusters, customers can contact our Support team to upgrade at [email protected]. For new customers, you can spin up an OpenSearch cluster for free through our customer console now. If you have any questions about this update or OpenSearch in general, please contact our friendly team at any time. About the author Alex Bunday | Product Manager Alex Bunday is a Product Manager with a strong focus on security and search within the Instaclustr Managed Platform, driving value through innovative solutions in the open source community. With expertise in managing product lifecycles and engaging stakeholders, Alex leverages data-driven insights to continuously improve and deliver impactful results. His collaborative approach empowers teams to develop and ship enhancements that meet customer needs and strengthen product offerings. Get the latest articles for open source In your inbox Sign up now Related content Zero Downtime Migration to Instaclustr Yes, we can migrate existing Cassandra clusters to Instaclustr without any downtime. Here's what to expect from the process... Read more Workflow Comparison: Uber Cadence vs Netflix Conductor When choosing what\\u2019s right for your company\\u2019s opensource workflow needs it is important to know the difference and similarities ... Read more Will Your Cassandra Database Project Succeed?: The New Stack Open source Apache Cassandra\\u00ae continues to stand out as an enterprise-proven solution for organizations seeking high availability... Read more \\u00d7 Sign up to our Newsletter Platform + Explore our platform Security and trust Hosting AI Stream Apache Kafka\\u00ae Kafka\\u00ae Connect Store PostgreSQL\\u00ae Apache Cassandra\\u00ae Analyze ClickHouse\\u00ae Search OpenSearch Orchestrate Cadence Column 2 Pricing + Explore our pricing Services + Support Professional services Training About + About us Customers Careers Our commitment to open source Resources + Sign up Documentation Quick start videos Integrations Support portal Blog Events Content library Glossary Stream Apache Kafka\\u00ae Store PostgreSQL\\u00ae Apache Cassandra\\u00ae Valkey\\u2122 Analyze ClickHouse\\u00ae Apache Spark\\u2122 Search OpenSearch Data infrastructure Vector search Data streaming Policies + Terms of service Security and trust Security policy Support inclusions Subscription specifications Service-level agreements Cookie settings Privacy policy Platform + Explore our platform Security and trust Hosting AI Stream Apache Kafka\\u00ae Kafka\\u00ae Connect Store PostgreSQL\\u00ae Apache Cassandra\\u00ae Analyze ClickHouse\\u00ae Search OpenSearch Orchestrate Cadence Pricing Explore our pricing Services + Support Professional services Training About + About us Customers Careers Our commitment to open source Resources + Sign up Documentation Quick start videos Integrations Support portal Blog Events Content library Glossary Stream Apache Kafka\\u00ae Store PostgreSQL\\u00ae Apache Cassandra\\u00ae Valkey\\u2122 Analyze ClickHouse\\u00ae Apache Spark\\u2122 Search OpenSearch Data infrastructure Vector search Data streaming Policies + Terms of service Security and trust Security policy Support inclusions Subscription specifications Service-level agreements Cookie settings Privacy policy \\u00a92025 NetApp Copyright. NETAPP, the NETAPP logo, Instaclustr and the marks listed at https://www.netapp.com/TM are trademarks of NetApp, Inc. Other company and product names may be trademarks of their respective owners. Apache\\u00ae, Apache Cassandra\\u00ae, Apache Kafka\\u00ae, Apache Spark\\u2122, and Apache ZooKeeper\\u2122 are trademarks of The Apache Software Foundation.\\\"},{\\\"url\\\":\\\"https://opensearch.org/blog/opensearch-performance-improvements/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to main content Search Close Search search Menu About Foundation Governing Board Charter Meeting Calendar Platform Platform OpenSearch CoreOpenSearch is a powerful search and analytics engine built on Apache Lucene. OpenSearch DashboardsOur data visualization toolset is a flexible, fully integrated solution for visually exploring and querying your data. OpenSearch Data PrepperA server-side data collector designed to enrich, transform, and aggregate data for downstream analytics with Opensearch. OpenSearch Vector EnginePower machine learning and generative AI applications with a high-performance database designed for the way AI understands data. Capabilities Machine learning and AI Vector Search Anomaly Detection Search E-Commerce Document Search Search Relevance Observability Performance Monitoring Log Analysis Security Analytics Threat Intelligence Event Correlation Performance Benchmarks View key performance metrics across different workloads View Data Roadmap Image OpenSearch Project RoadmapExplore our official project roadmap on GitHub Community OpenSearch Community ForumFind answers to your questions, help others in the community, and join the conversation. EventsCommunity Meetings, Development Backlog & Triage, in-person, and virtual events. AmbassadorsAmbassadors Community leaders who share knowledge and grow OpenSearch. Solutions ProvidersFind open-source providers offering solutions and services. ProjectsHighlights of projects built by the community. User GroupsJoin the OpenSearch Project Meetup Network Community Resources SlackSpeak with other developers. GitHub Project OrganizationJoin us for in-person and virtual events to learn the latest about the project. OpenSearchCon Image OpenSearchCon North AmericaSeptember 8-10, 2025 | San Jose, CA OpenSearchCon India3-4 June 2025 | Bengaluru, India OpenSearchCon Korea2025 November 4 | Seoul, South Korea OpenSearchCon EuropeView Videos & Slides Documentation Documentation Library OpenSearch and DashboardsBuild your OpenSearch solution using core tooling and visualizations. OpenSearch Data PrepperFilter, mutate, and sample your data for ingestion into OpenSearch. Migration AssistantBegin your transition to OpenSearch with our migration toolkit Documentation Library II OpenSearch BenchmarkMeasure performance metrics for your OpenSearch cluster. ClientsInteract with OpenSearch from your application using language APIs. Blog & News Blog Announcements Case Studies News Authors Downloads search Blog An update on the OpenSearch Project\\u2019s continued performance progress through version 2.11 By Saurabh Singh, Pallavi Priyadarshini, Dagney Braun, Rishabh SinghJanuary 10, 2024June 18th, 2025No Comments OpenSearch is a community-driven, open-source search and analytics suite used by developers to ingest, search, visualize, and analyze data. Introduced in January 2021, the OpenSearch Project originated as an open-source fork of Elasticsearch 7.10.2. OpenSearch 1.0 was released for production use in July 2021 and is licensed under the Apache License, Version 2.0 (ALv2), with the complete codebase published to GitHub. The project has consistently focused on improving the performance of its core open-source engine for high-volume indexing and low-latency search operations. OpenSearch aims to provide the best experience for every user by reducing latency and improving efficiency. In this blog post, we\\u2019ll share a comprehensive view of strategic enhancements and performance features that OpenSearch has delivered to date. Additionally, we\\u2019ll provide a look forward at the Performance Roadmap. We\\u2019ll compare the core engine performance of the latest OpenSearch version (OpenSearch 2.11) to the state just before the OpenSearch fork, with a specific focus on the advancements made since then. With this goal in mind, we have chosen Elasticsearch 7.10.2 to represent the baseline from which OpenSearch was forked, allowing us to measure all changes that have been delivered after the fork (in OpenSearch 1.0\\u20132.11). These improvements were made in collaboration with the community; thus, the OpenSearch Project is actively seeking to enhance community engagement, specifically in the area of performance improvement. Performance improvements to date OpenSearch performance improvements can be categorized into three high-level buckets: Indexing performance Query performance Storage The following image summarizes OpenSearch performance improvements since launch. Log analytics workloads are typically indexing heavy, often relying on specific resource-intensive queries. In contrast, search workloads have a more balanced distribution between indexing and query operations. Based on the analysis we\\u2019ll detail below comparing Elasticsearch 7.10.2 to OpenSearch 2.11, we have seen a 25% improvement in indexing throughput, a 15\\u201398% decrease in query latencies among some of the most popular query types, and, now with Zstandard compression, a 15\\u201330% reduction in on-disk data size. Indexing performance investments Some of the key OpenSearch features launched this year delivered efficiency improvements in indexing performance. OpenSearch rearchitected the way indexing operations are performed in order to deliver segment replication\\u2014a physical replication method that replicates index segments rather than source documents. Segment replication, a new replication strategy built on Lucene\\u2019s Near-Real-Time (NRT) Segment Index Replication API, was released as generally available in OpenSearch 2.7. Segment replication showed increased ingestion rate throughput of up to 25% when compared to default document replication. You can find a more detailed look at segment replication in this blog post. In version 2.10, OpenSearch introduced remote-backed storage, allowing users to directly write segments to object storage, such as Amazon Simple Storage Service (Amazon S3) or Oracle Cloud Infrastructure (OCI) Object Storage, to improve data durability. With remote-backed storage, in addition to storing data on a local disk, all the ingested data is stored in the configured remote store. At every refresh, the remote store also automatically becomes a point-in-time recovery point, helping users achieve a recovery point objective (RPO) of zero with the same durability properties of the configured remote store. To learn more, see this blog post. Query performance investments OpenSearch supports an extensive array of query types for different use cases, from comprehensive search capabilities to a broad spectrum of aggregations, filtering options, and sorting functionalities. One of the major query performance areas in which OpenSearch has improved is in helping vector queries perform at scale, given the rise in vector search popularity. OpenSearch\\u2019s vector engine offers fast, billion-scale vector searches with efficient latency and recall. Recent additions like scalar and product quantization reduced the cluster memory footprint by up to 80%. The incorporation of native libraries (nmslib and faiss) and HNSW with SIMD instructions has expedited vector indexing and search queries. At a large scale, tested with billions of documents, OpenSearch delivered a roughly 30% lower latency compared to Lucene ANN searches. For more information, see this partner highlight. We\\u2019ve also continued to invest broadly in core query performance for popular query types used for log analytics, time-series data, and search. OpenSearch has demonstrated significant improvement since the fork from Elasticsearch 7.10.2 for many query types. The benchmarking we performed showed a 15%\\u201398% increase in performance across popular query operations such as match all, range queries, aggregation queries, and full-text queries. You can review key benchmarking findings in the following sections. Storage investments Storage is another major factor that affects the overall efficiency of log analytics and search workloads. In OpenSearch 2.9 and later, customers can use Zstandard compression, resulting in a 30% reduction in on-disk data size while maintaining a near-identical CPU utilization pattern compared to the default compression. Some of the ongoing work, such as the addition of a match_only_text field (see #11039), has shown a promising reduction of about 25% in data on disk, primarily with text data field optimization, and should be available to users in the upcoming OpenSearch 2.12 release. Measured performance improvements To compare performance between Elasticsearch 7.10.2 and OpenSearch 2.11, we ran query operations for widely used scenarios in log analytics, time series, and search. We ran the queries across clusters running each version and documented the resulting performance. The following subsections provide the key findings from this exercise. Log analytics For log analytics use cases, we used the http_logs workload from OpenSearch Benchmark\\u2014a macro-benchmark utility within the OpenSearch Project\\u2014to replicate some of the common query operations. Here are the key highlights: match_all queries with sorting showed a more than 20x performance boost across the board because of multiple improvements made in the area (see #6321 and #7244) and other Lucene enhancements. Queries for ascending and descending sort-after-timestamp saw a significant performance improvement of up to 70x overall. The optimizations introduced (such as #6424 and #8167) extend across various numeric types, including int, short, float, double, date, and others. Other popular queries, such as search_after, saw about a 60x reduction in latency, attributed to the improvements made in the area involving optimally skipping segments during search (see #7453). The search_after queries can be used as the recommended alternative to scroll queries for a better search experience. Implementation support for match_only_text field optimization on storage and indexing/search latency for text queries is in progress (see #11039). Time series In the context of aggregations over range and time-series data, we used the nyc_taxis and http_logs workloads from OpenSearch Benchmark to benchmark various popular use cases. Here are the key highlights: Range queries, popular for aggregation use cases, exhibited about a 50%\\u201375% improvement, attributed to system upgrades such as Lucene (from v8.8 in Elasticsearch 7.10.2 to v9.7 in OpenSearch 2.11) and JDK (from JDK15 in Elasticsearch 7.10.2 to JDK17 in OpenSearch 2.11). Hourly aggregations and multi-term aggregations also demonstrated improvement, varying from 5% to 35%, attributed to the time-series improvements discussed previously. date_histograms and date_histogram_agg queries exhibited either comparable or slightly decreased performance, ranging from 5% to around 20% in multi-node environments. These issues are actively being addressed as part of ongoing project efforts (see #11083). For date histogram aggregations, there are upcoming changes aiming to improve performance by rounding down dates to the nearest interval (such as year, quarter, month, week, or day) using SIMD (see #11194). Search In the realm of text queries, we used pmc workloads from OpenSearch Benchmark to emulate various common use cases. Here are the noteworthy highlights: Phrase and term queries for text search showed improved latency, with a 25% to 65% reduction, underscoring their improved effectiveness. Popular queries related to scrolling exhibited about 15% lower latency, further improving the overall user experience. Additional optional performance-enhancing features available in version 2.11 The core engine optimizations discussed in the previous sections are available by default. Additionally, OpenSearch 2.11 includes a few key performance-enhancing features that can be optionally enabled by users. These features were not available in prior versions, so we separately benchmarked performance with those features individually enabled, resulting in the following findings: LogByteSize merge policy: Showed a 40\\u201370% improvement in ascending and descending sort queries, which is advantageous for time-series data with timestamp sorting and minimal timestamp overlap between segments. Zstandard compression: This addition empowers OpenSearch users with the new Zstandard compression codecs for their data, resulting in a 30% reduction in on-disk data size while maintaining a near-identical CPU utilization pattern compared to the default compression. Concurrent segment search: Enabling every shard-level request to concurrently search across segments during the query phase resulted in latency reduction across multiple query types. Aggregate queries showed a 50%\\u201370% improvement, range queries showed a 65% improvement, and aggregation queries with hourly data aggregations showed a 50% improvement. Future roadmap The OpenSearch Project remains steadfast in its commitment to continuously improving the core engine performance in search, ingestion, and storage operations. The OpenSearch Project roadmap on GitHub is constantly evolving, and we are excited to share it with you. This roadmap places a special emphasis on the core engine advancements while also encompassing critical areas like benchmarking and query visibility. As part of our ongoing commitment, we plan to consistently update this roadmap with both short- and long-term improvement plans. We\\u2019re keeping performance excellence at the forefront of our investments, and OpenSearch users can anticipate a series of impactful improvements in new releases in 2024, starting with OpenSearch 2.12. In the upcoming releases, we will continue to improve the core engine by targeting specific query types. We will also undertake broad strategic initiatives to further enhance the core engine through Protobuf integration, query rewrites, tiered caching, and SIMD and RUST implementations. In addition to improving the core engine, we are committed to improving OpenSearch tooling capabilities. One such improvement that we\\u2019re currently working on is the query insights functionality, which helps identify the top N queries that impact performance. Additionally, OpenSearch is working on making benchmarks easier for community members to use. For a comprehensive list of investments and additional improvements, or to provide feedback, please check out the OpenSearch Performance Roadmap on GitHub. This concludes the main summary of OpenSearch performance improvements to date. The following appendix sections provide the benchmarking details for readers interested in replicating any run. Appendix: Detailed execution and results If you\\u2019re interested in the details of the performance benchmarks we used, exploring the methodologies behind their execution, or examining the comprehensive results, keep reading. For OpenSearch users interested in establishing benchmarks and replicating these runs, we\\u2019ve provided comprehensive setup details alongside each result. This section provides the core engine performance comparison between the latest OpenSearch version (OpenSearch 2.11) and the state just before the OpenSearch fork, Elasticsearch 7.10.2, with a mid-point performance measurement on OpenSearch 2.3. OpenSearch Benchmark and workloads OpenSearch Benchmark serves as a macro-benchmark utility within the OpenSearch Project. With the help of this tool, OpenSearch users and developers can generate and visualize performance metrics from an OpenSearch cluster for various purposes, including: Monitoring the overall performance of an OpenSearch cluster. Evaluating the benefits of and making decisions about upgrading the cluster to a new version. Assessing the potential impact on the cluster resulting from changes to the workflows, such as modifications to the index mappings or changes in queries. The OpenSearch Benchmark workloads are comprised of one or multiple benchmarking scenarios. A workload typically includes the ingestion of one or more data corpora into indexes and a collection of queries and operations that are executed as a part of the benchmark. We used the following workloads for performance evaluation, encompassing aspects such as text/term queries, sorting, aggregations, histograms, and ranges: HTTP logs workload: This workload is based on web server logs from the 1998 Football World Cup. It is used for evaluating the performance of (web) server logs, which is most in line with the OpenSearch log analytics use case. NYC taxis workload: This workload contains the rides taken in yellow taxis in New York in 2015. It is used for evaluating the performance of highly structured data. It is useful for aggregation and date histogram use cases for time-series data. PMC workload: This workload contains data retrieved from PubMed Central (PMC). It is used for evaluating the performance of full-text search, in line with the OpenSearch search use case. The configurations specific to the setup for each evaluation are provided along with the results in the following sections. Comparative baseline analysis: Elasticsearch 7.10.2 vs. OpenSearch 2.3 vs. OpenSearch 2.11 We compared the performance of Elasticsearch 7.10.2 (pre-fork), OpenSearch 2.3 (an interim release), and OpenSearch 2.11 (latest version at the time of testing). This analysis covers three workloads (http-logs, nyc-taxis, and pmc) used to assess performance across different use cases. The goal is to provide comparable core engine performance metrics since the Elasticsearch 7.10.2 fork. The benchmarks in the following sections show averages from 7 days of data, generated during nightly runs using OpenSearch Benchmark, intentionally excluding outliers. In the detailed results section, each table contains a percentage improvement column. This column emphasizes the improvements to OpenSearch 2.11 over the previous releases, with positive values indicating improvement and negative values indicating regression. Detailed results: Elasticsearch 7.10.2 vs. OpenSearch 2.3 vs. OpenSearch 2.11\\u2014deep dive into single-shard performance Objective: To eliminate variables introduced at the coordination level and concentrate on data node query performance. Setup: 1 data node (r5.xlarge) with 32 GB RAM and 16 GB heap. Index settings: 1 shard and 0 replicas. http_logs workload results: The following table provides a benchmark comparison for the http_logs workload between Elasticsearch 7.10.2, OpenSearch 2.3, and OpenSearch 2.11. It includes the 90th percentile of took time latency measurements for each (p90) and the observed percentage improvements. Operations ES 7.10.2 (p90_value) OS 2.3.0 (p90_value) OS 2.11.0 (p90_value) OS 2.11.0 improvement (vs. OS 2.3.0) OS 2.11.0 improvement (vs. ES 7.10.2) 200s-in-range 13 5 5.33 -7% 59% 400s-in-range 2.73 2 2.53 -26% 7% asc_sort_size 4,262.2 4,471 4.6 100% 100% asc_sort_timestamp 10.73 785 6.47 99% 40% asc_sort_with_after_timestamp 4,576 5,368 34.47 99% 99% default 2.91 3 3 0% -3% desc_sort_size 3,800.4 3,994 9.53 100% 100% desc_sort_timestamp 39.18 5,228 58.8 99% -50% desc_sort_with_after_timestamp 5,824.27 6,925 87.8 99% 98% hourly_agg 9,387.55 9,640 9,112.4 5% 3% multi_term_agg N/A 14,703 9,669.8 34% N/A range 28.18 12 13.4 -12% 52% scroll 213.91 173 197.4 -14% 8% term 3.45 3 3.4 -13% 1% nyc_taxis workload results: The following table provides a benchmark comparison for the nyc_taxis workload between Elasticsearch 7.10.2, OpenSearch 2.3, and OpenSearch 2.11. It includes the 90th percentile of took time latency measurements for each (p90) and the observed percentage improvements. Operations ES 7.10.2 (p90_value) OS 2.3.0 (p90_value) OS 2.11.0 (p90_value) OS 2.11.0 improvement (vs. OS 2.3.0) OS 2.11.0 improvement (vs. ES 7.10.2) autohisto_agg 559.13 596 554.6 7% 1% date_histogram_agg 562.4 584 545.07 7% 3% default 4.73 6 5.07 15% -7% distance_amount_agg 13181 12796 15285 -19% -16% range 654.67 213 213.4 0% 67% pmc workload results: The following table provides a benchmark comparison for the pmc workload between Elasticsearch 7.10.2, OpenSearch 2.3, and OpenSearch 2.11. It includes the 90th percentile of took time latency measurements for each (p90) and the observed percentage improvements. Operations ES 7.10.2 (p90_value) OS 2.3.0 (p90_value) OS 2.11.0 (p90_value) OS 2.11.0 improvement (vs. OS 2.3.0) OS 2.11.0 improvement (vs. ES 7.10.2) articles_monthly_agg_cached 2 2 2.4 -20% -20% articles_monthly_agg_uncached 26.5 27 27.8 -3% -5% default 6.5 6 5.2 13% 20% phrase 8.25 6 6.4 -7% 22% scroll 894.5 857 753.8 12% 16% term 9 5 5.6 -12% 38% Detailed results: Elasticsearch 7.10.2 vs. OpenSearch 2.3 vs. OpenSearch 2.11\\u2014deep dive into multiple-shard performance Objective: To introduce the coordination layer with parallel search operations extending across multiple nodes with primary shards. Setup: 3 data nodes (r5.xlarge) with 32 GB RAM and 16 GB heap. 3 cluster manager nodes (c5.xlarge) with 8 GB RAM and 4 GB heap. Index settings: 3 shards and 0 replicas. http_logs workload results: The following table provides a benchmark comparison for the http_logs workload between Elasticsearch 7.10.2, OpenSearch 2.3, and OpenSearch 2.11. It includes the 90th percentile of took time latency measurements for each (p90) and the observed percentage improvements. Operations ES 7.10.2 (p90_value) OS 2.3.0 (p90_value) OS 2.11.0 (p90_value) OS 2.11.0 improvement (vs. OS 2.3.0) OS 2.11.0 Improvement (vs. ES 7.10.2) 200s-in-range 9.8 6 6.85 -14% 30% 400s-in-range 5.8 5 5.5 -10% 5% asc_sort_size 1,451.13 1,602 8.35 99% 99% asc_sort_timestamp 10.4 291.5 10.58 96% -2% asc_sort_with_after_timestamp 1,488.25 1,910.5 25.38 99% 98% default 6 6 6.3 -5% -5% desc_sort_size 1,281.3 1,431 13.91 99% 99% desc_sort_timestamp 34.4 1,878.5 91.9 95% -167% desc_sort_with_after_timestamp 1,887.7 2,480 85.78 97% 95% hourly_agg 2,566.9 3,115 2,937 6% -14% multi_term_agg N/A 5205 3603 31% N/A range 18.1 9 8.95 1% 51% scroll 340.1 267 323.85 -21% 5% term 5.8 6 6.45 -8% -11% nyc_taxis workload results: The following table provides a benchmark comparison for the nyc_taxis workload between Elasticsearch 7.10.2, OpenSearch 2.3, and OpenSearch 2.11. It includes the 90th percentile of took time latency measurements for each (p90) and the observed percentage improvements. Operations ES 7.10.2 (p90_value) OS 2.3.0 (p90_value) OS 2.11.0 (p90_value) OS 2.11.0 Improvement (vs. OS 2.3.0) OS 2.11.0 Improvement (vs. ES 7.10.2) autohisto_agg 208.92 217 212.93 2% -2% date_histogram_agg 198.77 218 209.4 4% -5% default 8.46 7 9.67 -38% -14% distance_amount_agg 4,131 4,696 5,067.4 -8% -23% range 281.62 73 79.53 -9% 72% pmc workload results: The following table provides a benchmark comparison for the pmc workload between Elasticsearch 7.10.2, OpenSearch 2.3, and OpenSearch 2.11. It includes the 90th percentile of took time latency measurements for each (p90) and the observed percentage improvements. Operations ES 7.10.2 (p90_value) OS 2.3.0 (p90_value) OS 2.11.0 (p90_value) OS 2.11.0 improvement (vs. OS 2.3.0) OS 2.11.0 improvement (vs. ES 7.10.2) articles_monthly_agg_cached 3.55 3 3.71 -24% -5% articles_monthly_agg_uncached 12 12 12.43 -4% -4% default 9 6 6.79 -13% 25% phrase 8.18 7 7.14 -2% 13% scroll 755.18 593 642.79 -8% 15% term 9 7 7.14 -2% 21% Elevating performance with new features available in OpenSearch 2.11 The following sections present OpenSearch 2.11 features that improve performance. LogByteSize merge policy In the realm of log analytics, the Tiered merge policy has been a cornerstone of efficient shard merges. In OpenSearch 2.11 we introduced the LogByteSize merge policy. This new approach consistently merges adjacent segments, proving especially advantageous for time-series data characterized by timestamp sorting and minimal timestamp overlap between segments. The following are the key findings from this exercise. Timestamp queries with ascending sort had an improvement of over 75%. This transformation is attributable to the impactful contribution of enhancement #9241. About a 40% enhancement in descending sort timestamp queries, surpassing the Tiered merge policy. Use cases around ascending and descending sort with an after timestamp saw regression, which is a known case for smaller workloads with this merge policy. Other common use cases for log analytics, such as multi-term aggregation, hourly_agg, range, and scroll queries exhibited comparable performance, with a subtle improvement of less than 5% attributed to the new segment merge policy. Detailed results: OS 2.11 Tiered merge policy vs OS 2.11 LogByteSize merge policy Setup: 3 data nodes (r5.xlarge) with 32 GB RAM and 16 GB heap. 3 cluster manager nodes (c5.xlarge) with 8 GB RAM and 4 GB heap. Index settings: 3 shards and 0 replicas, max_segment_size: 500 MB, refresh_interval: 1 s. http_logs workload results: The following table provides a benchmark comparison for the http_logs workload for OpenSearch 2.11 with the Tiered merge policy vs. the LogByteSize merge policy. It includes the 90th percentile of took time latency measurements for each (p90) and the observed percentage improvements. Operations OS 2.11\\u2014Tiered (p90_value) OS 2.11\\u2014LogByteSize (p90_value) % improvement (vs. Tiered merge policy) 200s-in-range 6 6 0% 400s-in-range 5 6 -20% asc_sort_size 9 8 11% asc_sort_timestamp 34 8 76% asc_sort_with_after_timestamp 13 68 -423% default 7 6 14% desc_sort_size 11 10 9% desc_sort_timestamp 29 17 41% desc_sort_with_after_timestamp 35 130 -271% hourly_agg 2816 2809 0% multi_term_agg 2739 2800 -2% range 7 8 -14% scroll 349 344 1% term 7 6 14% Zstandard codec compression This addition empowers OpenSearch users with the new Zstandard compression codecs for their data. Users can specify zstd or zstd_no_dict in the index.codec setting during index creation or modify the codecs for existing indexes. OpenSearch will continue to support the existing zlib and lz4 codecs, with the default as lz4. The following sections contain benchmarking results representing the average of 5 days of data from nightly runs using OpenSearch Benchmark. Highlights Here are the key highlights: A notable increase in the ingestion throughput, ranging from 5% to 8%, attributed to the new zstd codec. This enhancement owes its success to codec-related pull requests (#7908, #7805, and #7555). About a 30% reduction in on-disk data size, surpassing the default lz4 codec for unparalleled efficiency, all while maintaining a near-identical CPU utilization pattern compared to the default compression. The search p90 latencies remained virtually unchanged, with negligible differences of less than 2% in a few areas. Detailed results: OpenSearch 2.11 default (lz4) compression vs. OpenSearch 2.11 zstd compression using multiple shards Setup: 3 data nodes (r5.xlarge) with 32 GB RAM and 16 GB heap. 3 cluster manager nodes (c5.xlarge) with 8 GB RAM and 4 G heap. Index settings: 3 shards and 0 replicas. Indexing throughput results (docs/sec): The following table provides an indexing throughput comparison of the http_logs and nyc_taxis workloads for OpenSearch 2.11 with the default codec vs. the zstd codec enabled and includes the percentage improvement observed when using zstd. Workload OS 2.11\\u2014default codec (mean_value) OS 2.11\\u2014zstd codec (mean_value) % improvement (vs. default codec) http_logs 209,959.75 220,948 5% nyc_taxis 118,123.5 127,131 8% nyc_taxis search workload results: The following table illustrates a benchmark comparison for the nyc_taxis workload for OpenSearch 2.11 with default codec vs. zstd codec enabled, including percentage improvement. Operations OS 2.11\\u2014default codec (p90_value) OS 2.11\\u2014zstd codec (p90_value) % improvement (vs. default codec) autohisto_agg 216.75 208 4% date_histogram_agg 211.25 205.5 3% default 8 7.5 6% distance_amount_agg 5,012 4,980 1% range 74.5 77.5 -4% Detailed results: Index data size on disk (bytes) with zstd compression using a single shard Setup: OpenSearch 2.11.0, single node (r5.xlarge) with 32 GB RAM and 16 GB heap. Index settings: 1 shard and 0 replicas. Data size of disk results (bytes): The following table illustrates a benchmark comparison of the on-disk data size for the http_logs and pmc workloads for OpenSearch 2.11 with default vs. zstd codec enabled, including percentage improvement. Default compression (bytes) ZSTD (bytes) ZSTD_NO_DICT (bytes) ZSTD improvement (vs. default codec) ZSTD_NO_DICT improvement (vs. default codec) http_logs 20,056,770,878.5 15,800,734,037 16,203,187,551 21% 19% pmc 20,701,211,614.5 15,608,881,718.5 15,822,040,185 25% 24% Concurrent search improvements (Experimental in 2.11) OpenSearch users can now achieve better execution speed with concurrent segment search, launched as experimental in OpenSearch 2.11. By default, OpenSearch processes a request sequentially across all the data segments on each shard during the query phase of a search request execution. With concurrent search, every shard-level request can concurrently search across segments during the query phase. Each shard divides its segments into multiple slices, where each slice serves as a unit of work executed in parallel on a separate thread. Therefore, the slice count governs the maximum degree of parallelism for a shard-level request. After all the slices finish their tasks, OpenSearch executes a reduce operation on the slices, merging them to generate the final result for the shard-level request. The following benchmarking results show the benefits of concurrent search in action. These are the averages of data generated from over 4 days of nightly runs using OpenSearch Benchmark. Highlights Here are the key highlights: An increase in performance with aggregate queries on workloads such as the nyc_taxis workload, showcasing an improvement ranging between 50% and 70% over the default configuration. The log analytics use cases for range queries demonstrated an improvement of around 65%. Aggregation queries with hourly data aggregations, such as those for the http_logs workload, demonstrated a boost of up to 50% in performance. Comparable latencies for auto or date histogram queries, with no noteworthy improvement or regression in performance. multi_term_agg, asc_sort_size, dec_sort_size, and scroll queries showed regression. To delve deeper into the intricacies, the concurrent search contributors are proactively addressing this in the upcoming OpenSearch 2.12 GA release. Detailed results: OpenSearch 2.11 with concurrent search enabled vs. disabled Setup: OpenSearch 2.11.0 single node (r5.2xlarge) with 64 GB RAM and 32 GB heap. Index settings: 1 shard and 0 replicas. nyc_taxis workload results: The following table provides a benchmark comparison of the nyc_taxis workload for OpenSearch 2.11 with concurrent search disabled and enabled (with 0 slices and with 4 slices). It includes the 90th percentile of took time latency measurements for each (p90) and the observed percentage improvements. Operations CS disabled (p90_value) CS enabled\\u20140-slice (p90_value) CS enabled\\u20144-slice (p90_value) % improvement (with 0 slices) % improvement (with 4 slices) autohisto_agg 575 295 287 49% 50% date_histogram_agg 563 292 288 48% 49% default 6 6 5 0% 17% distance_amount_agg 15,043 4,691 4744 69% 68% range 201 73 77 64% 62% http_logs workload results: The following table provides a benchmark comparison of the http_logs workload for OpenSearch 2.11 with concurrent search disabled and enabled (with 0 slices and with 4 slices). It includes the 90th percentile of latency measurements for each (p90) and the observed percentage improvements. Operations CS disabled (p90_value) CS enabled\\u20140-slice (p90_value) CS enabled\\u20144-slice (p90_value) % improvement (with 0 slices) % improvement (with 4 slices) 200s-in-range 6 4 4 33% 33% 400s-in-range 2 2 2 0% 0% asc-sort-timestamp-after-force-merge-1-seg 20 20 22 0% -10% asc-sort-with-after-timestamp-after-force-merge-1-seg 85 86 86 -1% -1% asc_sort_size 3 5 5 -67% -67% asc_sort_timestamp 4 4 4 0% 0% asc_sort_with_after_timestamp 34 33 34 3% 0% default 4 4 3 0% 25% desc-sort-timestamp-after-force-merge-1-seg 64 62 67 3% -5% desc-sort-with-after-timestamp-after-force-merge-1-seg 67 66 68 1% -1% desc_sort_size 6 91 9 -1417% -50% desc_sort_timestamp 26 34 28 -31% -8% desc_sort_with_after_timestamp 63 61 63 3% 0% hourly_agg 8180 3832 4034 53% 51% multi_term_agg 9818 40015 54107 -308% -451% range 15 12 13 20% 13% scroll 179 375 212 -109% -18% term 3 3 3 0% 0% We would like to take this opportunity to thank the OpenSearch core developers for their contributions to the technical roadmap. We sincerely appreciate all the suggestions from Michael Froh, Andriy Redko, Jonah Kowall, Amitai Stern, Jon Handler, Prabhakar Sithanandam, Mike McCandless, Anandhi Bumstead, Eli Fisher, Carl Meadows, and Mukul Karnik in writing this blog post. Credits to Fanit Kolchina and Nathan Bower for editing and Carlos Canas for creating the graphics. Authors Saurabh Singh Saurabh is a Software Development Manager at AWS leading the core search, release, and benchmarking areas of the OpenSearch Project. His passion lies in finding solutions for intricate challenges within large-scale distributed systems. View all posts Pallavi Priyadarshini Pallavi Priyadarshini is a Senior Engineering Manager at the OpenSearch Project leading the development of high-performing and scalable technologies for search, security, releases, and dashboards. View all posts Dagney Braun Dagney Braun is a Principal Product Manager at AWS working on the OpenSearch Project. View all posts Rishabh Singh Rishabh Singh is a Systems Development Engineer at AWS working on the OpenSearch Project. He is passionate about infrastructure automation, platform development, and improving the developer experience. View all posts Share Subscribe for updates, event info, and the latest community news OpenSearch is a community-driven, Apache 2.0-licensed open source search and analytics suite that makes it easy to ingest, search, visualize, and analyze data. linkedin github slack youtube mastodon bluesky x-twitter Participate Code of Conduct Forum Project Repo Community Repo Meetup Connect Providers Become a Provider Find a Provider Resources About FAQ Release Schedule Maintenance Policy Documentation Getting Started Testimonials Trademark & Brand Privacy \\u00a9 Copyright The Linux Foundation. The OpenSearch Project is a project of The Linux Foundation. For web site terms of use, trademark policy and other policies applicable to The OpenSearch Project please see Linux Foundation Policies. The OpenSearch Project supports the OpenSearch open source project, which has been established as OpenSearch Project a Series of LF Projects, LLC. For policies applicable to the OpenSearch Project a Series of LF Projects, LLC, please see LF Projects, LLC Policies, Privacy Policy, Terms of Use and the OpenSearch Trademark Policy. Close Menu About Foundation Governing Board Charter Meeting Calendar Platform Platform OpenSearch CoreOpenSearch is a powerful search and analytics engine built on Apache Lucene. OpenSearch DashboardsOur data visualization toolset is a flexible, fully integrated solution for visually exploring and querying your data. OpenSearch Data PrepperA server-side data collector designed to enrich, transform, and aggregate data for downstream analytics with Opensearch. OpenSearch Vector EnginePower machine learning and generative AI applications with a high-performance database designed for the way AI understands data. Capabilities Machine learning and AI Vector Search Anomaly Detection Search E-Commerce Document Search Search Relevance Observability Performance Monitoring Log Analysis Security Analytics Threat Intelligence Event Correlation Performance Benchmarks View key performance metrics across different workloads View Data Roadmap Image OpenSearch Project RoadmapExplore our official project roadmap on GitHub Community OpenSearch Community ForumFind answers to your questions, help others in the community, and join the conversation. EventsCommunity Meetings, Development Backlog & Triage, in-person, and virtual events. AmbassadorsAmbassadors Community leaders who share knowledge and grow OpenSearch. Solutions ProvidersFind open-source providers offering solutions and services. ProjectsHighlights of projects built by the community. User GroupsJoin the OpenSearch Project Meetup Network Community Resources SlackSpeak with other developers. GitHub Project OrganizationJoin us for in-person and virtual events to learn the latest about the project. OpenSearchCon Image OpenSearchCon North AmericaSeptember 8-10, 2025 | San Jose, CA OpenSearchCon India3-4 June 2025 | Bengaluru, India OpenSearchCon Korea2025 November 4 | Seoul, South Korea OpenSearchCon EuropeView Videos & Slides Documentation Documentation Library OpenSearch and DashboardsBuild your OpenSearch solution using core tooling and visualizations. OpenSearch Data PrepperFilter, mutate, and sample your data for ingestion into OpenSearch. Migration AssistantBegin your transition to OpenSearch with our migration toolkit Documentation Library II OpenSearch BenchmarkMeasure performance metrics for your OpenSearch cluster. ClientsInteract with OpenSearch from your application using language APIs. Blog & News Blog Announcements Case Studies News Authors Downloads\\\"},{\\\"url\\\":\\\"https://docs.oracle.com/en-us/iaas/releasenotes/changes/69cff0e5-0db2-4f97-83d9-809559f0f141/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Oracle Cloud Infrastructure Documentation / Release Notes All Pages Skip to main content Search with OpenSearch now supports OpenSearch version 2.11 Services: Oracle Cloud Infrastructure Government Cloud, Search with OpenSearch Release Date: March 13, 2024 OCI Search with OpenSearch now supports OpenSearch version 2.11. The upgrade to OpenSearch version 2.11 comes with several improvements, including: Semantic search with custom models. Conversational search with external connectors to OCI Generative AI-hosted LLM models. Inline upgrade for minor version upgrades. Support for additional plugins, including reporting, query workbench, enhanced table. New clusters are created by default as OpenSearch 2.11 clusters. Existing clusters will still use previous version of OpenSearch, however you can upgrade them to version 2.11 using one of the following approaches: For OpenSearch 2.3 clusters, see Performing a Minor Build Version Upgrade for an OpenSearch Cluster For OpenSearch 1.2.4 clusters, see Upgrading an OpenSearch Cluster For more information: Search Service with OpenSearch OpenSearch Search with OpenSearch documentation Copyright \\u00a9 2025, Oracle and/or its affiliates. About Oracle Contact Us Legal Notices Terms of Use & Privacy Document Conventions\\\"}]}\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Search for current information\n",
    "parameters = {\n",
    "    \"question\": \"Latest features in OpenSearch 2.11\"\n",
    "}\n",
    "\n",
    "print(\"‚ùì Question: Latest features in OpenSearch 2.11\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "response = execute_agent(client, agent_id, parameters)\n",
    "\n",
    "print(\"\\nüì∞ Current Information:\")\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47efc600",
   "metadata": {},
   "source": [
    "## Step 7: Test Case 4 - Search for Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "207e77cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì Question: OpenSearch cluster sizing best practices\n",
      "============================================================\n",
      "\n",
      "üí° Best Practices:\n",
      "{\n",
      "  \"inference_results\": [\n",
      "    {\n",
      "      \"output\": [\n",
      "        {\n",
      "          \"name\": \"response\",\n",
      "          \"result\": \"{\\\"next_page\\\":\\\"https://duckduckgo.com/html?q=OpenSearch+cluster+sizing+best+practices&s=10&nextParams=&v=l&o=json&dc=11&api=d.js&vqd=4-325981505372936351747571540840411248409&kl=wt-wt\\\",\\\"items\\\":[{\\\"url\\\":\\\"https://docs.aws.amazon.com/opensearch-service/latest/developerguide/bp.html\\\",\\\"title\\\":\\\"Operational best practices for Amazon OpenSearch Service - Amazon OpenSearch Service\\\",\\\"content\\\":\\\"Operational best practices for Amazon OpenSearch Service - Amazon OpenSearch Service DocumentationAmazon OpenSearch ServiceDeveloper Guide Monitoring and alertingShard strategyStabilityPerformanceSecurityCost optimization Operational best practices for Amazon OpenSearch Service This chapter provides best practices for operating Amazon OpenSearch Service domains and includes general guidelines that apply to many use cases. Each workload is unique, with unique characteristics, so no generic recommendation is exactly right for every use case. The most important best practice is to deploy, test, and tune your domains in a continuous cycle to find the optimal configuration, stability, and cost for your workload. Topics Monitoring and alerting Shard strategy Stability Performance Security Cost optimization Sizing Amazon OpenSearch Service domains Petabyte scale in Amazon OpenSearch Service Dedicated coordinator nodes in Amazon OpenSearch Service Dedicated master nodes in Amazon OpenSearch Service Monitoring and alerting The following best practices apply to monitoring your OpenSearch Service domains. Configure CloudWatch alarms OpenSearch Service emits performance metrics to Amazon CloudWatch. Regularly review your cluster and instance metrics and configure recommended CloudWatch alarms based on your workload performance. Enable log publishing OpenSearch Service exposes OpenSearch error logs, search slow logs, indexing slow logs, and audit logs in Amazon CloudWatch Logs. Search slow logs, indexing slow logs, and error logs are useful for troubleshooting performance and stability issues. Audit logs, which are only available if you enable fine-grained access control to track user activity. For more information, see Logs in the OpenSearch documentation. Search slow logs and indexing slow logs are an important tool for understanding and troubleshooting the performance of your search and indexing operations. Enable search and index slow log delivery for all production domains. You must also configure logging thresholds\\u2014otherwise, CloudWatch won't capture the logs. Shard strategy Shards distribute your workload across the data nodes in your OpenSearch Service domain. Properly configured indexes can help boost overall domain performance. When you send data to OpenSearch Service, you send that data to an index. An index is analogous to a database table, with documents as the rows, and fields as the columns. When you create the index, you tell OpenSearch how many primary shards you want to create. The primary shards are independent partitions of the full dataset. OpenSearch Service automatically distributes your data across the primary shards in an index. You can also configure replicas of the index. Each replica shard comprises a full set of copies of the primary shards for that index. OpenSearch Service maps the shards for each index across the data nodes in your cluster. It ensures that the primary and replica shards for the index reside on different data nodes. The first replica ensures that you have two copies of the data in the index. You should always use at least one replica. Additional replicas provide additional redundancy and read capacity. OpenSearch sends indexing requests to all of the data nodes that contain shards that belong to the index. It sends indexing requests first to data nodes that contain primary shards, and then to data nodes that contain replica shards. Search requests are routed by the coordinator node to either a primary or replica shard for all shards belonging to the index. For example, for an index with five primary shards and one replica, each indexing request touches 10 shards. In contrast, search requests are sent to n shards, where n is the number of primary shards. For an index with five primary shards and one replica, each search query touches five shards (primary or replica) from that index. Determine shard and data node counts Use the following best practices to determine shard and data node counts for your domain. Shard size \\u2013 The size of data on disk is a direct result of the size of your source data, and it changes as you index more data. The source-to-index ratio can vary wildly, from 1:10 to 10:1 or more, but usually it's around 1:1.10. You can use that ratio to predict the index size on disk. You can also index some data and retrieve the actual index sizes to determine the ratio for your workload. After you have a predicted index size, set a shard count so that each shard will be between 10\\u201330 GiB (for search workloads), or between 30\\u201350 GiB (for logs workloads). 50 GiB should be the maximum\\u2014be sure to plan for growth. Shard count \\u2013 The distribution of shards to data nodes has a large impact on a domain\\u2019s performance. When you have indexes with multiple shards, try to make the shard count a multiple of the data node count. This helps to ensure that shards are evenly distributed across data nodes, and prevents hot nodes. For example, if you have 12 primary shards, your data node count should be 2, 3, 4, 6, or 12. However, shard count is secondary to shard size\\u2014if you have 5 GiB of data, you should still use a single shard. Shards per data node \\u2013 The total number of shards that a node can hold is proportional to the node\\u2019s Java virtual machine (JVM) heap memory. Aim for 25 shards or fewer per GiB of heap memory. For example, a node with 32 GiB of heap memory should hold no more than 800 shards. Although shard distribution can vary based on your workload patterns, there's a limit of 1,000 shards per node for Elasticsearch and OpenSearch 1.1 to 2.15 and 4,000 for OpenSearch 2.17 and above. The cat/allocation API provides a quick view of the number of shards and total shard storage across data nodes. Shard to CPU ratio \\u2013 When a shard is involved in an indexing or search request, it uses a vCPU to process the request. As a best practice, use an initial scale point of 1.5 vCPU per shard. If your instance type has 8 vCPUs, set your data node count so that each node has no more than six shards. Note that this is an approximation. Be sure to test your workload and scale your cluster accordingly. For storage volume, shard size, and instance type recommendations, see the following resources: Sizing Amazon OpenSearch Service domains Petabyte scale in Amazon OpenSearch Service Avoid storage skew Storage skew occurs when one or more nodes within a cluster holds a higher proportion of storage for one or more indexes than the others. Indications of storage skew include uneven CPU utilization, intermittent and uneven latency, and uneven queueing across data nodes. To determine whether you have skew issues, see the following troubleshooting sections: Node shard and storage skew Index shard and storage skew Stability The following best practices apply to maintaining a stable and healthy OpenSearch Service domain. Keep current with OpenSearch Service software updates OpenSearch Service regularly releases software updates that add features or otherwise improve your domains. Updates don't change the OpenSearch or Elasticsearch engine version. We recommend that you schedule a recurring time to run the DescribeDomain API operation, and initiate a service software update if the UpdateStatus is ELIGIBLE. If you don't update your domain within a certain time frame (typically two weeks), OpenSearch Service automatically performs the update. OpenSearch version upgrades OpenSearch Service regularly adds support for community-maintained versions of OpenSearch. Always upgrade to the latest OpenSearch versions when they're available. OpenSearch Service simultaneously upgrades both OpenSearch and OpenSearch Dashboards (or Elasticsearch and Kibana if your domain is running a legacy engine). If the cluster has dedicated master nodes, upgrades complete without downtime. Otherwise, the cluster might be unresponsive for several seconds post-upgrade while it elects a master node. OpenSearch Dashboards might be unavailable during some or all of the upgrade. There are two ways to upgrade a domain: In-place upgrade \\u2013 This option is easier because you keep the same cluster. Snapshot/restore upgrade \\u2013 This option is good for testing new versions on a new cluster or migrating between clusters. Regardless of which upgrade process you use, we recommend that you maintain a domain that is solely for development and testing, and upgrade it to the new version before you upgrade your production domain. Choose Development and testing for the deployment type when you're creating the test domain. Make sure to upgrade all clients to compatible versions immediately following the domain upgrade. Improve snapshot performance To prevent your snapshot from getting stuck in processing, the instance type for the dedicated master node should match the shard count. For more information, see Choosing instance types for dedicated master nodes. Additionally, each node should have no more than the recommended 25 shards per GiB of Java heap memory. For more information, see Choosing the number of shards. Enable dedicated master nodes Dedicated master nodes improve cluster stability. A dedicated master node performs cluster management tasks, but doesn't hold index data or respond to client requests. This offloading of cluster management tasks increases the stability of your domain and makes it possible for some configuration changes to happen without downtime. Enable and use three dedicated master nodes for optimal domain stability across three Availability Zones. Deploying with Multi-AZ with Standby configures three dedicated master nodes for you. For instance type recommendations, see Choosing instance types for dedicated master nodes. Deploy across multiple Availability Zones To prevent data loss and minimize cluster downtime in the event of a service disruption, you can distribute nodes across two or three Availability Zones in the same AWS Region. Best practice is to deploy using Multi-AZ with Standby, which configures three Availability Zones, with two zones active and one acting as a standby, and with and two replica shards per index. This configuration lets OpenSearch Service distribute replica shards to different AZs than their corresponding primary shards. There are no cross-AZ data transfer charges for cluster communications between Availability Zones. Availability Zones are isolated locations within each Region. With a two-AZ configuration, losing one Availability Zone means that you lose half of all domain capacity. Moving to three Availability Zones further reduces the impact of losing a single Availability Zone. Control ingest flow and buffering We recommend that you limit the overall request count using the _bulk API operation. It's more efficient to send one _bulk request that contains 5,000 documents than it is to send 5,000 requests that contain a single document. For optimal operational stability, it's sometimes necessary to limit or even pause the upstream flow of indexing requests. Limiting the rate of index requests is an important mechanism for dealing with unexpected or occasional spikes in requests that might otherwise overwhelm the cluster. Consider building a flow control mechanism into your upstream architecture. The following diagram shows multiple component options for a log ingest architecture. Configure the aggregation layer to allow sufficient space to buffer incoming data for sudden traffic spikes and brief domain maintenance. Create mappings for search workloads For search workloads, create mappings that define how OpenSearch stores and indexes documents and their fields. Set dynamic to strict in order to prevent new fields from being added accidentally. PUT my-index\\\\n{\\\\n  \\\\\\\"mappings\\\\\\\": {\\\\n    \\\\\\\"dynamic\\\\\\\": \\\\\\\"strict\\\\\\\",\\\\n    \\\\\\\"properties\\\\\\\": {\\\\n      \\\\\\\"title\\\\\\\": { \\\\\\\"type\\\\\\\" : \\\\\\\"text\\\\\\\" },\\\\n      \\\\\\\"author\\\\\\\": { \\\\\\\"type\\\\\\\" : \\\\\\\"integer\\\\\\\" },\\\\n      \\\\\\\"year\\\\\\\": { \\\\\\\"type\\\\\\\" : \\\\\\\"text\\\\\\\" }\\\\n    }\\\\n  }\\\\n} Use index templates You can use an index template as a way to tell OpenSearch how to configure an index when it's created. Configure index templates before creating indexes. Then, when you create an index, it inherits the settings and mappings from the template. You can apply more than one template to a single index, so you can specify settings in one template and mappings in another. This strategy allows one template for common settings across multiple indexes, and separate templates for more specific settings and mappings. The following settings are helpful to configure in templates: Number of primary and replica shards Refresh interval (how often to refresh and make recent changes to the index available to search) Dynamic mapping control Explicit field mappings The following example template contains each of these settings: {\\\\n   \\\\\\\"index_patterns\\\\\\\":[\\\\n      \\\\\\\"index-*\\\\\\\"\\\\n   ],\\\\n   \\\\\\\"order\\\\\\\": 0,\\\\n   \\\\\\\"settings\\\\\\\": {\\\\n      \\\\\\\"index\\\\\\\": {\\\\n         \\\\\\\"number_of_shards\\\\\\\": 3,\\\\n         \\\\\\\"number_of_replicas\\\\\\\": 1,\\\\n         \\\\\\\"refresh_interval\\\\\\\": \\\\\\\"60s\\\\\\\"\\\\n      }\\\\n   },\\\\n   \\\\\\\"mappings\\\\\\\": {\\\\n      \\\\\\\"dynamic\\\\\\\": false,\\\\n      \\\\\\\"properties\\\\\\\": {\\\\n         \\\\\\\"field_name1\\\\\\\": {\\\\n            \\\\\\\"type\\\\\\\": \\\\\\\"keyword\\\\\\\"\\\\n         }\\\\n      }\\\\n   }\\\\n} Even if they rarely change, having settings and mappings defined centrally in OpenSearch is simpler to manage than updating multiple upstream clients. Manage indexes with Index State Management If you're managing logs or time-series data, we recommend using Index State Management (ISM). ISM lets you automate regular index lifecycle management tasks. With ISM, you can create policies that invoke index alias rollovers, take index snapshots, move indexes between storage tiers, and delete old indexes. You can even use the ISM rollover operation as an alternative data lifecycle management strategy to avoid shard skew. First, set up an ISM policy. For example, see Sample policies. Then, attach the policy to one or more indexes. If you include an ISM template field in the policy, OpenSearch Service automatically applies the policy to any index that matches the specified pattern. Remove unused indexes Regularly review the indexes in your cluster and identify any that aren't in use. Take a snapshot of those indexes so that they're stored in S3, and then delete them. When you remove unused indexes, you reduce the shard count, and make it possible to have more balanced storage distribution and resource utilization across nodes. Even when they're idle, indexes consume some resources during internal index maintenance activities. Rather than manually deleting unused indexes, you can use ISM to automatically take a snapshot and delete indexes after a certain period of time. Use multiple domains for high availability To achieve high availability beyond 99.9% uptime across multiple Regions, consider using two domains. For small or slowly changing datasets, you can set up cross-cluster replication to maintain an active-passive model. In this model, only the leader domain is written to, but either domain can be read from. For larger data sets and quickly changing data, configure dual delivery in your ingest pipeline so that all data is written independently to both domains in an active-active model. Architect your upstream and downstream applications with failover in mind. Make sure to test the failover process along with other disaster recovery processes. Performance The following best practices apply to tuning your domains for optimal performance. Optimize bulk request size and compression Bulk sizing depends on your data, analysis, and cluster configuration, but a good starting point is 3\\u20135 MiB per bulk request. Send requests and receive responses from your OpenSearch domains by using gzip compression to reduce the payload size of requests and responses. You can use gzip compression with the OpenSearch Python client, or by including the following headers from the client side: 'Accept-Encoding': 'gzip' 'Content-Encoding': 'gzip' To optimize your bulk request sizes, start with a bulk request size of 3 MiB. Then, slowly increase the request size until indexing performance stops improving. Note To enable gzip compression on domains running Elasticsearch version 6.x, you must set http_compression.enabled at the cluster level. This setting is true by default in Elasticsearch versions 7.x and all versions of OpenSearch. Reduce the size of bulk request responses To reduce the size of OpenSearch responses, exclude unnecessary fields with the filter_path parameter. Make sure that you don't filter out any fields that are required to identify or retry failed requests. For more information and examples, see Reducing response size. Tune refresh intervals OpenSearch indexes have eventual read consistency. A refresh operation makes all the updates that are performed on an index available for search. The default refresh interval is one second, which means that OpenSearch performs a refresh every second while an index is being written to. The less frequently that you refresh an index (higher refresh interval), the better the overall indexing performance is. The trade-off of increasing the refresh interval is that there\\u2019s a longer delay between an index update and when the new data is available for search. Set your refresh interval as high as you can tolerate to improve overall performance. We recommend setting the refresh_interval parameter for all of your indexes to 30 seconds or more. Enable Auto-Tune Auto-Tune uses performance and usage metrics from your OpenSearch cluster to suggest changes to queue sizes, cache sizes, and Java virtual machine (JVM) settings on your nodes. These optional changes improve cluster speed and stability. You can revert to the default OpenSearch Service settings at any time. Auto-Tune is enabled by default on new domains unless you explicitly disable it. We recommend that you enable Auto-Tune on all domains, and either set a recurring maintenance window or periodically review its recommendations. Security The following best practices apply to securing your domains. Enable fine-grained access control Fine-grained access control lets you control who can access certain data within an OpenSearch Service domain. Compared to generalized access control, fine-grained access control gives each cluster, index, document, and field its own specified policy for access. Access criteria can be based on a number of factors, including the role of the person who is requesting access and the action that they intend to perform on the data. For example, you might give one user access to write to an index, and another user access only to read the data on the index without making any changes. Fine-grained access control allows data with different access requirements to exist in the same storage space without running into security or compliance issues. We recommend enabling fine-grained access control on your domains. Deploy domains within a VPC Placing your OpenSearch Service domain within a virtual private cloud (VPC) helps enable secure communication between OpenSearch Service and other services within the VPC\\u2014without the need for an internet gateway, NAT device, or VPN connection. All traffic remains securely within the AWS Cloud. Because of their logical isolation, domains that reside within a VPC have an extra layer of security compared to domains that use public endpoints. We recommend that you create your domains within a VPC. Apply a restrictive access policy Even if your domain is deployed within a VPC, it's a best practice to implement security in layers. Make sure to check the configuration of your current access policies. Apply a restrictive resource-based access policy to your domains and follow the principle of least privilege when granting access to the configuration API and the OpenSearch API operations. As a general rule, avoid using the anonymous user principal \\\\\\\"Principal\\\\\\\": {\\\\\\\"AWS\\\\\\\": \\\\\\\"*\\\\\\\" } in your access policies. There are some situations, however, where it's acceptable to use an open access policy, such as when you enable fine-grained access control. An open access policy can enable you to access the domain in cases where request signing is difficult or impossible, such as from certain clients and tools. Enable encryption at rest OpenSearch Service domains offer encryption of data at rest to help prevent unauthorized access to your data. Encryption at rest uses AWS Key Management Service (AWS KMS) to store and manage your encryption keys, and the Advanced Encryption Standard algorithm with 256-bit keys (AES-256) to perform the encryption. If your domain stores sensitive data, enable encryption of data at rest. Enable node-to-node encryption Node-to-node encryption provides an additional layer of security on top of the default security features within OpenSearch Service. It implements Transport Layer Security (TLS) for all communications between the nodes that are provisioned within OpenSearch. Node-to-node encryption, any data sent to your OpenSearch Service domain over HTTPS remains encrypted in transit while it's being distributed and replicated between nodes. If your domain stores sensitive data, enable node-to-node encryption. Monitor with AWS Security Hub Monitor your usage of OpenSearch Service as it relates to security best practices by using AWS Security Hub. Security Hub uses security controls to evaluate resource configurations and security standards to help you comply with various compliance frameworks. For more information about using Security Hub to evaluate OpenSearch Service resources, see Amazon OpenSearch Service controls in the AWS Security Hub User Guide. Cost optimization The following best practices apply to optimizing and saving on your OpenSearch Service costs. Use the latest generation instance types OpenSearch Service is always adopting new Amazon EC2 instances types that deliver better performance at a lower cost. We recommend always using the latest generation instances. Avoid using T2 or t3.small instances for production domains because they can become unstable under sustained heavy load. r6g.large instances are an option for small production workloads (both as data nodes and as dedicated master nodes). Use the latest Amazon EBS gp3 volumes OpenSearch data nodes require low latency and high throughput storage to provide fast indexing and query. By using Amazon EBS gp3 volumes, you get higher baseline performance (IOPS and throughput) at a 9.6% lower cost than with the previously-offered Amazon EBS gp2 volume type. You can provision additional IOPS and throughput independent of volume size using gp3. These volumes are also more stable than previous generation volumes as they do not use burst credits. The gp3 volume type also doubles the per-data-node volume size limits of the gp2 volume type. With these larger volumes, you can reduce the cost of passive data by increasing the amount of storage per data node. Use UltraWarm and cold storage for time-series log data If you're using OpenSearch for log analytics, move your data to UltraWarm or cold storage to reduce costs. Use Index State Management (ISM) to migrate data between storage tiers and manage data retention. UltraWarm provides a cost-effective way to store large amounts of read-only data in OpenSearch Service. UltraWarm uses Amazon S3 for storage, which means that the data is immutable and only one copy is needed. You only pay for storage that's equivalent to the size of the primary shards in your indexes. Latencies for UltraWarm queries grow with the amount of S3 data that's needed to service the query. After the data has been cached on the nodes, queries to UltraWarm indexes perform similar to queries to hot indexes. Cold storage is also backed by S3. When you need to query cold data, you can selectively attach it to existing UltraWarm nodes. Cold data incurs the same managed storage cost as UltraWarm, but objects in cold storage don't consume UltraWarm node resources. Therefore, cold storage provides a significant amount of storage capacity without impacting UltraWarm node size or count. UltraWarm becomes cost-effective when you have roughly 2.5 TiB of data to migrate from hot storage. Monitor your fill rate and plan to move indexes to UltraWarm before you reach that volume of data. Review recommendations for Reserved Instances Consider purchasing Reserved Instances (RIs) after you have a good baseline on your performance and compute consumption. Discounts start at around 30% for no-upfront, 1-year reservations and can increase up to 50% for all-upfront, 3-year commitments. After you observe stable operation for at least 14 days, review Accessing reservation recommendations in the AWS Cost Management User Guide. The Amazon OpenSearch Service heading displays specific RI purchase recommendations and projected savings. Javascript is disabled or is unavailable in your browser. To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions. Document Conventions Piped Processing Language Sizing domains Did this page help you? - Yes Thanks for letting us know we're doing a good job! If you've got a moment, please tell us what we did right so we can do more of it. Did this page help you? - No Thanks for letting us know this page needs work. We're sorry we let you down. If you've got a moment, please tell us how we can make the documentation better.\\\"},{\\\"url\\\":\\\"https://docs.opensearch.org/latest/tuning-your-cluster/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Regular expression syntax Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Using UBI in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Creating a cluster Before diving into OpenSearch and searching and aggregating data, you first need to create an OpenSearch cluster. OpenSearch can operate as a single-node or multi-node cluster. The steps to configure both are, in general, quite similar. This page demonstrates how to create and configure a multi-node cluster, but with only a few minor adjustments, you can follow the same steps to create a single-node cluster. To create and deploy an OpenSearch cluster according to your requirements, it\\u2019s important to understand how node discovery and cluster formation work and what settings govern them. There are many ways to design a cluster. The following illustration shows a basic architecture that includes a four-node cluster that has one dedicated cluster manager node, one dedicated coordinating node, and two data nodes that are cluster manager eligible and also used for ingesting data. The master node is now referred to as the cluster manager node. Nodes The following table provides brief descriptions of the node types: Node type Description Best practices for production Cluster manager Manages the overall operation of a cluster and keeps track of the cluster state. This includes creating and deleting indexes, keeping track of the nodes that join and leave the cluster, checking the health of each node in the cluster (by running ping requests), and allocating shards to nodes. Three dedicated cluster manager nodes in three different zones is the right approach for almost all production use cases. This configuration ensures your cluster never loses quorum. Two nodes will be idle for most of the time except when one node goes down or needs some maintenance. Cluster manager eligible Elects one node among them as the cluster manager node through a voting process. For production clusters, make sure you have dedicated cluster manager nodes. The way to achieve a dedicated node type is to mark all other node types as false. In this case, you have to mark all the other nodes as not cluster manager eligible. Data Stores and searches data. Performs all data-related operations (indexing, searching, aggregating) on local shards. These are the worker nodes of your cluster and need more disk space than any other node type. As you add data nodes, keep them balanced between zones. For example, if you have three zones, add data nodes in multiples of three, one for each zone. We recommend using storage and RAM-heavy nodes. Ingest Pre-processes data before storing it in the cluster. Runs an ingest pipeline that transforms your data before adding it to an index. If you plan to ingest a lot of data and run complex ingest pipelines, we recommend you use dedicated ingest nodes. You can also optionally offload your indexing from the data nodes so that your data nodes are used exclusively for searching and aggregating. Coordinating Delegates client requests to the shards on the data nodes, collects and aggregates the results into one final result, and sends this result back to the client. A couple of dedicated coordinating-only nodes is appropriate to prevent bottlenecks for search-heavy workloads. We recommend using CPUs with as many cores as you can. Dynamic Delegates a specific node for custom work, such as machine learning (ML) tasks, preventing the consumption of resources from data nodes and therefore not affecting any OpenSearch functionality. Warm Provides access to searchable snapshots. Incorporates techniques like frequently caching used segments and removing the least used data segments in order to access the searchable snapshot index (stored in a remote long-term storage source, for example, Amazon Simple Storage Service [Amazon S3] or Google Cloud Storage). Search nodes contain an index allocated as a snapshot cache. Thus, we recommend using dedicated nodes with more compute (CPU and memory) than storage capacity (hard disk). Search Search nodes are dedicated nodes that host only search replica shards, helping separate search workloads from indexing workloads. Because search nodes host search replicas and handle search traffic, we recommend using them for dedicated memory-optimized instances. By default, each node is a cluster-manager-eligible, data, ingest, and coordinating node. Deciding on the number of nodes, assigning node types, and choosing the hardware for each node type depends on your use case. You must take into account factors like the amount of time you want to hold on to your data, the average size of your documents, your typical workload (indexing, searches, aggregations), your expected price-performance ratio, your risk tolerance, and so on. After you assess all these requirements, we recommend you use a benchmark testing tool like OpenSearch Benchmark to provision a small sample cluster and run tests with varying workloads and configurations. Compare and analyze the system and query metrics for these tests to design an optimum architecture. This page demonstrates how to work with the different node types. It assumes that you have a four-node cluster similar to the preceding illustration. It is a best practice to direct traffic from external sources, such as OpenSearch Dashboards, OpenSearch Data Prepper, and others, to the nodes in the following order of availability: ingest node, coordinating node, data node. We do not recommended sending traffic directly to the cluster manager node. Prerequisites Before you get started, you must install and configure OpenSearch on all of your nodes. For information about the available options, see Install and configure OpenSearch. After you\\u2019re done, use SSH to connect to each node, then open the config/opensearch.yml file. You can set all configurations for your cluster in this file. Step 1: Name a cluster Specify a unique name for the cluster. If you don\\u2019t specify a cluster name, it\\u2019s set to opensearch by default. Setting a descriptive cluster name is important, especially if you want to run multiple clusters inside a single network. To specify the cluster name, change the following line: #cluster.name: my-application\\\\n to cluster.name: opensearch-cluster\\\\n Make the same change on all the nodes to make sure that they\\u2019ll join to form a cluster. Step 2: Set node attributes for each node in a cluster After you name the cluster, set node attributes for each node in your cluster. Cluster manager node Give your cluster manager node a name. If you don\\u2019t specify a name, OpenSearch assigns a machine-generated name that makes the node difficult to monitor and troubleshoot. node.name: opensearch-cluster_manager\\\\n You can also explicitly specify that this node is a cluster manager node, even though it is already set to true by default. Set the node role to cluster_manager to make it easier to identify the cluster manager node. node.roles: [ cluster_manager ]\\\\n Data nodes Change the name of two nodes to opensearch-d1 and opensearch-d2, respectively: node.name: opensearch-d1\\\\n node.name: opensearch-d2\\\\n You can make them cluster-manager-eligible data nodes that will also be used for ingesting data: node.roles: [ data, ingest ]\\\\n You can also specify any other attributes that you\\u2019d like to set for the data nodes. Coordinating node Change the name of the coordinating node to opensearch-c1: node.name: opensearch-c1\\\\n Every node is a coordinating node by default, so to make this node a dedicated coordinating node, set node.roles to an empty list: node.roles: []\\\\n Step 3: Bind a cluster to specific IP addresses network.bind_host defines the IP address used to bind the node. By default, OpenSearch listens on a local host, which limits the cluster to a single node. You can also use _local_ and _site_ to bind to any loopback or site-local address, whether IPv4 or IPv6: network.bind_host: [_local_, _site_]\\\\n To form a multi-node cluster, specify the IP address of the node: network.bind_host: <IP address of the node>\\\\n Make sure to configure these settings on all of your nodes. Step 4: Configure discovery hosts and initial cluster manager nodes for a cluster Now that you\\u2019ve configured the network hosts, you need to configure the discovery hosts and specify the cluster manager nodes for the initial cluster election. Note that this is the node name and not the IP Address, hostname, or fully-qualified hostname. For example, the setting looks like the following: cluster.initial_cluster_manager_nodes: [\\\\\\\"opensearch-cluster_manager\\\\\\\"]\\\\n Zen Discovery is the built-in, default mechanism that uses unicast to find other nodes in the cluster. You can generally add all of your cluster-manager-eligible nodes to the discovery.seed_hosts array. When a node starts up, it finds the other cluster-manager-eligible nodes, determines which one is the cluster manager, and asks to join the cluster. For example, for opensearch-cluster_manager the line looks something like this: discovery.seed_hosts: [\\\\\\\"<private IP of opensearch-d1>\\\\\\\", \\\\\\\"<private IP of opensearch-d2>\\\\\\\", \\\\\\\"<private IP of opensearch-c1>\\\\\\\"]\\\\n Step 5: Start the cluster After you set the configurations, start OpenSearch on all nodes: sudo systemctl start opensearch.service\\\\n Installing OpenSearch from a tar archive will not automatically create a service with systemd. See Run OpenSearch as a service with systemd for instructions on how to create and start the service if you receive an error like Failed to start opensearch.service: Unit not found. Then go to the logs file to see the formation of the cluster: less /var/log/opensearch/opensearch-cluster.log\\\\n Perform the following _cat query on any node to see all the nodes formed as a cluster: curl -XGET https://<private-ip>:9200/_cat/nodes?v -u 'admin:<custom-admin-password>' --insecure\\\\n ip             heap.percent ram.percent cpu load_1m load_5m load_15m node.role cluster_manager name\\\\nx.x.x.x           13          61   0    0.02    0.04     0.05 mi        *      opensearch-cluster_manager\\\\nx.x.x.x           16          60   0    0.06    0.05     0.05 md        -      opensearch-d1\\\\nx.x.x.x           34          38   0    0.12    0.07     0.06 md        -      opensearch-d2\\\\nx.x.x.x           23          38   0    0.12    0.07     0.06 md        -      opensearch-c1\\\\n To better understand and monitor your cluster, use the CAT API. (Advanced) Step 6: Configure shard allocation awareness or forced awareness To further fine-tune your shard allocation, you can set custom node attributes for shard allocation awareness or forced awareness. Shard allocation awareness You can set custom node attributes on OpenSearch nodes to be used for shard allocation awareness. For example, you can set the zone attribute on each node to represent the zone in which the node is located. You can also use the zone attribute to ensure that the primary shard and its replica shards are allocated in a balanced manner across available, distinct zones. In this scenario, maximum shard copies per zone would equal ceil (number_of_shard_copies/number_of_distinct_zones). OpenSearch, by default, allocates shard copies of a single shard across different nodes. When only 1 zone is available, such as after a zone failure, OpenSearch allocates replica shards to the only remaining zone\\u2014it considers only available zones (attribute values) when calculating the maximum number of allowed shard copies per zone. For example, if your index has a total of 5 shard copies (1 primary and 4 replicas) and nodes in 3 distinct zones, then OpenSearch will perform the following to allocate all 5 shard copies: Allocate no more than 2 shards per zone, which will require at least 2 nodes in 2 zones. Allocate the last shard in the third zone, with at least 1 node needed in the third zone. Alternatively, if you have 3 nodes in the first zone and 1 node in each remaining zone, then OpenSearch will allocate: 2 shard copies in the first zone. 1 shard copy in the remaining 2 zones. The final shard copy will remain unallocated due to the lack of nodes. With shard allocation awareness, if the nodes in one of your zones fail, you can be assured that your replica shards are spread across your other zones, adding a layer of fault tolerance to ensure that your data survives zone failures. To configure shard allocation awareness, add zone attributes to opensearch-d1 and opensearch-d2, respectively: node.attr.zone: zoneA\\\\n node.attr.zone: zoneB\\\\n Update the cluster settings: PUT _cluster/settings\\\\n{\\\\n  \\\\\\\"persistent\\\\\\\": {\\\\n    \\\\\\\"cluster.routing.allocation.awareness.attributes\\\\\\\": \\\\\\\"zone\\\\\\\"\\\\n  }\\\\n}\\\\n You can also use multiple attributes for shard allocation awareness by providing the attributes as a comma-separated string, for example, zone,rack. You can either use persistent or transient settings. We recommend the persistent setting because it persists through a cluster reboot. Transient settings don\\u2019t persist through a cluster reboot. Shard allocation awareness attempts to separate primary and replica shards across multiple zones. However, if only one zone is available (such as after a zone failure), OpenSearch allocates replica shards to the only remaining zone. Forced awareness Another option is to require that primary and replica shards are never allocated to the same zone. This is called forced awareness. To configure forced awareness, specify all the possible values for your zone attributes: PUT _cluster/settings\\\\n{\\\\n  \\\\\\\"persistent\\\\\\\": {\\\\n    \\\\\\\"cluster.routing.allocation.awareness.attributes\\\\\\\": \\\\\\\"zone\\\\\\\",\\\\n    \\\\\\\"cluster.routing.allocation.awareness.force.zone.values\\\\\\\":[\\\\\\\"zoneA\\\\\\\", \\\\\\\"zoneB\\\\\\\"]\\\\n  }\\\\n}\\\\n Now, if a data node fails, forced awareness doesn\\u2019t allocate the replicas to a node in the same zone. Instead, the cluster enters a yellow state and only allocates the replicas when nodes in another zone come online. In our two-zone architecture, we can use allocation awareness if opensearch-d1 and opensearch-d2 are less than 50% utilized, so that each of them have the storage capacity to allocate replicas in the same zone. If that is not the case, and opensearch-d1 and opensearch-d2 do not have the capacity to contain all primary and replica shards, we can use forced awareness. This approach helps to make sure that, in the event of a failure, OpenSearch doesn\\u2019t overload your last remaining zone and lock up your cluster due to lack of storage. Choosing allocation awareness or forced awareness depends on how much space you might need in each zone to balance your primary and replica shards. Replica count enforcement To enforce an even distribution of shards across all zones and avoid hotspots, you can set the routing.allocation.awareness.balance attribute to true. This setting can be configured in the opensearch.yml file and dynamically updated using the cluster update settings API: PUT _cluster/settings\\\\n{\\\\n  \\\\\\\"persistent\\\\\\\": {\\\\n    \\\\\\\"cluster\\\\\\\": {\\\\n      \\\\\\\"routing.allocation.awareness.balance\\\\\\\": \\\\\\\"true\\\\\\\"\\\\n    }\\\\n  }\\\\n}\\\\n The routing.allocation.awareness.balance setting is false by default. When it is set to true, the total number of shards for the index must be a multiple of the highest count for any awareness attribute. For example, consider a configuration with two awareness attributes\\u2014zones and rack IDs. Let\\u2019s say there are two zones and three rack IDs. The highest count of either the number of zones or the number of rack IDs is three. Therefore, the number of shards must be a multiple of three. If it is not, OpenSearch throws a validation exception. routing.allocation.awareness.balance takes effect only if cluster.routing.allocation.awareness.attributes and cluster.routing.allocation.awareness.force.zone.values are set. routing.allocation.awareness.balance applies to all operations that create or update indexes. For example, let\\u2019s say you\\u2019re running a cluster with three nodes and three zones in a zone-aware setting. If you try to create an index with one replica or update an index\\u2019s settings to one replica, the attempt will fail with a validation exception because the number of shards must be a multiple of three. Similarly, if you try to create an index template with one shard and no replicas, the attempt will fail for the same reason. However, in all of those operations, if you set the number of shards to one and the number of replicas to two, the total number of shards is three and the attempt will succeed. (Advanced) Step 7: Set up a hot-warm architecture You can design a hot-warm architecture where you first index your data to hot nodes\\u2014fast and expensive\\u2014and after a certain period of time move them to warm nodes\\u2014slow and cheap. If you analyze time-series data that you rarely update and want the older data to go onto cheaper storage, this architecture can be a good fit. This architecture helps save money on storage costs. Rather than increasing the number of hot nodes and using fast, expensive storage, you can add warm nodes for data that you don\\u2019t access as frequently. To configure a hot-warm storage architecture, add temp attributes to opensearch-d1 and opensearch-d2, respectively: node.attr.temp: hot\\\\n node.attr.temp: warm\\\\n You can set the attribute name and value to whatever you want as long as it\\u2019s consistent for all your hot and warm nodes. To add an index newindex to the hot node: PUT newindex\\\\n{\\\\n  \\\\\\\"settings\\\\\\\": {\\\\n    \\\\\\\"index.routing.allocation.require.temp\\\\\\\": \\\\\\\"hot\\\\\\\"\\\\n  }\\\\n}\\\\n Take a look at the following shard allocation for newindex: GET _cat/shards/newindex?v\\\\nindex     shard prirep state      docs store ip         node\\\\nnew_index 2     p      STARTED       0  230b 10.0.0.225 opensearch-d1\\\\nnew_index 2     r      UNASSIGNED\\\\nnew_index 3     p      STARTED       0  230b 10.0.0.225 opensearch-d1\\\\nnew_index 3     r      UNASSIGNED\\\\nnew_index 4     p      STARTED       0  230b 10.0.0.225 opensearch-d1\\\\nnew_index 4     r      UNASSIGNED\\\\nnew_index 1     p      STARTED       0  230b 10.0.0.225 opensearch-d1\\\\nnew_index 1     r      UNASSIGNED\\\\nnew_index 0     p      STARTED       0  230b 10.0.0.225 opensearch-d1\\\\nnew_index 0     r      UNASSIGNED\\\\n In this example, all primary shards are allocated to opensearch-d1, which is our hot node. All replica shards are unassigned, because we\\u2019re forcing this index to allocate only to hot nodes. To add an index oldindex to the warm node: PUT oldindex\\\\n{\\\\n  \\\\\\\"settings\\\\\\\": {\\\\n    \\\\\\\"index.routing.allocation.require.temp\\\\\\\": \\\\\\\"warm\\\\\\\"\\\\n  }\\\\n}\\\\n The shard allocation for oldindex: GET _cat/shards/oldindex?v\\\\nindex     shard prirep state      docs store ip        node\\\\nold_index 2     p      STARTED       0  230b 10.0.0.74 opensearch-d2\\\\nold_index 2     r      UNASSIGNED\\\\nold_index 3     p      STARTED       0  230b 10.0.0.74 opensearch-d2\\\\nold_index 3     r      UNASSIGNED\\\\nold_index 4     p      STARTED       0  230b 10.0.0.74 opensearch-d2\\\\nold_index 4     r      UNASSIGNED\\\\nold_index 1     p      STARTED       0  230b 10.0.0.74 opensearch-d2\\\\nold_index 1     r      UNASSIGNED\\\\nold_index 0     p      STARTED       0  230b 10.0.0.74 opensearch-d2\\\\nold_index 0     r      UNASSIGNED\\\\n In this case, all primary shards are allocated to opensearch-d2. Again, all replica shards are unassigned because we only have one warm node. A popular approach is to configure your index templates to set the index.routing.allocation.require.temp value to hot. This way, OpenSearch stores your most recent data on your hot nodes. You can then use the Index State Management (ISM) plugin to periodically check the age of an index and specify actions to take on it. For example, when the index reaches a specific age, change the index.routing.allocation.require.temp setting to warm to automatically move your data from hot nodes to warm nodes. Next steps If you are using the Security plugin, the previous request to _cat/nodes?v might have failed with an initialization error. For full guidance around using the Security plugin, see Security configuration. Nodes Shard allocation awareness Forced awareness Replica count enforcement WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright \\u00a9 OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\\\"},null,{\\\"url\\\":\\\"https://logit.io/blog/post/opensearch-best-practises/\\\",\\\"title\\\":\\\"back back\\\",\\\"content\\\":\\\"Logit.io requires JavaScript to be enabled Platform Logging Log Management Logging as a Service Metrics Metrics as a Service Metrics Management Observability Cloud Application Performance Monitoring Application Performance Monitoring Application Performance Analyser SIEM as a Service Logit.io For OpenTelemetry Trace Analytics Features Hosted OpenSearch Hosted ELK Hosted Jaeger Hosted Prometheus Hosted Kibana Hosted Grafana Hosted Logstash Grafana Demo Using a managed solution like the one provided by Logit.io, enables you to get started with Grafana within minutes. Prometheus as a Service Identify the root cause behind container failures faster by using Prometheus as a Service ELK as a Service ELK as a Service provides busy DevOps, SysAdmins, and IT leaders with an affordable and scalable alternative to building their own Elastic Stacks. Solutions Monitoring Log Monitoring Container Monitoring Data Monitoring Production Monitoring Infrastructure Monitoring Hybrid Cloud & Multi-Cloud Monitoring Kubernetes Monitoring Logging Observability Security Logging Logging Made Easy (LME) Compliance and Auditing Compliance and Auditing Analysis Analysis Solutions Log Analysis Business Analytics DevOps Analytics Event Log Analyser Security Analytics Platform-Specific Logging Amazon Web Services (AWS) Azure Google Cloud Platform (GCP) Django CMMC Solution CMMC Audit Logging Datadog Alternative Learn more on how Logit.io can easily be leveraged as an affordable alternative to Datadog. Splunk Alternative See how metrics, traces & logs can be measured affordably for security and alerting with Logit.io. Logz.io Alternative Switch today & save when you use Logit.io as your highly affordable observability platform. New Relic Alternative Empower your team to observe key insights while saving on costs when using Logit.io. Pricing Docs Get a DemoStart Free TrialSign In back Back to Blog Top OpenSearch Best Practises for Success By David Benson May 27th, 2024 Resources 4 min read While OpenSearch provides a rich set of features and capabilities out of the box, optimizing its performance, reliability, and security requires adherence to best practices. To assist you in navigating OpenSearch we have put together an extensive guide of the best practices for OpenSearch to ensure that you get the most out of the solution. These best practices cover multiple aspects of cluster architecture, indexing, querying, monitoring, security, and more, guaranteeing that your OpenSearch deployment operates smoothly and delivers actionable insights to your organization. What is OpenSearch? OpenSearch is an open-source distributed search and analytics engine created for scalability, simplicity, and performance. It serves as a powerful tool for indexing, searching, and examining large volumes of data in real-time. OpenSearch is built on Apache Lucene, a commonly used full-text search library, and it offers a robust platform for a broad range of use cases such as log analytics, monitoring, search engines, and business intelligence. Originally, OpenSearch was a community-driven fork of Elasticsearch, an open-source search and analytics engine developed by Elastic. However, it has since evolved into a separate project with its own governance and roadmap. OpenSearch intends to supply users with a fully open-source alternative to proprietary search and analytics solutions, providing transparency, flexibility, and control over their data and infrastructure. Contents OpenSearch Best Practices Cluster Sizing and Configuration Index Management Data Ingestion and Pipeline Query Optimization Monitoring and Alerting Security, Backup, and Disaster Recovery Documentation and Training Hosted OpenSearch OpenSearch Best Practices Optimizing the utilization of OpenSearch entails adhering to a set of best practices aimed at improving performance, reliability, and security. We have listed a range of OpenSearch best practices that cover all aspects of the solution below. Cluster Sizing and Configuration Firstly, cluster sizing and configuration are crucial. You need to properly outline node types and hardware specifications to match your workload demands. Dedicate nodes for certain roles such as master, data, and coordinating nodes to streamline responsibilities and enhance performance. Additionally, you should determine the amount of shards and replicas for each index to stop resource overutilization and facilitate efficient cluster operation. Fine-tune network settings to ensure seamless communication between nodes to avoid latency issues and bottlenecks. Index Management Another vital aspect when using OpenSearch in index management. You should utilize Index Lifecycle Management (ILM) policies to automate index lifecycle operations such as rollover, retention, and deletion. Implement index shrink and split operations to manage index size and distribution effectively, to improve query performance and storage efficiency. Data Ingestion and Pipeline Efficient data ingestion and processing are vital for maintaining optimal cluster performance in OpenSearch. You and your team should employ bulk indexing techniques to ingest large volumes of data swiftly while minimizing overhead. Make sure to utilize ingest node pipelines to preprocess and enrich data before indexing, guaranteeing data quality and optimizing search capabilities. Query Optimization Query optimization is a vital practice to ensure maximum search performance. You should focus on carefully designing indices and mappings to support efficient querying. Utilize the Query DSL to construct enhanced queries, leveraging filters, aggregations, and scoring mechanisms. Regularly track query performance and use profiling tools to highlight and address performance bottlenecks. Monitoring and Alerting Maintaining cluster health and proactively addressing issues is made simpler by utilizing monitoring and alerting mechanisms. Track critical cluster metrics such as CPU usage, memory utilization, disk I/O, and JVM heap usage to identify anomalies and performance degradation. It\\u2019s vital to configure alerts to fire when critical events occur and thresholds are breached to notify administrators promptly to sped up time to resolution. Security, Backup, and Disaster Recovery Enhance the security of your OpenSearch cluster by enabling authentication and authorization mechanisms. Employ role-based access control (RBAC) to manage access to indices, documents, and cluster APIs based on user roles and permissions. Also, you should encrypt network traffic using Transport Layer Security (TLS) to protect data in transit. Ensure you enable encryption at rest to encrypt data stored on disk to prevent unauthorized access. Also, backup and disaster recovery strategies are crucial for guaranteeing data resilience and business continuity. Employ snapshot and restore functionality to create frequent backups of indices and restore them in case of data loss or corruption. Documentation and Training To continue the effective operation of Opensearch, comprehensive documentation and ongoing training are vital for fostering knowledge sharing and empowering administrators and users to leverage OpenSearch effectively. You should maintain detailed documentation covering cluster configuration, best practices, troubleshooting procedures, and recovery processes. As well as this, offer frequent training sessions and resources to guarantee administrators and users have the skills and knowledge to manage OpenSearch clusters effectively. Hosted OpenSearch Opting for a Hosted OpenSearch solution could be the perfect choice for your organization. With a Hosted OpenSearch solution, like the one provided by Logit.io, you can benefit from a streamlined deployment process, removing the need for manual setup and configuration. This lessens the complexity and time required to get started with OpenSearch. As well as this, Logit.io Hosted OpenSearch the infrastructure is managed by us, including provisioning, scaling, monitoring, and maintenance tasks. This reduces the burden of managing infrastructure from your team, enabling you to focus on your organisation's key business objectives. In addition to this, Logit.io's service employs stringent security features, including encryption at rest and in transit, role-based access control (RBAC), and integration with identity providers for authentication. This aids in enhancing the security posture of your OpenSearch deployment without requiring additional configuration. Our hosted OpenSearch offers a convenient and cost-effective way to leverage the power of OpenSearch without the overhead of managing infrastructure and operations. If you\\u2019re interested in finding out more about Logit.io\\u2019s hosted OpenSearch solution, don\\u2019t hesitate to arrange an OpenSearch demo, or begin exploring the platform for yourself with a 14-day free trial. If you've enjoyed this article why not read OpenSearch vs Elasticsearch or The Best OpenSearch Dashboard Examples next? Previous Post: The Critical Role of Log Management in SaaS Environments Next Post: The Top 50 OpenSearch Interview Questions Get the latest elastic Stack & logging resources when you subscribe back Back to Blog The Latest News from Logit.io OpenTelemetry Distributed Tracing Implementation Guide Manufacturing IoT Monitoring: Complete Enterprise Guide Media Streaming Performance: Complete Enterprise Guide Gaming Infrastructure Monitoring: Complete Enterprise Guide Financial Services Security Monitoring: Enterprise Guide Leading Tools Alternatives Dashboards Guides Kubernetes Management Tools Distributed Tracing Tools Data Visualisation Tools Log Management Tools Log Monitoring Tools Metrics Tools SIEM Tools Platform Logging Metrics Observability Features Pricing Solutions Monitoring Security Log Application Logging Logging Made Easy Django Logging Compliance and Auditing Analysis CMMC Solution Azure Logging Log Viewer Resources Integrations Documentation Platform Status Logit.io Blog Compare Compare alternatives Datadog alternative Dynatrace alternative Sumo Logic alternative Logz.io alternative LogicMonitor alternative Loggly alternative Stackify alternative Splunk alternative Papertrail alternative New Relic alternative Mezmo alternative About Us About Us Legal Why Logit? Security and Compliance Consultancy Contact Us Partner \\u00a9 2025 Logit.io Ltd, All rights reserved.\\\"},{\\\"url\\\":\\\"https://blog.devgenius.io/best-practices-aws-opensearch-97911c11e8fd\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Sitemap Open in app Sign up Sign in Medium Logo Write Search Sign up Sign in Dev Genius \\u00b7 Follow publication Coding, Tutorials, News, UX, UI and much more related to development Follow publication Best Practices \\u2014 AWS OpenSearch Amit Singh Rathore 11 min read \\u00b7 Feb 9, 2025 -- Listen Share Few pointers to look at while working with AWS OpenSearch Dedicated Master Nodes It is recommended to use Multi-AZ with three dedicated master nodes for optimal stability and fault tolerance. Three dedicated master nodes offer two backup nodes and the required quorum, providing a reliable configuration. Note: Avoid choosing an even number of dedicated master nodes. Dedicated master nodes Use at least 3 dedicated master nodes for clusters with 10+ data nodes. Choose instance types with at least 8 GB of RAM (m5.large or larger). Zone Awareness Enable zone awareness to distribute replicas across Availability Zones. Ensure even distribution of nodes across AZs. Estimating Storage Requirements OpenSearch Service reserves 20% of storage space for segment merges, logs, and other internal operations, with a maximum of 20 GiB per instance. This means that the total reserved space can vary depending on the number of instances in your domain. To calculate the minimum storage requirement for our example with 2 replicas and 2TB of source data, we can use the simplified formula provided: Source data * (1 + number of replicas) * 1.45 = minimum storage requirement Substituting the values: 2TB * (1 + 2) * 1.45 = 8.7TB If we do a full reindex at any time on the cluster we will need to allocate 2 * 8.7TB = 17.4TB. a) Determining optimal number of data nodes: Rule of thumb: Start with at least 3 data nodes for production workloads. Calculate required storage: (Daily data volume * Retention period * Replication factor) / 0.75 (leaving 25% free space) Divide total required storage by storage per node to get minimum number of nodes. Shard Strategy (Count) An index is analogous to a database table, with documents as the rows, and fields as the columns. Indices are composed of shards (primary & replica). When we create an index, we tell OpenSearch how many primary shards we want to create. The primary shards are independent partitions of the full dataset. OpenSearch Service automatically distributes our data across the primary shards in an index. We can also configure replicas of the index. Each replica shard comprises a full set of copies of the primary shards for that index. To optimize search performance in OpenSearch, careful consideration of the shard count in our index is crucial. Increasing the number of shards can significantly improve efficiency, particularly when dealing with large datasets. Read-heavy workloads, a shard size of 10\\u201330 GB is recommended Write-heavy workloads, a shard size of 30\\u201335 GB is recommended We can approximate the number of primary shards required using the formula (source_data) * (1 + indexing_overhead) / desired_shard_size. For our example, the approximate number of primary shards would be (2000) * 1.1 / 30 \\u2248 73.33. To ensure an even distribution of shards across our three data nodes, a suitable shard count would be 72. When we have indexes with multiple shards, we should try to make the shard count an even multiple of the data node count. This helps to ensure that shards are evenly distributed across data nodes, and prevents hot nodes. For example, if we have 12 primary shards, our data node count should be 2, 3, 4, 6, or 12. However, shard count is secondary to shard size \\u2014 if we have 5 GiB of data, we should still use a single shard. For example, a node with 32 GiB of heap memory should hold no more than 800 shards. Although shard distribution can vary based on our workload patterns, there\\u2019s a limit of 1,000 shards per node. Calculating optimal shard size Aim for shard sizes between 10\\u201350 GB. Calculate the number of shards: (Daily data volume * Retention period) / Target shard size Strategies for shard allocation Use shard allocation filtering to control data distribution: PUT logs*/_settings {   \\\\\\\"index.routing.allocation.include.data_type\\\\\\\": \\\\\\\"hot\\\\\\\" } Handling hot spots and shard balancing Monitor shard sizes and search rates. Use custom routing or time-based indices to distribute load evenly. Using custom routing for controlled distribution Implement custom routing for time-series data: PUT logs/_doc/1?routing=2023-07-22 {   \\\\\\\"timestamp\\\\\\\": \\\\\\\"2023-07-22T12:00:00Z\\\\\\\",   \\\\\\\"message\\\\\\\": \\\\\\\"Application started\\\\\\\" } Instance Type Selection When selecting hardware for our OpenSearch cluster, it\\u2019s crucial to consider storage requirements, shard count, and workload characteristics. The number of shards per data node should align with the node\\u2019s JVM heap memory, typically aiming for 25 shards or fewer per GiB. To ensure efficient processing, it\\u2019s recommended to have an initial scale point of 1.5 vCPUs per shard. For instance, with 72 shards per node, we would need approximately 108 vCPUs. To accommodate this, scaling our data nodes to 5 would be suitable, resulting in a shard count of approximately 43.2 per node. In this case, selecting a robust instance type like the m6g.12xlarge.search with 48 CPUs and 192 RAM would be advisable. However, additional instances may be required if performance falls short of expectations, tests fail, or CPUUtilization or JVMMemoryPressure indicators are high. As instances are added, OpenSearch automatically redistributes the shard distribution throughout the cluster, helping to balance the workload and optimize performance. 1 instance \\u2192 1000 Shard \\u2192 3TB storage \\u2192 8GB RAM \\u2192 1.5vCPC per shard Choosing instance types Memory-optimized (r5 or r7g series): Best for complex aggregations and caching. Compute-optimized (c5 or c7g series): Suitable for search-heavy workloads. Consider data-to-memory ratio: Aim for a 1:10 ratio of JVM heap to data on disk. OR1 optimized instance family \\u2014 A domain with OR1 instances uses Amazon Elastic Block Store (Amazon EBS) gp3 or io1 volumes for primary storage, with data copied synchronously to Amazon S3 as it arrives. For OpenSearch optimized instances, indexing is only performed on primary shards. aws opensearch create-domain \\\\\\\\   --domain-name test-domain \\\\\\\\   --engine-version OpenSearch_2.11 \\\\\\\\   --cluster-config \\\\\\\"InstanceType=or1.2xlarge.search,InstanceCount=3,DedicatedMasterEnabled=true,DedicatedMasterType=r6g.large.search,DedicatedMasterCount=3\\\\\\\" \\\\\\\\   --ebs-options \\\\\\\"EBSEnabled=true,VolumeType=gp3,VolumeSize=200\\\\\\\" \\\\\\\\   --encryption-at-rest-options Enabled=true \\\\\\\\   --advanced-security-options \\\\\\\"Enabled=true,InternalUserDatabaseEnabled=true,MasterUserOptions={MasterUserName=test-user,MasterUserPassword=test-password}\\\\\\\" \\\\\\\\   --node-to-node-encryption-options Enabled=true \\\\\\\\   --domain-endpoint-options EnforceHTTPS=true \\\\\\\\   --access-policies '{\\\\\\\"Version\\\\\\\":\\\\\\\"2012-10-17\\\\\\\",\\\\\\\"Statement\\\\\\\":[{\\\\\\\"Effect\\\\\\\":\\\\\\\"Allow\\\\\\\",\\\\\\\"Principal\\\\\\\":{\\\\\\\"AWS\\\\\\\":\\\\\\\"*\\\\\\\"},\\\\\\\"Action\\\\\\\":\\\\\\\"es:*\\\\\\\",\\\\\\\"Resource\\\\\\\":\\\\\\\"arn:aws:es:us-east-1:account-id:domain/test-domain/*\\\\\\\"}]}' OR1 instances keep a copy of data in both your local and remote store. In UltraWarm instances, data is kept primarily in remote store to reduce storage costs. Depending on your usage patterns, data can be moved to local storage. Graviton cost reduction with higher performance m5.large.search (2 Core, 8GB RAM, 10GB/s N/W) \\u2192 $0.142 m7g.large.search (2 Core, 8GB RAM, 12.5GB/s N/W) \\u2192 $0.135 Use the latest Amazon EBS gp3 volumes OpenSearch Service data nodes require low latency and high throughput storage to provide fast indexing and query. With gp3 EBS volumes, you get higher baseline performance (IOPS and throughput) at a 9.6% lower cost than with the previously offered gp2 EBS volume type. We can also provision additional IOPS and throughput independent of volume size using gp3. Storage \\u2014 $0.122/GB-month. IOPS \\u2014 3,000 IOPS free for volumes up to 1,024 GiB, or 3 IOPS/GiB free for volumes above 1,024 GiB. $0.008/provisioned IOPS-month over free limits. Throughput \\u2014 125 MiB/s free for volumes up to 170 GiB, or +250 MiB/s free for every 3 TiB for volumes above 170 GiB. $0.064/provisioned MiB/s-month over free limits. Data Ingestion Strategies Efficient data ingestion is critical for high-volume scenarios. Bulk indexing Use the _bulk API for indexing multiple documents in a single request. Optimal bulk size typically ranges from 5\\u201315 MB. We can use gzip compression with the OpenSearch Python client, or by including the following headers from the client side \\u2014 'Accept-Encoding': 'gzip' , 'Content-Encoding': 'gzip' Example bulk request: POST _bulk {\\\\\\\"index\\\\\\\":{\\\\\\\"_index\\\\\\\":\\\\\\\"logs\\\\\\\",\\\\\\\"_id\\\\\\\":\\\\\\\"1\\\\\\\"}} {\\\\\\\"timestamp\\\\\\\":\\\\\\\"2023-07-22T10:30:00Z\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"User login successful\\\\\\\"} {\\\\\\\"index\\\\\\\":{\\\\\\\"_index\\\\\\\":\\\\\\\"logs\\\\\\\",\\\\\\\"_id\\\\\\\":\\\\\\\"2\\\\\\\"}} {\\\\\\\"timestamp\\\\\\\":\\\\\\\"2023-07-22T10:31:00Z\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Data processing started\\\\\\\"} Using the Bulk API effectively Parallelize bulk requests, but avoid overloading the cluster. Monitor the bulk_total_time_in_millis metric to find the optimal concurrency level. Implement backoff mechanisms for retries: from elasticsearch import Elasticsearch, helpers import time def bulk_index_with_backoff(client, actions, max_retries=3):     for attempt in range(max_retries):         try:             helpers.bulk(client, actions)             break         except Exception as e:             if attempt == max_retries - 1:                 raise             time.sleep(2 ** attempt)  # Exponential backoff Implementing a buffer layer Use Amazon Kinesis Data Firehose for reliable, scalable data ingestion. Configure Firehose to batch and compress data before sending to OpenSearch. Example Firehose delivery stream configuration: {   \\\\\\\"DeliveryStreamName\\\\\\\": \\\\\\\"OpenSearchIngestStream\\\\\\\",   \\\\\\\"OpenSearchDestinationConfiguration\\\\\\\": {     \\\\\\\"IndexName\\\\\\\": \\\\\\\"logs\\\\\\\",     \\\\\\\"BufferingHints\\\\\\\": {       \\\\\\\"IntervalInSeconds\\\\\\\": 60,       \\\\\\\"SizeInMBs\\\\\\\": 5     },     \\\\\\\"CompressionFormat\\\\\\\": \\\\\\\"GZIP\\\\\\\"   } } Real-time vs. batch ingestion For real-time: Use the _bulk API with smaller batches, potentially through a queueing system. For batch: Use larger bulk sizes and consider off-peak hours for ingestion. Indexing Optimization Efficient index design is crucial for performance and storage optimization. Designing efficient mappings Explicitly define mappings to prevent type guessing: PUT logs {   \\\\\\\"mappings\\\\\\\": {     \\\\\\\"properties\\\\\\\": {       \\\\\\\"timestamp\\\\\\\": {\\\\\\\"type\\\\\\\": \\\\\\\"date\\\\\\\"},       \\\\\\\"message\\\\\\\": {\\\\\\\"type\\\\\\\": \\\\\\\"text\\\\\\\", \\\\\\\"fields\\\\\\\": {\\\\\\\"keyword\\\\\\\": {\\\\\\\"type\\\\\\\": \\\\\\\"keyword\\\\\\\"}}},       \\\\\\\"user_id\\\\\\\": {\\\\\\\"type\\\\\\\": \\\\\\\"keyword\\\\\\\"},       \\\\\\\"status_code\\\\\\\": {\\\\\\\"type\\\\\\\": \\\\\\\"integer\\\\\\\"}     }   } } Use appropriate data types (e.g., keyword for exact matches, text for full-text search). Using dynamic mapping judiciously Disable dynamic mapping for high-volume indices to prevent mapping explosions: PUT logs {   \\\\\\\"mappings\\\\\\\": {     \\\\\\\"dynamic\\\\\\\": \\\\\\\"strict\\\\\\\",     \\\\\\\"properties\\\\\\\": {       // defined fields here     }   } } Optimizing field types for search and aggregations Use keyword fields for aggregations and sorting. For numeric fields requiring range queries, consider using integer instead of long if possible. Index aliases for zero-downtime reindexing Use aliases to switch between indices without downtime: POST /_aliases {   \\\\\\\"actions\\\\\\\": [     {\\\\\\\"add\\\\\\\": {\\\\\\\"index\\\\\\\": \\\\\\\"logs-v2\\\\\\\", \\\\\\\"alias\\\\\\\": \\\\\\\"logs-write\\\\\\\"}},     {\\\\\\\"remove\\\\\\\": {\\\\\\\"index\\\\\\\": \\\\\\\"logs-v1\\\\\\\", \\\\\\\"alias\\\\\\\": \\\\\\\"logs-write\\\\\\\"}},     {\\\\\\\"add\\\\\\\": {\\\\\\\"index\\\\\\\": \\\\\\\"logs-v2\\\\\\\", \\\\\\\"alias\\\\\\\": \\\\\\\"logs-read\\\\\\\"}},     {\\\\\\\"remove\\\\\\\": {\\\\\\\"index\\\\\\\": \\\\\\\"logs-v1\\\\\\\", \\\\\\\"alias\\\\\\\": \\\\\\\"logs-read\\\\\\\"}}   ] } Caching Strategies Effective caching can significantly improve query performance and reduce load on your cluster. Configuring and using query cache Enable and size the query cache appropriately: PUT _cluster/settings {   \\\\\\\"persistent\\\\\\\": {     \\\\\\\"indices.queries.cache.size\\\\\\\": \\\\\\\"5%\\\\\\\"   } } The query cache is most effective for frequently run queries on mostly static data. Monitor cache hit rate using the indices_stats API: GET /_stats/query_cache?human Optimizing field data cache Field data is loaded into memory for sorting and aggregations on text fields. Limit field data cache size to prevent OOM errors: PUT _cluster/settings {   \\\\\\\"persistent\\\\\\\": {     \\\\\\\"indices.fielddata.cache.size\\\\\\\": \\\\\\\"10%\\\\\\\"   } } Use doc_values for fields that require sorting or aggregations: PUT logs {   \\\\\\\"mappings\\\\\\\": {     \\\\\\\"properties\\\\\\\": {       \\\\\\\"user_id\\\\\\\": {         \\\\\\\"type\\\\\\\": \\\\\\\"keyword\\\\\\\",         \\\\\\\"doc_values\\\\\\\": true       }     }   } } Shard request cache considerations Enable shard request cache for search-heavy workloads: PUT logs/_settings {   \\\\\\\"index.requests.cache.enable\\\\\\\": true } Set appropriate cache expiration: PUT logs/_settings {   \\\\\\\"index.requests.cache.expire\\\\\\\": \\\\\\\"10m\\\\\\\" } Implementing application-level caching Use external caching solutions like Redis/mamcache for frequently accessed, compute-intensive results. Implement cache invalidation strategies to ensure data freshness. Query Optimization Use of Structured Queries Prefer structured queries over unstructured ones for better performance: GET logs/_search {   \\\\\\\"query\\\\\\\": {     \\\\\\\"bool\\\\\\\": {       \\\\\\\"must\\\\\\\": [         {\\\\\\\"match\\\\\\\": {\\\\\\\"message\\\\\\\": \\\\\\\"error\\\\\\\"}},         {\\\\\\\"term\\\\\\\": {\\\\\\\"status_code\\\\\\\": 500}}       ],       \\\\\\\"filter\\\\\\\": [         {\\\\\\\"range\\\\\\\": {\\\\\\\"timestamp\\\\\\\": {\\\\\\\"gte\\\\\\\": \\\\\\\"now-1d\\\\\\\"}}}       ]     }   } } Optimize Aggregations Use date_histogram with fixed_interval for time-based aggregations: GET logs/_search {   \\\\\\\"size\\\\\\\": 0,   \\\\\\\"aggs\\\\\\\": {     \\\\\\\"errors_over_time\\\\\\\": {       \\\\\\\"date_histogram\\\\\\\": {         \\\\\\\"field\\\\\\\": \\\\\\\"timestamp\\\\\\\",         \\\\\\\"fixed_interval\\\\\\\": \\\\\\\"1h\\\\\\\",         \\\\\\\"min_doc_count\\\\\\\": 0       },       \\\\\\\"aggs\\\\\\\": {         \\\\\\\"error_count\\\\\\\": {           \\\\\\\"filter\\\\\\\": {\\\\\\\"term\\\\\\\": {\\\\\\\"status_code\\\\\\\": 500}}         }       }     }   } } Use of Script Fields Avoid heavy scripting in queries. If necessary, use painless scripts and cache them: GET logs/_search {   \\\\\\\"script_fields\\\\\\\": {     \\\\\\\"day_of_week\\\\\\\": {       \\\\\\\"script\\\\\\\": {         \\\\\\\"lang\\\\\\\": \\\\\\\"painless\\\\\\\",         \\\\\\\"source\\\\\\\": \\\\\\\"doc['timestamp'].value.dayOfWeek\\\\\\\",         \\\\\\\"params\\\\\\\": {}       }     }   } } Query Profiling Use the Profile API to analyze query performance: GET logs/_search {   \\\\\\\"profile\\\\\\\": true,   \\\\\\\"query\\\\\\\": {\\\\\\\"match\\\\\\\": {\\\\\\\"message\\\\\\\": \\\\\\\"error\\\\\\\"}} } Analyze the output to identify slow components of your query. exclude unnecessary fields with the filter_path parameter. Monitoring and Alerting Ensure that your AWS OpenSearch domains publish slow logs to AWS CloudWatch Logs. Key Metrics to Monitor Cluster health: RED, YELLOW, GREEN status Node-level metrics: CPU, memory, disk I/O Index-level metrics: indexing rate, search rate, refresh time JVM metrics: heap usage, garbage collection Setting up CloudWatch Alarms Set up alarms for critical metrics: {   \\\\\\\"AlarmName\\\\\\\": \\\\\\\"HighCPUUtilization\\\\\\\",   \\\\\\\"ComparisonOperator\\\\\\\": \\\\\\\"GreaterThanThreshold\\\\\\\",   \\\\\\\"EvaluationPeriods\\\\\\\": 2,   \\\\\\\"MetricName\\\\\\\": \\\\\\\"CPUUtilization\\\\\\\",   \\\\\\\"Namespace\\\\\\\": \\\\\\\"AWS/ES\\\\\\\",   \\\\\\\"Period\\\\\\\": 300,   \\\\\\\"Statistic\\\\\\\": \\\\\\\"Average\\\\\\\",   \\\\\\\"Threshold\\\\\\\": 80,   \\\\\\\"AlarmDescription\\\\\\\": \\\\\\\"Alarm when CPU exceeds 80%\\\\\\\",   \\\\\\\"Dimensions\\\\\\\": [     {       \\\\\\\"Name\\\\\\\": \\\\\\\"DomainName\\\\\\\",       \\\\\\\"Value\\\\\\\": \\\\\\\"your-domain-name\\\\\\\"     },     {       \\\\\\\"Name\\\\\\\": \\\\\\\"ClientId\\\\\\\",       \\\\\\\"Value\\\\\\\": \\\\\\\"your-account-id\\\\\\\"     }   ] } Using OpenSearch Dashboards Create custom dashboards for visualizing cluster health, indexing rates, and search performance. Use the \\u201cStack Monitoring\\u201d feature in OpenSearch Dashboards. Implementing Proactive Alerting Use Amazon SNS to send notifications for critical alarms. Implement custom alerting using AWS Lambda and the OpenSearch API. Data Lifecycle Management Use Index State Management (ISM) to migrate data between storage tiers and manage data retention. Press enter or click to view image in full size UltraWarm provides a cost-effective way to store large amounts of read-only data in OpenSearch Service. UltraWarm uses Amazon S3 for storage, which means that the data is immutable and only one copy is needed. Cold storage is also backed by S3. When you need to query cold data, you can selectively attach it to existing UltraWarm nodes. Cold data incurs the same managed storage cost as UltraWarm, but objects in cold storage don\\u2019t consume UltraWarm node resources Implementing Index State Management (ISM) Create an ISM policy: PUT _opendistro/_ism/policies/log_lifecycle_policy {   \\\\\\\"policy\\\\\\\": {     \\\\\\\"description\\\\\\\": \\\\\\\"Manage log index lifecycle\\\\\\\",     \\\\\\\"default_state\\\\\\\": \\\\\\\"hot\\\\\\\",     \\\\\\\"states\\\\\\\": [       {         \\\\\\\"name\\\\\\\": \\\\\\\"hot\\\\\\\",         \\\\\\\"actions\\\\\\\": [],         \\\\\\\"transitions\\\\\\\": [           {             \\\\\\\"state_name\\\\\\\": \\\\\\\"warm\\\\\\\",             \\\\\\\"conditions\\\\\\\": {               \\\\\\\"min_index_age\\\\\\\": \\\\\\\"7d\\\\\\\"             }           }         ]       },       {         \\\\\\\"name\\\\\\\": \\\\\\\"warm\\\\\\\",         \\\\\\\"actions\\\\\\\": [           {             \\\\\\\"replica_count\\\\\\\": {               \\\\\\\"number_of_replicas\\\\\\\": 1             }           },           {             \\\\\\\"force_merge\\\\\\\": {               \\\\\\\"max_num_segments\\\\\\\": 1             }           }         ],         \\\\\\\"transitions\\\\\\\": [           {             \\\\\\\"state_name\\\\\\\": \\\\\\\"cold\\\\\\\",             \\\\\\\"conditions\\\\\\\": {               \\\\\\\"min_index_age\\\\\\\": \\\\\\\"30d\\\\\\\"             }           }         ]       },       {         \\\\\\\"name\\\\\\\": \\\\\\\"cold\\\\\\\",         \\\\\\\"actions\\\\\\\": [           {             \\\\\\\"read_only\\\\\\\": {}           }         ],         \\\\\\\"transitions\\\\\\\": [           {             \\\\\\\"state_name\\\\\\\": \\\\\\\"delete\\\\\\\",             \\\\\\\"conditions\\\\\\\": {               \\\\\\\"min_index_age\\\\\\\": \\\\\\\"90d\\\\\\\"             }           }         ]       },       {         \\\\\\\"name\\\\\\\": \\\\\\\"delete\\\\\\\",         \\\\\\\"actions\\\\\\\": [           {             \\\\\\\"delete\\\\\\\": {}           }         ]       }     ]   } } Using UltraWarm and Cold Storage Move indices to UltraWarm after they become less frequently accessed: POST logs-2023-01/_ultrawarm/migration Move rarely accessed indices to Cold Storage: POST logs-2022-12/_cold/migration Backup and Recovery Use automated snapshots with S3: PUT _snapshot/my_s3_repository {   \\\\\\\"type\\\\\\\": \\\\\\\"s3\\\\\\\",   \\\\\\\"settings\\\\\\\": {     \\\\\\\"bucket\\\\\\\": \\\\\\\"my-snapshot-bucket\\\\\\\",     \\\\\\\"region\\\\\\\": \\\\\\\"us-west-2\\\\\\\",     \\\\\\\"role_arn\\\\\\\": \\\\\\\"arn:aws:iam::123456789012:role/OpenSearchSnapshotRole\\\\\\\"   } } Create daily snapshots PUT _snapshot/my_s3_repository/snapshot_1 Rather than manually deleting unused indexes, you can use ISM to automatically take a snapshot and delete indexes after a certain period of time. OpenSearch Rollups allow users to summarize and aggregate historical data into smaller, more manageable indices. This is useful for handling large volumes of time-series data, such as logs or metrics, where detailed granularity is only needed for recent data. Rollup indices are smaller than raw data indices, so querying them requires less processing power. Performance Tuning Shard Optimization Aim for shard sizes between 10\\u201350 GB. Use the force merge API to reduce shard count after bulk indexing: POST logs/_forcemerge?max_num_segments=1 Field Data Circuit Breaker Adjust field data circuit breaker to prevent OOM errors: PUT _cluster/settings {   \\\\\\\"persistent\\\\\\\": {     \\\\\\\"indices.breaker.fielddata.limit\\\\\\\": \\\\\\\"40%\\\\\\\"   } } Segment Merging Tune merge policy for write-heavy workloads: PUT logs/_settings {   \\\\\\\"index.merge.policy.segments_per_tier\\\\\\\": 10,   \\\\\\\"index.merge.policy.max_merge_at_once\\\\\\\": 10 } Bulk Indexing Optimization Disable refresh and replicas during bulk indexing: PUT logs/_settings {   \\\\\\\"index.refresh_interval\\\\\\\": -1,   \\\\\\\"index.number_of_replicas\\\\\\\": 0 } Re-enable after indexing is complete. Security Best Practices AWS offers many managed config rules for security best practices, we can leverage them using Config. Following is the list of supported config rules. OPENSEARCH_ACCESS_CONTROL_ENABLED OPENSEARCH_AUDIT_LOGGING_ENABLED OPENSEARCH_DATA_NODE_FAULT_TOLERANCE OPENSEARCH_ENCRYPTED_AT_REST OPENSEARCH_HTTPS_REQUIRED OPENSEARCH_IN_VPC_ONLY OPENSEARCH_LOGS_TO_CLOUDWATCH OPENSEARCH_NODE_TO_NODE_ENCRYPTION_CHECK Implement Fine-Grained Access Control Use role-based access control PUT _opendistro/_security/api/roles/logs_read {   \\\\\\\"cluster_permissions\\\\\\\": [\\\\\\\"cluster_composite_ops_ro\\\\\\\"],   \\\\\\\"index_permissions\\\\\\\": [     {       \\\\\\\"index_patterns\\\\\\\": [\\\\\\\"logs-*\\\\\\\"],       \\\\\\\"allowed_actions\\\\\\\": [\\\\\\\"read\\\\\\\", \\\\\\\"search\\\\\\\"]     }   ] } Encryption at Rest and in Transit Enable node-to-node encryption: PUT _cluster/settings {   \\\\\\\"persistent\\\\\\\": {     \\\\\\\"opendistro.security.ssl.http.enabled\\\\\\\": \\\\\\\"true\\\\\\\",     \\\\\\\"opendistro.security.ssl.transport.enabled\\\\\\\": \\\\\\\"true\\\\\\\"   } } Use AWS KMS for encryption at rest. Network Isolation Deploy OpenSearch within a VPC. Use VPC peering or AWS PrivateLink for secure access from other VPCs. Ensure that only approved IP addresses can access your Amazon OpenSearch domains. Audit Logging Enable and configure audit logs: PUT _cluster/settings {   \\\\\\\"persistent\\\\\\\": {     \\\\\\\"opendistro.security.audit.type\\\\\\\": \\\\\\\"internal_opensearch\\\\\\\",     \\\\\\\"opendistro.security.audit.enable_rest\\\\\\\": \\\\\\\"true\\\\\\\",     \\\\\\\"opendistro.security.audit.enable_transport\\\\\\\": \\\\\\\"true\\\\\\\"   } } Keep your OpenSearch clusters up-to-date with the latest security patches. Consider disabling the private tenant Use service-linked role \\u2014 VPC Domain Creation Role, Collection Creation Role, Pipeline Creation Role Enable SAML Authentication for OpenSearch Dashboards \\u2014 IAM Identity Center, Cognito Miscellaneous Consider refresh interval settings to balance between near real-time search and indexing speed. By default, Elasticsearch refreshes an index every second, but if you don\\u2019t need real-time search, you can increase the refresh interval to reduce overhead. We recommend setting the refresh_interval parameter for all of your indexes to 30 seconds or more. Review recommendations for Reserved Instances Auto-Tune uses performance and usage metrics from your OpenSearch cluster to suggest changes to queue sizes, cache sizes, and Java virtual machine (JVM) settings on your nodes. AWS Opensearch Indexing Data Engineering Cloud Computing -- -- Follow Published in Dev Genius 29K followers \\u00b7Last published 9 hours ago Coding, Tutorials, News, UX, UI and much more related to development Follow Written by Amit Singh Rathore 4.8K followers \\u00b7107 following Staff Data Engineer @ Visa \\u2014 Writes about Cloud | Big Data | ML No responses yet Help Status About Careers Press Blog Privacy Rules Terms Text to speech\\\"},{\\\"url\\\":\\\"https://docs.aws.amazon.com/prescriptive-guidance/latest/opensearch-service-migration/sizing.html\\\",\\\"title\\\":\\\"Sizing - AWS Prescriptive Guidance\\\",\\\"content\\\":\\\"Sizing - AWS Prescriptive Guidance DocumentationAWS Prescriptive GuidanceMigrating to Amazon OpenSearch Service StorageNumber of nodes and instance typesDetermining the indexing strategy and shard countCPU utilizationInstance types Sizing Sizing helps you determine the right instance type, number of data nodes, and storage requirement for your target environment. We recommend that you size first by the storage and then by CPUs. If you're already using Elasticsearch or OpenSearch, the sizing will generally remain the same. However, you need to identify the instance type that is equivalent to your current environment. To help determine the right size, we recommend using the following guidelines. Storage Sizing your cluster starts with defining the storage requirements. Identify the raw storage that you need for your cluster. This is determined by assessing the data generated by your source system (for example, servers generating logs, or product catalog raw size). After you identify how much raw data you have, use the following formula to calculate storage requirements. You can then use the result as a starting point for your PoC. storage needed = (daily source data in bytes \\u00d7 1.45) (number_of_replicas + 1) \\u00d7 number of days retained The formula takes into consideration the following: The on-disk size of an index varies, but it's often 10 percent larger than the source data. Operating system overhead of 5 percent is reserved by Linux for system recovery and to safeguard against disk defragmentation problems. OpenSearch reserves 20 percent of the storage space of each instance for segment merges, logs, and other internal operations. We recommend keeping 10 percent additional storage to help minimize the impact of node failure and Availability Zone outages. Combined, these overheads and reservations require 45 percent additional space based on the actual raw data in the source. That's why you multiply the source data by 1.45. Next, multiply this by number of copies of data (for example, one primary plus the number of replicas you will use). The replica count depends on your resiliency and throughput requirement. For an average use case, you start with one primary and one replica. Finally, multiply by the number of days that you want to retain data in a hot-storage tier. Amazon OpenSearch Service offers hot, warm, and cold storage tiers. The warm storage tier uses UltraWarm storage. UltraWarm provides a cost-effective way to store large amounts of read-only data on Amazon OpenSearch Service. Standard data nodes use hot storage, which takes the form of instance stores or Amazon Elastic Block Store (Amazon EBS) volumes attached to each node. Hot storage provides the fastest possible performance for indexing and searching new data. UltraWarm nodes use Amazon Simple Storage Service (Amazon S3) as storage and a sophisticated caching solution to improve performance. For indexes that you are not actively writing to, or query less frequently, and do not have the same performance requirements, UltraWarm offers significantly lower costs per GiB of data. For more information about UltraWarm, see the AWS documentation. When you create an OpenSearch Service domain and use hot storage, you might need to define the EBS volume size. It depends on your choice of instance type for the data nodes. You can use the same storage-requirement formula to determine the volume size for Amazon EBS backed instances. We recommend using gp3 volumes for latest-generation T3, R5, R6G, M5, M5g, C5, and C6g instance families. Using Amazon EBS gp3 volumes, you can provision performance independent of storage capacity. Amazon EBS gp3 volumes also provide better baseline performance, at a 9.6 percent lower cost per GB than existing gp2 volumes on OpenSearch Service. With gp3, you also get denser storage on R5, R6g, M5, and M6g instance families, which can help you to further optimize your costs. You can create EBS volumes up to the supported quota. For more information on quotas, see Amazon OpenSearch Service quotas. For data nodes that have NVM Express (NVMe) drives, such as i3 and r6gd instances, the volume size is fixed, so EBS volumes are not an option. Number of nodes and instance types The number of nodes is based on the number of CPUs required to operate your workload. The number of CPUs is based on the shard count. An index in OpenSearch is made up of multiple shards. When you create an index, you specify the number of shards for the index. Therefore, you need to do the following: Calculate the total shard count that you intend to store in the domain. Determine the CPU. Find the most cost-effective node type and count that gives you the required number of CPUs and storage. This is usually a starting point. Run tests to determine that the estimate size is meeting your functional and nonfunctional requirements. Determining the indexing strategy and shard count After you know the storage requirements, you can decide how many indexes you need and identify the shard count for each. Generally, search use cases have one or a few indexes, each representing a searchable entity or a catalog. For log analytics use cases, an index can represent a daily or weekly log file. After you decide how many indexes, begin with the following scale guidance, and determine appropriate shard count: Search use cases \\u2013 10\\u201330 GB/shard Log analytics use cases \\u2013 50 GB/shard You can divide the total volume of data in a single index by the shard size you are aiming for in your use case. This will give you the number of shards for the index. Identifying the total number of shards will help you find the right instance types that suit your workload. The shards shouldn't be too large or too numerous. Large shards can make it difficult for OpenSearch to recover from failure, but because each shard uses some amount of CPU and memory, having too many small shards can cause performance issues and out-of-memory errors. Moreover, imbalance in shard allocation to data nodes can lead to skewing. When you have indexes with multiple shards, try to make the shard count an even multiple of the data node count. This helps to ensure that shards are evenly distributed across data nodes, and prevents hot nodes. For example, if you have 12 primary shards, your data node count should be 2, 3, 4, 6, or 12. However, shard count is secondary to shard size\\u2014if you have 5 GiB of data, you should still use a single shard. Balancing replica shard count evenly across the Availability Zone also helps improve resilience. CPU utilization The next step is to identify how many CPUs you need for your workload. We recommend starting with a CPU count 1.5 times that of your active shards. An active shard is any shard for an index that is receiving substantial writes. Use the primary shard count to determine active shards for indexes that are receiving substantial read or write requests. For log analytics, only the current index is generally active. For search use cases, all primary shards will be considered as active shards. Although we recommend 1.5 CPU per active shard, this is highly workload-dependent. Be sure to test and monitor CPU utilization and scale accordingly. A best practice for maintaining your CPU utilization is to make sure that the OpenSearch service domain has enough resources to perform its tasks. A cluster that has consistently high CPU utilization can degrade cluster stability. When your cluster is overloaded, OpenSearch Service will block incoming requests, which results in request rejections. This is to protect the domain from failing. General guidelines on the CPU usage will be about 60 percent average, 80 percent max CPU utilization. Occasional spikes of 100 percent are still acceptable and might not require scaling or reconfiguration. Instance types Amazon OpenSearch Service provides you with a choice of several instance types. You can choose the instance types that best fit your use case. Amazon OpenSearch Service supports the R, C, M, T, and I instance families. You choose an instance family based on the workload: memory optimized, compute optimized, or mixed. After you identify an instance family, choose the latest-generation instance type. Generally, we recommend Graviton and later generations because they are built to provide improved performance with lower costs compared with previous-generation instances. Based on various testing that was performed for log analytics and search use cases, we recommend the following: For log analytics use cases , a general guideline is to begin with the R family of Graviton instances for data nodes. We recommend that you run tests, establish benchmarks for your requirements, and identify the appropriate instance size for your workload. For search use cases, we recommend using R and C family Graviton instances for data nodes, because search use cases require more CPU compared with log analytics use cases. For smaller workloads, you can use M family Graviton instances for both search and logs. I family instances offer NVMe drives and are used by customers with fast-indexing and low-latency search requirements. The cluster is composed of data nodes and cluster manager nodes. Although dedicated master nodes don't process search and query requests, their size is highly correlated with the instance size and number of instances, indexes, and shards that they can manage. AWS documentation provides a matrix that recommends minimum dedicated cluster manager instance type. AWS offers general purpose (M6g), compute optimized (C6g), and memory optimized (R6g and R6gd) for Amazon OpenSearch Service version 7.9 or later powered by AWS Graviton2 processors. These instances are built using custom silicon designed by Amazon. They are Amazon-designed hardware and software innovations that enable the delivery of efficient, flexible, and secure cloud services with isolated multi-tenancy, private networking, and fast local storage. The Graviton2 instance family reduces indexing latency by up to 50 percent and improves query performance by up to 30 percent when compared with the previous generation Intel-based instances available in OpenSearch Service (M5, C5, R5). Javascript is disabled or is unavailable in your browser. To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions. Document Conventions Planning Functionality Did this page help you? - Yes Thanks for letting us know we're doing a good job! If you've got a moment, please tell us what we did right so we can do more of it. Did this page help you? - No Thanks for letting us know this page needs work. We're sorry we let you down. If you've got a moment, please tell us how we can make the documentation better.\\\"},null,{\\\"url\\\":\\\"https://docs.opensearch.org/latest/tuning-your-cluster/performance/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Regular expression syntax Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Using UBI in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Tuning your cluster for indexing speed The following configurations demonstrated an improvement in throughput of around 60% when running an indexing-only workload as compared to the out-of-the-box experience. The workload did not incorporate search or other scenarios. Only the OpenSearch server process was run on the machines, with the benchmark clients hosted on a different node. The execution environment was comprised of Intel EC2 instances (r7iz.2xlarge) in the AWS Cloud, and the workload used was the StackOverflow dataset available as part of OpenSearch Benchmark. Java heap size A larger Java heap size is useful for indexing. Setting the Java min and max heap sizes to 50% of the RAM size shows better indexing performance on EC2 instances. Flush translog threshold The default value for flush_threshold_size is 512 MB. This means that the translog is flushed when it reaches 512 MB. The weight of the indexing load determines the frequency of the translog. When you increase index.translog.flush_threshold_size, the node performs the translog operation less frequently. Because flushes are resource-intensive operations, reducing the frequency of translogs improves indexing performance. By increasing the flush threshold size, the OpenSearch cluster also creates fewer large segments instead of multiple small segments. Large segments merge less often, and more threads are used for indexing instead of merging. For pure indexing workloads, consider increasing the flush_threshold_size to 25% of the Java heap size, for example, to improve indexing performance. An increased index.translog.flush_threshold_size can also increase the time that it takes for a translog to complete. If a shard fails, then recovery takes more time because the translog is larger. Before increasing index.translog.flush_threshold_size, call the following API operation to get current flush operation statistics: GET /<index>/_stats/flush?pretty\\\\n copy In the output, note the number of flushes and the total time. The following example output shows that there are 124 flushes, which took 17,690 milliseconds: {\\\\n     \\\\\\\"flush\\\\\\\": {\\\\n          \\\\\\\"total\\\\\\\": 124,\\\\n          \\\\\\\"total_time_in_millis\\\\\\\": 17690\\\\n     }\\\\n}\\\\n To increase the flush threshold size, call the following API operation: PUT /<index>/_settings \\\\n{\\\\n  \\\\\\\"index\\\\\\\":\\\\n  {\\\\n    \\\\\\\"translog.flush_threshold_size\\\\\\\" : \\\\\\\"1024MB\\\\\\\"\\\\n  }\\\\n}\\\\n copy In this example, the flush threshold size is set to 1024 MB, which is ideal for instances that have more than 32 GB of memory. Choose the appropriate threshold size for your cluster. Run the stats API operation again to see whether the flush activity changed: GET /<index>/_stats/flush\\\\n copy It\\u2019s a best practice to increase the index.translog.flush_threshold_size only for the current index. After you confirm the outcome, apply the changes to the index template. Index refresh interval By default, OpenSearch refreshes indexes every second. OpenSearch only refreshes indexes that have received at least one search request in the last 30 seconds. When you increase the refresh interval, the data node makes fewer API calls. To prevent 429 errors, it\\u2019s a best practice to increase the refresh interval. If your application can tolerate increasing the amount of time between when a document is indexed and when it becomes visible, you can increase the index.refresh_interval to a larger value, for example, 30s, or even disable it in a pure indexing scenario in order to improve indexing speed. Index buffer size If the node is performing heavy indexing, ensure that the index buffer size is large enough. You can set the index buffer size to be either a percentage of the Java heap size or the number of bytes. In most cases, the default value of 10% of JVM memory is sufficient. You can try increasing it to up to 25% for further improvement. Concurrent merges The maximum number of concurrent merges is specified as max_merge_count. The concurrentMergeScheduler controls the execution of merge operations when they are needed. Merges run in separate threads, and when the maximum number of threads is reached, further merges will wait until a merge thread becomes available. In cases where index throttling is an issue, consider increasing the number of merge threads beyond the default value. Shard distribution To ensure that the shards are distributed evenly across the data nodes of the index into which you\\u2019re ingesting, use the following formula to confirm that the shards are evenly distributed: Number of shards for index = k * (Number of data nodes), where k is the number of shards per node For example, if there are 24 shards in the index, and there are 8 data nodes, then OpenSearch assigns 3 shards to each node. Setting replica count to zero If you anticipate heavy indexing, consider setting the index.number_of_replicas value to 0. Each replica duplicates the indexing process. As a result, disabling the replicas improves your cluster performance. After the heavy indexing is complete, reactivate the replicated indexes. If a node fails while replicas are disabled, you might lose data. Disable the replicas only if you can tolerate data loss for a short duration. Experiment to find the optimal bulk request size Start with a bulk request size of 5 MiB to 15 MiB. Then slowly increase the request size until the indexing performance stops improving. Use an instance type that has SSD instance store volumes (such as I3) I3 instances provide fast and local memory express (NVMe) storage. I3 instances deliver better ingestion performance than instances that use General Purpose SSD (gp2) Amazon Elastic Block Store (Amazon EBS) volumes. For more information, see Petabyte scale for Amazon OpenSearch Service. Reduce response size To reduce the size of the OpenSearch response, use the filter_path parameter to exclude unnecessary fields. Be sure that you don\\u2019t filter out any fields that are required for identifying or retrying failed requests. These fields can vary by client. In the following example, the index-name, type-name, and took fields are excluded from the response: POST /_bulk?pretty&filter_path=-took,-items.index._index,-items.index._type\\\\n{ \\\\\\\"index\\\\\\\" : { \\\\\\\"_index\\\\\\\" : \\\\\\\"test2\\\\\\\", \\\\\\\"_id\\\\\\\" : \\\\\\\"1\\\\\\\" } }\\\\n{ \\\\\\\"user\\\\\\\" : \\\\\\\"testuser\\\\\\\" }\\\\n{ \\\\\\\"update\\\\\\\" : {\\\\\\\"_id\\\\\\\" : \\\\\\\"1\\\\\\\", \\\\\\\"_index\\\\\\\" : \\\\\\\"test2\\\\\\\"} }\\\\n{ \\\\\\\"doc\\\\\\\" : {\\\\\\\"user\\\\\\\" : \\\\\\\"example\\\\\\\"} }\\\\n copy Compression codecs In OpenSearch 2.9 and later, there are two new codecs for compression: zstd and zstd_no_dict. You can optionally specify a compression level for these in the index.codec.compression_level setting with values in the [1, 6] range. Benchmark data shows that zstd provides a 7% better write throughput and zstd_no_dict provides a 14% better throughput, along with a 30% improvement in storage compared with the default codec. For more information about compression, see Index codecs. Java heap size Flush translog threshold Index refresh interval Index buffer size Concurrent merges Shard distribution Setting replica count to zero Experiment to find the optimal bulk request size Use an instance type that has SSD instance store volumes (such as I3) Reduce response size Compression codecs WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright \\u00a9 OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\\\"},{\\\"url\\\":\\\"https://medium.com/@22.gautam/mastering-aws-opensearch-for-high-volume-data-best-practices-and-optimizations-part-1-5bff65506675\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Sitemap Open in app Sign up Sign in Medium Logo Write Search Sign up Sign in Mastering AWS OpenSearch for High-Volume Data: Best Practices and Optimizations \\u2014 part 1 Kumar Gautam 4 min read \\u00b7 Jul 22, 2024 -- Listen Share Press enter or click to view image in full size AWS OpenSearch is a distributed, open-source search and analytics suite used for a wide variety of applications, including log analytics, real-time application monitoring, and clickstream analytics. When dealing with high-volume data, optimizing your OpenSearch deployment becomes crucial for maintaining performance, reliability, and cost-effectiveness. This article will delve into best practices and advanced techniques for managing AWS OpenSearch clusters under high data volumes, covering everything from cluster architecture to advanced performance tuning. Cluster Architecture and Sizing Proper cluster architecture is fundamental to handling high-volume data efficiently. a) Determining optimal number of data nodes: Rule of thumb: Start with at least 3 data nodes for production workloads. Calculate required storage: (Daily data volume * Retention period * Replication factor) / 0.75 (leaving 25% free space) Divide total required storage by storage per node to get minimum number of nodes. b) Choosing instance types: Memory-optimized (r5 or r6g series): Best for complex aggregations and caching. Compute-optimized (c5 or c6g series): Suitable for search-heavy workloads. Consider data-to-memory ratio: Aim for a 1:10 ratio of JVM heap to data on disk. c) Dedicated master nodes: Use at least 3 dedicated master nodes for clusters with 10+ data nodes. Choose instance types with at least 8 GB of RAM (m5.large or larger). d) Zone Awareness: Enable zone awareness to distribute replicas across Availability Zones. Ensure even distribution of nodes across AZs. Data Ingestion Strategies Efficient data ingestion is critical for high-volume scenarios. a) Bulk indexing: Use the _bulk API for indexing multiple documents in a single request. Optimal bulk size typically ranges from 5\\u201315 MB. Example bulk request: POST _bulk {\\\\\\\"index\\\\\\\":{\\\\\\\"_index\\\\\\\":\\\\\\\"logs\\\\\\\",\\\\\\\"_id\\\\\\\":\\\\\\\"1\\\\\\\"}} {\\\\\\\"timestamp\\\\\\\":\\\\\\\"2023-07-22T10:30:00Z\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"User login successful\\\\\\\"} {\\\\\\\"index\\\\\\\":{\\\\\\\"_index\\\\\\\":\\\\\\\"logs\\\\\\\",\\\\\\\"_id\\\\\\\":\\\\\\\"2\\\\\\\"}} {\\\\\\\"timestamp\\\\\\\":\\\\\\\"2023-07-22T10:31:00Z\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Data processing started\\\\\\\"} b) Using the Bulk API effectively: Parallelize bulk requests, but avoid overloading the cluster. Monitor the bulk_total_time_in_millis metric to find the optimal concurrency level. Implement backoff mechanisms for retries: from elasticsearch import Elasticsearch, helpers import time def bulk_index_with_backoff(client, actions, max_retries=3):     for attempt in range(max_retries):         try:             helpers.bulk(client, actions)             break         except Exception as e:             if attempt == max_retries - 1:                 raise             time.sleep(2 ** attempt)  # Exponential backoff c) Implementing a buffer layer: Use Amazon Kinesis Data Firehose for reliable, scalable data ingestion. Configure Firehose to batch and compress data before sending to OpenSearch. Example Firehose delivery stream configuration: {   \\\\\\\"DeliveryStreamName\\\\\\\": \\\\\\\"OpenSearchIngestStream\\\\\\\",   \\\\\\\"OpenSearchDestinationConfiguration\\\\\\\": {     \\\\\\\"IndexName\\\\\\\": \\\\\\\"logs\\\\\\\",     \\\\\\\"BufferingHints\\\\\\\": {       \\\\\\\"IntervalInSeconds\\\\\\\": 60,       \\\\\\\"SizeInMBs\\\\\\\": 5     },     \\\\\\\"CompressionFormat\\\\\\\": \\\\\\\"GZIP\\\\\\\"   } } d) Real-time vs. batch ingestion: For real-time: Use the _bulk API with smaller batches, potentially through a queueing system. For batch: Use larger bulk sizes and consider off-peak hours for ingestion. Indexing Optimization Efficient index design is crucial for performance and storage optimization. a) Designing efficient mappings: Explicitly define mappings to prevent type guessing: PUT logs {   \\\\\\\"mappings\\\\\\\": {     \\\\\\\"properties\\\\\\\": {       \\\\\\\"timestamp\\\\\\\": {\\\\\\\"type\\\\\\\": \\\\\\\"date\\\\\\\"},       \\\\\\\"message\\\\\\\": {\\\\\\\"type\\\\\\\": \\\\\\\"text\\\\\\\", \\\\\\\"fields\\\\\\\": {\\\\\\\"keyword\\\\\\\": {\\\\\\\"type\\\\\\\": \\\\\\\"keyword\\\\\\\"}}},       \\\\\\\"user_id\\\\\\\": {\\\\\\\"type\\\\\\\": \\\\\\\"keyword\\\\\\\"},       \\\\\\\"status_code\\\\\\\": {\\\\\\\"type\\\\\\\": \\\\\\\"integer\\\\\\\"}     }   } } Use appropriate data types (e.g., keyword for exact matches, text for full-text search). b) Using dynamic mapping judiciously: Disable dynamic mapping for high-volume indices to prevent mapping explosions: PUT logs {   \\\\\\\"mappings\\\\\\\": {     \\\\\\\"dynamic\\\\\\\": \\\\\\\"strict\\\\\\\",     \\\\\\\"properties\\\\\\\": {       // defined fields here     }   } } c) Optimizing field types for search and aggregations: Use keyword fields for aggregations and sorting. For numeric fields requiring range queries, consider using integer instead of long if possible. d) Index aliases for zero-downtime reindexing: Use aliases to switch between indices without downtime: POST /_aliases {   \\\\\\\"actions\\\\\\\": [     {\\\\\\\"add\\\\\\\": {\\\\\\\"index\\\\\\\": \\\\\\\"logs-v2\\\\\\\", \\\\\\\"alias\\\\\\\": \\\\\\\"logs-write\\\\\\\"}},     {\\\\\\\"remove\\\\\\\": {\\\\\\\"index\\\\\\\": \\\\\\\"logs-v1\\\\\\\", \\\\\\\"alias\\\\\\\": \\\\\\\"logs-write\\\\\\\"}},     {\\\\\\\"add\\\\\\\": {\\\\\\\"index\\\\\\\": \\\\\\\"logs-v2\\\\\\\", \\\\\\\"alias\\\\\\\": \\\\\\\"logs-read\\\\\\\"}},     {\\\\\\\"remove\\\\\\\": {\\\\\\\"index\\\\\\\": \\\\\\\"logs-v1\\\\\\\", \\\\\\\"alias\\\\\\\": \\\\\\\"logs-read\\\\\\\"}}   ] } Shard Management Proper shard management is essential for distributed performance. a) Calculating optimal shard size: Aim for shard sizes between 10\\u201350 GB. Calculate number of shards: (Daily data volume * Retention period) / Target shard size b) Strategies for shard allocation: Use shard allocation filtering to control data distribution: PUT logs*/_settings {   \\\\\\\"index.routing.allocation.include.data_type\\\\\\\": \\\\\\\"hot\\\\\\\" } c) Handling hot spots and shard balancing: Monitor shard sizes and search rates. Use custom routing or time-based indices to distribute load evenly. d) Using custom routing for controlled distribution: Implement custom routing for time-series data: PUT logs/_doc/1?routing=2023-07-22 {   \\\\\\\"timestamp\\\\\\\": \\\\\\\"2023-07-22T12:00:00Z\\\\\\\",   \\\\\\\"message\\\\\\\": \\\\\\\"Application started\\\\\\\" } Caching Strategies Effective caching can significantly improve query performance and reduce load on your cluster. a) Configuring and using query cache: Enable and size the query cache appropriately: PUT _cluster/settings {   \\\\\\\"persistent\\\\\\\": {     \\\\\\\"indices.queries.cache.size\\\\\\\": \\\\\\\"5%\\\\\\\"   } } The query cache is most effective for frequently run queries on mostly static data. Monitor cache hit rate using the indices_stats API: GET /_stats/query_cache?human b) Optimizing field data cache: Field data is loaded into memory for sorting and aggregations on text fields. Limit field data cache size to prevent OOM errors: PUT _cluster/settings {   \\\\\\\"persistent\\\\\\\": {     \\\\\\\"indices.fielddata.cache.size\\\\\\\": \\\\\\\"10%\\\\\\\"   } } Use doc_values for fields that require sorting or aggregations: PUT logs {   \\\\\\\"mappings\\\\\\\": {     \\\\\\\"properties\\\\\\\": {       \\\\\\\"user_id\\\\\\\": {         \\\\\\\"type\\\\\\\": \\\\\\\"keyword\\\\\\\",         \\\\\\\"doc_values\\\\\\\": true       }     }   } } c) Shard request cache considerations: Enable shard request cache for search-heavy workloads: PUT logs/_settings {   \\\\\\\"index.requests.cache.enable\\\\\\\": true } Set appropriate cache expiration: PUT logs/_settings {   \\\\\\\"index.requests.cache.expire\\\\\\\": \\\\\\\"10m\\\\\\\" } d) Implementing application-level caching: Use external caching solutions like Redis/mamcache for frequently accessed, compute-intensive results. Implement cache invalidation strategies to ensure data freshness. Here I have covered around 5 topics crucial in managing your open search cluster for handling high data volume, I will cover other topics in the next part. -- -- Written by Kumar Gautam 108 followers \\u00b738 following I love Data and Technology No responses yet Help Status About Careers Press Blog Privacy Rules Terms Text to speech\\\"},{\\\"url\\\":\\\"https://docs.otc.t-systems.com/cloud-search-service/umn/using_opensearch_for_data_search/opensearch_cluster_planning_suggestions.html\\\",\\\"title\\\":\\\"Expand Collapse\\\",\\\"content\\\":\\\"section> IaaSComputing Auto Scaling Bare Metal Server Dedicated Host Elastic Cloud Server FunctionGraph Image Management ServiceNetwork Direct Connect Domain Name Service Elastic IP Elastic Load Balancing Enterprise Router NAT Gateway Private Link Access Service Secure Mail Gateway Virtual Private Cloud Virtual Private Network VPC EndpointStorage Cloud Backup and Recovery Cloud Server Backup Service Elastic Volume Service Object Storage Service Scalable File Service Storage Disaster Recovery Service Volume Backup Service PaaSApplication API Gateway (APIG) Application Operations Management Application Performance Management Distributed Message Service (for Kafka) Simple Message NotificationData Analysis Cloud Search Service Data Lake Insight Data Warehouse Service DataArts Studio MapReduce Service ModelArts Optical Character RecognitionContainer Application Service Mesh Cloud Container Engine Cloud Container Instance Software Repository for ContainersDatabases Data Replication Service Distributed Cache Service Distributed Database Middleware Document Database Service GeminiDB Relational Database Service TaurusDB ManagementManagement & Deployment Cloud Create Cloud Eye Cloud Trace Service Config Log Tank Service Resource Formation Service Tag Management Service SecuritySecurity Services Anti-DDoS Cloud Firewall Database Security Service Dedicated Web Application Firewall Host Security Service Identity and Access Management Key Management Service Web Application Firewall OtherOther Enterprise Dashboard Marketplace Price Calculator Status Dashboard DevelopersAPIs REST API API Usage Guidelines EndpointsDevelopment and Automation SDKs Drivers and Tools Terraform Ansible Cloud CreateArchitecture Center Best Practices Blueprints IaaSComputingAuto ScalingBare Metal ServerDedicated HostElastic Cloud ServerFunctionGraphImage Management ServiceNetworkDirect ConnectDomain Name ServiceElastic IPElastic Load BalancingEnterprise RouterNAT GatewayPrivate Link Access ServiceSecure Mail GatewayVirtual Private CloudVirtual Private NetworkVPC EndpointStorageCloud Backup and RecoveryCloud Server Backup ServiceElastic Volume ServiceObject Storage ServiceScalable File ServiceStorage Disaster Recovery ServiceVolume Backup ServicePaaSApplicationAPI Gateway (APIG)Application Operations ManagementApplication Performance ManagementDistributed Message Service (for Kafka)Simple Message NotificationData AnalysisCloud Search ServiceData Lake InsightData Warehouse ServiceDataArts StudioMapReduce ServiceModelArtsOptical Character RecognitionContainerApplication Service MeshCloud Container EngineCloud Container InstanceSoftware Repository for ContainersDatabasesData Replication ServiceDistributed Cache ServiceDistributed Database MiddlewareDocument Database ServiceGeminiDBRelational Database ServiceTaurusDBManagementManagement & DeploymentCloud CreateCloud EyeCloud Trace ServiceConfigLog Tank ServiceResource Formation ServiceTag Management ServiceSecuritySecurity ServicesAnti-DDoSCloud FirewallDatabase Security ServiceDedicated Web Application FirewallHost Security ServiceIdentity and Access ManagementKey Management ServiceWeb Application FirewallOtherOtherEnterprise DashboardMarketplacePrice CalculatorStatus Dashboard Expand Collapse Cloud Search Service Product Overview Getting Started CSS Service Permission Management Using Elasticsearch for Data Search Using OpenSearch for Data Search Procedure for Using OpenSearch OpenSearch Cluster Planning Suggestions Creating an OpenSearch Cluster Accessing an OpenSearch Cluster Importing Data to an OpenSearch Cluster Searching Data in an OpenSearch Cluster Enhancing Search Capabilities for OpenSearch Clusters Configuring Networking for an OpenSearch Cluster Backing up and Restoring the Data of an OpenSearch Cluster Scaling an OpenSearch Cluster Upgrading the Version of an OpenSearch Cluster Managing OpenSearch Clusters Managing Index Policies for OpenSearch Clusters OpenSearch Cluster Monitoring and Log Management Viewing OpenSearch Cluster Audit Logs CSS Resource Monitoring FAQs Change History User Guide Using OpenSearch for Data Search OpenSearch Cluster Planning Suggestions OpenSearch Cluster Planning Suggestions\\u00b6 Before creating an OpenSearch cluster, develop a plan for it, such as whether to deploy the cluster across multiple AZs to improve availability; the node quantity and specifications; the cluster version and security mode; and index sharding, in order to ensure the desired performance and reliability. Planning Cluster AZs\\u00b6 By deploying a CSS cluster across multiple AZs, you can increase the cluster's availability, lower the likelihood of data loss, and minimize service downtime. You can select two or three different AZs in the same region to deploy a cluster. If you select two or three AZs when creating a cluster, CSS automatically enables cross-AZ HA, ensuring cluster nodes distribute evenly across these AZs. Even distribution of cluster nodes across AZs means the difference between node quantities in different AZs does not exceed 1. For details, see Table 1. Important When creating a multi-AZ cluster, ensure that the number of selected nodes of any type is no less than the number of AZs. Otherwise, multi-AZ cluster deployment will fail. When a multi-AZ cluster is deployed, nodes of all types are evenly distributed across different AZs. The difference between node quantities in different AZs does not exceed 1. If the number of data nodes plus cold data nodes in a cluster is not an integer multiple of the number of AZs, data in the cluster may be unevenly distributed, affecting data query or write performance. Table 1 Node quantities and AZ distribution\\u00b6 Node Quantity Single AZ Two AZs Three AZs AZ1 AZ1 AZ2 AZ1 AZ2 AZ3 1 1 Not supported Not supported 2 2 1 1 Not supported 3 3 2 1 1 1 1 4 4 2 2 2 1 1 ... ... ... ... ... ... ... In the case of a multi-AZ deployment, configure the number of replicas in a manner that can better capitalize on the high availability that comes with such as deployment. In a two-AZ deployment, if one AZ becomes unavailable, the other AZ continues to provide services. In this case, at least one replica is required. OpenSearch uses one replica by default. You can retain the default value if you do not require higher read performance. In the case of a three-AZ deployment, if one AZ becomes unavailable, the other AZs can continue to provide services. In this case, at least one replica is required. OpenSearch uses one replica by default. If you need more replicas to improve the cluster's ability to handle queries, modify the replica setting to increase the number of replicas. For example, you can run the following command to set the number of index replicas: curl -XPUT http://ip:9200/{index_name}/_settings -d '{\\\\\\\"number_of_replicas\\\\\\\":2}' Alternatively, run the following command to specify the number of replicas in the index template: curl -XPUT http://ip:9200/_template/templatename -d '{ \\\\\\\"template\\\\\\\": \\\\\\\"*\\\\\\\", \\\\\\\"settings\\\\\\\": {\\\\\\\"number_of_replicas\\\\\\\": 2}}' where, ip indicates the private IP address of the cluster, index_name indicates the index name, and number_of_replicas indicates the number of index replicas to change to. In this example, the number of index replicas is changed to 2. Table 2 describes the service outage patterns for different variations of a multi-AZ deployment facing the failure of a single AZ. Table 2 Possible service outage patterns in the face of the failure of a single AZ\\u00b6 Number of AZs Number of Master Nodes Service Outage Patterns and Handling Suggestions 2 0 If the number of nodes is an even number: If half of the data nodes are faulty, you need to replace one node in the faulty AZ before a master node can be selected. If the number of nodes is an odd number: If the faulty AZ contains one more node than the normal AZ, you need to replace one node in the faulty AZ before a master node can be selected. For how to replace nodes, contact technical support. If the faulty AZ contains one less node than the normal AZ, services will not be interrupted and a master node can be selected. 2 3 There is a 50% chance of service interruption. When two dedicated master nodes are allocated to one AZ and another master node is allocated to the other AZ: If service interruption happens in the AZ with one master node, a master node can be selected from the AZ that has two dedicated master nodes. If service interruption happens in the AZ with two dedicated master nodes, master nodes cannot be selected because the remaining AZ has only one dedicated master node. In this case, services will be interrupted and you need to contact technical support. 3 0 If you have three AZs and four nodes, one AZ will have two nodes, and the other two will each have one node. If the AZ with two nodes becomes faulty, services will be interrupted. Therefore, you are advised not to configure four nodes when selecting three AZs. There is a small chance of service interruption if you follow this advice. 3 3 Service interruption does not occur. Note You can switch AZs for an existing cluster. For details, see Switching AZs for an OpenSearch Cluster. You can Add AZ or Migrate AZ. Add AZ: Add one or two AZs to a single-AZ cluster, or add an AZ to a dual-AZ cluster to improve cluster availability. Migrate AZ: Completely migrate data from the current AZ to another AZ that has sufficient resources. Planning the Cluster Version\\u00b6 When selecting an OpenSearch cluster version, consider factors such as service requirements, available features, performance, security updates, and long-term support, ensuring that the selected version can meet both current and future needs and provide a stable, secure environment for your data. Table 3 Cluster version support\\u00b6 Feature OpenSearch 1.3.6 OpenSearch 2.17.1 Related Documents Vector search Y x Configuring Vector Search for OpenSearch Clusters Decoupled storage and compute Y x Configuring Storage-Compute Decoupling for an OpenSearch Cluster Switching over between hot and cold storage Y Y Switching Between Hot and Cold Storage for an OpenSearch Cluster Enhanced import performance Y x Enhancing the Data Import Performance of OpenSearch Clusters Planning Node Types\\u00b6 For an OpenSearch cluster, the proper planning of different types of nodes is critical to optimizing performance and resource utilization. Before creating a cluster, determine the types of nodes to use based on service requirements, query load, data growth patterns, and performance goals. Table 4 describes the characteristics of different node types and the purposes they are suited for. Note If no master or client nodes were enabled when a cluster was created, you can add them if data nodes become overloaded later at some point. For details, see Adding Master or Client Nodes. If no cold data nodes were enabled during cluster creation, they cannot be added later, so you have to determine whether to use cold data nodes while creating a cluster. Table 4 Characteristics and purposes of different types of nodes\\u00b6 Node Type Node Description Characteristics Data node (ESS) Data nodes are used to store data. In a cluster that has neither master nor client nodes, data nodes provide the functions of both types of nodes. Data nodes are mandatory for any cluster. If Master node and Client node are both unselected, data nodes will be used for all of the following purposes: cluster management, data storage, cluster access, and data analysis. To ensure reliability, a cluster should have a least three nodes. If Master node is selected but Client node is not, data nodes will be used for data storage, cluster access, and data analysis. If Master node is unselected but Client node is selected, data nodes will be used for data storage and cluster management. If Master node and Client node are both selected, data nodes will be used for data storage only. Master node (ess-master) The master node is responsible for cluster management, such as metadata management, index creation and deletion, and shard allocation. It plays a critical role in metadata management, node management, stability guarantee, and cluster operation control for large-scale clusters. Large-scale cluster: For a cluster that has more than 16 nodes, you are advised to add dedicated master nodes to effectively manage the cluster status and metadata. Large quantities of indexes and shards: If the number of indexes or shards exceeds 10,000, a master node will have better performance in handling complex cluster management tasks, avoiding impact on the performance of data nodes. Better management of cluster nodes: The master node maintains the cluster metadata, including index mapping, settings, and aliases. For a complex cluster structure, a dedicated master node offers better management, including node joining, exiting, and fault detection. The master node plays a critical role in cluster node management. Improved cluster stability and reliability: A dedicated master node improves cluster stability and reliability by taking over cluster management responsibilities from data storage and query nodes. Optimized performance for data nodes: By offloading cluster management tasks from data nodes to master nodes, you can allow data nodes to focus on data processing, which leads to improved performance. Client node (ess-client) Client nodes receive and coordinate external requests, such as search and write requests. They play an important role in handling high-load queries, complex aggregations, managing a large number of shards, and improving cluster scalability. High QPS: In the face of a high queries per second (QPS), a dedicated client node can evenly distribute query requests, reducing the load of data nodes and improving the overall query performance. Complex aggregation queries: For complex, compute-intensive aggregation queries, a client node can dedicate to the handling of aggregation results, thus improving the efficiency and response speed of such queries. Large number of shards: In a cluster with a large number of shards, a client node can effectively coordinate and manage query requests to each shard, improving efficiency in request forwarding and processing. Reducing the load of data nodes: A client node parses search requests, determines the locations of index shards, and coordinates different nodes to execute searches. This reduces the load of data nodes by allowing them to focus on data storage and indexing. Improved cluster scalability: The use of client nodes allows for better cluster scalability and flexibility, enabling supporting for large datasets and more complex query requirements. Cold data node (ess-cold) Cold data nodes are used to store query latency-insensitive data in large quantities. They offer an effective way to manage large datasets and cut storage costs. Storage of historical data in large quantities: Cold data nodes offer a more cost-effective solution for storing large quantities of historical data that are infrequently accessed but useful for analytical purposes. Optimizing hot data performance: By migrating cold data to cold data nodes, you reduce the storage load of hot data nodes, thereby optimizing their query and write performance. Insensitivity to query latency: Cold data nodes are a better option for storing data that is insensitive to a high query latency. Cost-effectiveness: Cold data nodes usually use large disks that offer inexpensive storage. Planning Node Storage\\u00b6 Planning node models CSS supports various ECS models suited for different application needs. Select the appropriate models based on service requirements and performance expectations to achieve a perfect balance between storage performance and costs. Table 5 Different node models and the intended application scenarios\\u00b6 Node Model Disk Type Specifications Description Recommended Scenario Computing-intensive Cloud drive vCPUs:Memory = 1:2 Small-volume searches (less than 100 GB on a single node). General computing Cloud drive vCPUs:Memory = 1:4 Medium-scale e-commerce site search, social search, and log search, search and analysis where the data volume on a single node is in the range 100 GB to 1,000 GB. Memory-optimized Cloud drive vCPUs:Memory = 1:8 Search and analysis where the data volume on a single node is in the range 100 GB to 2,000 GB. This type of node is a good option for vector search, as its large memory helps improve cluster performance and stability. Planning node specifications Given the expected data handling capacities, it is always preferable to use a smaller number of nodes with larger specifications rather than a larger number of nodes with smaller specifications. For example, a cluster consisting of three nodes each with 32 CPU cores and 64 GB memory is usually better than a cluster consisting of 12 nodes each with 8 CPU cores and 16 GB memory in terms of stability and scalability. The specific advantages are as follows: Cluster stability: High-specs nodes provide more powerful data processing capabilities and larger memory space, leading to higher overall cluster stability. Improved scalability: When a cluster consisting of high-specs nodes encounters a performance bottleneck, you simply add more of these high-specs nodes. This is easier than increasing the specifications of existing nodes. Easier maintenance: A smaller number of nodes means easier maintenance and less complex management. In contrast, when a cluster consisting of low-specs nodes needs extra capacity, usually a vertical scale-up is performed, meaning to increase the specifications of existing nodes. This may entail not only more complex, challenging migration and upgrade processes, but also additional maintenance costs. To sum up, when planning a cluster, you must fully consider performance, costs, maintenance, and scalability, and choose the node specifications that best suit your needs. Planning storage capacity When planning the storage capacity of a CSS cluster, consider the following factors: the original data size, number of data replicas, data bloat rate, and disk usage The following is a recommended formula for determining the needed cluster storage capacity. Storage capacity = Original data size x (1 + Number of replicas) x (1 + Data bloat rate) x (1 + Ratio of reserved space) Original data size: Determine the size of the original data that needs to be stored. Number of replicas: The default value is 1. Data bloat rate: Extra data may be generated due to data indexing. Generally, you are advised to use a 25% data bloat rate. Disk usage: Considering the space occupied by the operating system and file system and the space reserved for optimized disk performance and redundancy, you are advised to keep the disk usage under 70%. That is, you need to reserve 30% of the total disk capacity. A recommended formula is as follows: Cluster storage capacity = Original data size x 2 x 1.25 x 1.3 To put it simply, if the original data size is known, the total storage capacity of the cluster needs to be 3.25 times that. This formula is for quick reference only. You still need to adjust it based on the actual applications and projected data growth rate. Planning the Node Quantity\\u00b6 Plan the node quantity based on performance requirements and predicted load. Table 6 provides a method for calculating the appropriate number of nodes. Following this method helps you ensure cluster performance and stability. Table 6 Calculating the number of cluster nodes\\u00b6 Node Performance Baseline Formula Example Write node For a node that uses cloud disks, the write performance baseline of a single vCPU is 1 MB/s. For an ultra-high I/O node, the write performance baseline of a single vCPU is 1.5 MB/s. Number of write nodes = Peak traffic/Number of vCPUs per node/Write throughput per vCPU x Number of replicas If the peak inbound traffic is 100 MB/s and a node has 16 vCPUs and 64 GB memory, 12 nodes (100/16/1 x 2) are needed. Query node It is difficult to evaluate the performance baseline of a single node out of the context of specific application scenarios. The average query response time (in seconds) is used here to measure the query performance baseline. Number of query nodes = QPS/(Number of vCPUs per node x 3/2/Average query response time in seconds) x Number of shards If the query QPS is 1000, the average query response time is 100 ms (0.1s), three index shards are planned, and a node has 16 vCPUs and 64 GB memory, ~12 nodes (1000/(16 x 3/2/0.1) x 3) are needed. Total number of nodes N/A Total number of nodes = Number of write nodes + Number of query nodes Total number of nodes = Number of write nodes + Number of query nodes = 24 Note Here, the total number of nodes refer to the number of data nodes plus that of cold data nodes. In each cluster, the number of nodes supported by each node type varies, depending on the types of nodes used in that cluster. For details, see Table 7. Table 7 Number of nodes of different types allowed in a single cluster\\u00b6 Node Type Node Quantity ess ess: 1-32 ess, ess-master ess: 1-200 ess-master: an odd number ranging from 3 to 9 ess, ess-client ess: 1-32 ess-client: 1-32 ess, ess-cold ess: 1-32 ess-cold: 1-32 ess, ess-master, ess-client ess: 1-200 ess-master: an odd number ranging from 3 to 9 ess-client: 1-32 ess, ess-master, ess-cold ess: 1-200 ess-master: an odd number ranging from 3 to 9 ess-cold: 1-32 ess, ess-client, ess-cold ess: 1-32 ess-client: 1-32 ess-cold: 1-32 ess, ess-master, ess-client, ess-cold ess: 1-200 ess-master: an odd number ranging from 3 to 9 ess-client: 1-32 ess-cold: 1-32 Note ess: data node, which is the default node type that is mandatory for cluster creation. The other three node types are optional. ess-master: master node ess-client: client node ess-cold: cold data node Planning a Cluster's Security Mode\\u00b6 Table 8 Cluster security modes\\u00b6 Cluster Type Description Recommended Scenario Non-security mode cluster Cluster for which the security mode is disabled With such a cluster, access to the cluster will not require user authentication, and data will be transmitted in plaintext using HTTP. Make sure the customer is in a secure environment, and do not expose the cluster access interface to the public network. This type of cluster is mostly used for internal services and testing. Advantage: simple and easy to access. Disadvantage: poor security as anyone can access it. Security-mode cluster Cluster in security mode + HTTP A security-mode cluster requires user authentication. It supports access control and data encryption, and it uses HTTP to transmit data in plaintext. Make sure the customer is in a secure environment, and do not expose the cluster access interface to the public network. Access control by user permissions is supported. This type of cluster is suitable for workloads that are particularly performance-demanding. Advantage: User authentication improves cluster security. HTTP-based access ensures high performance of the cluster. Disadvantage: The cluster cannot be accessed from the public network. Cluster in security mode + HTTPS A security-mode cluster requires user authentication. It supports access control and data encryption, and it uses HTTPS to encrypt communication and enhance data security. This type of cluster is suitable where there is a high security standard and public network access is required. Advantage: User authentication improves cluster security, and HTTPS-based secure communication allows for secure public network access. Disadvantage: HTTPS encrypts nearly all information sent between server and client, causing a read performance loss of around 20%. To access a security-mode cluster, you need to provide a username and password. CSS supports authentication for the following two types of users: Administrator: The default administrator username is admin, and the password is the one specified during cluster creation. Cluster user: created by the cluster administrator on Kibana. For details, see Creating Users for an OpenSearch Cluster and Granting Cluster Access. Note You can change the security mode of an existing cluster. For details, see Changing the Security Mode of an OpenSearch Cluster. You have many options when it comes to changing the security mode of a cluster: from non-security mode to security mode, from security mode to non-security mode, and switching between security modes using different web protocols (HTTP or HTTPS). Planning the Number of Index Shards\\u00b6 Before importing data to a cluster, carefully consider your service needs and plan the cluster's data structure and distribution in advance. This includes properly designing indexes and deciding on the appropriate number of index shards. To ensure optimal performance and scalability for a cluster, consider following these best practices: The size of a single shard: Keep the size of each shard between 10 GB and 50 GB. This helps strike a balance between storage efficiency and query performance. Total number of shards in a cluster: To facilitate management and avoid an excessively large scale, make sure the total number of shards in a cluster is less than 30,000. This helps maintain the stability and responsiveness of the cluster. Memory-to-shards ratio: Limit the number of shards per 1 GB of memory to 20 to 30. This ensures that each shard has sufficient memory resources to respond to indexing and query operations. Number of shards per node: To prevent node overload, keep the number of shards on each node under 1000. This helps to improve node stability. Relationship between the number of index shards and the number of nodes: For each index, make sure the number of shards is the same as or is an integral multiple of the number of nodes in the cluster. This helps improve load balancing and optimize query and indexing performance. Following these suggestions, you can plan and manage index shards for a CSS cluster more effectively, improving the cluster's overall performance and maintainability. Prev Next last updated: 2025-10-17 08:30 UTC - commit: 72cf7ac7e660373c1a0b45109197d9d453cd565f Edit pageReport Documentation Bug Page Contents OpenSearch Cluster Planning Suggestions Planning Cluster AZs Planning the Cluster Version Planning Node Types Planning Node Storage Planning the Node Quantity Planning a Cluster's Security Mode Planning the Number of Index Shards \\u00a9 T-Systems International GmbH Contact Data privacy Disclaimer of Liabilities Imprint\\\"}]}\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "üí° Best Practices:\n",
      "{\n",
      "  \"inference_results\": [\n",
      "    {\n",
      "      \"output\": [\n",
      "        {\n",
      "          \"name\": \"response\",\n",
      "          \"result\": \"{\\\"next_page\\\":\\\"https://duckduckgo.com/html?q=OpenSearch+cluster+sizing+best+practices&s=10&nextParams=&v=l&o=json&dc=11&api=d.js&vqd=4-325981505372936351747571540840411248409&kl=wt-wt\\\",\\\"items\\\":[{\\\"url\\\":\\\"https://docs.aws.amazon.com/opensearch-service/latest/developerguide/bp.html\\\",\\\"title\\\":\\\"Operational best practices for Amazon OpenSearch Service - Amazon OpenSearch Service\\\",\\\"content\\\":\\\"Operational best practices for Amazon OpenSearch Service - Amazon OpenSearch Service DocumentationAmazon OpenSearch ServiceDeveloper Guide Monitoring and alertingShard strategyStabilityPerformanceSecurityCost optimization Operational best practices for Amazon OpenSearch Service This chapter provides best practices for operating Amazon OpenSearch Service domains and includes general guidelines that apply to many use cases. Each workload is unique, with unique characteristics, so no generic recommendation is exactly right for every use case. The most important best practice is to deploy, test, and tune your domains in a continuous cycle to find the optimal configuration, stability, and cost for your workload. Topics Monitoring and alerting Shard strategy Stability Performance Security Cost optimization Sizing Amazon OpenSearch Service domains Petabyte scale in Amazon OpenSearch Service Dedicated coordinator nodes in Amazon OpenSearch Service Dedicated master nodes in Amazon OpenSearch Service Monitoring and alerting The following best practices apply to monitoring your OpenSearch Service domains. Configure CloudWatch alarms OpenSearch Service emits performance metrics to Amazon CloudWatch. Regularly review your cluster and instance metrics and configure recommended CloudWatch alarms based on your workload performance. Enable log publishing OpenSearch Service exposes OpenSearch error logs, search slow logs, indexing slow logs, and audit logs in Amazon CloudWatch Logs. Search slow logs, indexing slow logs, and error logs are useful for troubleshooting performance and stability issues. Audit logs, which are only available if you enable fine-grained access control to track user activity. For more information, see Logs in the OpenSearch documentation. Search slow logs and indexing slow logs are an important tool for understanding and troubleshooting the performance of your search and indexing operations. Enable search and index slow log delivery for all production domains. You must also configure logging thresholds\\u2014otherwise, CloudWatch won't capture the logs. Shard strategy Shards distribute your workload across the data nodes in your OpenSearch Service domain. Properly configured indexes can help boost overall domain performance. When you send data to OpenSearch Service, you send that data to an index. An index is analogous to a database table, with documents as the rows, and fields as the columns. When you create the index, you tell OpenSearch how many primary shards you want to create. The primary shards are independent partitions of the full dataset. OpenSearch Service automatically distributes your data across the primary shards in an index. You can also configure replicas of the index. Each replica shard comprises a full set of copies of the primary shards for that index. OpenSearch Service maps the shards for each index across the data nodes in your cluster. It ensures that the primary and replica shards for the index reside on different data nodes. The first replica ensures that you have two copies of the data in the index. You should always use at least one replica. Additional replicas provide additional redundancy and read capacity. OpenSearch sends indexing requests to all of the data nodes that contain shards that belong to the index. It sends indexing requests first to data nodes that contain primary shards, and then to data nodes that contain replica shards. Search requests are routed by the coordinator node to either a primary or replica shard for all shards belonging to the index. For example, for an index with five primary shards and one replica, each indexing request touches 10 shards. In contrast, search requests are sent to n shards, where n is the number of primary shards. For an index with five primary shards and one replica, each search query touches five shards (primary or replica) from that index. Determine shard and data node counts Use the following best practices to determine shard and data node counts for your domain. Shard size \\u2013 The size of data on disk is a direct result of the size of your source data, and it changes as you index more data. The source-to-index ratio can vary wildly, from 1:10 to 10:1 or more, but usually it's around 1:1.10. You can use that ratio to predict the index size on disk. You can also index some data and retrieve the actual index sizes to determine the ratio for your workload. After you have a predicted index size, set a shard count so that each shard will be between 10\\u201330 GiB (for search workloads), or between 30\\u201350 GiB (for logs workloads). 50 GiB should be the maximum\\u2014be sure to plan for growth. Shard count \\u2013 The distribution of shards to data nodes has a large impact on a domain\\u2019s performance. When you have indexes with multiple shards, try to make the shard count a multiple of the data node count. This helps to ensure that shards are evenly distributed across data nodes, and prevents hot nodes. For example, if you have 12 primary shards, your data node count should be 2, 3, 4, 6, or 12. However, shard count is secondary to shard size\\u2014if you have 5 GiB of data, you should still use a single shard. Shards per data node \\u2013 The total number of shards that a node can hold is proportional to the node\\u2019s Java virtual machine (JVM) heap memory. Aim for 25 shards or fewer per GiB of heap memory. For example, a node with 32 GiB of heap memory should hold no more than 800 shards. Although shard distribution can vary based on your workload patterns, there's a limit of 1,000 shards per node for Elasticsearch and OpenSearch 1.1 to 2.15 and 4,000 for OpenSearch 2.17 and above. The cat/allocation API provides a quick view of the number of shards and total shard storage across data nodes. Shard to CPU ratio \\u2013 When a shard is involved in an indexing or search request, it uses a vCPU to process the request. As a best practice, use an initial scale point of 1.5 vCPU per shard. If your instance type has 8 vCPUs, set your data node count so that each node has no more than six shards. Note that this is an approximation. Be sure to test your workload and scale your cluster accordingly. For storage volume, shard size, and instance type recommendations, see the following resources: Sizing Amazon OpenSearch Service domains Petabyte scale in Amazon OpenSearch Service Avoid storage skew Storage skew occurs when one or more nodes within a cluster holds a higher proportion of storage for one or more indexes than the others. Indications of storage skew include uneven CPU utilization, intermittent and uneven latency, and uneven queueing across data nodes. To determine whether you have skew issues, see the following troubleshooting sections: Node shard and storage skew Index shard and storage skew Stability The following best practices apply to maintaining a stable and healthy OpenSearch Service domain. Keep current with OpenSearch Service software updates OpenSearch Service regularly releases software updates that add features or otherwise improve your domains. Updates don't change the OpenSearch or Elasticsearch engine version. We recommend that you schedule a recurring time to run the DescribeDomain API operation, and initiate a service software update if the UpdateStatus is ELIGIBLE. If you don't update your domain within a certain time frame (typically two weeks), OpenSearch Service automatically performs the update. OpenSearch version upgrades OpenSearch Service regularly adds support for community-maintained versions of OpenSearch. Always upgrade to the latest OpenSearch versions when they're available. OpenSearch Service simultaneously upgrades both OpenSearch and OpenSearch Dashboards (or Elasticsearch and Kibana if your domain is running a legacy engine). If the cluster has dedicated master nodes, upgrades complete without downtime. Otherwise, the cluster might be unresponsive for several seconds post-upgrade while it elects a master node. OpenSearch Dashboards might be unavailable during some or all of the upgrade. There are two ways to upgrade a domain: In-place upgrade \\u2013 This option is easier because you keep the same cluster. Snapshot/restore upgrade \\u2013 This option is good for testing new versions on a new cluster or migrating between clusters. Regardless of which upgrade process you use, we recommend that you maintain a domain that is solely for development and testing, and upgrade it to the new version before you upgrade your production domain. Choose Development and testing for the deployment type when you're creating the test domain. Make sure to upgrade all clients to compatible versions immediately following the domain upgrade. Improve snapshot performance To prevent your snapshot from getting stuck in processing, the instance type for the dedicated master node should match the shard count. For more information, see Choosing instance types for dedicated master nodes. Additionally, each node should have no more than the recommended 25 shards per GiB of Java heap memory. For more information, see Choosing the number of shards. Enable dedicated master nodes Dedicated master nodes improve cluster stability. A dedicated master node performs cluster management tasks, but doesn't hold index data or respond to client requests. This offloading of cluster management tasks increases the stability of your domain and makes it possible for some configuration changes to happen without downtime. Enable and use three dedicated master nodes for optimal domain stability across three Availability Zones. Deploying with Multi-AZ with Standby configures three dedicated master nodes for you. For instance type recommendations, see Choosing instance types for dedicated master nodes. Deploy across multiple Availability Zones To prevent data loss and minimize cluster downtime in the event of a service disruption, you can distribute nodes across two or three Availability Zones in the same AWS Region. Best practice is to deploy using Multi-AZ with Standby, which configures three Availability Zones, with two zones active and one acting as a standby, and with and two replica shards per index. This configuration lets OpenSearch Service distribute replica shards to different AZs than their corresponding primary shards. There are no cross-AZ data transfer charges for cluster communications between Availability Zones. Availability Zones are isolated locations within each Region. With a two-AZ configuration, losing one Availability Zone means that you lose half of all domain capacity. Moving to three Availability Zones further reduces the impact of losing a single Availability Zone. Control ingest flow and buffering We recommend that you limit the overall request count using the _bulk API operation. It's more efficient to send one _bulk request that contains 5,000 documents than it is to send 5,000 requests that contain a single document. For optimal operational stability, it's sometimes necessary to limit or even pause the upstream flow of indexing requests. Limiting the rate of index requests is an important mechanism for dealing with unexpected or occasional spikes in requests that might otherwise overwhelm the cluster. Consider building a flow control mechanism into your upstream architecture. The following diagram shows multiple component options for a log ingest architecture. Configure the aggregation layer to allow sufficient space to buffer incoming data for sudden traffic spikes and brief domain maintenance. Create mappings for search workloads For search workloads, create mappings that define how OpenSearch stores and indexes documents and their fields. Set dynamic to strict in order to prevent new fields from being added accidentally. PUT my-index\\\\n{\\\\n  \\\\\\\"mappings\\\\\\\": {\\\\n    \\\\\\\"dynamic\\\\\\\": \\\\\\\"strict\\\\\\\",\\\\n    \\\\\\\"properties\\\\\\\": {\\\\n      \\\\\\\"title\\\\\\\": { \\\\\\\"type\\\\\\\" : \\\\\\\"text\\\\\\\" },\\\\n      \\\\\\\"author\\\\\\\": { \\\\\\\"type\\\\\\\" : \\\\\\\"integer\\\\\\\" },\\\\n      \\\\\\\"year\\\\\\\": { \\\\\\\"type\\\\\\\" : \\\\\\\"text\\\\\\\" }\\\\n    }\\\\n  }\\\\n} Use index templates You can use an index template as a way to tell OpenSearch how to configure an index when it's created. Configure index templates before creating indexes. Then, when you create an index, it inherits the settings and mappings from the template. You can apply more than one template to a single index, so you can specify settings in one template and mappings in another. This strategy allows one template for common settings across multiple indexes, and separate templates for more specific settings and mappings. The following settings are helpful to configure in templates: Number of primary and replica shards Refresh interval (how often to refresh and make recent changes to the index available to search) Dynamic mapping control Explicit field mappings The following example template contains each of these settings: {\\\\n   \\\\\\\"index_patterns\\\\\\\":[\\\\n      \\\\\\\"index-*\\\\\\\"\\\\n   ],\\\\n   \\\\\\\"order\\\\\\\": 0,\\\\n   \\\\\\\"settings\\\\\\\": {\\\\n      \\\\\\\"index\\\\\\\": {\\\\n         \\\\\\\"number_of_shards\\\\\\\": 3,\\\\n         \\\\\\\"number_of_replicas\\\\\\\": 1,\\\\n         \\\\\\\"refresh_interval\\\\\\\": \\\\\\\"60s\\\\\\\"\\\\n      }\\\\n   },\\\\n   \\\\\\\"mappings\\\\\\\": {\\\\n      \\\\\\\"dynamic\\\\\\\": false,\\\\n      \\\\\\\"properties\\\\\\\": {\\\\n         \\\\\\\"field_name1\\\\\\\": {\\\\n            \\\\\\\"type\\\\\\\": \\\\\\\"keyword\\\\\\\"\\\\n         }\\\\n      }\\\\n   }\\\\n} Even if they rarely change, having settings and mappings defined centrally in OpenSearch is simpler to manage than updating multiple upstream clients. Manage indexes with Index State Management If you're managing logs or time-series data, we recommend using Index State Management (ISM). ISM lets you automate regular index lifecycle management tasks. With ISM, you can create policies that invoke index alias rollovers, take index snapshots, move indexes between storage tiers, and delete old indexes. You can even use the ISM rollover operation as an alternative data lifecycle management strategy to avoid shard skew. First, set up an ISM policy. For example, see Sample policies. Then, attach the policy to one or more indexes. If you include an ISM template field in the policy, OpenSearch Service automatically applies the policy to any index that matches the specified pattern. Remove unused indexes Regularly review the indexes in your cluster and identify any that aren't in use. Take a snapshot of those indexes so that they're stored in S3, and then delete them. When you remove unused indexes, you reduce the shard count, and make it possible to have more balanced storage distribution and resource utilization across nodes. Even when they're idle, indexes consume some resources during internal index maintenance activities. Rather than manually deleting unused indexes, you can use ISM to automatically take a snapshot and delete indexes after a certain period of time. Use multiple domains for high availability To achieve high availability beyond 99.9% uptime across multiple Regions, consider using two domains. For small or slowly changing datasets, you can set up cross-cluster replication to maintain an active-passive model. In this model, only the leader domain is written to, but either domain can be read from. For larger data sets and quickly changing data, configure dual delivery in your ingest pipeline so that all data is written independently to both domains in an active-active model. Architect your upstream and downstream applications with failover in mind. Make sure to test the failover process along with other disaster recovery processes. Performance The following best practices apply to tuning your domains for optimal performance. Optimize bulk request size and compression Bulk sizing depends on your data, analysis, and cluster configuration, but a good starting point is 3\\u20135 MiB per bulk request. Send requests and receive responses from your OpenSearch domains by using gzip compression to reduce the payload size of requests and responses. You can use gzip compression with the OpenSearch Python client, or by including the following headers from the client side: 'Accept-Encoding': 'gzip' 'Content-Encoding': 'gzip' To optimize your bulk request sizes, start with a bulk request size of 3 MiB. Then, slowly increase the request size until indexing performance stops improving. Note To enable gzip compression on domains running Elasticsearch version 6.x, you must set http_compression.enabled at the cluster level. This setting is true by default in Elasticsearch versions 7.x and all versions of OpenSearch. Reduce the size of bulk request responses To reduce the size of OpenSearch responses, exclude unnecessary fields with the filter_path parameter. Make sure that you don't filter out any fields that are required to identify or retry failed requests. For more information and examples, see Reducing response size. Tune refresh intervals OpenSearch indexes have eventual read consistency. A refresh operation makes all the updates that are performed on an index available for search. The default refresh interval is one second, which means that OpenSearch performs a refresh every second while an index is being written to. The less frequently that you refresh an index (higher refresh interval), the better the overall indexing performance is. The trade-off of increasing the refresh interval is that there\\u2019s a longer delay between an index update and when the new data is available for search. Set your refresh interval as high as you can tolerate to improve overall performance. We recommend setting the refresh_interval parameter for all of your indexes to 30 seconds or more. Enable Auto-Tune Auto-Tune uses performance and usage metrics from your OpenSearch cluster to suggest changes to queue sizes, cache sizes, and Java virtual machine (JVM) settings on your nodes. These optional changes improve cluster speed and stability. You can revert to the default OpenSearch Service settings at any time. Auto-Tune is enabled by default on new domains unless you explicitly disable it. We recommend that you enable Auto-Tune on all domains, and either set a recurring maintenance window or periodically review its recommendations. Security The following best practices apply to securing your domains. Enable fine-grained access control Fine-grained access control lets you control who can access certain data within an OpenSearch Service domain. Compared to generalized access control, fine-grained access control gives each cluster, index, document, and field its own specified policy for access. Access criteria can be based on a number of factors, including the role of the person who is requesting access and the action that they intend to perform on the data. For example, you might give one user access to write to an index, and another user access only to read the data on the index without making any changes. Fine-grained access control allows data with different access requirements to exist in the same storage space without running into security or compliance issues. We recommend enabling fine-grained access control on your domains. Deploy domains within a VPC Placing your OpenSearch Service domain within a virtual private cloud (VPC) helps enable secure communication between OpenSearch Service and other services within the VPC\\u2014without the need for an internet gateway, NAT device, or VPN connection. All traffic remains securely within the AWS Cloud. Because of their logical isolation, domains that reside within a VPC have an extra layer of security compared to domains that use public endpoints. We recommend that you create your domains within a VPC. Apply a restrictive access policy Even if your domain is deployed within a VPC, it's a best practice to implement security in layers. Make sure to check the configuration of your current access policies. Apply a restrictive resource-based access policy to your domains and follow the principle of least privilege when granting access to the configuration API and the OpenSearch API operations. As a general rule, avoid using the anonymous user principal \\\\\\\"Principal\\\\\\\": {\\\\\\\"AWS\\\\\\\": \\\\\\\"*\\\\\\\" } in your access policies. There are some situations, however, where it's acceptable to use an open access policy, such as when you enable fine-grained access control. An open access policy can enable you to access the domain in cases where request signing is difficult or impossible, such as from certain clients and tools. Enable encryption at rest OpenSearch Service domains offer encryption of data at rest to help prevent unauthorized access to your data. Encryption at rest uses AWS Key Management Service (AWS KMS) to store and manage your encryption keys, and the Advanced Encryption Standard algorithm with 256-bit keys (AES-256) to perform the encryption. If your domain stores sensitive data, enable encryption of data at rest. Enable node-to-node encryption Node-to-node encryption provides an additional layer of security on top of the default security features within OpenSearch Service. It implements Transport Layer Security (TLS) for all communications between the nodes that are provisioned within OpenSearch. Node-to-node encryption, any data sent to your OpenSearch Service domain over HTTPS remains encrypted in transit while it's being distributed and replicated between nodes. If your domain stores sensitive data, enable node-to-node encryption. Monitor with AWS Security Hub Monitor your usage of OpenSearch Service as it relates to security best practices by using AWS Security Hub. Security Hub uses security controls to evaluate resource configurations and security standards to help you comply with various compliance frameworks. For more information about using Security Hub to evaluate OpenSearch Service resources, see Amazon OpenSearch Service controls in the AWS Security Hub User Guide. Cost optimization The following best practices apply to optimizing and saving on your OpenSearch Service costs. Use the latest generation instance types OpenSearch Service is always adopting new Amazon EC2 instances types that deliver better performance at a lower cost. We recommend always using the latest generation instances. Avoid using T2 or t3.small instances for production domains because they can become unstable under sustained heavy load. r6g.large instances are an option for small production workloads (both as data nodes and as dedicated master nodes). Use the latest Amazon EBS gp3 volumes OpenSearch data nodes require low latency and high throughput storage to provide fast indexing and query. By using Amazon EBS gp3 volumes, you get higher baseline performance (IOPS and throughput) at a 9.6% lower cost than with the previously-offered Amazon EBS gp2 volume type. You can provision additional IOPS and throughput independent of volume size using gp3. These volumes are also more stable than previous generation volumes as they do not use burst credits. The gp3 volume type also doubles the per-data-node volume size limits of the gp2 volume type. With these larger volumes, you can reduce the cost of passive data by increasing the amount of storage per data node. Use UltraWarm and cold storage for time-series log data If you're using OpenSearch for log analytics, move your data to UltraWarm or cold storage to reduce costs. Use Index State Management (ISM) to migrate data between storage tiers and manage data retention. UltraWarm provides a cost-effective way to store large amounts of read-only data in OpenSearch Service. UltraWarm uses Amazon S3 for storage, which means that the data is immutable and only one copy is needed. You only pay for storage that's equivalent to the size of the primary shards in your indexes. Latencies for UltraWarm queries grow with the amount of S3 data that's needed to service the query. After the data has been cached on the nodes, queries to UltraWarm indexes perform similar to queries to hot indexes. Cold storage is also backed by S3. When you need to query cold data, you can selectively attach it to existing UltraWarm nodes. Cold data incurs the same managed storage cost as UltraWarm, but objects in cold storage don't consume UltraWarm node resources. Therefore, cold storage provides a significant amount of storage capacity without impacting UltraWarm node size or count. UltraWarm becomes cost-effective when you have roughly 2.5 TiB of data to migrate from hot storage. Monitor your fill rate and plan to move indexes to UltraWarm before you reach that volume of data. Review recommendations for Reserved Instances Consider purchasing Reserved Instances (RIs) after you have a good baseline on your performance and compute consumption. Discounts start at around 30% for no-upfront, 1-year reservations and can increase up to 50% for all-upfront, 3-year commitments. After you observe stable operation for at least 14 days, review Accessing reservation recommendations in the AWS Cost Management User Guide. The Amazon OpenSearch Service heading displays specific RI purchase recommendations and projected savings. Javascript is disabled or is unavailable in your browser. To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions. Document Conventions Piped Processing Language Sizing domains Did this page help you? - Yes Thanks for letting us know we're doing a good job! If you've got a moment, please tell us what we did right so we can do more of it. Did this page help you? - No Thanks for letting us know this page needs work. We're sorry we let you down. If you've got a moment, please tell us how we can make the documentation better.\\\"},{\\\"url\\\":\\\"https://docs.opensearch.org/latest/tuning-your-cluster/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Regular expression syntax Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Using UBI in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Creating a cluster Before diving into OpenSearch and searching and aggregating data, you first need to create an OpenSearch cluster. OpenSearch can operate as a single-node or multi-node cluster. The steps to configure both are, in general, quite similar. This page demonstrates how to create and configure a multi-node cluster, but with only a few minor adjustments, you can follow the same steps to create a single-node cluster. To create and deploy an OpenSearch cluster according to your requirements, it\\u2019s important to understand how node discovery and cluster formation work and what settings govern them. There are many ways to design a cluster. The following illustration shows a basic architecture that includes a four-node cluster that has one dedicated cluster manager node, one dedicated coordinating node, and two data nodes that are cluster manager eligible and also used for ingesting data. The master node is now referred to as the cluster manager node. Nodes The following table provides brief descriptions of the node types: Node type Description Best practices for production Cluster manager Manages the overall operation of a cluster and keeps track of the cluster state. This includes creating and deleting indexes, keeping track of the nodes that join and leave the cluster, checking the health of each node in the cluster (by running ping requests), and allocating shards to nodes. Three dedicated cluster manager nodes in three different zones is the right approach for almost all production use cases. This configuration ensures your cluster never loses quorum. Two nodes will be idle for most of the time except when one node goes down or needs some maintenance. Cluster manager eligible Elects one node among them as the cluster manager node through a voting process. For production clusters, make sure you have dedicated cluster manager nodes. The way to achieve a dedicated node type is to mark all other node types as false. In this case, you have to mark all the other nodes as not cluster manager eligible. Data Stores and searches data. Performs all data-related operations (indexing, searching, aggregating) on local shards. These are the worker nodes of your cluster and need more disk space than any other node type. As you add data nodes, keep them balanced between zones. For example, if you have three zones, add data nodes in multiples of three, one for each zone. We recommend using storage and RAM-heavy nodes. Ingest Pre-processes data before storing it in the cluster. Runs an ingest pipeline that transforms your data before adding it to an index. If you plan to ingest a lot of data and run complex ingest pipelines, we recommend you use dedicated ingest nodes. You can also optionally offload your indexing from the data nodes so that your data nodes are used exclusively for searching and aggregating. Coordinating Delegates client requests to the shards on the data nodes, collects and aggregates the results into one final result, and sends this result back to the client. A couple of dedicated coordinating-only nodes is appropriate to prevent bottlenecks for search-heavy workloads. We recommend using CPUs with as many cores as you can. Dynamic Delegates a specific node for custom work, such as machine learning (ML) tasks, preventing the consumption of resources from data nodes and therefore not affecting any OpenSearch functionality. Warm Provides access to searchable snapshots. Incorporates techniques like frequently caching used segments and removing the least used data segments in order to access the searchable snapshot index (stored in a remote long-term storage source, for example, Amazon Simple Storage Service [Amazon S3] or Google Cloud Storage). Search nodes contain an index allocated as a snapshot cache. Thus, we recommend using dedicated nodes with more compute (CPU and memory) than storage capacity (hard disk). Search Search nodes are dedicated nodes that host only search replica shards, helping separate search workloads from indexing workloads. Because search nodes host search replicas and handle search traffic, we recommend using them for dedicated memory-optimized instances. By default, each node is a cluster-manager-eligible, data, ingest, and coordinating node. Deciding on the number of nodes, assigning node types, and choosing the hardware for each node type depends on your use case. You must take into account factors like the amount of time you want to hold on to your data, the average size of your documents, your typical workload (indexing, searches, aggregations), your expected price-performance ratio, your risk tolerance, and so on. After you assess all these requirements, we recommend you use a benchmark testing tool like OpenSearch Benchmark to provision a small sample cluster and run tests with varying workloads and configurations. Compare and analyze the system and query metrics for these tests to design an optimum architecture. This page demonstrates how to work with the different node types. It assumes that you have a four-node cluster similar to the preceding illustration. It is a best practice to direct traffic from external sources, such as OpenSearch Dashboards, OpenSearch Data Prepper, and others, to the nodes in the following order of availability: ingest node, coordinating node, data node. We do not recommended sending traffic directly to the cluster manager node. Prerequisites Before you get started, you must install and configure OpenSearch on all of your nodes. For information about the available options, see Install and configure OpenSearch. After you\\u2019re done, use SSH to connect to each node, then open the config/opensearch.yml file. You can set all configurations for your cluster in this file. Step 1: Name a cluster Specify a unique name for the cluster. If you don\\u2019t specify a cluster name, it\\u2019s set to opensearch by default. Setting a descriptive cluster name is important, especially if you want to run multiple clusters inside a single network. To specify the cluster name, change the following line: #cluster.name: my-application\\\\n to cluster.name: opensearch-cluster\\\\n Make the same change on all the nodes to make sure that they\\u2019ll join to form a cluster. Step 2: Set node attributes for each node in a cluster After you name the cluster, set node attributes for each node in your cluster. Cluster manager node Give your cluster manager node a name. If you don\\u2019t specify a name, OpenSearch assigns a machine-generated name that makes the node difficult to monitor and troubleshoot. node.name: opensearch-cluster_manager\\\\n You can also explicitly specify that this node is a cluster manager node, even though it is already set to true by default. Set the node role to cluster_manager to make it easier to identify the cluster manager node. node.roles: [ cluster_manager ]\\\\n Data nodes Change the name of two nodes to opensearch-d1 and opensearch-d2, respectively: node.name: opensearch-d1\\\\n node.name: opensearch-d2\\\\n You can make them cluster-manager-eligible data nodes that will also be used for ingesting data: node.roles: [ data, ingest ]\\\\n You can also specify any other attributes that you\\u2019d like to set for the data nodes. Coordinating node Change the name of the coordinating node to opensearch-c1: node.name: opensearch-c1\\\\n Every node is a coordinating node by default, so to make this node a dedicated coordinating node, set node.roles to an empty list: node.roles: []\\\\n Step 3: Bind a cluster to specific IP addresses network.bind_host defines the IP address used to bind the node. By default, OpenSearch listens on a local host, which limits the cluster to a single node. You can also use _local_ and _site_ to bind to any loopback or site-local address, whether IPv4 or IPv6: network.bind_host: [_local_, _site_]\\\\n To form a multi-node cluster, specify the IP address of the node: network.bind_host: <IP address of the node>\\\\n Make sure to configure these settings on all of your nodes. Step 4: Configure discovery hosts and initial cluster manager nodes for a cluster Now that you\\u2019ve configured the network hosts, you need to configure the discovery hosts and specify the cluster manager nodes for the initial cluster election. Note that this is the node name and not the IP Address, hostname, or fully-qualified hostname. For example, the setting looks like the following: cluster.initial_cluster_manager_nodes: [\\\\\\\"opensearch-cluster_manager\\\\\\\"]\\\\n Zen Discovery is the built-in, default mechanism that uses unicast to find other nodes in the cluster. You can generally add all of your cluster-manager-eligible nodes to the discovery.seed_hosts array. When a node starts up, it finds the other cluster-manager-eligible nodes, determines which one is the cluster manager, and asks to join the cluster. For example, for opensearch-cluster_manager the line looks something like this: discovery.seed_hosts: [\\\\\\\"<private IP of opensearch-d1>\\\\\\\", \\\\\\\"<private IP of opensearch-d2>\\\\\\\", \\\\\\\"<private IP of opensearch-c1>\\\\\\\"]\\\\n Step 5: Start the cluster After you set the configurations, start OpenSearch on all nodes: sudo systemctl start opensearch.service\\\\n Installing OpenSearch from a tar archive will not automatically create a service with systemd. See Run OpenSearch as a service with systemd for instructions on how to create and start the service if you receive an error like Failed to start opensearch.service: Unit not found. Then go to the logs file to see the formation of the cluster: less /var/log/opensearch/opensearch-cluster.log\\\\n Perform the following _cat query on any node to see all the nodes formed as a cluster: curl -XGET https://<private-ip>:9200/_cat/nodes?v -u 'admin:<custom-admin-password>' --insecure\\\\n ip             heap.percent ram.percent cpu load_1m load_5m load_15m node.role cluster_manager name\\\\nx.x.x.x           13          61   0    0.02    0.04     0.05 mi        *      opensearch-cluster_manager\\\\nx.x.x.x           16          60   0    0.06    0.05     0.05 md        -      opensearch-d1\\\\nx.x.x.x           34          38   0    0.12    0.07     0.06 md        -      opensearch-d2\\\\nx.x.x.x           23          38   0    0.12    0.07     0.06 md        -      opensearch-c1\\\\n To better understand and monitor your cluster, use the CAT API. (Advanced) Step 6: Configure shard allocation awareness or forced awareness To further fine-tune your shard allocation, you can set custom node attributes for shard allocation awareness or forced awareness. Shard allocation awareness You can set custom node attributes on OpenSearch nodes to be used for shard allocation awareness. For example, you can set the zone attribute on each node to represent the zone in which the node is located. You can also use the zone attribute to ensure that the primary shard and its replica shards are allocated in a balanced manner across available, distinct zones. In this scenario, maximum shard copies per zone would equal ceil (number_of_shard_copies/number_of_distinct_zones). OpenSearch, by default, allocates shard copies of a single shard across different nodes. When only 1 zone is available, such as after a zone failure, OpenSearch allocates replica shards to the only remaining zone\\u2014it considers only available zones (attribute values) when calculating the maximum number of allowed shard copies per zone. For example, if your index has a total of 5 shard copies (1 primary and 4 replicas) and nodes in 3 distinct zones, then OpenSearch will perform the following to allocate all 5 shard copies: Allocate no more than 2 shards per zone, which will require at least 2 nodes in 2 zones. Allocate the last shard in the third zone, with at least 1 node needed in the third zone. Alternatively, if you have 3 nodes in the first zone and 1 node in each remaining zone, then OpenSearch will allocate: 2 shard copies in the first zone. 1 shard copy in the remaining 2 zones. The final shard copy will remain unallocated due to the lack of nodes. With shard allocation awareness, if the nodes in one of your zones fail, you can be assured that your replica shards are spread across your other zones, adding a layer of fault tolerance to ensure that your data survives zone failures. To configure shard allocation awareness, add zone attributes to opensearch-d1 and opensearch-d2, respectively: node.attr.zone: zoneA\\\\n node.attr.zone: zoneB\\\\n Update the cluster settings: PUT _cluster/settings\\\\n{\\\\n  \\\\\\\"persistent\\\\\\\": {\\\\n    \\\\\\\"cluster.routing.allocation.awareness.attributes\\\\\\\": \\\\\\\"zone\\\\\\\"\\\\n  }\\\\n}\\\\n You can also use multiple attributes for shard allocation awareness by providing the attributes as a comma-separated string, for example, zone,rack. You can either use persistent or transient settings. We recommend the persistent setting because it persists through a cluster reboot. Transient settings don\\u2019t persist through a cluster reboot. Shard allocation awareness attempts to separate primary and replica shards across multiple zones. However, if only one zone is available (such as after a zone failure), OpenSearch allocates replica shards to the only remaining zone. Forced awareness Another option is to require that primary and replica shards are never allocated to the same zone. This is called forced awareness. To configure forced awareness, specify all the possible values for your zone attributes: PUT _cluster/settings\\\\n{\\\\n  \\\\\\\"persistent\\\\\\\": {\\\\n    \\\\\\\"cluster.routing.allocation.awareness.attributes\\\\\\\": \\\\\\\"zone\\\\\\\",\\\\n    \\\\\\\"cluster.routing.allocation.awareness.force.zone.values\\\\\\\":[\\\\\\\"zoneA\\\\\\\", \\\\\\\"zoneB\\\\\\\"]\\\\n  }\\\\n}\\\\n Now, if a data node fails, forced awareness doesn\\u2019t allocate the replicas to a node in the same zone. Instead, the cluster enters a yellow state and only allocates the replicas when nodes in another zone come online. In our two-zone architecture, we can use allocation awareness if opensearch-d1 and opensearch-d2 are less than 50% utilized, so that each of them have the storage capacity to allocate replicas in the same zone. If that is not the case, and opensearch-d1 and opensearch-d2 do not have the capacity to contain all primary and replica shards, we can use forced awareness. This approach helps to make sure that, in the event of a failure, OpenSearch doesn\\u2019t overload your last remaining zone and lock up your cluster due to lack of storage. Choosing allocation awareness or forced awareness depends on how much space you might need in each zone to balance your primary and replica shards. Replica count enforcement To enforce an even distribution of shards across all zones and avoid hotspots, you can set the routing.allocation.awareness.balance attribute to true. This setting can be configured in the opensearch.yml file and dynamically updated using the cluster update settings API: PUT _cluster/settings\\\\n{\\\\n  \\\\\\\"persistent\\\\\\\": {\\\\n    \\\\\\\"cluster\\\\\\\": {\\\\n      \\\\\\\"routing.allocation.awareness.balance\\\\\\\": \\\\\\\"true\\\\\\\"\\\\n    }\\\\n  }\\\\n}\\\\n The routing.allocation.awareness.balance setting is false by default. When it is set to true, the total number of shards for the index must be a multiple of the highest count for any awareness attribute. For example, consider a configuration with two awareness attributes\\u2014zones and rack IDs. Let\\u2019s say there are two zones and three rack IDs. The highest count of either the number of zones or the number of rack IDs is three. Therefore, the number of shards must be a multiple of three. If it is not, OpenSearch throws a validation exception. routing.allocation.awareness.balance takes effect only if cluster.routing.allocation.awareness.attributes and cluster.routing.allocation.awareness.force.zone.values are set. routing.allocation.awareness.balance applies to all operations that create or update indexes. For example, let\\u2019s say you\\u2019re running a cluster with three nodes and three zones in a zone-aware setting. If you try to create an index with one replica or update an index\\u2019s settings to one replica, the attempt will fail with a validation exception because the number of shards must be a multiple of three. Similarly, if you try to create an index template with one shard and no replicas, the attempt will fail for the same reason. However, in all of those operations, if you set the number of shards to one and the number of replicas to two, the total number of shards is three and the attempt will succeed. (Advanced) Step 7: Set up a hot-warm architecture You can design a hot-warm architecture where you first index your data to hot nodes\\u2014fast and expensive\\u2014and after a certain period of time move them to warm nodes\\u2014slow and cheap. If you analyze time-series data that you rarely update and want the older data to go onto cheaper storage, this architecture can be a good fit. This architecture helps save money on storage costs. Rather than increasing the number of hot nodes and using fast, expensive storage, you can add warm nodes for data that you don\\u2019t access as frequently. To configure a hot-warm storage architecture, add temp attributes to opensearch-d1 and opensearch-d2, respectively: node.attr.temp: hot\\\\n node.attr.temp: warm\\\\n You can set the attribute name and value to whatever you want as long as it\\u2019s consistent for all your hot and warm nodes. To add an index newindex to the hot node: PUT newindex\\\\n{\\\\n  \\\\\\\"settings\\\\\\\": {\\\\n    \\\\\\\"index.routing.allocation.require.temp\\\\\\\": \\\\\\\"hot\\\\\\\"\\\\n  }\\\\n}\\\\n Take a look at the following shard allocation for newindex: GET _cat/shards/newindex?v\\\\nindex     shard prirep state      docs store ip         node\\\\nnew_index 2     p      STARTED       0  230b 10.0.0.225 opensearch-d1\\\\nnew_index 2     r      UNASSIGNED\\\\nnew_index 3     p      STARTED       0  230b 10.0.0.225 opensearch-d1\\\\nnew_index 3     r      UNASSIGNED\\\\nnew_index 4     p      STARTED       0  230b 10.0.0.225 opensearch-d1\\\\nnew_index 4     r      UNASSIGNED\\\\nnew_index 1     p      STARTED       0  230b 10.0.0.225 opensearch-d1\\\\nnew_index 1     r      UNASSIGNED\\\\nnew_index 0     p      STARTED       0  230b 10.0.0.225 opensearch-d1\\\\nnew_index 0     r      UNASSIGNED\\\\n In this example, all primary shards are allocated to opensearch-d1, which is our hot node. All replica shards are unassigned, because we\\u2019re forcing this index to allocate only to hot nodes. To add an index oldindex to the warm node: PUT oldindex\\\\n{\\\\n  \\\\\\\"settings\\\\\\\": {\\\\n    \\\\\\\"index.routing.allocation.require.temp\\\\\\\": \\\\\\\"warm\\\\\\\"\\\\n  }\\\\n}\\\\n The shard allocation for oldindex: GET _cat/shards/oldindex?v\\\\nindex     shard prirep state      docs store ip        node\\\\nold_index 2     p      STARTED       0  230b 10.0.0.74 opensearch-d2\\\\nold_index 2     r      UNASSIGNED\\\\nold_index 3     p      STARTED       0  230b 10.0.0.74 opensearch-d2\\\\nold_index 3     r      UNASSIGNED\\\\nold_index 4     p      STARTED       0  230b 10.0.0.74 opensearch-d2\\\\nold_index 4     r      UNASSIGNED\\\\nold_index 1     p      STARTED       0  230b 10.0.0.74 opensearch-d2\\\\nold_index 1     r      UNASSIGNED\\\\nold_index 0     p      STARTED       0  230b 10.0.0.74 opensearch-d2\\\\nold_index 0     r      UNASSIGNED\\\\n In this case, all primary shards are allocated to opensearch-d2. Again, all replica shards are unassigned because we only have one warm node. A popular approach is to configure your index templates to set the index.routing.allocation.require.temp value to hot. This way, OpenSearch stores your most recent data on your hot nodes. You can then use the Index State Management (ISM) plugin to periodically check the age of an index and specify actions to take on it. For example, when the index reaches a specific age, change the index.routing.allocation.require.temp setting to warm to automatically move your data from hot nodes to warm nodes. Next steps If you are using the Security plugin, the previous request to _cat/nodes?v might have failed with an initialization error. For full guidance around using the Security plugin, see Security configuration. Nodes Shard allocation awareness Forced awareness Replica count enforcement WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright \\u00a9 OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\\\"},null,{\\\"url\\\":\\\"https://logit.io/blog/post/opensearch-best-practises/\\\",\\\"title\\\":\\\"back back\\\",\\\"content\\\":\\\"Logit.io requires JavaScript to be enabled Platform Logging Log Management Logging as a Service Metrics Metrics as a Service Metrics Management Observability Cloud Application Performance Monitoring Application Performance Monitoring Application Performance Analyser SIEM as a Service Logit.io For OpenTelemetry Trace Analytics Features Hosted OpenSearch Hosted ELK Hosted Jaeger Hosted Prometheus Hosted Kibana Hosted Grafana Hosted Logstash Grafana Demo Using a managed solution like the one provided by Logit.io, enables you to get started with Grafana within minutes. Prometheus as a Service Identify the root cause behind container failures faster by using Prometheus as a Service ELK as a Service ELK as a Service provides busy DevOps, SysAdmins, and IT leaders with an affordable and scalable alternative to building their own Elastic Stacks. Solutions Monitoring Log Monitoring Container Monitoring Data Monitoring Production Monitoring Infrastructure Monitoring Hybrid Cloud & Multi-Cloud Monitoring Kubernetes Monitoring Logging Observability Security Logging Logging Made Easy (LME) Compliance and Auditing Compliance and Auditing Analysis Analysis Solutions Log Analysis Business Analytics DevOps Analytics Event Log Analyser Security Analytics Platform-Specific Logging Amazon Web Services (AWS) Azure Google Cloud Platform (GCP) Django CMMC Solution CMMC Audit Logging Datadog Alternative Learn more on how Logit.io can easily be leveraged as an affordable alternative to Datadog. Splunk Alternative See how metrics, traces & logs can be measured affordably for security and alerting with Logit.io. Logz.io Alternative Switch today & save when you use Logit.io as your highly affordable observability platform. New Relic Alternative Empower your team to observe key insights while saving on costs when using Logit.io. Pricing Docs Get a DemoStart Free TrialSign In back Back to Blog Top OpenSearch Best Practises for Success By David Benson May 27th, 2024 Resources 4 min read While OpenSearch provides a rich set of features and capabilities out of the box, optimizing its performance, reliability, and security requires adherence to best practices. To assist you in navigating OpenSearch we have put together an extensive guide of the best practices for OpenSearch to ensure that you get the most out of the solution. These best practices cover multiple aspects of cluster architecture, indexing, querying, monitoring, security, and more, guaranteeing that your OpenSearch deployment operates smoothly and delivers actionable insights to your organization. What is OpenSearch? OpenSearch is an open-source distributed search and analytics engine created for scalability, simplicity, and performance. It serves as a powerful tool for indexing, searching, and examining large volumes of data in real-time. OpenSearch is built on Apache Lucene, a commonly used full-text search library, and it offers a robust platform for a broad range of use cases such as log analytics, monitoring, search engines, and business intelligence. Originally, OpenSearch was a community-driven fork of Elasticsearch, an open-source search and analytics engine developed by Elastic. However, it has since evolved into a separate project with its own governance and roadmap. OpenSearch intends to supply users with a fully open-source alternative to proprietary search and analytics solutions, providing transparency, flexibility, and control over their data and infrastructure. Contents OpenSearch Best Practices Cluster Sizing and Configuration Index Management Data Ingestion and Pipeline Query Optimization Monitoring and Alerting Security, Backup, and Disaster Recovery Documentation and Training Hosted OpenSearch OpenSearch Best Practices Optimizing the utilization of OpenSearch entails adhering to a set of best practices aimed at improving performance, reliability, and security. We have listed a range of OpenSearch best practices that cover all aspects of the solution below. Cluster Sizing and Configuration Firstly, cluster sizing and configuration are crucial. You need to properly outline node types and hardware specifications to match your workload demands. Dedicate nodes for certain roles such as master, data, and coordinating nodes to streamline responsibilities and enhance performance. Additionally, you should determine the amount of shards and replicas for each index to stop resource overutilization and facilitate efficient cluster operation. Fine-tune network settings to ensure seamless communication between nodes to avoid latency issues and bottlenecks. Index Management Another vital aspect when using OpenSearch in index management. You should utilize Index Lifecycle Management (ILM) policies to automate index lifecycle operations such as rollover, retention, and deletion. Implement index shrink and split operations to manage index size and distribution effectively, to improve query performance and storage efficiency. Data Ingestion and Pipeline Efficient data ingestion and processing are vital for maintaining optimal cluster performance in OpenSearch. You and your team should employ bulk indexing techniques to ingest large volumes of data swiftly while minimizing overhead. Make sure to utilize ingest node pipelines to preprocess and enrich data before indexing, guaranteeing data quality and optimizing search capabilities. Query Optimization Query optimization is a vital practice to ensure maximum search performance. You should focus on carefully designing indices and mappings to support efficient querying. Utilize the Query DSL to construct enhanced queries, leveraging filters, aggregations, and scoring mechanisms. Regularly track query performance and use profiling tools to highlight and address performance bottlenecks. Monitoring and Alerting Maintaining cluster health and proactively addressing issues is made simpler by utilizing monitoring and alerting mechanisms. Track critical cluster metrics such as CPU usage, memory utilization, disk I/O, and JVM heap usage to identify anomalies and performance degradation. It\\u2019s vital to configure alerts to fire when critical events occur and thresholds are breached to notify administrators promptly to sped up time to resolution. Security, Backup, and Disaster Recovery Enhance the security of your OpenSearch cluster by enabling authentication and authorization mechanisms. Employ role-based access control (RBAC) to manage access to indices, documents, and cluster APIs based on user roles and permissions. Also, you should encrypt network traffic using Transport Layer Security (TLS) to protect data in transit. Ensure you enable encryption at rest to encrypt data stored on disk to prevent unauthorized access. Also, backup and disaster recovery strategies are crucial for guaranteeing data resilience and business continuity. Employ snapshot and restore functionality to create frequent backups of indices and restore them in case of data loss or corruption. Documentation and Training To continue the effective operation of Opensearch, comprehensive documentation and ongoing training are vital for fostering knowledge sharing and empowering administrators and users to leverage OpenSearch effectively. You should maintain detailed documentation covering cluster configuration, best practices, troubleshooting procedures, and recovery processes. As well as this, offer frequent training sessions and resources to guarantee administrators and users have the skills and knowledge to manage OpenSearch clusters effectively. Hosted OpenSearch Opting for a Hosted OpenSearch solution could be the perfect choice for your organization. With a Hosted OpenSearch solution, like the one provided by Logit.io, you can benefit from a streamlined deployment process, removing the need for manual setup and configuration. This lessens the complexity and time required to get started with OpenSearch. As well as this, Logit.io Hosted OpenSearch the infrastructure is managed by us, including provisioning, scaling, monitoring, and maintenance tasks. This reduces the burden of managing infrastructure from your team, enabling you to focus on your organisation's key business objectives. In addition to this, Logit.io's service employs stringent security features, including encryption at rest and in transit, role-based access control (RBAC), and integration with identity providers for authentication. This aids in enhancing the security posture of your OpenSearch deployment without requiring additional configuration. Our hosted OpenSearch offers a convenient and cost-effective way to leverage the power of OpenSearch without the overhead of managing infrastructure and operations. If you\\u2019re interested in finding out more about Logit.io\\u2019s hosted OpenSearch solution, don\\u2019t hesitate to arrange an OpenSearch demo, or begin exploring the platform for yourself with a 14-day free trial. If you've enjoyed this article why not read OpenSearch vs Elasticsearch or The Best OpenSearch Dashboard Examples next? Previous Post: The Critical Role of Log Management in SaaS Environments Next Post: The Top 50 OpenSearch Interview Questions Get the latest elastic Stack & logging resources when you subscribe back Back to Blog The Latest News from Logit.io OpenTelemetry Distributed Tracing Implementation Guide Manufacturing IoT Monitoring: Complete Enterprise Guide Media Streaming Performance: Complete Enterprise Guide Gaming Infrastructure Monitoring: Complete Enterprise Guide Financial Services Security Monitoring: Enterprise Guide Leading Tools Alternatives Dashboards Guides Kubernetes Management Tools Distributed Tracing Tools Data Visualisation Tools Log Management Tools Log Monitoring Tools Metrics Tools SIEM Tools Platform Logging Metrics Observability Features Pricing Solutions Monitoring Security Log Application Logging Logging Made Easy Django Logging Compliance and Auditing Analysis CMMC Solution Azure Logging Log Viewer Resources Integrations Documentation Platform Status Logit.io Blog Compare Compare alternatives Datadog alternative Dynatrace alternative Sumo Logic alternative Logz.io alternative LogicMonitor alternative Loggly alternative Stackify alternative Splunk alternative Papertrail alternative New Relic alternative Mezmo alternative About Us About Us Legal Why Logit? Security and Compliance Consultancy Contact Us Partner \\u00a9 2025 Logit.io Ltd, All rights reserved.\\\"},{\\\"url\\\":\\\"https://blog.devgenius.io/best-practices-aws-opensearch-97911c11e8fd\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Sitemap Open in app Sign up Sign in Medium Logo Write Search Sign up Sign in Dev Genius \\u00b7 Follow publication Coding, Tutorials, News, UX, UI and much more related to development Follow publication Best Practices \\u2014 AWS OpenSearch Amit Singh Rathore 11 min read \\u00b7 Feb 9, 2025 -- Listen Share Few pointers to look at while working with AWS OpenSearch Dedicated Master Nodes It is recommended to use Multi-AZ with three dedicated master nodes for optimal stability and fault tolerance. Three dedicated master nodes offer two backup nodes and the required quorum, providing a reliable configuration. Note: Avoid choosing an even number of dedicated master nodes. Dedicated master nodes Use at least 3 dedicated master nodes for clusters with 10+ data nodes. Choose instance types with at least 8 GB of RAM (m5.large or larger). Zone Awareness Enable zone awareness to distribute replicas across Availability Zones. Ensure even distribution of nodes across AZs. Estimating Storage Requirements OpenSearch Service reserves 20% of storage space for segment merges, logs, and other internal operations, with a maximum of 20 GiB per instance. This means that the total reserved space can vary depending on the number of instances in your domain. To calculate the minimum storage requirement for our example with 2 replicas and 2TB of source data, we can use the simplified formula provided: Source data * (1 + number of replicas) * 1.45 = minimum storage requirement Substituting the values: 2TB * (1 + 2) * 1.45 = 8.7TB If we do a full reindex at any time on the cluster we will need to allocate 2 * 8.7TB = 17.4TB. a) Determining optimal number of data nodes: Rule of thumb: Start with at least 3 data nodes for production workloads. Calculate required storage: (Daily data volume * Retention period * Replication factor) / 0.75 (leaving 25% free space) Divide total required storage by storage per node to get minimum number of nodes. Shard Strategy (Count) An index is analogous to a database table, with documents as the rows, and fields as the columns. Indices are composed of shards (primary & replica). When we create an index, we tell OpenSearch how many primary shards we want to create. The primary shards are independent partitions of the full dataset. OpenSearch Service automatically distributes our data across the primary shards in an index. We can also configure replicas of the index. Each replica shard comprises a full set of copies of the primary shards for that index. To optimize search performance in OpenSearch, careful consideration of the shard count in our index is crucial. Increasing the number of shards can significantly improve efficiency, particularly when dealing with large datasets. Read-heavy workloads, a shard size of 10\\u201330 GB is recommended Write-heavy workloads, a shard size of 30\\u201335 GB is recommended We can approximate the number of primary shards required using the formula (source_data) * (1 + indexing_overhead) / desired_shard_size. For our example, the approximate number of primary shards would be (2000) * 1.1 / 30 \\u2248 73.33. To ensure an even distribution of shards across our three data nodes, a suitable shard count would be 72. When we have indexes with multiple shards, we should try to make the shard count an even multiple of the data node count. This helps to ensure that shards are evenly distributed across data nodes, and prevents hot nodes. For example, if we have 12 primary shards, our data node count should be 2, 3, 4, 6, or 12. However, shard count is secondary to shard size \\u2014 if we have 5 GiB of data, we should still use a single shard. For example, a node with 32 GiB of heap memory should hold no more than 800 shards. Although shard distribution can vary based on our workload patterns, there\\u2019s a limit of 1,000 shards per node. Calculating optimal shard size Aim for shard sizes between 10\\u201350 GB. Calculate the number of shards: (Daily data volume * Retention period) / Target shard size Strategies for shard allocation Use shard allocation filtering to control data distribution: PUT logs*/_settings {   \\\\\\\"index.routing.allocation.include.data_type\\\\\\\": \\\\\\\"hot\\\\\\\" } Handling hot spots and shard balancing Monitor shard sizes and search rates. Use custom routing or time-based indices to distribute load evenly. Using custom routing for controlled distribution Implement custom routing for time-series data: PUT logs/_doc/1?routing=2023-07-22 {   \\\\\\\"timestamp\\\\\\\": \\\\\\\"2023-07-22T12:00:00Z\\\\\\\",   \\\\\\\"message\\\\\\\": \\\\\\\"Application started\\\\\\\" } Instance Type Selection When selecting hardware for our OpenSearch cluster, it\\u2019s crucial to consider storage requirements, shard count, and workload characteristics. The number of shards per data node should align with the node\\u2019s JVM heap memory, typically aiming for 25 shards or fewer per GiB. To ensure efficient processing, it\\u2019s recommended to have an initial scale point of 1.5 vCPUs per shard. For instance, with 72 shards per node, we would need approximately 108 vCPUs. To accommodate this, scaling our data nodes to 5 would be suitable, resulting in a shard count of approximately 43.2 per node. In this case, selecting a robust instance type like the m6g.12xlarge.search with 48 CPUs and 192 RAM would be advisable. However, additional instances may be required if performance falls short of expectations, tests fail, or CPUUtilization or JVMMemoryPressure indicators are high. As instances are added, OpenSearch automatically redistributes the shard distribution throughout the cluster, helping to balance the workload and optimize performance. 1 instance \\u2192 1000 Shard \\u2192 3TB storage \\u2192 8GB RAM \\u2192 1.5vCPC per shard Choosing instance types Memory-optimized (r5 or r7g series): Best for complex aggregations and caching. Compute-optimized (c5 or c7g series): Suitable for search-heavy workloads. Consider data-to-memory ratio: Aim for a 1:10 ratio of JVM heap to data on disk. OR1 optimized instance family \\u2014 A domain with OR1 instances uses Amazon Elastic Block Store (Amazon EBS) gp3 or io1 volumes for primary storage, with data copied synchronously to Amazon S3 as it arrives. For OpenSearch optimized instances, indexing is only performed on primary shards. aws opensearch create-domain \\\\\\\\   --domain-name test-domain \\\\\\\\   --engine-version OpenSearch_2.11 \\\\\\\\   --cluster-config \\\\\\\"InstanceType=or1.2xlarge.search,InstanceCount=3,DedicatedMasterEnabled=true,DedicatedMasterType=r6g.large.search,DedicatedMasterCount=3\\\\\\\" \\\\\\\\   --ebs-options \\\\\\\"EBSEnabled=true,VolumeType=gp3,VolumeSize=200\\\\\\\" \\\\\\\\   --encryption-at-rest-options Enabled=true \\\\\\\\   --advanced-security-options \\\\\\\"Enabled=true,InternalUserDatabaseEnabled=true,MasterUserOptions={MasterUserName=test-user,MasterUserPassword=test-password}\\\\\\\" \\\\\\\\   --node-to-node-encryption-options Enabled=true \\\\\\\\   --domain-endpoint-options EnforceHTTPS=true \\\\\\\\   --access-policies '{\\\\\\\"Version\\\\\\\":\\\\\\\"2012-10-17\\\\\\\",\\\\\\\"Statement\\\\\\\":[{\\\\\\\"Effect\\\\\\\":\\\\\\\"Allow\\\\\\\",\\\\\\\"Principal\\\\\\\":{\\\\\\\"AWS\\\\\\\":\\\\\\\"*\\\\\\\"},\\\\\\\"Action\\\\\\\":\\\\\\\"es:*\\\\\\\",\\\\\\\"Resource\\\\\\\":\\\\\\\"arn:aws:es:us-east-1:account-id:domain/test-domain/*\\\\\\\"}]}' OR1 instances keep a copy of data in both your local and remote store. In UltraWarm instances, data is kept primarily in remote store to reduce storage costs. Depending on your usage patterns, data can be moved to local storage. Graviton cost reduction with higher performance m5.large.search (2 Core, 8GB RAM, 10GB/s N/W) \\u2192 $0.142 m7g.large.search (2 Core, 8GB RAM, 12.5GB/s N/W) \\u2192 $0.135 Use the latest Amazon EBS gp3 volumes OpenSearch Service data nodes require low latency and high throughput storage to provide fast indexing and query. With gp3 EBS volumes, you get higher baseline performance (IOPS and throughput) at a 9.6% lower cost than with the previously offered gp2 EBS volume type. We can also provision additional IOPS and throughput independent of volume size using gp3. Storage \\u2014 $0.122/GB-month. IOPS \\u2014 3,000 IOPS free for volumes up to 1,024 GiB, or 3 IOPS/GiB free for volumes above 1,024 GiB. $0.008/provisioned IOPS-month over free limits. Throughput \\u2014 125 MiB/s free for volumes up to 170 GiB, or +250 MiB/s free for every 3 TiB for volumes above 170 GiB. $0.064/provisioned MiB/s-month over free limits. Data Ingestion Strategies Efficient data ingestion is critical for high-volume scenarios. Bulk indexing Use the _bulk API for indexing multiple documents in a single request. Optimal bulk size typically ranges from 5\\u201315 MB. We can use gzip compression with the OpenSearch Python client, or by including the following headers from the client side \\u2014 'Accept-Encoding': 'gzip' , 'Content-Encoding': 'gzip' Example bulk request: POST _bulk {\\\\\\\"index\\\\\\\":{\\\\\\\"_index\\\\\\\":\\\\\\\"logs\\\\\\\",\\\\\\\"_id\\\\\\\":\\\\\\\"1\\\\\\\"}} {\\\\\\\"timestamp\\\\\\\":\\\\\\\"2023-07-22T10:30:00Z\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"User login successful\\\\\\\"} {\\\\\\\"index\\\\\\\":{\\\\\\\"_index\\\\\\\":\\\\\\\"logs\\\\\\\",\\\\\\\"_id\\\\\\\":\\\\\\\"2\\\\\\\"}} {\\\\\\\"timestamp\\\\\\\":\\\\\\\"2023-07-22T10:31:00Z\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Data processing started\\\\\\\"} Using the Bulk API effectively Parallelize bulk requests, but avoid overloading the cluster. Monitor the bulk_total_time_in_millis metric to find the optimal concurrency level. Implement backoff mechanisms for retries: from elasticsearch import Elasticsearch, helpers import time def bulk_index_with_backoff(client, actions, max_retries=3):     for attempt in range(max_retries):         try:             helpers.bulk(client, actions)             break         except Exception as e:             if attempt == max_retries - 1:                 raise             time.sleep(2 ** attempt)  # Exponential backoff Implementing a buffer layer Use Amazon Kinesis Data Firehose for reliable, scalable data ingestion. Configure Firehose to batch and compress data before sending to OpenSearch. Example Firehose delivery stream configuration: {   \\\\\\\"DeliveryStreamName\\\\\\\": \\\\\\\"OpenSearchIngestStream\\\\\\\",   \\\\\\\"OpenSearchDestinationConfiguration\\\\\\\": {     \\\\\\\"IndexName\\\\\\\": \\\\\\\"logs\\\\\\\",     \\\\\\\"BufferingHints\\\\\\\": {       \\\\\\\"IntervalInSeconds\\\\\\\": 60,       \\\\\\\"SizeInMBs\\\\\\\": 5     },     \\\\\\\"CompressionFormat\\\\\\\": \\\\\\\"GZIP\\\\\\\"   } } Real-time vs. batch ingestion For real-time: Use the _bulk API with smaller batches, potentially through a queueing system. For batch: Use larger bulk sizes and consider off-peak hours for ingestion. Indexing Optimization Efficient index design is crucial for performance and storage optimization. Designing efficient mappings Explicitly define mappings to prevent type guessing: PUT logs {   \\\\\\\"mappings\\\\\\\": {     \\\\\\\"properties\\\\\\\": {       \\\\\\\"timestamp\\\\\\\": {\\\\\\\"type\\\\\\\": \\\\\\\"date\\\\\\\"},       \\\\\\\"message\\\\\\\": {\\\\\\\"type\\\\\\\": \\\\\\\"text\\\\\\\", \\\\\\\"fields\\\\\\\": {\\\\\\\"keyword\\\\\\\": {\\\\\\\"type\\\\\\\": \\\\\\\"keyword\\\\\\\"}}},       \\\\\\\"user_id\\\\\\\": {\\\\\\\"type\\\\\\\": \\\\\\\"keyword\\\\\\\"},       \\\\\\\"status_code\\\\\\\": {\\\\\\\"type\\\\\\\": \\\\\\\"integer\\\\\\\"}     }   } } Use appropriate data types (e.g., keyword for exact matches, text for full-text search). Using dynamic mapping judiciously Disable dynamic mapping for high-volume indices to prevent mapping explosions: PUT logs {   \\\\\\\"mappings\\\\\\\": {     \\\\\\\"dynamic\\\\\\\": \\\\\\\"strict\\\\\\\",     \\\\\\\"properties\\\\\\\": {       // defined fields here     }   } } Optimizing field types for search and aggregations Use keyword fields for aggregations and sorting. For numeric fields requiring range queries, consider using integer instead of long if possible. Index aliases for zero-downtime reindexing Use aliases to switch between indices without downtime: POST /_aliases {   \\\\\\\"actions\\\\\\\": [     {\\\\\\\"add\\\\\\\": {\\\\\\\"index\\\\\\\": \\\\\\\"logs-v2\\\\\\\", \\\\\\\"alias\\\\\\\": \\\\\\\"logs-write\\\\\\\"}},     {\\\\\\\"remove\\\\\\\": {\\\\\\\"index\\\\\\\": \\\\\\\"logs-v1\\\\\\\", \\\\\\\"alias\\\\\\\": \\\\\\\"logs-write\\\\\\\"}},     {\\\\\\\"add\\\\\\\": {\\\\\\\"index\\\\\\\": \\\\\\\"logs-v2\\\\\\\", \\\\\\\"alias\\\\\\\": \\\\\\\"logs-read\\\\\\\"}},     {\\\\\\\"remove\\\\\\\": {\\\\\\\"index\\\\\\\": \\\\\\\"logs-v1\\\\\\\", \\\\\\\"alias\\\\\\\": \\\\\\\"logs-read\\\\\\\"}}   ] } Caching Strategies Effective caching can significantly improve query performance and reduce load on your cluster. Configuring and using query cache Enable and size the query cache appropriately: PUT _cluster/settings {   \\\\\\\"persistent\\\\\\\": {     \\\\\\\"indices.queries.cache.size\\\\\\\": \\\\\\\"5%\\\\\\\"   } } The query cache is most effective for frequently run queries on mostly static data. Monitor cache hit rate using the indices_stats API: GET /_stats/query_cache?human Optimizing field data cache Field data is loaded into memory for sorting and aggregations on text fields. Limit field data cache size to prevent OOM errors: PUT _cluster/settings {   \\\\\\\"persistent\\\\\\\": {     \\\\\\\"indices.fielddata.cache.size\\\\\\\": \\\\\\\"10%\\\\\\\"   } } Use doc_values for fields that require sorting or aggregations: PUT logs {   \\\\\\\"mappings\\\\\\\": {     \\\\\\\"properties\\\\\\\": {       \\\\\\\"user_id\\\\\\\": {         \\\\\\\"type\\\\\\\": \\\\\\\"keyword\\\\\\\",         \\\\\\\"doc_values\\\\\\\": true       }     }   } } Shard request cache considerations Enable shard request cache for search-heavy workloads: PUT logs/_settings {   \\\\\\\"index.requests.cache.enable\\\\\\\": true } Set appropriate cache expiration: PUT logs/_settings {   \\\\\\\"index.requests.cache.expire\\\\\\\": \\\\\\\"10m\\\\\\\" } Implementing application-level caching Use external caching solutions like Redis/mamcache for frequently accessed, compute-intensive results. Implement cache invalidation strategies to ensure data freshness. Query Optimization Use of Structured Queries Prefer structured queries over unstructured ones for better performance: GET logs/_search {   \\\\\\\"query\\\\\\\": {     \\\\\\\"bool\\\\\\\": {       \\\\\\\"must\\\\\\\": [         {\\\\\\\"match\\\\\\\": {\\\\\\\"message\\\\\\\": \\\\\\\"error\\\\\\\"}},         {\\\\\\\"term\\\\\\\": {\\\\\\\"status_code\\\\\\\": 500}}       ],       \\\\\\\"filter\\\\\\\": [         {\\\\\\\"range\\\\\\\": {\\\\\\\"timestamp\\\\\\\": {\\\\\\\"gte\\\\\\\": \\\\\\\"now-1d\\\\\\\"}}}       ]     }   } } Optimize Aggregations Use date_histogram with fixed_interval for time-based aggregations: GET logs/_search {   \\\\\\\"size\\\\\\\": 0,   \\\\\\\"aggs\\\\\\\": {     \\\\\\\"errors_over_time\\\\\\\": {       \\\\\\\"date_histogram\\\\\\\": {         \\\\\\\"field\\\\\\\": \\\\\\\"timestamp\\\\\\\",         \\\\\\\"fixed_interval\\\\\\\": \\\\\\\"1h\\\\\\\",         \\\\\\\"min_doc_count\\\\\\\": 0       },       \\\\\\\"aggs\\\\\\\": {         \\\\\\\"error_count\\\\\\\": {           \\\\\\\"filter\\\\\\\": {\\\\\\\"term\\\\\\\": {\\\\\\\"status_code\\\\\\\": 500}}         }       }     }   } } Use of Script Fields Avoid heavy scripting in queries. If necessary, use painless scripts and cache them: GET logs/_search {   \\\\\\\"script_fields\\\\\\\": {     \\\\\\\"day_of_week\\\\\\\": {       \\\\\\\"script\\\\\\\": {         \\\\\\\"lang\\\\\\\": \\\\\\\"painless\\\\\\\",         \\\\\\\"source\\\\\\\": \\\\\\\"doc['timestamp'].value.dayOfWeek\\\\\\\",         \\\\\\\"params\\\\\\\": {}       }     }   } } Query Profiling Use the Profile API to analyze query performance: GET logs/_search {   \\\\\\\"profile\\\\\\\": true,   \\\\\\\"query\\\\\\\": {\\\\\\\"match\\\\\\\": {\\\\\\\"message\\\\\\\": \\\\\\\"error\\\\\\\"}} } Analyze the output to identify slow components of your query. exclude unnecessary fields with the filter_path parameter. Monitoring and Alerting Ensure that your AWS OpenSearch domains publish slow logs to AWS CloudWatch Logs. Key Metrics to Monitor Cluster health: RED, YELLOW, GREEN status Node-level metrics: CPU, memory, disk I/O Index-level metrics: indexing rate, search rate, refresh time JVM metrics: heap usage, garbage collection Setting up CloudWatch Alarms Set up alarms for critical metrics: {   \\\\\\\"AlarmName\\\\\\\": \\\\\\\"HighCPUUtilization\\\\\\\",   \\\\\\\"ComparisonOperator\\\\\\\": \\\\\\\"GreaterThanThreshold\\\\\\\",   \\\\\\\"EvaluationPeriods\\\\\\\": 2,   \\\\\\\"MetricName\\\\\\\": \\\\\\\"CPUUtilization\\\\\\\",   \\\\\\\"Namespace\\\\\\\": \\\\\\\"AWS/ES\\\\\\\",   \\\\\\\"Period\\\\\\\": 300,   \\\\\\\"Statistic\\\\\\\": \\\\\\\"Average\\\\\\\",   \\\\\\\"Threshold\\\\\\\": 80,   \\\\\\\"AlarmDescription\\\\\\\": \\\\\\\"Alarm when CPU exceeds 80%\\\\\\\",   \\\\\\\"Dimensions\\\\\\\": [     {       \\\\\\\"Name\\\\\\\": \\\\\\\"DomainName\\\\\\\",       \\\\\\\"Value\\\\\\\": \\\\\\\"your-domain-name\\\\\\\"     },     {       \\\\\\\"Name\\\\\\\": \\\\\\\"ClientId\\\\\\\",       \\\\\\\"Value\\\\\\\": \\\\\\\"your-account-id\\\\\\\"     }   ] } Using OpenSearch Dashboards Create custom dashboards for visualizing cluster health, indexing rates, and search performance. Use the \\u201cStack Monitoring\\u201d feature in OpenSearch Dashboards. Implementing Proactive Alerting Use Amazon SNS to send notifications for critical alarms. Implement custom alerting using AWS Lambda and the OpenSearch API. Data Lifecycle Management Use Index State Management (ISM) to migrate data between storage tiers and manage data retention. Press enter or click to view image in full size UltraWarm provides a cost-effective way to store large amounts of read-only data in OpenSearch Service. UltraWarm uses Amazon S3 for storage, which means that the data is immutable and only one copy is needed. Cold storage is also backed by S3. When you need to query cold data, you can selectively attach it to existing UltraWarm nodes. Cold data incurs the same managed storage cost as UltraWarm, but objects in cold storage don\\u2019t consume UltraWarm node resources Implementing Index State Management (ISM) Create an ISM policy: PUT _opendistro/_ism/policies/log_lifecycle_policy {   \\\\\\\"policy\\\\\\\": {     \\\\\\\"description\\\\\\\": \\\\\\\"Manage log index lifecycle\\\\\\\",     \\\\\\\"default_state\\\\\\\": \\\\\\\"hot\\\\\\\",     \\\\\\\"states\\\\\\\": [       {         \\\\\\\"name\\\\\\\": \\\\\\\"hot\\\\\\\",         \\\\\\\"actions\\\\\\\": [],         \\\\\\\"transitions\\\\\\\": [           {             \\\\\\\"state_name\\\\\\\": \\\\\\\"warm\\\\\\\",             \\\\\\\"conditions\\\\\\\": {               \\\\\\\"min_index_age\\\\\\\": \\\\\\\"7d\\\\\\\"             }           }         ]       },       {         \\\\\\\"name\\\\\\\": \\\\\\\"warm\\\\\\\",         \\\\\\\"actions\\\\\\\": [           {             \\\\\\\"replica_count\\\\\\\": {               \\\\\\\"number_of_replicas\\\\\\\": 1             }           },           {             \\\\\\\"force_merge\\\\\\\": {               \\\\\\\"max_num_segments\\\\\\\": 1             }           }         ],         \\\\\\\"transitions\\\\\\\": [           {             \\\\\\\"state_name\\\\\\\": \\\\\\\"cold\\\\\\\",             \\\\\\\"conditions\\\\\\\": {               \\\\\\\"min_index_age\\\\\\\": \\\\\\\"30d\\\\\\\"             }           }         ]       },       {         \\\\\\\"name\\\\\\\": \\\\\\\"cold\\\\\\\",         \\\\\\\"actions\\\\\\\": [           {             \\\\\\\"read_only\\\\\\\": {}           }         ],         \\\\\\\"transitions\\\\\\\": [           {             \\\\\\\"state_name\\\\\\\": \\\\\\\"delete\\\\\\\",             \\\\\\\"conditions\\\\\\\": {               \\\\\\\"min_index_age\\\\\\\": \\\\\\\"90d\\\\\\\"             }           }         ]       },       {         \\\\\\\"name\\\\\\\": \\\\\\\"delete\\\\\\\",         \\\\\\\"actions\\\\\\\": [           {             \\\\\\\"delete\\\\\\\": {}           }         ]       }     ]   } } Using UltraWarm and Cold Storage Move indices to UltraWarm after they become less frequently accessed: POST logs-2023-01/_ultrawarm/migration Move rarely accessed indices to Cold Storage: POST logs-2022-12/_cold/migration Backup and Recovery Use automated snapshots with S3: PUT _snapshot/my_s3_repository {   \\\\\\\"type\\\\\\\": \\\\\\\"s3\\\\\\\",   \\\\\\\"settings\\\\\\\": {     \\\\\\\"bucket\\\\\\\": \\\\\\\"my-snapshot-bucket\\\\\\\",     \\\\\\\"region\\\\\\\": \\\\\\\"us-west-2\\\\\\\",     \\\\\\\"role_arn\\\\\\\": \\\\\\\"arn:aws:iam::123456789012:role/OpenSearchSnapshotRole\\\\\\\"   } } Create daily snapshots PUT _snapshot/my_s3_repository/snapshot_1 Rather than manually deleting unused indexes, you can use ISM to automatically take a snapshot and delete indexes after a certain period of time. OpenSearch Rollups allow users to summarize and aggregate historical data into smaller, more manageable indices. This is useful for handling large volumes of time-series data, such as logs or metrics, where detailed granularity is only needed for recent data. Rollup indices are smaller than raw data indices, so querying them requires less processing power. Performance Tuning Shard Optimization Aim for shard sizes between 10\\u201350 GB. Use the force merge API to reduce shard count after bulk indexing: POST logs/_forcemerge?max_num_segments=1 Field Data Circuit Breaker Adjust field data circuit breaker to prevent OOM errors: PUT _cluster/settings {   \\\\\\\"persistent\\\\\\\": {     \\\\\\\"indices.breaker.fielddata.limit\\\\\\\": \\\\\\\"40%\\\\\\\"   } } Segment Merging Tune merge policy for write-heavy workloads: PUT logs/_settings {   \\\\\\\"index.merge.policy.segments_per_tier\\\\\\\": 10,   \\\\\\\"index.merge.policy.max_merge_at_once\\\\\\\": 10 } Bulk Indexing Optimization Disable refresh and replicas during bulk indexing: PUT logs/_settings {   \\\\\\\"index.refresh_interval\\\\\\\": -1,   \\\\\\\"index.number_of_replicas\\\\\\\": 0 } Re-enable after indexing is complete. Security Best Practices AWS offers many managed config rules for security best practices, we can leverage them using Config. Following is the list of supported config rules. OPENSEARCH_ACCESS_CONTROL_ENABLED OPENSEARCH_AUDIT_LOGGING_ENABLED OPENSEARCH_DATA_NODE_FAULT_TOLERANCE OPENSEARCH_ENCRYPTED_AT_REST OPENSEARCH_HTTPS_REQUIRED OPENSEARCH_IN_VPC_ONLY OPENSEARCH_LOGS_TO_CLOUDWATCH OPENSEARCH_NODE_TO_NODE_ENCRYPTION_CHECK Implement Fine-Grained Access Control Use role-based access control PUT _opendistro/_security/api/roles/logs_read {   \\\\\\\"cluster_permissions\\\\\\\": [\\\\\\\"cluster_composite_ops_ro\\\\\\\"],   \\\\\\\"index_permissions\\\\\\\": [     {       \\\\\\\"index_patterns\\\\\\\": [\\\\\\\"logs-*\\\\\\\"],       \\\\\\\"allowed_actions\\\\\\\": [\\\\\\\"read\\\\\\\", \\\\\\\"search\\\\\\\"]     }   ] } Encryption at Rest and in Transit Enable node-to-node encryption: PUT _cluster/settings {   \\\\\\\"persistent\\\\\\\": {     \\\\\\\"opendistro.security.ssl.http.enabled\\\\\\\": \\\\\\\"true\\\\\\\",     \\\\\\\"opendistro.security.ssl.transport.enabled\\\\\\\": \\\\\\\"true\\\\\\\"   } } Use AWS KMS for encryption at rest. Network Isolation Deploy OpenSearch within a VPC. Use VPC peering or AWS PrivateLink for secure access from other VPCs. Ensure that only approved IP addresses can access your Amazon OpenSearch domains. Audit Logging Enable and configure audit logs: PUT _cluster/settings {   \\\\\\\"persistent\\\\\\\": {     \\\\\\\"opendistro.security.audit.type\\\\\\\": \\\\\\\"internal_opensearch\\\\\\\",     \\\\\\\"opendistro.security.audit.enable_rest\\\\\\\": \\\\\\\"true\\\\\\\",     \\\\\\\"opendistro.security.audit.enable_transport\\\\\\\": \\\\\\\"true\\\\\\\"   } } Keep your OpenSearch clusters up-to-date with the latest security patches. Consider disabling the private tenant Use service-linked role \\u2014 VPC Domain Creation Role, Collection Creation Role, Pipeline Creation Role Enable SAML Authentication for OpenSearch Dashboards \\u2014 IAM Identity Center, Cognito Miscellaneous Consider refresh interval settings to balance between near real-time search and indexing speed. By default, Elasticsearch refreshes an index every second, but if you don\\u2019t need real-time search, you can increase the refresh interval to reduce overhead. We recommend setting the refresh_interval parameter for all of your indexes to 30 seconds or more. Review recommendations for Reserved Instances Auto-Tune uses performance and usage metrics from your OpenSearch cluster to suggest changes to queue sizes, cache sizes, and Java virtual machine (JVM) settings on your nodes. AWS Opensearch Indexing Data Engineering Cloud Computing -- -- Follow Published in Dev Genius 29K followers \\u00b7Last published 9 hours ago Coding, Tutorials, News, UX, UI and much more related to development Follow Written by Amit Singh Rathore 4.8K followers \\u00b7107 following Staff Data Engineer @ Visa \\u2014 Writes about Cloud | Big Data | ML No responses yet Help Status About Careers Press Blog Privacy Rules Terms Text to speech\\\"},{\\\"url\\\":\\\"https://docs.aws.amazon.com/prescriptive-guidance/latest/opensearch-service-migration/sizing.html\\\",\\\"title\\\":\\\"Sizing - AWS Prescriptive Guidance\\\",\\\"content\\\":\\\"Sizing - AWS Prescriptive Guidance DocumentationAWS Prescriptive GuidanceMigrating to Amazon OpenSearch Service StorageNumber of nodes and instance typesDetermining the indexing strategy and shard countCPU utilizationInstance types Sizing Sizing helps you determine the right instance type, number of data nodes, and storage requirement for your target environment. We recommend that you size first by the storage and then by CPUs. If you're already using Elasticsearch or OpenSearch, the sizing will generally remain the same. However, you need to identify the instance type that is equivalent to your current environment. To help determine the right size, we recommend using the following guidelines. Storage Sizing your cluster starts with defining the storage requirements. Identify the raw storage that you need for your cluster. This is determined by assessing the data generated by your source system (for example, servers generating logs, or product catalog raw size). After you identify how much raw data you have, use the following formula to calculate storage requirements. You can then use the result as a starting point for your PoC. storage needed = (daily source data in bytes \\u00d7 1.45) (number_of_replicas + 1) \\u00d7 number of days retained The formula takes into consideration the following: The on-disk size of an index varies, but it's often 10 percent larger than the source data. Operating system overhead of 5 percent is reserved by Linux for system recovery and to safeguard against disk defragmentation problems. OpenSearch reserves 20 percent of the storage space of each instance for segment merges, logs, and other internal operations. We recommend keeping 10 percent additional storage to help minimize the impact of node failure and Availability Zone outages. Combined, these overheads and reservations require 45 percent additional space based on the actual raw data in the source. That's why you multiply the source data by 1.45. Next, multiply this by number of copies of data (for example, one primary plus the number of replicas you will use). The replica count depends on your resiliency and throughput requirement. For an average use case, you start with one primary and one replica. Finally, multiply by the number of days that you want to retain data in a hot-storage tier. Amazon OpenSearch Service offers hot, warm, and cold storage tiers. The warm storage tier uses UltraWarm storage. UltraWarm provides a cost-effective way to store large amounts of read-only data on Amazon OpenSearch Service. Standard data nodes use hot storage, which takes the form of instance stores or Amazon Elastic Block Store (Amazon EBS) volumes attached to each node. Hot storage provides the fastest possible performance for indexing and searching new data. UltraWarm nodes use Amazon Simple Storage Service (Amazon S3) as storage and a sophisticated caching solution to improve performance. For indexes that you are not actively writing to, or query less frequently, and do not have the same performance requirements, UltraWarm offers significantly lower costs per GiB of data. For more information about UltraWarm, see the AWS documentation. When you create an OpenSearch Service domain and use hot storage, you might need to define the EBS volume size. It depends on your choice of instance type for the data nodes. You can use the same storage-requirement formula to determine the volume size for Amazon EBS backed instances. We recommend using gp3 volumes for latest-generation T3, R5, R6G, M5, M5g, C5, and C6g instance families. Using Amazon EBS gp3 volumes, you can provision performance independent of storage capacity. Amazon EBS gp3 volumes also provide better baseline performance, at a 9.6 percent lower cost per GB than existing gp2 volumes on OpenSearch Service. With gp3, you also get denser storage on R5, R6g, M5, and M6g instance families, which can help you to further optimize your costs. You can create EBS volumes up to the supported quota. For more information on quotas, see Amazon OpenSearch Service quotas. For data nodes that have NVM Express (NVMe) drives, such as i3 and r6gd instances, the volume size is fixed, so EBS volumes are not an option. Number of nodes and instance types The number of nodes is based on the number of CPUs required to operate your workload. The number of CPUs is based on the shard count. An index in OpenSearch is made up of multiple shards. When you create an index, you specify the number of shards for the index. Therefore, you need to do the following: Calculate the total shard count that you intend to store in the domain. Determine the CPU. Find the most cost-effective node type and count that gives you the required number of CPUs and storage. This is usually a starting point. Run tests to determine that the estimate size is meeting your functional and nonfunctional requirements. Determining the indexing strategy and shard count After you know the storage requirements, you can decide how many indexes you need and identify the shard count for each. Generally, search use cases have one or a few indexes, each representing a searchable entity or a catalog. For log analytics use cases, an index can represent a daily or weekly log file. After you decide how many indexes, begin with the following scale guidance, and determine appropriate shard count: Search use cases \\u2013 10\\u201330 GB/shard Log analytics use cases \\u2013 50 GB/shard You can divide the total volume of data in a single index by the shard size you are aiming for in your use case. This will give you the number of shards for the index. Identifying the total number of shards will help you find the right instance types that suit your workload. The shards shouldn't be too large or too numerous. Large shards can make it difficult for OpenSearch to recover from failure, but because each shard uses some amount of CPU and memory, having too many small shards can cause performance issues and out-of-memory errors. Moreover, imbalance in shard allocation to data nodes can lead to skewing. When you have indexes with multiple shards, try to make the shard count an even multiple of the data node count. This helps to ensure that shards are evenly distributed across data nodes, and prevents hot nodes. For example, if you have 12 primary shards, your data node count should be 2, 3, 4, 6, or 12. However, shard count is secondary to shard size\\u2014if you have 5 GiB of data, you should still use a single shard. Balancing replica shard count evenly across the Availability Zone also helps improve resilience. CPU utilization The next step is to identify how many CPUs you need for your workload. We recommend starting with a CPU count 1.5 times that of your active shards. An active shard is any shard for an index that is receiving substantial writes. Use the primary shard count to determine active shards for indexes that are receiving substantial read or write requests. For log analytics, only the current index is generally active. For search use cases, all primary shards will be considered as active shards. Although we recommend 1.5 CPU per active shard, this is highly workload-dependent. Be sure to test and monitor CPU utilization and scale accordingly. A best practice for maintaining your CPU utilization is to make sure that the OpenSearch service domain has enough resources to perform its tasks. A cluster that has consistently high CPU utilization can degrade cluster stability. When your cluster is overloaded, OpenSearch Service will block incoming requests, which results in request rejections. This is to protect the domain from failing. General guidelines on the CPU usage will be about 60 percent average, 80 percent max CPU utilization. Occasional spikes of 100 percent are still acceptable and might not require scaling or reconfiguration. Instance types Amazon OpenSearch Service provides you with a choice of several instance types. You can choose the instance types that best fit your use case. Amazon OpenSearch Service supports the R, C, M, T, and I instance families. You choose an instance family based on the workload: memory optimized, compute optimized, or mixed. After you identify an instance family, choose the latest-generation instance type. Generally, we recommend Graviton and later generations because they are built to provide improved performance with lower costs compared with previous-generation instances. Based on various testing that was performed for log analytics and search use cases, we recommend the following: For log analytics use cases , a general guideline is to begin with the R family of Graviton instances for data nodes. We recommend that you run tests, establish benchmarks for your requirements, and identify the appropriate instance size for your workload. For search use cases, we recommend using R and C family Graviton instances for data nodes, because search use cases require more CPU compared with log analytics use cases. For smaller workloads, you can use M family Graviton instances for both search and logs. I family instances offer NVMe drives and are used by customers with fast-indexing and low-latency search requirements. The cluster is composed of data nodes and cluster manager nodes. Although dedicated master nodes don't process search and query requests, their size is highly correlated with the instance size and number of instances, indexes, and shards that they can manage. AWS documentation provides a matrix that recommends minimum dedicated cluster manager instance type. AWS offers general purpose (M6g), compute optimized (C6g), and memory optimized (R6g and R6gd) for Amazon OpenSearch Service version 7.9 or later powered by AWS Graviton2 processors. These instances are built using custom silicon designed by Amazon. They are Amazon-designed hardware and software innovations that enable the delivery of efficient, flexible, and secure cloud services with isolated multi-tenancy, private networking, and fast local storage. The Graviton2 instance family reduces indexing latency by up to 50 percent and improves query performance by up to 30 percent when compared with the previous generation Intel-based instances available in OpenSearch Service (M5, C5, R5). Javascript is disabled or is unavailable in your browser. To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions. Document Conventions Planning Functionality Did this page help you? - Yes Thanks for letting us know we're doing a good job! If you've got a moment, please tell us what we did right so we can do more of it. Did this page help you? - No Thanks for letting us know this page needs work. We're sorry we let you down. If you've got a moment, please tell us how we can make the documentation better.\\\"},null,{\\\"url\\\":\\\"https://docs.opensearch.org/latest/tuning-your-cluster/performance/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Regular expression syntax Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Using UBI in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Tuning your cluster for indexing speed The following configurations demonstrated an improvement in throughput of around 60% when running an indexing-only workload as compared to the out-of-the-box experience. The workload did not incorporate search or other scenarios. Only the OpenSearch server process was run on the machines, with the benchmark clients hosted on a different node. The execution environment was comprised of Intel EC2 instances (r7iz.2xlarge) in the AWS Cloud, and the workload used was the StackOverflow dataset available as part of OpenSearch Benchmark. Java heap size A larger Java heap size is useful for indexing. Setting the Java min and max heap sizes to 50% of the RAM size shows better indexing performance on EC2 instances. Flush translog threshold The default value for flush_threshold_size is 512 MB. This means that the translog is flushed when it reaches 512 MB. The weight of the indexing load determines the frequency of the translog. When you increase index.translog.flush_threshold_size, the node performs the translog operation less frequently. Because flushes are resource-intensive operations, reducing the frequency of translogs improves indexing performance. By increasing the flush threshold size, the OpenSearch cluster also creates fewer large segments instead of multiple small segments. Large segments merge less often, and more threads are used for indexing instead of merging. For pure indexing workloads, consider increasing the flush_threshold_size to 25% of the Java heap size, for example, to improve indexing performance. An increased index.translog.flush_threshold_size can also increase the time that it takes for a translog to complete. If a shard fails, then recovery takes more time because the translog is larger. Before increasing index.translog.flush_threshold_size, call the following API operation to get current flush operation statistics: GET /<index>/_stats/flush?pretty\\\\n copy In the output, note the number of flushes and the total time. The following example output shows that there are 124 flushes, which took 17,690 milliseconds: {\\\\n     \\\\\\\"flush\\\\\\\": {\\\\n          \\\\\\\"total\\\\\\\": 124,\\\\n          \\\\\\\"total_time_in_millis\\\\\\\": 17690\\\\n     }\\\\n}\\\\n To increase the flush threshold size, call the following API operation: PUT /<index>/_settings \\\\n{\\\\n  \\\\\\\"index\\\\\\\":\\\\n  {\\\\n    \\\\\\\"translog.flush_threshold_size\\\\\\\" : \\\\\\\"1024MB\\\\\\\"\\\\n  }\\\\n}\\\\n copy In this example, the flush threshold size is set to 1024 MB, which is ideal for instances that have more than 32 GB of memory. Choose the appropriate threshold size for your cluster. Run the stats API operation again to see whether the flush activity changed: GET /<index>/_stats/flush\\\\n copy It\\u2019s a best practice to increase the index.translog.flush_threshold_size only for the current index. After you confirm the outcome, apply the changes to the index template. Index refresh interval By default, OpenSearch refreshes indexes every second. OpenSearch only refreshes indexes that have received at least one search request in the last 30 seconds. When you increase the refresh interval, the data node makes fewer API calls. To prevent 429 errors, it\\u2019s a best practice to increase the refresh interval. If your application can tolerate increasing the amount of time between when a document is indexed and when it becomes visible, you can increase the index.refresh_interval to a larger value, for example, 30s, or even disable it in a pure indexing scenario in order to improve indexing speed. Index buffer size If the node is performing heavy indexing, ensure that the index buffer size is large enough. You can set the index buffer size to be either a percentage of the Java heap size or the number of bytes. In most cases, the default value of 10% of JVM memory is sufficient. You can try increasing it to up to 25% for further improvement. Concurrent merges The maximum number of concurrent merges is specified as max_merge_count. The concurrentMergeScheduler controls the execution of merge operations when they are needed. Merges run in separate threads, and when the maximum number of threads is reached, further merges will wait until a merge thread becomes available. In cases where index throttling is an issue, consider increasing the number of merge threads beyond the default value. Shard distribution To ensure that the shards are distributed evenly across the data nodes of the index into which you\\u2019re ingesting, use the following formula to confirm that the shards are evenly distributed: Number of shards for index = k * (Number of data nodes), where k is the number of shards per node For example, if there are 24 shards in the index, and there are 8 data nodes, then OpenSearch assigns 3 shards to each node. Setting replica count to zero If you anticipate heavy indexing, consider setting the index.number_of_replicas value to 0. Each replica duplicates the indexing process. As a result, disabling the replicas improves your cluster performance. After the heavy indexing is complete, reactivate the replicated indexes. If a node fails while replicas are disabled, you might lose data. Disable the replicas only if you can tolerate data loss for a short duration. Experiment to find the optimal bulk request size Start with a bulk request size of 5 MiB to 15 MiB. Then slowly increase the request size until the indexing performance stops improving. Use an instance type that has SSD instance store volumes (such as I3) I3 instances provide fast and local memory express (NVMe) storage. I3 instances deliver better ingestion performance than instances that use General Purpose SSD (gp2) Amazon Elastic Block Store (Amazon EBS) volumes. For more information, see Petabyte scale for Amazon OpenSearch Service. Reduce response size To reduce the size of the OpenSearch response, use the filter_path parameter to exclude unnecessary fields. Be sure that you don\\u2019t filter out any fields that are required for identifying or retrying failed requests. These fields can vary by client. In the following example, the index-name, type-name, and took fields are excluded from the response: POST /_bulk?pretty&filter_path=-took,-items.index._index,-items.index._type\\\\n{ \\\\\\\"index\\\\\\\" : { \\\\\\\"_index\\\\\\\" : \\\\\\\"test2\\\\\\\", \\\\\\\"_id\\\\\\\" : \\\\\\\"1\\\\\\\" } }\\\\n{ \\\\\\\"user\\\\\\\" : \\\\\\\"testuser\\\\\\\" }\\\\n{ \\\\\\\"update\\\\\\\" : {\\\\\\\"_id\\\\\\\" : \\\\\\\"1\\\\\\\", \\\\\\\"_index\\\\\\\" : \\\\\\\"test2\\\\\\\"} }\\\\n{ \\\\\\\"doc\\\\\\\" : {\\\\\\\"user\\\\\\\" : \\\\\\\"example\\\\\\\"} }\\\\n copy Compression codecs In OpenSearch 2.9 and later, there are two new codecs for compression: zstd and zstd_no_dict. You can optionally specify a compression level for these in the index.codec.compression_level setting with values in the [1, 6] range. Benchmark data shows that zstd provides a 7% better write throughput and zstd_no_dict provides a 14% better throughput, along with a 30% improvement in storage compared with the default codec. For more information about compression, see Index codecs. Java heap size Flush translog threshold Index refresh interval Index buffer size Concurrent merges Shard distribution Setting replica count to zero Experiment to find the optimal bulk request size Use an instance type that has SSD instance store volumes (such as I3) Reduce response size Compression codecs WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright \\u00a9 OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\\\"},{\\\"url\\\":\\\"https://medium.com/@22.gautam/mastering-aws-opensearch-for-high-volume-data-best-practices-and-optimizations-part-1-5bff65506675\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Sitemap Open in app Sign up Sign in Medium Logo Write Search Sign up Sign in Mastering AWS OpenSearch for High-Volume Data: Best Practices and Optimizations \\u2014 part 1 Kumar Gautam 4 min read \\u00b7 Jul 22, 2024 -- Listen Share Press enter or click to view image in full size AWS OpenSearch is a distributed, open-source search and analytics suite used for a wide variety of applications, including log analytics, real-time application monitoring, and clickstream analytics. When dealing with high-volume data, optimizing your OpenSearch deployment becomes crucial for maintaining performance, reliability, and cost-effectiveness. This article will delve into best practices and advanced techniques for managing AWS OpenSearch clusters under high data volumes, covering everything from cluster architecture to advanced performance tuning. Cluster Architecture and Sizing Proper cluster architecture is fundamental to handling high-volume data efficiently. a) Determining optimal number of data nodes: Rule of thumb: Start with at least 3 data nodes for production workloads. Calculate required storage: (Daily data volume * Retention period * Replication factor) / 0.75 (leaving 25% free space) Divide total required storage by storage per node to get minimum number of nodes. b) Choosing instance types: Memory-optimized (r5 or r6g series): Best for complex aggregations and caching. Compute-optimized (c5 or c6g series): Suitable for search-heavy workloads. Consider data-to-memory ratio: Aim for a 1:10 ratio of JVM heap to data on disk. c) Dedicated master nodes: Use at least 3 dedicated master nodes for clusters with 10+ data nodes. Choose instance types with at least 8 GB of RAM (m5.large or larger). d) Zone Awareness: Enable zone awareness to distribute replicas across Availability Zones. Ensure even distribution of nodes across AZs. Data Ingestion Strategies Efficient data ingestion is critical for high-volume scenarios. a) Bulk indexing: Use the _bulk API for indexing multiple documents in a single request. Optimal bulk size typically ranges from 5\\u201315 MB. Example bulk request: POST _bulk {\\\\\\\"index\\\\\\\":{\\\\\\\"_index\\\\\\\":\\\\\\\"logs\\\\\\\",\\\\\\\"_id\\\\\\\":\\\\\\\"1\\\\\\\"}} {\\\\\\\"timestamp\\\\\\\":\\\\\\\"2023-07-22T10:30:00Z\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"User login successful\\\\\\\"} {\\\\\\\"index\\\\\\\":{\\\\\\\"_index\\\\\\\":\\\\\\\"logs\\\\\\\",\\\\\\\"_id\\\\\\\":\\\\\\\"2\\\\\\\"}} {\\\\\\\"timestamp\\\\\\\":\\\\\\\"2023-07-22T10:31:00Z\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Data processing started\\\\\\\"} b) Using the Bulk API effectively: Parallelize bulk requests, but avoid overloading the cluster. Monitor the bulk_total_time_in_millis metric to find the optimal concurrency level. Implement backoff mechanisms for retries: from elasticsearch import Elasticsearch, helpers import time def bulk_index_with_backoff(client, actions, max_retries=3):     for attempt in range(max_retries):         try:             helpers.bulk(client, actions)             break         except Exception as e:             if attempt == max_retries - 1:                 raise             time.sleep(2 ** attempt)  # Exponential backoff c) Implementing a buffer layer: Use Amazon Kinesis Data Firehose for reliable, scalable data ingestion. Configure Firehose to batch and compress data before sending to OpenSearch. Example Firehose delivery stream configuration: {   \\\\\\\"DeliveryStreamName\\\\\\\": \\\\\\\"OpenSearchIngestStream\\\\\\\",   \\\\\\\"OpenSearchDestinationConfiguration\\\\\\\": {     \\\\\\\"IndexName\\\\\\\": \\\\\\\"logs\\\\\\\",     \\\\\\\"BufferingHints\\\\\\\": {       \\\\\\\"IntervalInSeconds\\\\\\\": 60,       \\\\\\\"SizeInMBs\\\\\\\": 5     },     \\\\\\\"CompressionFormat\\\\\\\": \\\\\\\"GZIP\\\\\\\"   } } d) Real-time vs. batch ingestion: For real-time: Use the _bulk API with smaller batches, potentially through a queueing system. For batch: Use larger bulk sizes and consider off-peak hours for ingestion. Indexing Optimization Efficient index design is crucial for performance and storage optimization. a) Designing efficient mappings: Explicitly define mappings to prevent type guessing: PUT logs {   \\\\\\\"mappings\\\\\\\": {     \\\\\\\"properties\\\\\\\": {       \\\\\\\"timestamp\\\\\\\": {\\\\\\\"type\\\\\\\": \\\\\\\"date\\\\\\\"},       \\\\\\\"message\\\\\\\": {\\\\\\\"type\\\\\\\": \\\\\\\"text\\\\\\\", \\\\\\\"fields\\\\\\\": {\\\\\\\"keyword\\\\\\\": {\\\\\\\"type\\\\\\\": \\\\\\\"keyword\\\\\\\"}}},       \\\\\\\"user_id\\\\\\\": {\\\\\\\"type\\\\\\\": \\\\\\\"keyword\\\\\\\"},       \\\\\\\"status_code\\\\\\\": {\\\\\\\"type\\\\\\\": \\\\\\\"integer\\\\\\\"}     }   } } Use appropriate data types (e.g., keyword for exact matches, text for full-text search). b) Using dynamic mapping judiciously: Disable dynamic mapping for high-volume indices to prevent mapping explosions: PUT logs {   \\\\\\\"mappings\\\\\\\": {     \\\\\\\"dynamic\\\\\\\": \\\\\\\"strict\\\\\\\",     \\\\\\\"properties\\\\\\\": {       // defined fields here     }   } } c) Optimizing field types for search and aggregations: Use keyword fields for aggregations and sorting. For numeric fields requiring range queries, consider using integer instead of long if possible. d) Index aliases for zero-downtime reindexing: Use aliases to switch between indices without downtime: POST /_aliases {   \\\\\\\"actions\\\\\\\": [     {\\\\\\\"add\\\\\\\": {\\\\\\\"index\\\\\\\": \\\\\\\"logs-v2\\\\\\\", \\\\\\\"alias\\\\\\\": \\\\\\\"logs-write\\\\\\\"}},     {\\\\\\\"remove\\\\\\\": {\\\\\\\"index\\\\\\\": \\\\\\\"logs-v1\\\\\\\", \\\\\\\"alias\\\\\\\": \\\\\\\"logs-write\\\\\\\"}},     {\\\\\\\"add\\\\\\\": {\\\\\\\"index\\\\\\\": \\\\\\\"logs-v2\\\\\\\", \\\\\\\"alias\\\\\\\": \\\\\\\"logs-read\\\\\\\"}},     {\\\\\\\"remove\\\\\\\": {\\\\\\\"index\\\\\\\": \\\\\\\"logs-v1\\\\\\\", \\\\\\\"alias\\\\\\\": \\\\\\\"logs-read\\\\\\\"}}   ] } Shard Management Proper shard management is essential for distributed performance. a) Calculating optimal shard size: Aim for shard sizes between 10\\u201350 GB. Calculate number of shards: (Daily data volume * Retention period) / Target shard size b) Strategies for shard allocation: Use shard allocation filtering to control data distribution: PUT logs*/_settings {   \\\\\\\"index.routing.allocation.include.data_type\\\\\\\": \\\\\\\"hot\\\\\\\" } c) Handling hot spots and shard balancing: Monitor shard sizes and search rates. Use custom routing or time-based indices to distribute load evenly. d) Using custom routing for controlled distribution: Implement custom routing for time-series data: PUT logs/_doc/1?routing=2023-07-22 {   \\\\\\\"timestamp\\\\\\\": \\\\\\\"2023-07-22T12:00:00Z\\\\\\\",   \\\\\\\"message\\\\\\\": \\\\\\\"Application started\\\\\\\" } Caching Strategies Effective caching can significantly improve query performance and reduce load on your cluster. a) Configuring and using query cache: Enable and size the query cache appropriately: PUT _cluster/settings {   \\\\\\\"persistent\\\\\\\": {     \\\\\\\"indices.queries.cache.size\\\\\\\": \\\\\\\"5%\\\\\\\"   } } The query cache is most effective for frequently run queries on mostly static data. Monitor cache hit rate using the indices_stats API: GET /_stats/query_cache?human b) Optimizing field data cache: Field data is loaded into memory for sorting and aggregations on text fields. Limit field data cache size to prevent OOM errors: PUT _cluster/settings {   \\\\\\\"persistent\\\\\\\": {     \\\\\\\"indices.fielddata.cache.size\\\\\\\": \\\\\\\"10%\\\\\\\"   } } Use doc_values for fields that require sorting or aggregations: PUT logs {   \\\\\\\"mappings\\\\\\\": {     \\\\\\\"properties\\\\\\\": {       \\\\\\\"user_id\\\\\\\": {         \\\\\\\"type\\\\\\\": \\\\\\\"keyword\\\\\\\",         \\\\\\\"doc_values\\\\\\\": true       }     }   } } c) Shard request cache considerations: Enable shard request cache for search-heavy workloads: PUT logs/_settings {   \\\\\\\"index.requests.cache.enable\\\\\\\": true } Set appropriate cache expiration: PUT logs/_settings {   \\\\\\\"index.requests.cache.expire\\\\\\\": \\\\\\\"10m\\\\\\\" } d) Implementing application-level caching: Use external caching solutions like Redis/mamcache for frequently accessed, compute-intensive results. Implement cache invalidation strategies to ensure data freshness. Here I have covered around 5 topics crucial in managing your open search cluster for handling high data volume, I will cover other topics in the next part. -- -- Written by Kumar Gautam 108 followers \\u00b738 following I love Data and Technology No responses yet Help Status About Careers Press Blog Privacy Rules Terms Text to speech\\\"},{\\\"url\\\":\\\"https://docs.otc.t-systems.com/cloud-search-service/umn/using_opensearch_for_data_search/opensearch_cluster_planning_suggestions.html\\\",\\\"title\\\":\\\"Expand Collapse\\\",\\\"content\\\":\\\"section> IaaSComputing Auto Scaling Bare Metal Server Dedicated Host Elastic Cloud Server FunctionGraph Image Management ServiceNetwork Direct Connect Domain Name Service Elastic IP Elastic Load Balancing Enterprise Router NAT Gateway Private Link Access Service Secure Mail Gateway Virtual Private Cloud Virtual Private Network VPC EndpointStorage Cloud Backup and Recovery Cloud Server Backup Service Elastic Volume Service Object Storage Service Scalable File Service Storage Disaster Recovery Service Volume Backup Service PaaSApplication API Gateway (APIG) Application Operations Management Application Performance Management Distributed Message Service (for Kafka) Simple Message NotificationData Analysis Cloud Search Service Data Lake Insight Data Warehouse Service DataArts Studio MapReduce Service ModelArts Optical Character RecognitionContainer Application Service Mesh Cloud Container Engine Cloud Container Instance Software Repository for ContainersDatabases Data Replication Service Distributed Cache Service Distributed Database Middleware Document Database Service GeminiDB Relational Database Service TaurusDB ManagementManagement & Deployment Cloud Create Cloud Eye Cloud Trace Service Config Log Tank Service Resource Formation Service Tag Management Service SecuritySecurity Services Anti-DDoS Cloud Firewall Database Security Service Dedicated Web Application Firewall Host Security Service Identity and Access Management Key Management Service Web Application Firewall OtherOther Enterprise Dashboard Marketplace Price Calculator Status Dashboard DevelopersAPIs REST API API Usage Guidelines EndpointsDevelopment and Automation SDKs Drivers and Tools Terraform Ansible Cloud CreateArchitecture Center Best Practices Blueprints IaaSComputingAuto ScalingBare Metal ServerDedicated HostElastic Cloud ServerFunctionGraphImage Management ServiceNetworkDirect ConnectDomain Name ServiceElastic IPElastic Load BalancingEnterprise RouterNAT GatewayPrivate Link Access ServiceSecure Mail GatewayVirtual Private CloudVirtual Private NetworkVPC EndpointStorageCloud Backup and RecoveryCloud Server Backup ServiceElastic Volume ServiceObject Storage ServiceScalable File ServiceStorage Disaster Recovery ServiceVolume Backup ServicePaaSApplicationAPI Gateway (APIG)Application Operations ManagementApplication Performance ManagementDistributed Message Service (for Kafka)Simple Message NotificationData AnalysisCloud Search ServiceData Lake InsightData Warehouse ServiceDataArts StudioMapReduce ServiceModelArtsOptical Character RecognitionContainerApplication Service MeshCloud Container EngineCloud Container InstanceSoftware Repository for ContainersDatabasesData Replication ServiceDistributed Cache ServiceDistributed Database MiddlewareDocument Database ServiceGeminiDBRelational Database ServiceTaurusDBManagementManagement & DeploymentCloud CreateCloud EyeCloud Trace ServiceConfigLog Tank ServiceResource Formation ServiceTag Management ServiceSecuritySecurity ServicesAnti-DDoSCloud FirewallDatabase Security ServiceDedicated Web Application FirewallHost Security ServiceIdentity and Access ManagementKey Management ServiceWeb Application FirewallOtherOtherEnterprise DashboardMarketplacePrice CalculatorStatus Dashboard Expand Collapse Cloud Search Service Product Overview Getting Started CSS Service Permission Management Using Elasticsearch for Data Search Using OpenSearch for Data Search Procedure for Using OpenSearch OpenSearch Cluster Planning Suggestions Creating an OpenSearch Cluster Accessing an OpenSearch Cluster Importing Data to an OpenSearch Cluster Searching Data in an OpenSearch Cluster Enhancing Search Capabilities for OpenSearch Clusters Configuring Networking for an OpenSearch Cluster Backing up and Restoring the Data of an OpenSearch Cluster Scaling an OpenSearch Cluster Upgrading the Version of an OpenSearch Cluster Managing OpenSearch Clusters Managing Index Policies for OpenSearch Clusters OpenSearch Cluster Monitoring and Log Management Viewing OpenSearch Cluster Audit Logs CSS Resource Monitoring FAQs Change History User Guide Using OpenSearch for Data Search OpenSearch Cluster Planning Suggestions OpenSearch Cluster Planning Suggestions\\u00b6 Before creating an OpenSearch cluster, develop a plan for it, such as whether to deploy the cluster across multiple AZs to improve availability; the node quantity and specifications; the cluster version and security mode; and index sharding, in order to ensure the desired performance and reliability. Planning Cluster AZs\\u00b6 By deploying a CSS cluster across multiple AZs, you can increase the cluster's availability, lower the likelihood of data loss, and minimize service downtime. You can select two or three different AZs in the same region to deploy a cluster. If you select two or three AZs when creating a cluster, CSS automatically enables cross-AZ HA, ensuring cluster nodes distribute evenly across these AZs. Even distribution of cluster nodes across AZs means the difference between node quantities in different AZs does not exceed 1. For details, see Table 1. Important When creating a multi-AZ cluster, ensure that the number of selected nodes of any type is no less than the number of AZs. Otherwise, multi-AZ cluster deployment will fail. When a multi-AZ cluster is deployed, nodes of all types are evenly distributed across different AZs. The difference between node quantities in different AZs does not exceed 1. If the number of data nodes plus cold data nodes in a cluster is not an integer multiple of the number of AZs, data in the cluster may be unevenly distributed, affecting data query or write performance. Table 1 Node quantities and AZ distribution\\u00b6 Node Quantity Single AZ Two AZs Three AZs AZ1 AZ1 AZ2 AZ1 AZ2 AZ3 1 1 Not supported Not supported 2 2 1 1 Not supported 3 3 2 1 1 1 1 4 4 2 2 2 1 1 ... ... ... ... ... ... ... In the case of a multi-AZ deployment, configure the number of replicas in a manner that can better capitalize on the high availability that comes with such as deployment. In a two-AZ deployment, if one AZ becomes unavailable, the other AZ continues to provide services. In this case, at least one replica is required. OpenSearch uses one replica by default. You can retain the default value if you do not require higher read performance. In the case of a three-AZ deployment, if one AZ becomes unavailable, the other AZs can continue to provide services. In this case, at least one replica is required. OpenSearch uses one replica by default. If you need more replicas to improve the cluster's ability to handle queries, modify the replica setting to increase the number of replicas. For example, you can run the following command to set the number of index replicas: curl -XPUT http://ip:9200/{index_name}/_settings -d '{\\\\\\\"number_of_replicas\\\\\\\":2}' Alternatively, run the following command to specify the number of replicas in the index template: curl -XPUT http://ip:9200/_template/templatename -d '{ \\\\\\\"template\\\\\\\": \\\\\\\"*\\\\\\\", \\\\\\\"settings\\\\\\\": {\\\\\\\"number_of_replicas\\\\\\\": 2}}' where, ip indicates the private IP address of the cluster, index_name indicates the index name, and number_of_replicas indicates the number of index replicas to change to. In this example, the number of index replicas is changed to 2. Table 2 describes the service outage patterns for different variations of a multi-AZ deployment facing the failure of a single AZ. Table 2 Possible service outage patterns in the face of the failure of a single AZ\\u00b6 Number of AZs Number of Master Nodes Service Outage Patterns and Handling Suggestions 2 0 If the number of nodes is an even number: If half of the data nodes are faulty, you need to replace one node in the faulty AZ before a master node can be selected. If the number of nodes is an odd number: If the faulty AZ contains one more node than the normal AZ, you need to replace one node in the faulty AZ before a master node can be selected. For how to replace nodes, contact technical support. If the faulty AZ contains one less node than the normal AZ, services will not be interrupted and a master node can be selected. 2 3 There is a 50% chance of service interruption. When two dedicated master nodes are allocated to one AZ and another master node is allocated to the other AZ: If service interruption happens in the AZ with one master node, a master node can be selected from the AZ that has two dedicated master nodes. If service interruption happens in the AZ with two dedicated master nodes, master nodes cannot be selected because the remaining AZ has only one dedicated master node. In this case, services will be interrupted and you need to contact technical support. 3 0 If you have three AZs and four nodes, one AZ will have two nodes, and the other two will each have one node. If the AZ with two nodes becomes faulty, services will be interrupted. Therefore, you are advised not to configure four nodes when selecting three AZs. There is a small chance of service interruption if you follow this advice. 3 3 Service interruption does not occur. Note You can switch AZs for an existing cluster. For details, see Switching AZs for an OpenSearch Cluster. You can Add AZ or Migrate AZ. Add AZ: Add one or two AZs to a single-AZ cluster, or add an AZ to a dual-AZ cluster to improve cluster availability. Migrate AZ: Completely migrate data from the current AZ to another AZ that has sufficient resources. Planning the Cluster Version\\u00b6 When selecting an OpenSearch cluster version, consider factors such as service requirements, available features, performance, security updates, and long-term support, ensuring that the selected version can meet both current and future needs and provide a stable, secure environment for your data. Table 3 Cluster version support\\u00b6 Feature OpenSearch 1.3.6 OpenSearch 2.17.1 Related Documents Vector search Y x Configuring Vector Search for OpenSearch Clusters Decoupled storage and compute Y x Configuring Storage-Compute Decoupling for an OpenSearch Cluster Switching over between hot and cold storage Y Y Switching Between Hot and Cold Storage for an OpenSearch Cluster Enhanced import performance Y x Enhancing the Data Import Performance of OpenSearch Clusters Planning Node Types\\u00b6 For an OpenSearch cluster, the proper planning of different types of nodes is critical to optimizing performance and resource utilization. Before creating a cluster, determine the types of nodes to use based on service requirements, query load, data growth patterns, and performance goals. Table 4 describes the characteristics of different node types and the purposes they are suited for. Note If no master or client nodes were enabled when a cluster was created, you can add them if data nodes become overloaded later at some point. For details, see Adding Master or Client Nodes. If no cold data nodes were enabled during cluster creation, they cannot be added later, so you have to determine whether to use cold data nodes while creating a cluster. Table 4 Characteristics and purposes of different types of nodes\\u00b6 Node Type Node Description Characteristics Data node (ESS) Data nodes are used to store data. In a cluster that has neither master nor client nodes, data nodes provide the functions of both types of nodes. Data nodes are mandatory for any cluster. If Master node and Client node are both unselected, data nodes will be used for all of the following purposes: cluster management, data storage, cluster access, and data analysis. To ensure reliability, a cluster should have a least three nodes. If Master node is selected but Client node is not, data nodes will be used for data storage, cluster access, and data analysis. If Master node is unselected but Client node is selected, data nodes will be used for data storage and cluster management. If Master node and Client node are both selected, data nodes will be used for data storage only. Master node (ess-master) The master node is responsible for cluster management, such as metadata management, index creation and deletion, and shard allocation. It plays a critical role in metadata management, node management, stability guarantee, and cluster operation control for large-scale clusters. Large-scale cluster: For a cluster that has more than 16 nodes, you are advised to add dedicated master nodes to effectively manage the cluster status and metadata. Large quantities of indexes and shards: If the number of indexes or shards exceeds 10,000, a master node will have better performance in handling complex cluster management tasks, avoiding impact on the performance of data nodes. Better management of cluster nodes: The master node maintains the cluster metadata, including index mapping, settings, and aliases. For a complex cluster structure, a dedicated master node offers better management, including node joining, exiting, and fault detection. The master node plays a critical role in cluster node management. Improved cluster stability and reliability: A dedicated master node improves cluster stability and reliability by taking over cluster management responsibilities from data storage and query nodes. Optimized performance for data nodes: By offloading cluster management tasks from data nodes to master nodes, you can allow data nodes to focus on data processing, which leads to improved performance. Client node (ess-client) Client nodes receive and coordinate external requests, such as search and write requests. They play an important role in handling high-load queries, complex aggregations, managing a large number of shards, and improving cluster scalability. High QPS: In the face of a high queries per second (QPS), a dedicated client node can evenly distribute query requests, reducing the load of data nodes and improving the overall query performance. Complex aggregation queries: For complex, compute-intensive aggregation queries, a client node can dedicate to the handling of aggregation results, thus improving the efficiency and response speed of such queries. Large number of shards: In a cluster with a large number of shards, a client node can effectively coordinate and manage query requests to each shard, improving efficiency in request forwarding and processing. Reducing the load of data nodes: A client node parses search requests, determines the locations of index shards, and coordinates different nodes to execute searches. This reduces the load of data nodes by allowing them to focus on data storage and indexing. Improved cluster scalability: The use of client nodes allows for better cluster scalability and flexibility, enabling supporting for large datasets and more complex query requirements. Cold data node (ess-cold) Cold data nodes are used to store query latency-insensitive data in large quantities. They offer an effective way to manage large datasets and cut storage costs. Storage of historical data in large quantities: Cold data nodes offer a more cost-effective solution for storing large quantities of historical data that are infrequently accessed but useful for analytical purposes. Optimizing hot data performance: By migrating cold data to cold data nodes, you reduce the storage load of hot data nodes, thereby optimizing their query and write performance. Insensitivity to query latency: Cold data nodes are a better option for storing data that is insensitive to a high query latency. Cost-effectiveness: Cold data nodes usually use large disks that offer inexpensive storage. Planning Node Storage\\u00b6 Planning node models CSS supports various ECS models suited for different application needs. Select the appropriate models based on service requirements and performance expectations to achieve a perfect balance between storage performance and costs. Table 5 Different node models and the intended application scenarios\\u00b6 Node Model Disk Type Specifications Description Recommended Scenario Computing-intensive Cloud drive vCPUs:Memory = 1:2 Small-volume searches (less than 100 GB on a single node). General computing Cloud drive vCPUs:Memory = 1:4 Medium-scale e-commerce site search, social search, and log search, search and analysis where the data volume on a single node is in the range 100 GB to 1,000 GB. Memory-optimized Cloud drive vCPUs:Memory = 1:8 Search and analysis where the data volume on a single node is in the range 100 GB to 2,000 GB. This type of node is a good option for vector search, as its large memory helps improve cluster performance and stability. Planning node specifications Given the expected data handling capacities, it is always preferable to use a smaller number of nodes with larger specifications rather than a larger number of nodes with smaller specifications. For example, a cluster consisting of three nodes each with 32 CPU cores and 64 GB memory is usually better than a cluster consisting of 12 nodes each with 8 CPU cores and 16 GB memory in terms of stability and scalability. The specific advantages are as follows: Cluster stability: High-specs nodes provide more powerful data processing capabilities and larger memory space, leading to higher overall cluster stability. Improved scalability: When a cluster consisting of high-specs nodes encounters a performance bottleneck, you simply add more of these high-specs nodes. This is easier than increasing the specifications of existing nodes. Easier maintenance: A smaller number of nodes means easier maintenance and less complex management. In contrast, when a cluster consisting of low-specs nodes needs extra capacity, usually a vertical scale-up is performed, meaning to increase the specifications of existing nodes. This may entail not only more complex, challenging migration and upgrade processes, but also additional maintenance costs. To sum up, when planning a cluster, you must fully consider performance, costs, maintenance, and scalability, and choose the node specifications that best suit your needs. Planning storage capacity When planning the storage capacity of a CSS cluster, consider the following factors: the original data size, number of data replicas, data bloat rate, and disk usage The following is a recommended formula for determining the needed cluster storage capacity. Storage capacity = Original data size x (1 + Number of replicas) x (1 + Data bloat rate) x (1 + Ratio of reserved space) Original data size: Determine the size of the original data that needs to be stored. Number of replicas: The default value is 1. Data bloat rate: Extra data may be generated due to data indexing. Generally, you are advised to use a 25% data bloat rate. Disk usage: Considering the space occupied by the operating system and file system and the space reserved for optimized disk performance and redundancy, you are advised to keep the disk usage under 70%. That is, you need to reserve 30% of the total disk capacity. A recommended formula is as follows: Cluster storage capacity = Original data size x 2 x 1.25 x 1.3 To put it simply, if the original data size is known, the total storage capacity of the cluster needs to be 3.25 times that. This formula is for quick reference only. You still need to adjust it based on the actual applications and projected data growth rate. Planning the Node Quantity\\u00b6 Plan the node quantity based on performance requirements and predicted load. Table 6 provides a method for calculating the appropriate number of nodes. Following this method helps you ensure cluster performance and stability. Table 6 Calculating the number of cluster nodes\\u00b6 Node Performance Baseline Formula Example Write node For a node that uses cloud disks, the write performance baseline of a single vCPU is 1 MB/s. For an ultra-high I/O node, the write performance baseline of a single vCPU is 1.5 MB/s. Number of write nodes = Peak traffic/Number of vCPUs per node/Write throughput per vCPU x Number of replicas If the peak inbound traffic is 100 MB/s and a node has 16 vCPUs and 64 GB memory, 12 nodes (100/16/1 x 2) are needed. Query node It is difficult to evaluate the performance baseline of a single node out of the context of specific application scenarios. The average query response time (in seconds) is used here to measure the query performance baseline. Number of query nodes = QPS/(Number of vCPUs per node x 3/2/Average query response time in seconds) x Number of shards If the query QPS is 1000, the average query response time is 100 ms (0.1s), three index shards are planned, and a node has 16 vCPUs and 64 GB memory, ~12 nodes (1000/(16 x 3/2/0.1) x 3) are needed. Total number of nodes N/A Total number of nodes = Number of write nodes + Number of query nodes Total number of nodes = Number of write nodes + Number of query nodes = 24 Note Here, the total number of nodes refer to the number of data nodes plus that of cold data nodes. In each cluster, the number of nodes supported by each node type varies, depending on the types of nodes used in that cluster. For details, see Table 7. Table 7 Number of nodes of different types allowed in a single cluster\\u00b6 Node Type Node Quantity ess ess: 1-32 ess, ess-master ess: 1-200 ess-master: an odd number ranging from 3 to 9 ess, ess-client ess: 1-32 ess-client: 1-32 ess, ess-cold ess: 1-32 ess-cold: 1-32 ess, ess-master, ess-client ess: 1-200 ess-master: an odd number ranging from 3 to 9 ess-client: 1-32 ess, ess-master, ess-cold ess: 1-200 ess-master: an odd number ranging from 3 to 9 ess-cold: 1-32 ess, ess-client, ess-cold ess: 1-32 ess-client: 1-32 ess-cold: 1-32 ess, ess-master, ess-client, ess-cold ess: 1-200 ess-master: an odd number ranging from 3 to 9 ess-client: 1-32 ess-cold: 1-32 Note ess: data node, which is the default node type that is mandatory for cluster creation. The other three node types are optional. ess-master: master node ess-client: client node ess-cold: cold data node Planning a Cluster's Security Mode\\u00b6 Table 8 Cluster security modes\\u00b6 Cluster Type Description Recommended Scenario Non-security mode cluster Cluster for which the security mode is disabled With such a cluster, access to the cluster will not require user authentication, and data will be transmitted in plaintext using HTTP. Make sure the customer is in a secure environment, and do not expose the cluster access interface to the public network. This type of cluster is mostly used for internal services and testing. Advantage: simple and easy to access. Disadvantage: poor security as anyone can access it. Security-mode cluster Cluster in security mode + HTTP A security-mode cluster requires user authentication. It supports access control and data encryption, and it uses HTTP to transmit data in plaintext. Make sure the customer is in a secure environment, and do not expose the cluster access interface to the public network. Access control by user permissions is supported. This type of cluster is suitable for workloads that are particularly performance-demanding. Advantage: User authentication improves cluster security. HTTP-based access ensures high performance of the cluster. Disadvantage: The cluster cannot be accessed from the public network. Cluster in security mode + HTTPS A security-mode cluster requires user authentication. It supports access control and data encryption, and it uses HTTPS to encrypt communication and enhance data security. This type of cluster is suitable where there is a high security standard and public network access is required. Advantage: User authentication improves cluster security, and HTTPS-based secure communication allows for secure public network access. Disadvantage: HTTPS encrypts nearly all information sent between server and client, causing a read performance loss of around 20%. To access a security-mode cluster, you need to provide a username and password. CSS supports authentication for the following two types of users: Administrator: The default administrator username is admin, and the password is the one specified during cluster creation. Cluster user: created by the cluster administrator on Kibana. For details, see Creating Users for an OpenSearch Cluster and Granting Cluster Access. Note You can change the security mode of an existing cluster. For details, see Changing the Security Mode of an OpenSearch Cluster. You have many options when it comes to changing the security mode of a cluster: from non-security mode to security mode, from security mode to non-security mode, and switching between security modes using different web protocols (HTTP or HTTPS). Planning the Number of Index Shards\\u00b6 Before importing data to a cluster, carefully consider your service needs and plan the cluster's data structure and distribution in advance. This includes properly designing indexes and deciding on the appropriate number of index shards. To ensure optimal performance and scalability for a cluster, consider following these best practices: The size of a single shard: Keep the size of each shard between 10 GB and 50 GB. This helps strike a balance between storage efficiency and query performance. Total number of shards in a cluster: To facilitate management and avoid an excessively large scale, make sure the total number of shards in a cluster is less than 30,000. This helps maintain the stability and responsiveness of the cluster. Memory-to-shards ratio: Limit the number of shards per 1 GB of memory to 20 to 30. This ensures that each shard has sufficient memory resources to respond to indexing and query operations. Number of shards per node: To prevent node overload, keep the number of shards on each node under 1000. This helps to improve node stability. Relationship between the number of index shards and the number of nodes: For each index, make sure the number of shards is the same as or is an integral multiple of the number of nodes in the cluster. This helps improve load balancing and optimize query and indexing performance. Following these suggestions, you can plan and manage index shards for a CSS cluster more effectively, improving the cluster's overall performance and maintainability. Prev Next last updated: 2025-10-17 08:30 UTC - commit: 72cf7ac7e660373c1a0b45109197d9d453cd565f Edit pageReport Documentation Bug Page Contents OpenSearch Cluster Planning Suggestions Planning Cluster AZs Planning the Cluster Version Planning Node Types Planning Node Storage Planning the Node Quantity Planning a Cluster's Security Mode Planning the Number of Index Shards \\u00a9 T-Systems International GmbH Contact Data privacy Disclaimer of Liabilities Imprint\\\"}]}\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Search for operational best practices\n",
    "parameters = {\n",
    "    \"question\": \"OpenSearch cluster sizing best practices\"\n",
    "}\n",
    "\n",
    "print(\"‚ùì Question: OpenSearch cluster sizing best practices\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "response = execute_agent(client, agent_id, parameters)\n",
    "\n",
    "print(\"\\nüí° Best Practices:\")\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4b9e8f",
   "metadata": {},
   "source": [
    "## Step 8: Test Case 5 - Search for Troubleshooting Help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb6e28d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì Question: How to fix circuit breaker errors in OpenSearch\n",
      "============================================================\n",
      "\n",
      "üîß Troubleshooting Information:\n",
      "{\n",
      "  \"inference_results\": [\n",
      "    {\n",
      "      \"output\": [\n",
      "        {\n",
      "          \"name\": \"response\",\n",
      "          \"result\": \"{\\\"next_page\\\":\\\"https://duckduckgo.com/html?q=How+to+fix+circuit+breaker+errors+in+OpenSearch&s=10&nextParams=&v=l&o=json&dc=11&api=d.js&vqd=4-81341745925542226748053961715693796901&kl=wt-wt\\\",\\\"items\\\":[{\\\"url\\\":\\\"https://opster.com/guides/opensearch/opensearch-basics/opensearch-circuit-breaker-exceptions-how-to-handle-circuit-breakers/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Product BUILT FOR ELASTICSEARCH AutoOps Prevent & resolve issues, cut down administration time & hardware costs. Community Tools Tools For The Community Check-Up, Search Log Analyzer & OpsGPT Resources Guides Technical guides on Elasticsearch & Opensearch Blog Insights, Opster news, blogs and more Documentation Opster product documentation Error Messages Error Repository About About Our story & vision Login AutoOps Login Contact Login Contact Running self-managed Elasticsearch just got easier. Announcing AutoOps for your clusters. Read the announcement \\ud83c\\udf89\\ud83c\\udf89 Opensearch Guides > OpenSearch Basics Elasticsearch OpenSearch Circuit Breaker Exceptions: How to Handle Circuit Breakers By Opster Team Updated: Jun 19, 2024 | 4 min read Quick links What are circuit breakers? Finding out your current circuit breaker status Fielddata circuit breaker Request circuit breaker Inflight requests circuit breaker Script compilation circuit breaker Parent circuit breakers Accounting circuit breakers Adjusting circuit breakers What are circuit breakers? 50% of memory on an OpenSearch node is generally used for the JVM (Java Virtual Machine) heap, while the other half of the memory is used for other requirements such as cache. In order to prevent \\u201cOut of Memory\\u201d (OOM) errors, OpenSearch implements circuit breakers. If a certain request could cause errors in the node because of memory issues, OpenSearch will throw a \\u201cCircuitBreakerException\\u201d and reject the request rather than risk crashing the entire node. A circuit breaker exception is usually an exception that is thrown to alert us of something else that needs to be fixed to reduce memory usage. Circuit breakers generally come with sensible defaults. Simply increasing the circuit breaking limit is likely to increase the risk that your node crashes due to an OutOfMemoryError. If you get a circuit breaking exception, you should check what type of circuit breaker it is, and then look at your monitoring data and OpenSearch logs to diagnose what caused it. Remember that the event or query that appears in the log may just be the \\u201cstraw that broke the camel\\u2019s back\\u201d. There may be other causes of high memory usage, and the event in the log is just the very last one which pushed OpenSearch over the limit. Possible causes are discussed in each section below. Finding out your current circuit breaker status Get your current settings GET /_cluster/settings?include_defaults=true Find out your current memory usage and breakers GET _nodes/stats/breaker This will return useful information like this \\\\\\\"breakers\\\\\\\" : {\\\\n    \\\\t\\\\\\\"request\\\\\\\" : {\\\\n      \\\\t\\\\\\\"limit_size_in_bytes\\\\\\\" : 20574004838,\\\\n      \\\\t\\\\\\\"limit_size\\\\\\\" : \\\\\\\"19.1gb\\\\\\\",\\\\n      \\\\t\\\\\\\"estimated_size_in_bytes\\\\\\\" : 0,\\\\n      \\\\t\\\\\\\"estimated_size\\\\\\\" : \\\\\\\"0b\\\\\\\",\\\\n      \\\\t\\\\\\\"overhead\\\\\\\" : 1.0,\\\\n      \\\\t\\\\\\\"tripped\\\\\\\" : 0\\\\n    \\\\t},\\\\n    \\\\t\\\\\\\"fielddata\\\\\\\" : {\\\\n      \\\\t\\\\\\\"limit_size_in_bytes\\\\\\\" : 13716003225,\\\\n      \\\\t\\\\\\\"limit_size\\\\\\\" : \\\\\\\"12.7gb\\\\\\\",\\\\n      \\\\t\\\\\\\"estimated_size_in_bytes\\\\\\\" : 0,\\\\n      \\\\t\\\\\\\"estimated_size\\\\\\\" : \\\\\\\"0b\\\\\\\",\\\\n      \\\\t\\\\\\\"overhead\\\\\\\" : 1.03,\\\\n      \\\\t\\\\\\\"tripped\\\\\\\" : 0\\\\n    \\\\t},\\\\n    \\\\t\\\\\\\"in_flight_requests\\\\\\\" : {\\\\n      \\\\t\\\\\\\"limit_size_in_bytes\\\\\\\" : 34290008064,\\\\n      \\\\t\\\\\\\"limit_size\\\\\\\" : \\\\\\\"31.9gb\\\\\\\",\\\\n      \\\\t\\\\\\\"estimated_size_in_bytes\\\\\\\" : 6254164,\\\\n      \\\\t\\\\\\\"estimated_size\\\\\\\" : \\\\\\\"5.9mb\\\\\\\",\\\\n      \\\\t\\\\\\\"overhead\\\\\\\" : 2.0,\\\\n      \\\\t\\\\\\\"tripped\\\\\\\" : 0\\\\n    \\\\t},\\\\n    \\\\t\\\\\\\"accounting\\\\\\\" : {\\\\n      \\\\t\\\\\\\"limit_size_in_bytes\\\\\\\" : 34290008064,\\\\n      \\\\t\\\\\\\"limit_size\\\\\\\" : \\\\\\\"31.9gb\\\\\\\",\\\\n      \\\\t\\\\\\\"estimated_size_in_bytes\\\\\\\" : 282771278,\\\\n      \\\\t\\\\\\\"estimated_size\\\\\\\" : \\\\\\\"269.6mb\\\\\\\",\\\\n      \\\\t\\\\\\\"overhead\\\\\\\" : 1.0,\\\\n      \\\\t\\\\\\\"tripped\\\\\\\" : 0\\\\n    \\\\t},\\\\n    \\\\t\\\\\\\"parent\\\\\\\" : {\\\\n      \\\\t\\\\\\\"limit_size_in_bytes\\\\\\\" : 32575507660,\\\\n      \\\\t\\\\\\\"limit_size\\\\\\\" : \\\\\\\"30.3gb\\\\\\\",\\\\n      \\\\t\\\\\\\"estimated_size_in_bytes\\\\\\\" : 13431618584,\\\\n      \\\\t\\\\\\\"estimated_size\\\\\\\" : \\\\\\\"12.5gb\\\\\\\",\\\\n      \\\\t\\\\\\\"overhead\\\\\\\" : 1.0,\\\\n      \\\\t\\\\\\\"tripped\\\\\\\" : 0\\\\n    \\\\t}\\\\n  \\\\t} Fielddata circuit breaker indices.breaker.fielddata.limit (default=40% JVM heap) indices.breaker.fielddata.overhead (default=1.03) The limit is set as a proportion of the JVM heap set in jvm.options, while the \\u201coverhead\\u201d setting is a fixed ratio which OpenSearch uses to multiply the theoretical calculations to estimate the circuit breaker memory requirement. Fielddata circuit breaker is a limit on the total amount of memory used by fielddata in your indices. Fielddata is by default set to false on a text field, but may be used where you have defined it in one of your mappings: \\\\\\\"fielddata\\\\\\\": true In general it is recommended to avoid this setting because of the large amount of memory required in putting individual text values into memory. If possible you should change your mappings to set it to false, and use keyword type mappings rather than text type for aggregations and sorting. However, if this is not possible and you need to aggregate based on individual terms in a text rather than keywords, then you could also consider setting a fielddata frequency filter on the mapping to limit the amount of fielddata put into memory. PUT my-index-000001\\\\n{\\\\n  \\\\\\\"mappings\\\\\\\": {\\\\n    \\\\\\\"properties\\\\\\\": {\\\\n      \\\\\\\"need_to_aggregate_individual_terms_on_this_field\\\\\\\": {\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"text\\\\\\\",\\\\n        \\\\\\\"fielddata\\\\\\\": true,\\\\n        \\\\\\\"fielddata_frequency_filter\\\\\\\": {\\\\n          \\\\\\\"min\\\\\\\": 0.001,\\\\n          \\\\\\\"max\\\\\\\": 0.1,\\\\n          \\\\\\\"min_segment_size\\\\\\\": 500\\\\n        }\\\\n      }\\\\n    }\\\\n  }\\\\n} Request circuit breaker indices.breaker.request.limit(default=60% JVM heap) indices.breaker.request.overhead(default=1) The limit is set as a proportion of the JVM heap set in jvm.options, while the \\u201coverhead\\u201d setting is a fixed ratio which OpenSearch uses to multiply the theoretical calculations to estimate the circuit breaker memory requirement. The request circuit breaker takes into account the memory required based on the request structures, in particular aggregations. The most common cause of exceeding this circuit breaker is through the use of aggregations with a large size value. Try reducing the value of \\u201csize\\u201d in your aggregations. Inflight requests circuit breaker network.breaker.inflight_requests.limit (default=100% JVM heap) network.breaker.inflight_requests.overhead (default=2) The limit is set as a proportion of the JVM heap set in jvm.options, while the \\u201coverhead\\u201d setting is a fixed ratio which OpenSearch uses to multiply the theoretical calculations to estimate the circuit breaker memory requirement. The in-flight requests circuit breaker considers the size of active transport and http requests for the node based on the byte size of those requests. Generally this circuit breaker is activated when batch sizes for bulk requests are too large. Try reducing the size of bulk requests, particularly if those requests contain large documents. Script compilation circuit breaker script.context.$CONTEXT.max_compilations_rate (default=75/5m) The script compilation circuit breaker is slightly different from the others. Rather than applying a memory limit, it limits the number of times a script can be compiled in a given period. If you get this warning, you should use stored scripts with parameters instead of inline ones, as the former are compiled only once, while the latter are compiled on each execution. Parent circuit breakers indices.breaker.total.use_real_memory default=true indices.breaker.total.limit default=95% JVM heap Parent circuit breaker exceptions are caused by the sum of all memory being used across the different types of circuit breakers. If the use_real_memory is left as the default, then the parent circuit breaker will take into account real memory usage and will be based upon 95% of the JVM heap size. In general it is better to base this circuit upon real memory usage since it gives you a more accurate picture of what is going on in the instance. On the other hand if you choose to set \\u201cuse_real_memory\\u201d to false, then the limit will be based on the sum of the estimates of other circuit breakers in which case the default limit will be reduced to 70% of the JVM heap size to take into account the margin or error with using a sum of estimates. Accounting circuit breakers indices.breaker.accounting.limit default= 100% of JVM heap indices.breaker.accounting.overhead default=1 This circuit breaker is to protect the node from over usage of memory due to things that persist in memory after a request has completed, such as lucene segments before they are flushed to disk. The default limit is however set at 100% of JVM heap so the parent circuit breaker will trip before this limit becomes effective. The accounting overhead setting is a coefficient which is used to multiply all estimates before applying the limit. Adjusting circuit breakers In general, and as warned above, it is usually not advisable to modify circuit breakers from their defaults, since it is far worse to lose a node from an OutOfMemoryError than to drop a few requests. Instead you should try to understand why you are exceeding them and prevent this from happening. Also bear in mind that the default calculations are based on your JVM heap size which is generally assumed to be 50% of the total available size. If this is not the case, then you may want to re-consider setting the JVM settings in jvm.options before reconfiguring everything else. However if you still think you need to modify the circuit breakers (or restore the defaults), you can adjust circuit breaker settings just like any other cluster settings PUT _cluster/settings\\\\n{\\\\n  \\\\\\\"transient\\\\\\\": {\\\\\\\"indices.breaker.total.limit\\\\\\\":\\\\\\\"5GB\\\\\\\" }\\\\n} Or to restore the setting to it\\u2019s default PUT _cluster/settings\\\\n{\\\\n  \\\\\\\"transient\\\\\\\": {\\\\\\\"indices.breaker.total.limit\\\\\\\":null }\\\\n} Additional notes Elasticsearch and OpenSearch are both powerful search and analytics engines, but Elasticsearch has several key advantages. Elasticsearch boasts a more mature and feature-rich development history, translating to a better user experience, more features, and continuous optimizations. Our testing has consistently shown that Elasticsearch delivers faster performance while using fewer compute resources than OpenSearch. Additionally, Elasticsearch\\u2019s comprehensive documentation and active community forums provide invaluable resources for troubleshooting and further optimization. Elastic, the company behind Elasticsearch, offers dedicated support, ensuring enterprise-grade reliability and performance. These factors collectively make Elasticsearch a more versatile, efficient, and dependable choice for organizations requiring sophisticated search and analytics capabilities. Related Articles How to Easily Upgrade Elasticsearch Versions How to Handle Recurring RED Status Backblaze Optimized OpenSearch Back to all articles Product AutoOps for Elasticsearch Community Tools Tools for the Community Company About Our Customers info@opster.com Resources Documentation Blog Guides Elasticsearch Error Messages Elasticsearch Log Errors Taking Care of Your Entire Search Operation. Opster\\u2019s solutions reduce the time and cost of running Elasticsearch. Get Improved performance & stability with less hardware. Contact Us \\u00a9 2025 Opster Privacy Policy Terms of Use We use cookies to ensure that we give you the best experience on our website. By continuing to browse this site, you agree to our Privacy Policy and Terms of Use. Agree Close GDPR Cookie Settings Privacy Overview Strictly Necessary Cookies Powered by GDPR Cookie Compliance Privacy Overview This website uses cookies so that we can provide you with the best user experience possible. Cookie information is stored in your browser and performs functions such as recognising you when you return to our website and helping our team to understand which sections of the website you find most interesting and useful. Strictly Necessary Cookies Strictly Necessary Cookie should be enabled at all times so that we can save your preferences for cookie settings. Enable or Disable Cookies Enabled Disabled Enable All Save Settings\\\"},{\\\"url\\\":\\\"https://docs.opensearch.org/latest/install-and-configure/configuring-opensearch/circuit-breaker/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Regular expression syntax Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Using UBI in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Configuring OpenSearch Circuit breaker settings Circuit breaker settings Circuit breakers prevent OpenSearch from causing a Java OutOfMemoryError. The parent circuit breaker specifies the total available amount of memory for all child circuit breakers. The child circuit breakers specify the total available amount of memory for themselves. To learn more about static and dynamic settings, see Configuring OpenSearch. Parent circuit breaker settings OpenSearch supports the following parent circuit breaker settings: indices.breaker.total.use_real_memory (Static, Boolean): If true, the parent circuit breaker considers the actual memory usage. Otherwise, the parent circuit breaker considers the amount of memory reserved by the child circuit breakers. Default is true. indices.breaker.total.limit (Dynamic, percentage): Specifies the initial memory limit for the parent circuit breaker. If indices.breaker.total.use_real_memory is true, defaults to 95% of the JVM heap. If indices.breaker.total.use_real_memory is false, defaults to 70% of the JVM heap. Field data circuit breaker settings The field data circuit breaker limits the heap memory required to load a field into the field data cache. OpenSearch supports the following field data circuit breaker settings: indices.breaker.fielddata.limit (Dynamic, percentage): Specifies the memory limit for the field data circuit breaker. Default is 40% of the JVM heap. indices.breaker.fielddata.overhead (Dynamic, double): A constant by which the field data estimations are multiplied to determine the final estimation. Default is 1.03. Request circuit breaker settings The request circuit breaker limits the memory required to build data structures that are needed for a request (for example, when calculating aggregations). OpenSearch supports the following request circuit breaker settings: indices.breaker.request.limit (Dynamic, percentage): Specifies the memory limit for the request circuit breaker. Default is 60% of the JVM heap. indices.breaker.request.overhead (Dynamic, double): A constant by which the request estimations are multiplied to determine the final estimation. Default is 1. In-flight request circuit breaker settings The in-flight request circuit breaker limits the memory usage for all currently running incoming requests on transport and HTTP level. The memory usage for a request is based on the content length of the request and includes memory needed for the raw request and a structured object representing the request. OpenSearch supports the following in-flight request circuit breaker settings: network.breaker.inflight_requests.limit (Dynamic, percentage): Specifies the memory limit for the in-flight request circuit breaker. Default is 100% of JVM heap (thus, the memory usage limit for an in-flight request is determined by the memory limit of the parent circuit breaker). network.breaker.inflight_requests.overhead (Dynamic, double): A constant by which the in-flight request estimations are multiplied to determine the final estimation. Default is 2. Script compilation circuit breaker settings The script compilation circuit breaker limits the number of inline script compilations within a time interval. OpenSearch supports the following script compilation circuit breaker setting: script.max_compilations_rate (Dynamic, rate): The maximum number of unique dynamic scripts compiled within a time interval for a given context. Default is 150 every 5 minutes (150/5m). Regular expression circuit breaker settings The regular expression circuit breaker enables or disables regular expressions and limits their complexity. OpenSearch supports the following regular expression circuit breaker settings: script.painless.regex.enabled (Static, string): Enables regular expressions in Painless scripts. Valid values are: limited: Enables regular expressions and limits their complexity using the script.painless.regex.limit-factor setting. true: Enables regular expressions. Turns off the regular expression circuit breaker and does not limit regular expression complexity. false: Disables regular expressions. If a Painless script contains a regular expression, it returns an error. Default is limited. script.painless.regex.limit-factor (Static, integer): Applied only if script.painless.regex.enabled is set to limited. Limits the number of characters a regular expression in a Painless script. The character limit is calculated by multiplying the number of characters in the script input by script.painless.regex.limit-factor. Default is 6 (thus, if the input has 5 characters, the maximum number of characters in a regular expression is 5 \\u00b7 6 = 30). Parent circuit breaker settings Field data circuit breaker settings Request circuit breaker settings In-flight request circuit breaker settings Script compilation circuit breaker settings Regular expression circuit breaker settings WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright \\u00a9 OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\\\"},{\\\"url\\\":\\\"https://repost.aws/knowledge-center/opensearch-circuit-breaker-exception\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to content By using AWS re:Post, you agree to the AWS re:Post Terms of Use re:Post Search About re:Post English EnglishDeutschEspa\\u00f1olFran\\u00e7aisItaliano\\u65e5\\u672c\\u8a9e\\ud55c\\uad6d\\uc5b4Portugu\\u00eas\\u4e2d\\u6587 (\\u7b80\\u4f53)\\u4e2d\\u6587 (\\u7e41\\u9ad4) Resources Sign in Home Questions Knowledge Center Articles Selections Tags Topics Community Groups AWS Support Official AWS Trust & Safety Center Ask question / How do I troubleshoot a circuit breaker exception in OpenSearch Service?lg.../ How do I troubleshoot a circuit breaker exception in OpenSearch Service? 6 minute read 1 I want to send data to my Amazon OpenSearch Service cluster. However, I receive a circuit breaking exception error that states that my data is too large. Short description When a request reaches OpenSearch Service nodes, circuit breakers estimate the amount of memory required to load the data. OpenSearch Service then compares the estimated size with the configured heap size quota. If the estimated size of the data is greater than the available heap size, then OpenSearch Service terminates the query. To prevent overloading the node, OpenSearch Service shows a CircuitBreakerException error. To resolve circuit breaking exception errors, first identify the circuit breaking exemption. Then, to reduce the load on your data nodes in the future, reduce high Java virtual machine (JVM) pressure. Resolution Identify the circuit breaking exemption OpenSearch Service uses the following circuit breakers to prevent JVM OutofMemoryError exceptions: Request Field data In flight requests Accounting Parent Important: Identify each of the five circuit breakers that raises the exception. Each circuit breaker has its own tuning needs. For more information about circuit breaker types, see Circuit breaker settings on the Elasticsearch website. To get the current memory usage per node and per breaker, run the following command: GET _nodes/stats/breaker Note that circuit breakers are a best-effort mechanism. Circuit breakers provide limited resiliency against overloading nodes. However, you might still receive an OutOfMemoryError. Circuit breakers can track memory only if it's explicitly reserved. It's not always possible to estimate the exact memory usage in advance. For example, if you have a small amount of memory heap, then the relative overhead of untracked memory is larger. For more information about circuit breakers and node resiliency, see Improving node resiliency with the real memory circuit breaker on the Elasticsearch website. If you reach the circuit breaker quota and use Elasticsearch version 7.x or higher with 16 GB of heap, then you receive the following error: {\\\\n    \\\\\\\"error\\\\\\\": {\\\\n\\\\n        \\\\\\\"root_cause\\\\\\\": [{\\\\n\\\\n            \\\\\\\"type\\\\\\\": \\\\\\\"circuit_breaking_exception\\\\\\\",\\\\n\\\\n            \\\\\\\"reason\\\\\\\": \\\\\\\"[parent] Data too large, data for [<http_request>] would be [16355096754/15.2gb], which is larger than the limit of [16213167308/15gb]\\\\\\\",\\\\n\\\\n            \\\\\\\"bytes_wanted\\\\\\\": 16355096754,\\\\n\\\\n            \\\\\\\"bytes_limit\\\\\\\": 16213167308\\\\n\\\\n        }],\\\\n\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"circuit_breaking_exception\\\\\\\",\\\\n\\\\n        \\\\\\\"reason\\\\\\\": \\\\\\\"[parent] Data too large, data for [<http_request>] would be [16355096754/15.2gb], which is larger than the limit of [16213167308/15gb]\\\\\\\",\\\\n\\\\n        \\\\\\\"bytes_wanted\\\\\\\": 16355096754,\\\\n\\\\n        \\\\\\\"bytes_limit\\\\\\\": 16213167308\\\\n\\\\n    },\\\\n\\\\n    \\\\\\\"status\\\\\\\": 503\\\\n\\\\n} The preceding example output shows that the data is too large for the parent circuit breaker to process. The parent circuit breaker manages the overall memory usage of your cluster. When a parent circuit breaker exception occurs, the total memory used across all circuit breakers exceeds the set limit. A parent breaker throws an exception when the cluster exceeds 95% of 16 GB (15.2 GB of heap). To verify the logic, calculate the difference between memory usage and set circuit breaker limit. That is, with this example output, subtract the real usage of [15283269136/14.2gb] from the limit of [16213167308/15gb]. The example request needs 1.02 GB of new bytes reserved memory to process the request. However, the cluster has less than 0.8 GB of available free memory heap when the data request is received. As a result, the circuit breaker trips. To interpret the circuit breaker exception message, use the following guidelines: data for [<http_request>]: The client sends an HTTP request to a node in your cluster. OpenSearch Service either processes the request locally or passes it to another node for additional processing. would be [#]: The heap size when the request is processed. limit of [#]: The current circuit breaker limit. real usage: The actual use of the JVM heap. new bytes reserved: The actual memory needed to process the request. Reduce high JVM memory pressure High JVM pressure often causes circuit breaking exemptions. JVM memory pressure is the percentage of Java heap that all data nodes in your cluster use. Check the JVMMemoryPressure metric in Amazon CloudWatch to determine your current usage. Note: The JVM heap size of a data node is set to half the size of physical memory (RAM) per node, up to 32 GB. For example, if the physical memory is 30 GB per node, then the heap size is 15 GB. If the physical memory is 128 GB per node, then the heap size is 32 GB. To resolve high JVM memory pressure, take one or more of the following actions: Reduce incoming traffic to your cluster, especially if you have a heavy workload. An increase in the number of requests to the cluster can cause high JVM pressure. Check the IndexRate and SearchRate metrics in CloudWatch to determine your current load. Scale the cluster to get more JVM memory to support your workload. If you can't scale the cluster, then delete old or unused indices to reduce the number of shards. Shard metadata is stored in memory. When you reduce the number of shards, you reduce the overall memory usage. To identify faulty requests, turn on slow logs. Note: Before you make configuration changes, to avoid additional overhead to existing resources, verify that JVM memory pressure is below 85%. Optimize search and indexing requests, and choose the correct number of shards for your use case. Unbalanced shard allocation across nodes or too many shards in a cluster can cause high JVM pressure. For more information about indexing and shard count, see Get started with Amazon OpenSearch Service: How many shards do I need? Turn off and don't use the fielddata data structure to query data. By default, fielddata is set to false on a text field unless explicitly defined otherwise in index mappings. Fielddata can consume a large amount of heap space, and remains in the heap for the lifetime of a segment. As a result, when you use fielddata, JVM memory pressure remains high on the cluster. For more information, see fielddata on the Elasticsearch website. Change your index type to a keyword. For more information, see Reindex API or Create or update index template API on the Elasticsearch website. You can use the keyword type as an alternative to aggregations and sorting on text fields. To prevent increases in field data, avoid aggregating on text fields. When you use more field data, you consume more heap space. Use the cluster stats API operation on the Elasticsearch website to check your field data. Remove aggregation, wildcards, and wide time ranges from your queries. Clear the fielddata cache. Run the following API call: POST /index_name/_cache/clear?fielddata=true (index-level cache)POST */_cache/clear?fielddata=true (cluster-level cache) Important: If you clear the fielddata cache, then you might disrupt in-progress queries. For more information, see How do I troubleshoot high JVM memory pressure on my OpenSearch Service cluster? Related information Operational best practices for Amazon OpenSearch Service How can I improve the indexing performance on my Amazon OpenSearch Service cluster? Follow Share Topics Analytics Tags Amazon OpenSearch Service Language English AWS OFFICIALUpdated a year ago No comments Comment on this article Clear Post comment Relevant content resetting knn circuit breaker triggered Accepted Answer iamlmt asked 2 years ago Error deploying service: ECS Deployment Circuit Breaker was triggered Accepted Answer mertt asked 2 years ago Always this errorECS Deployment Circuit Breaker was triggered Accepted Answer Orlando Parra asked 2 years ago Error occurred during operation 'ECS Deployment Circuit Breaker was triggered rePost-User-3108449 asked 2 years ago ECS Circuit Breaker is not preventing deployment loop Sam asked 10 months ago Why did the Amazon ECS deployment circuit breaker set my deployment state to FAILED? AWS OFFICIALUpdated 9 months ago Why is OpenSearch Dashboards in red status on my Amazon OpenSearch Service domain? AWS OFFICIALUpdated 2 years ago How do I configure and monitor the Amazon ECS deployment circuit breaker? AWS OFFICIALUpdated a year ago How do I troubleshoot high JVM memory pressure on my OpenSearch Service cluster? AWS OFFICIALUpdated 3 months ago ECS Deployment Circuit Breaker was triggered. EXPERT Chethangowda B C published 7 months ago FEEDBACK Privacy| Site Terms| Cookie Preferences | Sitemap| Legal| \\u00a9 2025, Amazon Web Services, Inc. or its affiliates. All rights reserved. Community Guidelines\\\"},{\\\"url\\\":\\\"https://medium.com/@antstack/how-to-handle-the-circuit-breaker-exception-in-opensearch-be1872ed98ac\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Sitemap Open in app Sign up Sign in Medium Logo Write Search Sign up Sign in Press enter or click to view image in full size How to Handle the Circuit Breaker Exception in OpenSearch AntStack Inc. 6 min read \\u00b7 Nov 11, 2024 -- Listen Share We had a search functionality requirement in one of the projects and that\\u2019s how I got to know about Amazon OpenSearch Service, It provides a quick, relevant search experience and makes it easier to add a search feature to your applications. The only hiccup is sizing the OpenSearch is a tricky and long-term process, and it often takes many iterations to make sure that you get the right specifications according to your workload. It also needs monitoring so as to be aware of future problems. You make an initial estimate of the resources, test them, and verify their performance. If the performance is not good, then you need to resize it and iterate. In this process, you often face many challenges. Some of them are listed below: Red / Yellow Cluster Status Exceeded maximum shard limit JVM OutOfMemoryError Failed cluster nodes While I was working with OpenSearch, I faced one such issue, which I will cover in this post. Our cluster was ready to go after going through the estimation process and performance testing, but after a while, we started seeing CircuitBreakerException in our logs. I find it difficult to understand, so I thought to write about it. I hope this blog helps you understand it better. Before we get into the topic, I would like to explain a little about clusters and nodes in OpenSearch. OpenSearch cluster is made up of one or more nodes, which are servers that handle search queries and store your data. As the cluster grows we can subdivide the responsibilities among different nodes(Master, Data, and more). Now, Let\\u2019s dive into the issue. What is a circuit breaker? In data nodes, 50 % of the available memory up to 32GB is used by the JVM heap and the rest is used for other operations. Circuit breakers are limitations put on a node to stop operations with the risk of resulting in JVM OutofMemoryError, which could cause the node to crash completely. The amount of memory each circuit breaker can utilize is specified. In response to requests, the breakers calculate how much memory the activity requires and compare the calculated size to the specified heap size limit. The query is aborted if the anticipated size exceeds the available heap size. In order to avoid overloading the node, a CircuitBreakerException is raised. Types of Circuit breakers There are many types of circuit breakers and a few of them are as follows: Parent circuit breaker \\u2014 It specifies the maximum amount of memory that all breakers can utilize. If the combined memory utilization results in more than the specified limit the parent circuit exception will occur. It is configured using the below settings. indices.breaker.total.use_real_memory (default to true) \\u2014 Determines whether the parent breaker should take real memory usage into account (true) or only consider the amount that is reserved by child circuit breakers (false). indices.breaker.total.limit (default \\u2014 95% of JVM heap) \\u2014 Limit for overall parent breaker. If indices.breaker.total.use_real_memory is false then 70% JVM heap otherwise 95% of the JVM heap. Field Data circuit breaker \\u2014 It is anticipated how much heap memory will be required to load a field into the field data cache. The circuit breaker terminates the operation and reports an error if loading the field will cause the cache to use more memory than was allowed. The field data cache contains field data (to allow text fields to be available for aggregations, sorting, and scripting) and global ordinals (It is an internal data structure used in elasticsearch for pre-computing and optimizing the performance of terms aggregations). indices.breaker.fielddata.limit \\u2014 Limit for fielddata breaker. Defaults to 40% of the JVM heap. indices.breaker.fielddata.overhead \\u2014 A constant (1.03) that all field data estimations are multiplied to determine a final estimation. Request circuit breaker \\u2014 It is estimated how much heap memory will be required to process a request. It also includes the memory used for calculating aggregations during a request. If the memory usage is more than the limit, the request is terminated and an exception is raised. indices.breaker.request.limit \\u2014 Defaults to 60% of the JVM heap. indices.breaker.request.overhead \\u2014 A constant (1) that all request estimations are multiplied to determine a final estimation. In-flight requests circuit breaker \\u2014 It is caused when the memory usage of all active incoming requests exceeds the configured threshold on a node. network.breaker.inflight_requests.limit \\u2014 Defaults to 100% of JVM heap. This means that it is bound by the limit configured for the parent circuit breaker. network.breaker.inflight_requests.overhead \\u2014 A constant (2) that is multiplied to determine a final estimation. Accounting circuit breaker \\u2014 It is a limit to prevent items from using too much memory that isn\\u2019t released when a request is finished, such as Lucene segment memory. A segment is an inverted index. indices.breaker.accounting.limit \\u2014 Limit for accounting breaker, defaults to 100% of JVM heap. This means that it is bound by the limit configured for the parent circuit breaker. indices.breaker.accounting.overhead \\u2014 A constant (1) that is multiplied to determine a final estimation. Useful Commands GET /_nodes/stats/breaker To retrieve the current memory use per node and per breaker. GET _cat/nodes?v=true&h=id,r,ram,heap* To obtain information about heap and memory details per node. GET /_cluster/settings?include_defaults=true It will return explicitly defined and default setting in the cluster including breaker settings. GET _nodes/stats?filter_path=nodes..jvm.mem.pools.old To calculate the JVM memory pressure of each node. Use the response to calculate memory pressure as JVM Memory Pressure = used_in_bytes / max_in_bytes. Circuit Breaker Exception Example Press enter or click to view image in full size Above is an example of a circuit breaker error message which I had encountered while working with AWS OpenSearch Service. The error will result in a 429 status code. Let\\u2019s look into the error more closely and try to understand what is happening here. type \\u2014 It specifies the type of the exception raised. reason \\u2014 More detailed information about the reason which led to the mentioned exception. [parent] \\u2014 It specifies that the parent circuit breaker exception has resulted in the error. The default parent circuit breaker setting is 95%. real usage \\u2014 It defines the current heap usage. new bytes reserved \\u2014 It specifies the number of new bytes required. limit of \\u2014 It is the maximum memory allocation for the parent circuit breaker. If the real usage + new bytes reserved exceeds the limit of, the parent circuit breaker will be triggered. durability \\u2014 It specifies if the issue that triggered the circuit breaker eventually resolves itself (TRANSIENT) or calls for manual intervention (PERMANENT). Suggestions Reduce JVM memory pressure \\u2014 High JVM memory pressure often causes circuit breaker errors. Check the JVM memory pressure and try to reduce it using the following suggestions. Reduce the shard numbers of each index- For search latency workloads use a shard size between 10\\u201330 GiB. For write-heavy workloads use a shard size between 30\\u201350 GiB. On a given node, have no more than 20 shards per GiB of Java heap. Avoid searches that might be very expensive (Using large size in pagination). Enable slow logs for identifying expensive search queries. Aggregation, wildcards, and wide time ranges in your queries might also result in high JVM pressure. A mapping explosion, which consumes a lot of memory, might result from defining too many fields or nesting fields too deeply. Avoid sending a large number of requests at the same time or tuning bulk size according to your workload. Increase the cluster\\u2019s size to get an extra JVM heap to handle yours. Disable and avoid using fielddata as it can consume a large amount of heap space. Monitoring OpenSearch cluster metrics with Amazon CloudWatch and create alarms for various cluster metrics. Enable logs for better observability of the errors and issues. Author(s) Somya Sharma Backend Dev currently focusing on AWS Services, Algorithms, and Serverless Application Development. AWS Elasticsearch Opensearch Circuit Breakers -- -- Written by AntStack Inc. 12 followers \\u00b71 following AntStack is one of the leading full-stack serverless companies aiming at disrupting the cloud computing space by providing holistic solutions to get you up No responses yet Help Status About Careers Press Blog Privacy Rules Terms Text to speech\\\"},{\\\"url\\\":\\\"https://socprime.com/blog/opensearch-circuit-breakers/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Platform Threat Detection Marketplace Your Home for Threat Detection Attack Detective Industry-First SaaS for Advanced Threat Hunting Uncoder AI Single IDE for Detection Engineering Shift-Left Detection Run Sigma rules on Kafka Ecosystem Use Cases Fortify SIEM Posture Audit your SIEM posture to maximize threat visibility & address detection coverage gaps. Obtain Rules for Alerting Get prioritized SIEM use cases ready-to-deploy as low-noise and high-value alerts. Advance Threat Detection Access the world\\u2019s largest rule feed for emerging threats, manage & deploy detections at scale. Elevate Detection Engineering Save time and costs, obtain CTI-enriched use cases, adapt CI/CD workflows. Accelerate MDR Services Reduce customer churn, address technical debt in threat detection, and save on SIEM costs. Hyperscale SIEM Migration Accelerate time-to-value and maximize the ROI of your SIEM migration project. Enable Bear Fence For Your MDE Maximize your Microsoft Defender for Endpoint with automated hunting for APT28 (Fancy Bear) and other Russian APTs. Services Professional Services Overview Explore our on-demand services and training. MITRE ATT&CK Audit Minimize blind spots and ensure comprehensive data visibility. Custom Content Engineering Adopt out-of-the-box detection engineering capability to identify threats challenging your business. SIEM Migration Services Accelerate time-to-value and maximize the ROI of your SIEM migration project. Resources Blog Research, guides, interviews News Headlines in cyberspace Events Stay tuned to our cybersecurity events Data Sheets Explore our data sheets for detailed insights Threat Bounty Monetize your Threat Detection content Customer Success Stories Learn how global organizations trust SOC Prime Detection as Code Explore our latest innovation reports Roota Open-Source Language for Collective Cyber Defence Sigma History of Sigma Evolution Industry Expertise Center of Excellence for Microsoft Sentinel Center of Excellence for Amazon Web Services Splunk Migration & Support Tools Uncoder.IO The Prime Hunt browser extension: Chrome Firefox Edge Company Why SOC Prime? Collective cyber defense for a secure tomorrow About Us Our story and mission Industry Recognition Verified value for cybersecurity Leadership Biography and DNA Careers Job opportunities at SOC Prime Privacy SOC Prime\\u2019s privacy-centric mindset SOC 2 Type II Compliance Benchmark for security compliance Partner Programs for Universities Sigma & MITRE ATT&CK\\u00ae Education Pricing Log In Request a Demo Request a Demo Request a Demo Blog/Knowledge Bits/This article OpenSearch Circuit Breakers WRITTEN BY Oleksii K. DevOps Engineer [post-views] December 04, 2024 \\u00b7 2 min read Table of contents: Types of Circuit Breakers in OpenSearch Handling Circuit Breaker Exceptions OpenSearch employs circuit breakers to prevent nodes from running out of Java Virtual Machine (JVM) heap memory, which could lead to crashes. These circuit breakers estimate the memory required for operations and compare it to the available heap size. If an operation exceeds the configured limit, OpenSearch throws a CircuitBreakerException to avoid potential OutOfMemoryErrors. Types of Circuit Breakers in OpenSearch Parent Circuit Breaker: This breaker sets the overall memory limit for all child circuit breakers. By default, it is configured to 95% of the JVM heap size. It\\u2019s crucial to ensure that the indices.breaker.request.limit is set lower than the parent breaker to prevent the parent breaker from being triggered prematurely. Fielddata Circuit Breaker: This breaker limits the memory used to load fields into the fielddata cache, which is essential for operations like aggregations and sorting. The default limit is 40% of the JVM heap. To adjust this limit, you can use the following command: PUT /_cluster/settings\\\\n{\\\\n  \\\\\\\"persistent\\\\\\\": {\\\\n    \\\\\\\"indices.breaker.fielddata.limit\\\\\\\": \\\\\\\"60%\\\\\\\"\\\\n  }\\\\n} Request Circuit Breaker: This breaker estimates the memory required to process a request, including memory for aggregations. The default limit is 60% of the JVM heap. If a request exceeds this limit, it is terminated to prevent memory overload. In-Flight Requests Circuit Breaker: This breaker monitors the memory usage of active incoming requests. The default limit is set to 100% of the JVM heap, which is effectively controlled by the parent circuit breaker. Script Compilation Circuit Breaker: This breaker limits the number of inline script compilations within a specified time interval. The default setting allows 150 compilations every 5 minutes. To adjust this limit, you can modify the script.max_compilations_rate setting. Handling Circuit Breaker Exceptions When a circuit breaker is triggered, OpenSearch throws a CircuitBreakerException, often accompanied by a 429 status code indicating \\u201cdata too large.\\u201d To handle these exceptions effectively: Review Query and Mapping: Examine your queries and index mappings to identify operations that consume excessive memory. For instance, using large size values in aggregations can lead to high memory usage. Optimize Fielddata Usage: Avoid enabling fielddata on text fields unless absolutely necessary, as it can consume significant memory. Instead, use keyword fields for aggregations and sorting. Adjust Circuit Breaker Settings: While it\\u2019s generally advisable to keep default settings to prevent OutOfMemoryErrors, you can adjust circuit breaker limits if you have a clear understanding of your workload and memory requirements. For example, to increase the fielddata limit to 60%, use the command mentioned earlier. Scale Your Cluster: If your workload consistently exceeds memory limits, consider scaling your cluster by adding more nodes or increasing the JVM heap size to accommodate the increased memory demands. Table of Contents Types of Circuit Breakers in OpenSearch Handling Circuit Breaker Exceptions Was this article helpful? Like and share it with your peers. Join SOC Prime's Detection as Code platform to improve visibility into threats most relevant to your business. To help you get started and drive immediate value, book a meeting now with SOC Prime experts. Join for Free Book a Meeting Call with SOC Prime \\u00d7 Related Posts Apr 25/2025 2 min read SOC Prime Platform Rule Deployment into a Data Plane by Steven Edwards Apr 25/2025 2 min read SOC Prime Platform Translate from Sigma into 48 Languages by Steven Edwards Dec 4/2024 2 min read Knowledge Bits Splunk: How to Write a Query to Monitor Multiple Sources and Send Alert if they Stop Coming by Oleh P. All News Boost Your Cyber Defense with Threat Detection Marketplace The leading platform for Detection as Code and Continuous Security Intelligence Join Now Platform Threat Detection Marketplace Attack Detective Uncoder AI Shift-Left Detection Ecosystem Use Cases Fortify SIEM Posture Obtain Rules for Alerting Advance Threat Detection Elevate Detection Engineering Accelerate MDR Services Hyperscale SIEM Migration Enable Bear Fence For Your MDE Services Professional Services Overview MITRE ATT&CK Audit Custom Content Engineering SIEM Migration Services Industry Expertise Center of Excellence for Microsoft Sentinel Center of Excellence for Amazon Web Services Splunk Migration & Support Tools Uncoder.IO The Prime Hunt for: Chrome Firefox Edge Resources Blog News Events Data Sheets Threat Bounty Customer Success Stories Detection as Code Roota Sigma Company Why SOC Prime? About Us Industry Recognition Leadership Careers Privacy SOC 2 Type II Compliance Partner Programs for Universities PRICING Cookie Policy Privacy Policy LEGAL NOTICE (IMPRESSUM) SOC PRIME PLATFORM TERMS OF SERVICE Privacy FAQ Engage WIth Us SOC Prime, SOC Prime Logo and Threat Detection Marketplace are registered trademarks of SOC Prime, Inc. All other trademarks are the property of their respective owners. This website uses cookies (small text files that are stored by the web browser on the user's device) to improve the user experience while you navigate through the website for the statistical analysis of traffic and to adapt the content of the website to your individual needs. It also lets us improve your overall experience of the website. These cookies will only be stored in your browser with your consent. However, if you would like to, you can opt-out of these cookies in your browser settings at any time. But opting out of some of these cookies may have a negative impact on your viewing experience. More information can be found in our Cookie Policy, and for a detailed list of the cookies we use, see our Cookie Settings. Accept and Close Cookie Settings Cookie Settings Below is a detailed list of the cookies we use on our Site. We classify cookies in the following categories: Strictly Necessary Cookies Performance Cookies Functional Cookies Targeting Cookies Strictly Necessary Cookies Cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information. Name Descripiton PHPSESSID Preserves user session state across page requests. Cookie generated by applications based on the PHP language. This is a general purpose identifier used to maintain user session variables. It is normally a random generated number, how it is used can be specific to the site, but a good example is maintaining a logged-in status for a user between pages. sp_i Used to store information about authenticated User. sp_r Used to store information about authenticated User. sp_a Used to store information about authenticated User. Performance Cookies These cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site. All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site, and will not be able to monitor its performance. Name Descripiton tuuid Collects anonymous data related to the user's visits to the website, such as the number of visits, average time spent on the website and what pages have been loaded. tuuid_last_update Collects anonymous data related to the user's visits to the website, such as the number of visits, average time spent on the website and what pages have been loaded. um Collects anonymous data related to the user's visits to the website, such as the number of visits, average time spent on the website and what pages have been loaded. umeh Collects anonymous data related to the user's visits to the website, such as the number of visits, average time spent on the website and what pages have been loaded. na_sc_x Used by the social sharing platform AddThis to keep a record of parts of the site that has been visited in order to recommend other parts of the site. APID Collects anonymous data related to the user's visits to the website. IDSYNC Collects anonymous data related to the user's visits to the website. _cc_aud Collects anonymous statistical data related to the user's website visits, such as the number of visits, average time spent on the website and what pages have been loaded. The purpose is to segment the website's users according to factors such as demographics and geographical location, in order to enable media and marketing agencies to structure and understand their target groups to enable customised online advertising. _cc_cc Collects anonymous statistical data related to the user's website visits, such as the number of visits, average time spent on the website and what pages have been loaded. The purpose is to segment the website's users according to factors such as demographics and geographical location, in order to enable media and marketing agencies to structure and understand their target groups to enable customised online advertising. _cc_dc Collects anonymous statistical data related to the user's website visits, such as the number of visits, average time spent on the website and what pages have been loaded. The purpose is to segment the website's users according to factors such as demographics and geographical location, in order to enable media and marketing agencies to structure and understand their target groups to enable customised online advertising. _cc_id Collects anonymous statistical data related to the user's website visits, such as the number of visits, average time spent on the website and what pages have been loaded. The purpose is to segment the website's users according to factors such as demographics and geographical location, in order to enable media and marketing agencies to structure and understand their target groups to enable customised online advertising. dpm Via a unique ID that is used for semantic content analysis, the user's navigation on the website is registered and linked to offline data from surveys and similar registrations to display targeted ads. acs Collects anonymous data related to the user's visits to the website, such as the number of visits, average time spent on the website and what pages have been loaded, with the purpose of displaying targeted ads. clid Collects anonymous data related to the user's visits to the website, such as the number of visits, average time spent on the website and what pages have been loaded, with the purpose of displaying targeted ads. KRTBCOOKIE_# Registers a unique ID that identifies the user's device during return visits across websites that use the same ad network. The ID is used to allow targeted ads. PUBMDCID Registers a unique ID that identifies the user's device during return visits across websites that use the same ad network. The ID is used to allow targeted ads. PugT Registers a unique ID that identifies the user's device during return visits across websites that use the same ad network. The ID is used to allow targeted ads. ssi Registers a unique ID that identifies a returning user's device. The ID is used for targeted ads. _tmid Registers a unique ID that identifies the user's device upon return visits. The ID is used to target ads in video clips. wam-sync Used by the advertising platform Weborama to determine the visitor's interests based on pages visits, content clicked and other actions on the website. wui Used by the advertising platform Weborama to determine the visitor's interests based on pages visits, content clicked and other actions on the website. AFFICHE_W Used by the advertising platform Weborama to determine the visitor's interests based on pages visits, content clicked and other actions on the website. B Collects anonymous data related to the user's website visits, such as the number of visits, average time spent on the website and what pages have been loaded. The registered data is used to categorise the users' interest and demographical profiles with the purpose of customising the website content depending on the visitor. 1P_JAR These cookies are used to gather website statistics, and track conversion rates. APISID Google set a number of cookies on any page that includes a Google reCAPTCHA. While we have no control over the cookies set by Google, they appear to include a mixture of pieces of information to measure the number and behaviour of Google reCAPTCHA users. HSID Google set a number of cookies on any page that includes a Google reCAPTCHA. While we have no control over the cookies set by Google, they appear to include a mixture of pieces of information to measure the number and behaviour of Google reCAPTCHA users. NID Google set a number of cookies on any page that includes a Google reCAPTCHA. While we have no control over the cookies set by Google, they appear to include a mixture of pieces of information to measure the number and behaviour of Google reCAPTCHA users. SAPISID Google set a number of cookies on any page that includes a Google reCAPTCHA. While we have no control over the cookies set by Google, they appear to include a mixture of pieces of information to measure the number and behaviour of Google reCAPTCHA users. SID Google set a number of cookies on any page that includes a Google reCAPTCHA. While we have no control over the cookies set by Google, they appear to include a mixture of pieces of information to measure the number and behaviour of Google reCAPTCHA users. SIDCC Security cookie to protect users data from unauthorised access. SSID Google set a number of cookies on any page that includes a Google reCAPTCHA. While we have no control over the cookies set by Google, they appear to include a mixture of pieces of information to measure the number and behaviour of Google reCAPTCHA users. __utmx This cookie is associated with Google Website Optimizer, a tool designed to help site owners improve their wbesites. It is used to distinguish between two varaitions a webpage that might be shown to a visitor as part of an A/B split test. This helps site owners to detemine which version of a page performs better, and therefore helps to improve the website. __utmxx This cookie is associated with Google Website Optimizer, a tool designed to help site owners improve their wbesites. It is used to distinguish between two varaitions a webpage that might be shown to a visitor as part of an A/B split test. This helps site owners to detemine which version of a page performs better, and therefore helps to improve the website. Functional Cookies These cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages. If you do not allow these cookies then some or all of these services may not function properly. Name Descripiton _hjid Hotjar cookie. This cookie is set when the customer first lands on a page with the Hotjar script. It is used to persist the random user ID, unique to that site on the browser. This ensures that behavior in subsequent visits to the same site will be attributed to the same user ID. _hjIncludedInSample This cookie is associated with web analytics functionality and services from Hot Jar, a Malta based company. It uniquely identifies a visitor during a single browser session and indicates they are included in an audience sample. intercom-id-[xxx] This cookie is used by Intercom as a session so that users can continue a chat as they move through the site. intercom-session-[xxx] Used to keeping track of sessions and remember logins and conversations. demdex Via a unique ID that is used for semantic content analysis, the user's navigation on the website is registered and linked to offline data from surveys and similar registrations to display targeted ads. CookieConsent Stores the user's cookie consent state for the current domain. __cfduid Used by the content network, Cloudflare, to identify trusted web traffic. ss These cookies enable the website to provide enhanced functionality and personalisation . They may be set by us or by third party providers whose services we have added to our pages. These services may include the Live Chat facility, Contact Us form(s), the Product Quotation forms and submission process, and the Email Newsletter sign up functionality . Targeting Cookies These cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. They do not store directly personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising. Name Descripiton _ga This cookie name is asssociated with Google Universal Analytics - which is a significant update to Google's more commonly used analytics service. This cookie is used to distinguish unique users by assigning a randomly generated number as a client identifier. It is included in each page. Registers a unique ID that is used to generate statistical data on how the visitor uses the website. request in a site and used to calculate visitor, session and campaign data for the sites analytics reports. By default it is set to expire after 2 years, although this is customisable by website owners. _gat Used by Google Analytics to throttle request rate. This cookie name is associated with Google Universal Analytics, according to documentation it is used to throttle the request rate - limiting the collection of data on high traffic sites. It expires after 10 minutes. _gid This cookie name is asssociated with Google Universal Analytics. This appears to be a new cookie and as of Spring 2017 no information is available from Google. It appears to store and update a unique value for each page visited. Registers a unique ID that is used to generate statistical data on how the visitor uses the website. IDE Used by Google DoubleClick to register and report the website user's actions after viewing or clicking one of the advertiser's ads with the purpose of measuring the efficacy of an ad and to present targeted ads to the user. r/collect Used by Google DoubleClick to register and report the website user's actions after viewing or clicking one of the advertiser's ads with the purpose of measuring the efficacy of an ad and to present targeted ads to the user. test_cookie Used to check if the user's browser supports cookies. collect Used to send data to Google Analytics about the visitor's device and behaviour. Tracks the visitor across devices and marketing channels. ads/user-lists/# These cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. c Registers anonymised user data, such as IP address, geographical location, visited websites, and what ads the user has clicked, with the purpose of optimising ad display based on the user's movement on websites that use the same ad network. khaos Registers anonymised user data, such as IP address, geographical location, visited websites, and what ads the user has clicked, with the purpose of optimising ad display based on the user's movement on websites that use the same ad network. put_# Registers anonymised user data, such as IP address, geographical location, visited websites, and what ads the user has clicked, with the purpose of optimising ad display based on the user's movement on websites that use the same ad network. rpb Registers anonymised user data, such as IP address, geographical location, visited websites, and what ads the user has clicked, with the purpose of optimising ad display based on the user's movement on websites that use the same ad network. rpx Registers anonymised user data, such as IP address, geographical location, visited websites, and what ads the user has clicked, with the purpose of optimising ad display based on the user's movement on websites that use the same ad network. tap.php Registers anonymised user data, such as IP address, geographical location, visited websites, and what ads the user has clicked, with the purpose of optimising ad display based on the user's movement on websites that use the same ad network.\\\"},{\\\"url\\\":\\\"https://www.bookstack.cn/read/opensearch-3.0-en/e7d13147ebaa1f74.md\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"\\u00d7 \\u601d\\u7ef4\\u5bfc\\u56fe\\u5907\\u6ce8 \\u5173\\u95ed OpenSearch v3.0 Documentation \\u9996\\u9875 \\u767d\\u5929 \\u591c\\u95f4 \\u5c0f\\u7a0b\\u5e8f \\u9605\\u8bfb \\u4e66\\u7b7e \\u6211\\u7684\\u4e66\\u7b7e \\u6dfb\\u52a0\\u4e66\\u7b7e \\u79fb\\u9664\\u4e66\\u7b7e Circuit breaker settings GitHub \\u6765\\u6e90:OpenSearch \\u6d4f\\u89c8 84 \\u626b\\u7801 \\u5206\\u4eab 2025-05-09 14:10:24 Circuit breaker settings Parent circuit breaker settings Field data circuit breaker settings Request circuit breaker settings In-flight request circuit breaker settings Script compilation circuit breaker settings Regular expression circuit breaker settings Circuit breaker settings Circuit breakers prevent OpenSearch from causing a Java OutOfMemoryError. The parent circuit breaker specifies the total available amount of memory for all child circuit breakers. The child circuit breakers specify the total available amount of memory for themselves. To learn more about static and dynamic settings, see Configuring OpenSearch. Parent circuit breaker settings OpenSearch supports the following parent circuit breaker settings: indices.breaker.total.use_real_memory (Static, Boolean): If true, the parent circuit breaker considers the actual memory usage. Otherwise, the parent circuit breaker considers the amount of memory reserved by the child circuit breakers. Default is true. indices.breaker.total.limit (Dynamic, percentage): Specifies the initial memory limit for the parent circuit breaker. If indices.breaker.total.use_real_memory is true, defaults to 95% of the JVM heap. If indices.breaker.total.use_real_memory is false, defaults to 70% of the JVM heap. Field data circuit breaker settings The field data circuit breaker limits the heap memory required to load a field into the field data cache. OpenSearch supports the following field data circuit breaker settings: indices.breaker.fielddata.limit (Dynamic, percentage): Specifies the memory limit for the field data circuit breaker. Default is 40% of the JVM heap. indices.breaker.fielddata.overhead (Dynamic, double): A constant by which the field data estimations are multiplied to determine the final estimation. Default is 1.03. Request circuit breaker settings The request circuit breaker limits the memory required to build data structures that are needed for a request (for example, when calculating aggregations). OpenSearch supports the following request circuit breaker settings: indices.breaker.request.limit (Dynamic, percentage): Specifies the memory limit for the request circuit breaker. Default is 60% of the JVM heap. indices.breaker.request.overhead (Dynamic, double): A constant by which the request estimations are multiplied to determine the final estimation. Default is 1. In-flight request circuit breaker settings The in-flight request circuit breaker limits the memory usage for all currently running incoming requests on transport and HTTP level. The memory usage for a request is based on the content length of the request and includes memory needed for the raw request and a structured object representing the request. OpenSearch supports the following in-flight request circuit breaker settings: network.breaker.inflight_requests.limit (Dynamic, percentage): Specifies the memory limit for the in-flight request circuit breaker. Default is 100% of JVM heap (thus, the memory usage limit for an in-flight request is determined by the memory limit of the parent circuit breaker). network.breaker.inflight_requests.overhead (Dynamic, double): A constant by which the in-flight request estimations are multiplied to determine the final estimation. Default is 2. Script compilation circuit breaker settings The script compilation circuit breaker limits the number of inline script compilations within a time interval. OpenSearch supports the following script compilation circuit breaker setting: script.max_compilations_rate (Dynamic, rate): The maximum number of unique dynamic scripts compiled within a time interval for a given context. Default is 150 every 5 minutes (150/5m). Regular expression circuit breaker settings The regular expression circuit breaker enables or disables regular expressions and limits their complexity. OpenSearch supports the following regular expression circuit breaker settings: script.painless.regex.enabled (Static, string): Enables regular expressions in Painless scripts. Valid values are: limited: Enables regular expressions and limits their complexity using the script.painless.regex.limit-factor setting. true: Enables regular expressions. Turns off the regular expression circuit breaker and does not limit regular expression complexity. false: Disables regular expressions. If a Painless script contains a regular expression, it returns an error. Default is limited. script.painless.regex.limit-factor (Static, integer): Applied only if script.painless.regex.enabled is set to limited. Limits the number of characters a regular expression in a Painless script. The character limit is calculated by multiplying the number of characters in the script input by script.painless.regex.limit-factor. Default is 6 (thus, if the input has 5 characters, the maximum number of characters in a regular expression is 5 \\u00b7 6 = 30). \\u5f53\\u524d\\u5185\\u5bb9\\u7248\\u6743\\u5f52 OpenSearch \\u6216\\u5176\\u5173\\u8054\\u65b9\\u6240\\u6709\\uff0c\\u5982\\u9700\\u5bf9\\u5185\\u5bb9\\u6216\\u5185\\u5bb9\\u76f8\\u5173\\u8054\\u5f00\\u6e90\\u9879\\u76ee\\u8fdb\\u884c\\u5173\\u6ce8\\u4e0e\\u8d44\\u52a9\\uff0c\\u8bf7\\u8bbf\\u95ee OpenSearch . \\u4e0a\\u4e00\\u7bc7: \\u4e0b\\u4e00\\u7bc7: \\u7248\\u672c OpenSearch v3.0 Documentation OpenSearch v2.19 Documentation OpenSearch v2.18 Documentation OpenSearch v2.17 Documentation OpenSearch v2.16 Documentation OpenSearch v2.15 Documentation OpenSearch v2.14 Documentation OpenSearch v2.13 Documentation OpenSearch v2.12 Documentation OpenSearch v2.11 Documentation OpenSearch v2.10 Documentation OpenSearch v2.9 Documentation OpenSearch v2.8 Documentation OpenSearch v2.7 Documentation OpenSearch v2.6 Documentation OpenSearch v2.5 Documentation OpenSearch v2.4 Documentation OpenSearch v2.3 Documentation OpenSearch v2.2 Documentation OpenSearch v2.1 Documentation OpenSearch v2.0 Documentation OpenSearch v1.3 Documentation OpenSearch v1.2 Documentation OpenSearch v1.1 Documentation OpenSearch v1.0 Documentation About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Getting started with OpenSearch security Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Creating and customizing AI search workflows Model guardrails Amazon Bedrock model guardrails Install and upgrade Installing OpenSearch Docker Helm Tarball RPM Debian Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Circuit breaker settings Cluster settings Index settings Search settings Availability and recovery settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Upgrading OpenSearch Rolling Upgrade Upgrades appendix Rolling upgrade lab Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Workload management Workload Group Lifecycle API Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Reindex data Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings Index management security Refresh search analyzer ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Ingest Pipelines Create pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove_by_pattern Remove Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data Time filter Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dev Tools Running queries in the Dev Tools console Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security in OpenSearch Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings and field types Mapping parameters Analyzer Boost Coerce Copy_to Doc values Dynamic Eager global ordinals Enabled Ignore above Ignore malformed Format Index Index options Fields Meta Normalizer Norms Null value Properties Search analyzer Store Term vector Supported field types Alias Binary Numeric field types Unsigned long Boolean k-NN vector Spaces Methods and engines Memory-optimized vectors Date field types Date Date nanoseconds IP address Range field types Object field types Object Nested Flat object Join String field types Keyword Text Match-only text Wildcard Token count Constant keyword Autocomplete field types Completion Search as you type Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Rank field types Star-tree Derived Percolator Metadata fields Field names ID Ignored Index Meta Routing Source Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Exists Fuzzy IDs Prefix Range Regexp Term Terms Terms set Wildcard Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Distance feature k-NN k-NN query explain Neural Neural sparse Script score Template Minimum should match Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Range Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Search features Search options Paginate results Point in Time Point in Time API Sort results Filter results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Comparing search results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI client data structures Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines Search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data Types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Neural sparse search using raw vectors Conversational search with RAG Building AI search workflows in OpenSearch Dashboards Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Specialized vector search Nested field search Radial search Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Index Mapping tool List Index tool Log Pattern Tool ML Model tool Neural Sparse Search tool PPL tool RAG tool Search Alerts tool CreateAnomalyDetectorTool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web search tool Using MCP tools Connecting to an external MCP server OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Execute agent Get agent Search agent Delete agent MCP server APIs Register MCP tools Remove MCP tools MCP SSE session MCP SSE message Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI OpenSearch Kubernetes Operator Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Index APIs Alias Create or update alias Blocks Clear cache Clone index Open index Index exists Close index Create index Delete index Get index Shrink index Create or update index template Get index template Delete index template Simulate index templates Create or update mappings Create or update component template Dangling indexes Flush Force merge Recovery Get settings Update settings Scale Refresh index Resolve index Roll over index Segment Split index Stats Analyze API Analysis API Terminology CAT API CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster routing and awareness Cluster decommission Cluster health Cluster settings Cluster stats Count Document APIs Index document Get document Update document Delete document Reindex document Bulk Streaming bulk Multi-get document Delete by query Update by query Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) Explain Ingest APIs List API List shards List indices Multi-search Multi-search Template Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Profile Ranking evaluation Remote cluster information Script APIs Create or Update Stored Script Execute Painless stored script Get Stored Script Delete Script Get Stored Script Contexts Get Script Language Execute Painless script Scroll Search Search templates Snapshot APIs Register Snapshot Repository Get Snapshot Repository Delete Snapshot Repository Verify Snaphot Repository Create Snapshot Get Snapshot Delete Snapshot Get Snapshot Status Restore Snapshot Clone snapshot Cleanup Snapshot Repository Render Template Tasks API List tasks Get task Cancel tasks Validate Query Supported units Common REST Parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions \\u6682\\u65e0\\u76f8\\u5173\\u641c\\u7d22\\u7ed3\\u679c\\uff01 \\u672c\\u6587\\u6863\\u4f7f\\u7528 BookStack \\u6784\\u5efa \\u00d7 \\u5206\\u4eab\\uff0c\\u8ba9\\u77e5\\u8bc6\\u4f20\\u627f\\u66f4\\u4e45\\u8fdc \\u53d6\\u6d88\\u5206\\u4eab \\u00d7 \\u6587\\u7ae0\\u4e8c\\u7ef4\\u7801 \\u624b\\u673a\\u626b\\u4e00\\u626b\\uff0c\\u8f7b\\u677e\\u638c\\u4e0a\\u8bfb \\u5173\\u95ed \\u00d7 \\u6587\\u6863\\u4e0b\\u8f7d \\u666e\\u901a\\u4e0b\\u8f7d \\u4e0b\\u8f7d\\u7801\\u4e0b\\u8f7d(\\u514d\\u767b\\u5f55\\u65e0\\u9650\\u4e0b\\u8f7d) \\u4f60\\u4e0e\\u5927\\u795e\\u7684\\u8ddd\\u79bb\\uff0c\\u53ea\\u5dee\\u4e00\\u4e2aAPP \\u8bf7\\u4e0b\\u8f7d\\u60a8\\u9700\\u8981\\u7684\\u683c\\u5f0f\\u7684\\u6587\\u6863\\uff0c\\u968f\\u65f6\\u968f\\u5730\\uff0c\\u4eab\\u53d7\\u6c72\\u53d6\\u77e5\\u8bc6\\u7684\\u4e50\\u8da3\\uff01 PDF\\u6587\\u6863 EPUB\\u6587\\u6863 MOBI\\u6587\\u6863 \\u6e29\\u99a8\\u63d0\\u793a \\u6bcf\\u5929\\u6bcf\\u5728\\u7f51\\u7ad9\\u9605\\u8bfb\\u5b66\\u4e60\\u4e00\\u5206\\u949f\\u65f6\\u957f\\u53ef\\u4e0b\\u8f7d\\u4e00\\u672c\\u7535\\u5b50\\u4e66\\uff0c\\u6bcf\\u5929\\u8fde\\u7eed\\u7b7e\\u5230\\u53ef\\u589e\\u52a0\\u9605\\u8bfb\\u65f6\\u957f \\u4e0b\\u8f7d\\u7801\\u65b9\\u5f0f\\u4e0b\\u8f7d\\uff1a\\u514d\\u8d39\\u3001\\u514d\\u767b\\u5f55\\u3001\\u65e0\\u9650\\u5236\\u3002 \\u514d\\u8d39\\u83b7\\u53d6\\u4e0b\\u8f7d\\u7801 \\u4e0b\\u8f7d\\u7801 \\u6587\\u6863\\u683c\\u5f0f PDF EPUB MOBI \\u7801\\u4e0a\\u4e0b\\u8f7d \\u5173\\u95ed\\u7a97\\u53e3 \\u00d7 \\u5fae\\u4fe1\\u5c0f\\u7a0b\\u5e8f\\u9605\\u8bfb \\u60a8\\u4e0e\\u4ed6\\u4eba\\u7684\\u85aa\\u8d44\\u5dee\\u8ddd\\uff0c\\u53ea\\u5dee\\u4e00\\u4e2a\\u968f\\u65f6\\u968f\\u5730\\u5b66\\u4e60\\u7684\\u5c0f\\u7a0b\\u5e8f \\u5173\\u95ed\\u7a97\\u53e3 \\u00d7 \\u4e66\\u7b7e\\u5217\\u8868 \\u5173\\u95ed \\u00d7 \\u9605\\u8bfb\\u8bb0\\u5f55 \\u9605\\u8bfb\\u8fdb\\u5ea6: 0.00% ( 0/0 ) \\u91cd\\u7f6e\\u9605\\u8bfb\\u8fdb\\u5ea6 \\u5173\\u95ed \\u6b22\\u8fce\\u4f7f\\u7528\\u3010\\u7801\\u7075\\u85af\\u00b7CoderBot\\u3011 \\u7801\\u7075\\u85af\\u00b7CoderBot \\u5168\\u5c4f \\u7f29\\u5c0f \\u9690\\u85cf \\u65b0\\u6807\\u7b7e\\\"},{\\\"url\\\":\\\"https://opster.com/guides/opensearch/opensearch-basics/opensearch-circuit-breakers/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Product BUILT FOR ELASTICSEARCH AutoOps Prevent & resolve issues, cut down administration time & hardware costs. Community Tools Tools For The Community Check-Up, Search Log Analyzer & OpsGPT Resources Guides Technical guides on Elasticsearch & Opensearch Blog Insights, Opster news, blogs and more Documentation Opster product documentation Error Messages Error Repository About About Our story & vision Login AutoOps Login Contact Login Contact Running self-managed Elasticsearch just got easier. Announcing AutoOps for your clusters. Read the announcement \\ud83c\\udf89\\ud83c\\udf89 Opensearch Guides > OpenSearch Basics Elasticsearch OpenSearch Circuit Breakers By Opster Team Updated: Jun 19, 2024 | 2 min read Overview OpenSearch has the concept of circuit breakers to deal with OutOfMemory errors that cause nodes to crash. When a request reaches OpenSearch nodes, the circuit breakers first estimate the amount of memory needed to load the required data. They then compare the estimated size with the configured heap size limit. If the estimated size is greater than the heap size, the query is terminated and an exception is thrown to avoid the node loading more than the available heap size. What they are used for OpenSearch has several circuit breakers available such as fielddata, requests, network, indices and script compilation. Each breaker is used to limit the memory an operation can use. In addition, OpenSearch has a parent circuit breaker which is used to limit the combined memory used by all the other circuit breakers. Examples Increasing circuit breaker size for fielddata limit \\u2013 The default limit for fielddata breakers is 40%. The following command can be used to increase it to 60%: PUT /_cluster/settings\\\\n{\\\\n  \\\\\\\"persistent\\\\\\\": {\\\\n    \\\\\\\"indices.breaker.fielddata.limit\\\\\\\": \\\\\\\"60%\\\\\\\"\\\\n  }\\\\n} Notes Each breaker ships with default limits and their limits can be modified as well. But this is an expert level setting and you should understand the pitfalls carefully before changing the limits, otherwise the node may start throwing OOM exceptions. Sometimes it is better to fail a query instead of getting an OOM exception, because when OOM appears JVM becomes unresponsive. It is important to keep indices.breaker.request.limit lower than indices.breaker.total.limit so that request circuit breakers trip before the total circuit breaker. Common problems The most common error resulting from circuit breakers is \\u201cdata too large\\u201d with 429 status code. The application should be ready to handle such exceptions. If the application starts throwing exceptions because of circuit breaker limits, it is important to review the queries and memory requirements. In most cases, a scaling is required by adding more resources to the cluster. Check out this guide to learn more about OpenSearch circuit breaker exceptions and how to handle circuit breakers: https://opster.com/guides/opensearch/opensearch-basics/opensearch-circuit-breaker-exceptions-how-to-handle-circuit-breakers/ Additional notes Elasticsearch and OpenSearch are both powerful search and analytics engines, but Elasticsearch has several key advantages. Elasticsearch boasts a more mature and feature-rich development history, translating to a better user experience, more features, and continuous optimizations. Our testing has consistently shown that Elasticsearch delivers faster performance while using fewer compute resources than OpenSearch. Additionally, Elasticsearch\\u2019s comprehensive documentation and active community forums provide invaluable resources for troubleshooting and further optimization. Elastic, the company behind Elasticsearch, offers dedicated support, ensuring enterprise-grade reliability and performance. These factors collectively make Elasticsearch a more versatile, efficient, and dependable choice for organizations requiring sophisticated search and analytics capabilities. Related Articles How to Increase Primary Shard Count in Elasticsearch Elasticsearch Large Cluster State - How to Discover & Prevent BMC Launched a New Feature Based on OpenSearch Back to all articles Product AutoOps for Elasticsearch Community Tools Tools for the Community Company About Our Customers info@opster.com Resources Documentation Blog Guides Elasticsearch Error Messages Elasticsearch Log Errors Taking Care of Your Entire Search Operation. Opster\\u2019s solutions reduce the time and cost of running Elasticsearch. Get Improved performance & stability with less hardware. Contact Us \\u00a9 2025 Opster Privacy Policy Terms of Use We use cookies to ensure that we give you the best experience on our website. By continuing to browse this site, you agree to our Privacy Policy and Terms of Use. Agree Close GDPR Cookie Settings Privacy Overview Strictly Necessary Cookies Powered by GDPR Cookie Compliance Privacy Overview This website uses cookies so that we can provide you with the best user experience possible. Cookie information is stored in your browser and performs functions such as recognising you when you return to our website and helping our team to understand which sections of the website you find most interesting and useful. Strictly Necessary Cookies Strictly Necessary Cookie should be enabled at all times so that we can save your preferences for cookie settings. Enable or Disable Cookies Enabled Disabled Enable All Save Settings\\\"},{\\\"url\\\":\\\"https://www.antstack.com/blog/how-to-handle-the-circuit-breaker-exception-in-open-search/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Services UX & Design UI Engineering Application Development Application Modernization Data Engineering & Modernization AI Engineering Industries SME Healthcare QSR Media & Entertainment BFSI SaaS Logistics Case Studies Blogs About us Talk to us Somya Sharma 7 min read Dec 8, 2022 aws elasticsearch opensearch Subscribe to newsletter How to Handle the Circuit Breaker Exception in OpenSearch Summarize Chat GPT Perplexity Gemini Claude AI aws elasticsearch opensearch We had a search functionality requirement in one of the projects and that\\u2019s how I got to know about Amazon OpenSearch Service, It provides a quick, relevant search experience and makes it easier to add a search feature to your applications. The only hiccup is sizing the OpenSearch is a tricky and long-term process, and it often takes many iterations to make sure that you get the right specifications according to your workload. It also needs monitoring so as to be aware of future problems. You make an initial estimate of the resources, test them, and verify their performance. If the performance is not good, then you need to resize it and iterate. In this process, you often face many challenges. Some of them are listed below: Red / Yellow Cluster Status Exceeded maximum shard limit JVM OutOfMemoryError Failed cluster nodes While I was working with OpenSearch, I faced one such issue, which I will cover in this post. Our cluster was ready to go after going through the estimation process and performance testing, but after a while, we started seeing CircuitBreakerException in our logs. I find it difficult to understand, so I thought to write about it. I hope this blog helps you understand it better. Before we get into the topic, I would like to explain a little about clusters and nodes in OpenSearch. OpenSearch cluster is made up of one or more nodes, which are servers that handle search queries and store your data. As the cluster grows we can subdivide the responsibilities among different nodes(Master, Data, and more). Now, Let\\u2019s dive into the issue. What is a circuit breaker? In data nodes, 50 % of the available memory up to 32GB is used by the JVM heap and the rest is used for other operations. Circuit breakers are limitations put on a node to stop operations with the risk of resulting in JVM OutofMemoryError, which could cause the node to crash completely. The amount of memory each circuit breaker can utilize is specified. In response to requests, the breakers calculate how much memory the activity requires and compare the calculated size to the specified heap size limit. The query is aborted if the anticipated size exceeds the available heap size. In order to avoid overloading the node, a CircuitBreakerException is raised. Types of Circuit breakers There are many types of circuit breakers and a few of them are as follows: Parent circuit breaker - It specifies the maximum amount of memory that all breakers can utilize. If the combined memory utilization results in more than the specified limit the parent circuit exception will occur. It is configured using the below settings. indices.breaker.total.use_real_memory (default to true) - Determines whether the parent breaker should take real memory usage into account (true) or only consider the amount that is reserved by child circuit breakers (false). indices.breaker.total.limit (default - 95% of JVM heap) - Limit for overall parent breaker. If indices.breaker.total.use_real_memory is false then 70% JVM heap otherwise 95% of the JVM heap. Field Data circuit breaker - It is anticipated how much heap memory will be required to load a field into the field data cache. The circuit breaker terminates the operation and reports an error if loading the field will cause the cache to use more memory than was allowed. The field data cache contains field data (to allow text fields to be available for aggregations, sorting, and scripting) and global ordinals (It is an internal data structure used in elasticsearch for pre-computing and optimizing the performance of terms aggregations). indices.breaker.fielddata.limit - Limit for fielddata breaker. Defaults to 40% of the JVM heap. indices.breaker.fielddata.overhead - A constant (1.03) that all field data estimations are multiplied to determine a final estimation. Request circuit breaker - It is estimated how much heap memory will be required to process a request. It also includes the memory used for calculating aggregations during a request. If the memory usage is more than the limit, the request is terminated and an exception is raised. indices.breaker.request.limit - Defaults to 60% of the JVM heap. indices.breaker.request.overhead - A constant (1) that all request estimations are multiplied to determine a final estimation. In-flight requests circuit breaker - It is caused when the memory usage of all active incoming requests exceeds the configured threshold on a node. network.breaker.inflight_requests.limit - Defaults to 100% of JVM heap. This means that it is bound by the limit configured for the parent circuit breaker. network.breaker.inflight_requests.overhead - A constant (2) that is multiplied to determine a final estimation. Accounting circuit breaker - It is a limit to prevent items from using too much memory that isn\\u2019t released when a request is finished, such as Lucene segment memory. A segment is an inverted index. indices.breaker.accounting.limit - Limit for accounting breaker, defaults to 100% of JVM heap. This means that it is bound by the limit configured for the parent circuit breaker. indices.breaker.accounting.overhead - A constant (1) that is multiplied to determine a final estimation. Useful Commands GET /_nodes/stats/breaker To retrieve the current memory use per node and per breaker. GET _cat/nodes?v=true&h=id,r,ram,heap* To obtain information about heap and memory details per node. GET /_cluster/settings?include_defaults=true It will return explicitly defined and default setting in the cluster including breaker settings. GET _nodes/stats?filter_path=nodes..jvm.mem.pools.old To calculate the JVM memory pressure of each node. Use the response to calculate memory pressure as JVM Memory Pressure = used_in_bytes / max_in_bytes. Circuit Breaker Exception Example Above is an example of a circuit breaker error message which I had encountered while working with AWS OpenSearch Service. The error will result in a 429 status code. Let\\u2019s look into the error more closely and try to understand what is happening here. type - It specifies the type of the exception raised. reason - More detailed information about the reason which led to the mentioned exception. [parent] - It specifies that the parent circuit breaker exception has resulted in the error. The default parent circuit breaker setting is 95%. real usage - It defines the current heap usage. new bytes reserved - It specifies the number of new bytes required. limit of - It is the maximum memory allocation for the parent circuit breaker. If the real usage + new bytes reserved exceeds the limit of, the parent circuit breaker will be triggered. durability - It specifies if the issue that triggered the circuit breaker eventually resolves itself (TRANSIENT) or calls for manual intervention (PERMANENT). Suggestions Reduce JVM memory pressure - High JVM memory pressure often causes circuit breaker errors. Check the JVM memory pressure and try to reduce it using the following suggestions. Reduce the shard numbers of each index- For search latency workloads use a shard size between 10\\u201330 GiB. For write-heavy workloads use a shard size between 30\\u201350 GiB. On a given node, have no more than 20 shards per GiB of Java heap. Avoid searches that might be very expensive (Using large size in pagination). Enable slow logs for identifying expensive search queries. Aggregation, wildcards, and wide time ranges in your queries might also result in high JVM pressure. A mapping explosion, which consumes a lot of memory, might result from defining too many fields or nesting fields too deeply. Avoid sending a large number of requests at the same time or tuning bulk size according to your workload. Increase the cluster\\u2019s size to get an extra JVM heap to handle yours. Disable and avoid using fielddata as it can consume a large amount of heap space. Monitoring OpenSearch cluster metrics with Amazon CloudWatch and create alarms for various cluster metrics. Enable logs for better observability of the errors and issues. Innovate faster, and go farther with serverless-native application development. Explore limitless possibilities with AntStack's serverless solutions. Empowering your business to achieve your most audacious goals. Talk to us Author(s) Somya Sharma Backend Dev currently focusing on AWS Services, Algorithms, and Serverless Application Development. Tags aws elasticsearch opensearch Share this blog Subscribe to newsletter Your Digital Journey deserves a great story. Build one with us. Talk to us Recommended Blogs Krishna Muddi 6 min read Oct 20, 2025 Managing Roles and Permissions in Amazon OpenSearch with AWS SSO Oct 20, 2025 Krishna Muddi 5 min read Sep 15, 2025 Integrating Amazon OpenSearch with AWS SSO for Secure Authentication Sep 15, 2025 Jeevan Dongre 5 min read Jul 11, 2025 Why Your Menu API Is Slowing Down Your QSR Jul 11, 2025 Jeevan Dongre 6 min read Jun 12, 2025 The Hidden Cost of Status Quo: Why Healthcare CTOs Can't Afford to Delay Modernization Jun 12, 2025 Vishwasa Navada K 5 min read Jun 2, 2025 Comparison of LLM Prompt Caching: Cloudflare AI Gateway, Portkey, and Amazon Bedrock Jun 2, 2025 Jeevan Dongre 6 min read May 29, 2025 Breaking Through the 3 Major Roadblocks to Healthcare Modernization: The Serverless Way May 29, 2025 This website stores cookies on your computer. These cookies are used to collect information about how you interact with this website and allow us to remember you. We use this information to improve and customize your browsing experience, as well as for analytics. If you decline, your information won\\u2019t be tracked when you visit this website. A single cookie will be used in your browser to remember your preference. Decline Accept Services DesignUI EngineeringApplication DevelopmentApplication ModernizationData Engineering & ModernizationAI Engineering Industries Small and mid level enterprisesHealthcareQSRMedia & EntertainmentBFSISaaSLogistics Quick links BlogEventsCase StudiesGuidesTalksServerlessServerless ToolsServerless Architecture Company About usAntVerseCareersPrivacy PolicyBrand GuidelinesTrust Center Headquarters AntStack Inc. 8 The Green STE D, Dover, Kent, 19901, USA. +1 (650) 305-6238 Delivery Centre AntStack Technologies Private Limited #620, 3rd Floor, Dr Rajkumar Rd, 2nd Block, 1st Main, Rajajinagar, Bengaluru, Karnataka 560010 080-41330449 / +91-9353139419 Follow Subscribe to our newsletter Our bi-weekly newsletter delivers serverless, AI, tech trends, podcasts and blogs straight to your inbox. Subscribe \\u00a9 2019 - 2025 AntStack. All Rights Reserved.\\\"},{\\\"url\\\":\\\"https://forum.opensearch.org/t/opensearch-high-memory-usage-circuit-breaker-exceptions/26416\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"OpenSearch OpenSearch - High Memory usage / Circuit Breaker Exceptions OpenSearch troubleshoot aidevelop46 August 18, 2025, 9:46am 1 Versions (relevant - OpenSearch/Dashboard/Server OS/Browser): OpenSearch 2.11 Describe the issue: In my case, my cluster started triggering numerous circuit breaker exception alerts. More informations about my cluster/operation: In this case where the circuit_breaker occurred the document size was 3.57 KB. I have some documents bigger than this, but i dont think the average are \\u201ctoo big\\u201d. In this case where the circuit_breaker error occurred, the document contained neither nested nor parent-child. In my system we have several bulk requests, I also wouldn\\u2019t know how big these requests are and how many are occurring at the same time. Configuration: 6 Nodes with this current configuration showed in the image below Relevant Logs or Screenshots: image628\\u00d7850 138 KB Despite my limited experience with Elastic, I truly believe that the reason the cluster are triggering so many circuit_breaker requests has more to do with how I\\u2019m using Elastic than with my cluster\\u2019s configuration, which I think is \\u201cnormal/good.\\u201d I think the biggest problem is that Elastic is the single source of truth for my entire system. I don\\u2019t think Elastic is designed for that. This means I have thousands of read/write operations occurring simultaneously. Do you agree with this? Thanks for all! Leeroy August 18, 2025, 5:44pm 2 Hey @aidevelop46 , Looking at what you provided it looks that you\\u2019re using Elasticsearch? Could you confirm this? Ram usage being high might indicate that additional ram is required especially if you\\u2019re seeing issues with circuit_breaker or high heap usage. However it is hard to say much without first knowing more about the issue, so I first would like to ask a few questions. What version of Elasticsearch? Opensearch? are you using? Are you using roles? If so how many nodes of each are you using and what are their specs? - Creating a cluster - OpenSearch Documentation How many documents are you updating over say 15 minutes? Has this recently grown in number? Are updates being pushed in bulk? Bulk - OpenSearch Documentation Leeroy. Related topics Topic Replies Views Activity How to Solve Circuit Breaker Exception [Data too large] Performance Analyzer troubleshoot 6 22371 April 26, 2022 Circuit_breaking_exception error on kubernetes General Feedback 1 2015 January 3, 2020 Heap Memory Issues Open Source Elasticsearch and Kibana 6 4403 April 6, 2021 Essential Memory Metrics to monitor? DevOps troubleshoot 4 25 November 1, 2025 Parents circuit breaker tripping for the same node after upgrade to opensearch 2.16.0 OpenSearch troubleshoot , configure , upgrade 3 276 August 31, 2024 Home Categories Guidelines Terms of Service Privacy Policy Powered by Discourse, best viewed with JavaScript enabled\\\"},{\\\"url\\\":\\\"https://github.com/opensearch-project/OpenSearch/issues/12475\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to content Navigation Menu Toggle navigation Sign in Appearance settings Platform AI CODE CREATION GitHub CopilotWrite better code with AI GitHub SparkBuild and deploy intelligent apps GitHub ModelsManage and compare prompts MCP RegistryNewDiscover and integrate external tools DEVELOPER WORKFLOWS ActionsAutomate any workflow CodespacesInstant dev environments IssuesPlan and track work Code ReviewManage code changes APPLICATION SECURITY GitHub Advanced SecurityFind and fix vulnerabilities Code securitySecure your code as you build Secret protectionStop leaks before they start EXPLORE Why GitHub Documentation Blog Changelog Marketplace View all features Solutions BY COMPANY SIZE Enterprises Small and medium teams Startups Nonprofits BY USE CASE App Modernization DevSecOps DevOps CI/CD View all use cases BY INDUSTRY Healthcare Financial services Manufacturing Government View all industries View all solutions Resources EXPLORE BY TOPIC AI Software Development DevOps Security View all topics EXPLORE BY TYPE Customer stories Events & webinars Ebooks & reports Business insights GitHub Skills SUPPORT & SERVICES Documentation Customer support Community forum Trust center Partners Open Source COMMUNITY GitHub SponsorsFund open source developers PROGRAMS Security Lab Maintainer Community Accelerator Archive Program REPOSITORIES Topics Trending Collections Enterprise ENTERPRISE SOLUTIONS Enterprise platformAI-powered developer platform AVAILABLE ADD-ONS GitHub Advanced SecurityEnterprise-grade security features Copilot for BusinessEnterprise-grade AI features Premium SupportEnterprise-grade 24/7 support Pricing Search or jump to... Search code, repositories, users, issues, pull requests... Search Clear Search syntax tips Provide feedback We read every piece of feedback, and take your input very seriously. Include my email address so I can be contacted Cancel Submit feedback Saved searches Use saved searches to filter your results more quickly Name Query To see all available qualifiers, see our documentation. Cancel Create saved search Sign in Sign up Appearance settings Resetting focus You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert {{ message }} opensearch-project / OpenSearch Public Notifications You must be signed in to change notification settings Fork 2.3k Star 11.8k Code Issues 2.2k Pull requests 275 Actions Projects 3 Wiki Security Uh oh! There was an error while loading. Please reload this page. Insights Additional navigation options Code Issues Pull requests Actions Projects Wiki Security Insights [BUG] Circuit breaker exceptions due to misconfigured fielddata cache size and circuit breaker for fieldcache #12475 New issue Copy link New issue Copy link Open Open [BUG] Circuit breaker exceptions due to misconfigured fielddata cache size and circuit breaker for fieldcache#12475 Copy link Labels SearchSearch query, autocomplete ...etcSearch query, autocomplete ...etcSearch:ResiliencybugSomething isn't workingSomething isn't workinglucene Description vikasvb90 opened on Feb 27, 2024 Issue body actions Describe the bug We allow users to configure setting indices.breaker.fielddata.limit lesser than indices.fielddata.cache.size. If this happens and if fielddata cache is enabled on one or more fields then it is possible for fielddata cache to grow beyond fielddata breaker limit. This can happen if there is a sudden burst of heavy search queries which can fill up the cache with more field data than CB limit before circuit breaker starts kicking in. Due to this, subsequent search queries or aggregations on fielddata cache enabled fields will start failing with circuit breaker exceptions. [2024-02-25T09:00:44,638][DEBUG][o.o.a.s.TransportSearchAction] [f92acfa0c58f3643980f1cada9df945d] [l3F63B3JR0KY7qbJ5cyJAg][.opendistro-ism-config][1]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[.opendistro-ism-config], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, expand_wildcards_hidden=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], routing='null', preference='_shards:1|_primary', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=null, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={\\\\\\\"size\\\\\\\":100,\\\\\\\"query\\\\\\\":{\\\\\\\"match_all\\\\\\\":{\\\\\\\"boost\\\\\\\":1.0}},\\\\\\\"version\\\\\\\":true,\\\\\\\"seq_no_primary_term\\\\\\\":true,\\\\\\\"sort\\\\\\\":[{\\\\\\\"_id\\\\\\\":{\\\\\\\"order\\\\\\\":\\\\\\\"asc\\\\\\\",\\\\\\\"missing\\\\\\\":\\\\\\\"_last\\\\\\\",\\\\\\\"unmapped_type\\\\\\\":\\\\\\\"keyword\\\\\\\"}}],\\\\\\\"search_after\\\\\\\":[\\\\\\\"\\\\\\\"]}, cancelAfterTimeInterval=null, pipeline=null}] lastShard [true][2024-02-25T09:00:44,638][DEBUG][o.o.a.s.TransportSearchAction] [f92acfa0c58f3643980f1cada9df945d] #[org.opensearch.OpenSearchException,java.util.concurrent.ExecutionException,org.opensearch.core.common.breaker.CircuitBreakingException]#All shards failed for phase: [query]\\\\nOpenSearchException[java.util.concurrent.ExecutionException: CircuitBreakingException[[fielddata] Data too large, data for [_id] would be [3469348057/3.2gb], which is larger than the limit of [515396075/491.5mb]]]; nested: ExecutionException[CircuitBreakingException[[fielddata] Data too large, data for [_id] would be [3469348057/3.2gb], which is larger than the limit of [515396075/491.5mb]]]; nested: CircuitBreakingException[[fielddata] Data too large, data for [_id] would be [3469348057/3.2gb], which is larger than the limit of [515396075/491.5mb]];\\\\n        at org.opensearch.index.fielddata.plain.AbstractIndexOrdinalsFieldData.load(AbstractIndexOrdinalsFieldData.java:116)\\\\n        at org.opensearch.index.fielddata.plain.AbstractIndexOrdinalsFieldData.load(AbstractIndexOrdinalsFieldData.java:62)\\\\n        at org.opensearch.index.mapper.IdFieldMapper$IdFieldType$1$1.load(IdFieldMapper.java:209)\\\\n        at org.opensearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource.getValues(BytesRefFieldComparatorSource.java:91)\\\\n        at org.opensearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$2.getBinaryDocValues(BytesRefFieldComparatorSource.java:141)\\\\n        at org.apache.lucene.search.FieldComparator$TermValComparator.getLeafComparator(FieldComparator.java:280)\\\\n        at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:176)\\\\n        at org.apache.lucene.search.TopFieldCollector$TopFieldLeafCollector.<init>(TopFieldCollector.java:64)\\\\n        at org.apache.lucene.search.TopFieldCollector$PagingFieldCollector$1.<init>(TopFieldCollector.java:254)\\\\n        at org.apache.lucene.search.TopFieldCollector$PagingFieldCollector.getLeafCollector(TopFieldCollector.java:254)\\\\n        at org.opensearch.search.internal.ContextIndexSearcher.searchLeaf(ContextIndexSearcher.java:306)\\\\n        at org.opensearch.search.internal.ContextIndexSearcher.search(ContextIndexSearcher.java:281)\\\\n        at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:551)\\\\n        at org.opensearch.search.query.QueryPhase.searchWithCollector(QueryPhase.java:360)\\\\n        at org.opensearch.search.query.QueryPhase$DefaultQueryPhaseSearcher.searchWithCollector(QueryPhase.java:447)\\\\n        at org.opensearch.search.query.QueryPhase$DefaultQueryPhaseSearcher.searchWith(QueryPhase.java:431)\\\\n        at org.opensearch.search.query.QueryPhaseSearcherWrapper.searchWith(QueryPhaseSearcherWrapper.java:65)\\\\n        at org.opensearch.neuralsearch.search.query.HybridQueryPhaseSearcher.searchWith(HybridQueryPhaseSearcher.java:66)\\\\n        at org.opensearch.search.query.QueryPhase.executeInternal(QueryPhase.java:282)\\\\n        at org.opensearch.search.query.QueryPhase.execute(QueryPhase.java:155)\\\\n        at org.opensearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:533)\\\\n        at org.opensearch.search.SearchService.executeQueryPhase(SearchService.java:597)\\\\n        at org.opensearch.search.SearchService$2.lambda$onResponse$0(SearchService.java:566)\\\\n        at org.opensearch.action.ActionRunnable.lambda$supply$0(ActionRunnable.java:74)\\\\n        at org.opensearch.action.ActionRunnable$2.doRun(ActionRunnable.java:89)\\\\n        at org.opensearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:917)\\\\n        at org.opensearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:52)\\\\n        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\\\\n        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\\\\n        at java.base/java.lang.Thread.run(Thread.java:833)\\\\n Related component Search:Resiliency To Reproduce One way to potentially reproduce this is Create an index with field data cache enabled on some of the text value fields. Ingest data till field data cache reaches (say 20%). Use GET /_cat/fielddata for monitoring. Set breaker limit to 1%. Execute heavy search queries (resulting in >1% of data size) on fields with field data cache enabled. Expected behavior A validation should be added in OpenSearch to reject update setting request if indices.breaker.fielddata.limit is less than indices.fielddata.cache.size. Default value of indices.breaker.fielddata.limit is 40% of JVM and default cache size is unbounded. We should also consider setting the default cache size to be less than default breaker limit (say 38%). Additional Details Plugins Please list all plugins currently enabled. Screenshots If applicable, add screenshots to help explain your problem. Host/Environment (please complete the following information): OS: [e.g. iOS] Version [e.g. 22] Additional context Add any other context about the problem here. Metadata Metadata Assignees No one assigned Labels SearchSearch query, autocomplete ...etcSearch query, autocomplete ...etcSearch:ResiliencybugSomething isn't workingSomething isn't workinglucene Type No type Projects Search Project Board Status Later (6 months plus) Show more project fields Milestone No milestone Relationships None yet Development No branches or pull requests Issue actions Footer \\u00a9 2025 GitHub, Inc. Footer navigation Terms Privacy Security Status Community Docs Contact Manage cookies Do not share my personal information You can\\u2019t perform that action at this time.\\\"}]}\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "üîß Troubleshooting Information:\n",
      "{\n",
      "  \"inference_results\": [\n",
      "    {\n",
      "      \"output\": [\n",
      "        {\n",
      "          \"name\": \"response\",\n",
      "          \"result\": \"{\\\"next_page\\\":\\\"https://duckduckgo.com/html?q=How+to+fix+circuit+breaker+errors+in+OpenSearch&s=10&nextParams=&v=l&o=json&dc=11&api=d.js&vqd=4-81341745925542226748053961715693796901&kl=wt-wt\\\",\\\"items\\\":[{\\\"url\\\":\\\"https://opster.com/guides/opensearch/opensearch-basics/opensearch-circuit-breaker-exceptions-how-to-handle-circuit-breakers/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Product BUILT FOR ELASTICSEARCH AutoOps Prevent & resolve issues, cut down administration time & hardware costs. Community Tools Tools For The Community Check-Up, Search Log Analyzer & OpsGPT Resources Guides Technical guides on Elasticsearch & Opensearch Blog Insights, Opster news, blogs and more Documentation Opster product documentation Error Messages Error Repository About About Our story & vision Login AutoOps Login Contact Login Contact Running self-managed Elasticsearch just got easier. Announcing AutoOps for your clusters. Read the announcement \\ud83c\\udf89\\ud83c\\udf89 Opensearch Guides > OpenSearch Basics Elasticsearch OpenSearch Circuit Breaker Exceptions: How to Handle Circuit Breakers By Opster Team Updated: Jun 19, 2024 | 4 min read Quick links What are circuit breakers? Finding out your current circuit breaker status Fielddata circuit breaker Request circuit breaker Inflight requests circuit breaker Script compilation circuit breaker Parent circuit breakers Accounting circuit breakers Adjusting circuit breakers What are circuit breakers? 50% of memory on an OpenSearch node is generally used for the JVM (Java Virtual Machine) heap, while the other half of the memory is used for other requirements such as cache. In order to prevent \\u201cOut of Memory\\u201d (OOM) errors, OpenSearch implements circuit breakers. If a certain request could cause errors in the node because of memory issues, OpenSearch will throw a \\u201cCircuitBreakerException\\u201d and reject the request rather than risk crashing the entire node. A circuit breaker exception is usually an exception that is thrown to alert us of something else that needs to be fixed to reduce memory usage. Circuit breakers generally come with sensible defaults. Simply increasing the circuit breaking limit is likely to increase the risk that your node crashes due to an OutOfMemoryError. If you get a circuit breaking exception, you should check what type of circuit breaker it is, and then look at your monitoring data and OpenSearch logs to diagnose what caused it. Remember that the event or query that appears in the log may just be the \\u201cstraw that broke the camel\\u2019s back\\u201d. There may be other causes of high memory usage, and the event in the log is just the very last one which pushed OpenSearch over the limit. Possible causes are discussed in each section below. Finding out your current circuit breaker status Get your current settings GET /_cluster/settings?include_defaults=true Find out your current memory usage and breakers GET _nodes/stats/breaker This will return useful information like this \\\\\\\"breakers\\\\\\\" : {\\\\n    \\\\t\\\\\\\"request\\\\\\\" : {\\\\n      \\\\t\\\\\\\"limit_size_in_bytes\\\\\\\" : 20574004838,\\\\n      \\\\t\\\\\\\"limit_size\\\\\\\" : \\\\\\\"19.1gb\\\\\\\",\\\\n      \\\\t\\\\\\\"estimated_size_in_bytes\\\\\\\" : 0,\\\\n      \\\\t\\\\\\\"estimated_size\\\\\\\" : \\\\\\\"0b\\\\\\\",\\\\n      \\\\t\\\\\\\"overhead\\\\\\\" : 1.0,\\\\n      \\\\t\\\\\\\"tripped\\\\\\\" : 0\\\\n    \\\\t},\\\\n    \\\\t\\\\\\\"fielddata\\\\\\\" : {\\\\n      \\\\t\\\\\\\"limit_size_in_bytes\\\\\\\" : 13716003225,\\\\n      \\\\t\\\\\\\"limit_size\\\\\\\" : \\\\\\\"12.7gb\\\\\\\",\\\\n      \\\\t\\\\\\\"estimated_size_in_bytes\\\\\\\" : 0,\\\\n      \\\\t\\\\\\\"estimated_size\\\\\\\" : \\\\\\\"0b\\\\\\\",\\\\n      \\\\t\\\\\\\"overhead\\\\\\\" : 1.03,\\\\n      \\\\t\\\\\\\"tripped\\\\\\\" : 0\\\\n    \\\\t},\\\\n    \\\\t\\\\\\\"in_flight_requests\\\\\\\" : {\\\\n      \\\\t\\\\\\\"limit_size_in_bytes\\\\\\\" : 34290008064,\\\\n      \\\\t\\\\\\\"limit_size\\\\\\\" : \\\\\\\"31.9gb\\\\\\\",\\\\n      \\\\t\\\\\\\"estimated_size_in_bytes\\\\\\\" : 6254164,\\\\n      \\\\t\\\\\\\"estimated_size\\\\\\\" : \\\\\\\"5.9mb\\\\\\\",\\\\n      \\\\t\\\\\\\"overhead\\\\\\\" : 2.0,\\\\n      \\\\t\\\\\\\"tripped\\\\\\\" : 0\\\\n    \\\\t},\\\\n    \\\\t\\\\\\\"accounting\\\\\\\" : {\\\\n      \\\\t\\\\\\\"limit_size_in_bytes\\\\\\\" : 34290008064,\\\\n      \\\\t\\\\\\\"limit_size\\\\\\\" : \\\\\\\"31.9gb\\\\\\\",\\\\n      \\\\t\\\\\\\"estimated_size_in_bytes\\\\\\\" : 282771278,\\\\n      \\\\t\\\\\\\"estimated_size\\\\\\\" : \\\\\\\"269.6mb\\\\\\\",\\\\n      \\\\t\\\\\\\"overhead\\\\\\\" : 1.0,\\\\n      \\\\t\\\\\\\"tripped\\\\\\\" : 0\\\\n    \\\\t},\\\\n    \\\\t\\\\\\\"parent\\\\\\\" : {\\\\n      \\\\t\\\\\\\"limit_size_in_bytes\\\\\\\" : 32575507660,\\\\n      \\\\t\\\\\\\"limit_size\\\\\\\" : \\\\\\\"30.3gb\\\\\\\",\\\\n      \\\\t\\\\\\\"estimated_size_in_bytes\\\\\\\" : 13431618584,\\\\n      \\\\t\\\\\\\"estimated_size\\\\\\\" : \\\\\\\"12.5gb\\\\\\\",\\\\n      \\\\t\\\\\\\"overhead\\\\\\\" : 1.0,\\\\n      \\\\t\\\\\\\"tripped\\\\\\\" : 0\\\\n    \\\\t}\\\\n  \\\\t} Fielddata circuit breaker indices.breaker.fielddata.limit (default=40% JVM heap) indices.breaker.fielddata.overhead (default=1.03) The limit is set as a proportion of the JVM heap set in jvm.options, while the \\u201coverhead\\u201d setting is a fixed ratio which OpenSearch uses to multiply the theoretical calculations to estimate the circuit breaker memory requirement. Fielddata circuit breaker is a limit on the total amount of memory used by fielddata in your indices. Fielddata is by default set to false on a text field, but may be used where you have defined it in one of your mappings: \\\\\\\"fielddata\\\\\\\": true In general it is recommended to avoid this setting because of the large amount of memory required in putting individual text values into memory. If possible you should change your mappings to set it to false, and use keyword type mappings rather than text type for aggregations and sorting. However, if this is not possible and you need to aggregate based on individual terms in a text rather than keywords, then you could also consider setting a fielddata frequency filter on the mapping to limit the amount of fielddata put into memory. PUT my-index-000001\\\\n{\\\\n  \\\\\\\"mappings\\\\\\\": {\\\\n    \\\\\\\"properties\\\\\\\": {\\\\n      \\\\\\\"need_to_aggregate_individual_terms_on_this_field\\\\\\\": {\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"text\\\\\\\",\\\\n        \\\\\\\"fielddata\\\\\\\": true,\\\\n        \\\\\\\"fielddata_frequency_filter\\\\\\\": {\\\\n          \\\\\\\"min\\\\\\\": 0.001,\\\\n          \\\\\\\"max\\\\\\\": 0.1,\\\\n          \\\\\\\"min_segment_size\\\\\\\": 500\\\\n        }\\\\n      }\\\\n    }\\\\n  }\\\\n} Request circuit breaker indices.breaker.request.limit(default=60% JVM heap) indices.breaker.request.overhead(default=1) The limit is set as a proportion of the JVM heap set in jvm.options, while the \\u201coverhead\\u201d setting is a fixed ratio which OpenSearch uses to multiply the theoretical calculations to estimate the circuit breaker memory requirement. The request circuit breaker takes into account the memory required based on the request structures, in particular aggregations. The most common cause of exceeding this circuit breaker is through the use of aggregations with a large size value. Try reducing the value of \\u201csize\\u201d in your aggregations. Inflight requests circuit breaker network.breaker.inflight_requests.limit (default=100% JVM heap) network.breaker.inflight_requests.overhead (default=2) The limit is set as a proportion of the JVM heap set in jvm.options, while the \\u201coverhead\\u201d setting is a fixed ratio which OpenSearch uses to multiply the theoretical calculations to estimate the circuit breaker memory requirement. The in-flight requests circuit breaker considers the size of active transport and http requests for the node based on the byte size of those requests. Generally this circuit breaker is activated when batch sizes for bulk requests are too large. Try reducing the size of bulk requests, particularly if those requests contain large documents. Script compilation circuit breaker script.context.$CONTEXT.max_compilations_rate (default=75/5m) The script compilation circuit breaker is slightly different from the others. Rather than applying a memory limit, it limits the number of times a script can be compiled in a given period. If you get this warning, you should use stored scripts with parameters instead of inline ones, as the former are compiled only once, while the latter are compiled on each execution. Parent circuit breakers indices.breaker.total.use_real_memory default=true indices.breaker.total.limit default=95% JVM heap Parent circuit breaker exceptions are caused by the sum of all memory being used across the different types of circuit breakers. If the use_real_memory is left as the default, then the parent circuit breaker will take into account real memory usage and will be based upon 95% of the JVM heap size. In general it is better to base this circuit upon real memory usage since it gives you a more accurate picture of what is going on in the instance. On the other hand if you choose to set \\u201cuse_real_memory\\u201d to false, then the limit will be based on the sum of the estimates of other circuit breakers in which case the default limit will be reduced to 70% of the JVM heap size to take into account the margin or error with using a sum of estimates. Accounting circuit breakers indices.breaker.accounting.limit default= 100% of JVM heap indices.breaker.accounting.overhead default=1 This circuit breaker is to protect the node from over usage of memory due to things that persist in memory after a request has completed, such as lucene segments before they are flushed to disk. The default limit is however set at 100% of JVM heap so the parent circuit breaker will trip before this limit becomes effective. The accounting overhead setting is a coefficient which is used to multiply all estimates before applying the limit. Adjusting circuit breakers In general, and as warned above, it is usually not advisable to modify circuit breakers from their defaults, since it is far worse to lose a node from an OutOfMemoryError than to drop a few requests. Instead you should try to understand why you are exceeding them and prevent this from happening. Also bear in mind that the default calculations are based on your JVM heap size which is generally assumed to be 50% of the total available size. If this is not the case, then you may want to re-consider setting the JVM settings in jvm.options before reconfiguring everything else. However if you still think you need to modify the circuit breakers (or restore the defaults), you can adjust circuit breaker settings just like any other cluster settings PUT _cluster/settings\\\\n{\\\\n  \\\\\\\"transient\\\\\\\": {\\\\\\\"indices.breaker.total.limit\\\\\\\":\\\\\\\"5GB\\\\\\\" }\\\\n} Or to restore the setting to it\\u2019s default PUT _cluster/settings\\\\n{\\\\n  \\\\\\\"transient\\\\\\\": {\\\\\\\"indices.breaker.total.limit\\\\\\\":null }\\\\n} Additional notes Elasticsearch and OpenSearch are both powerful search and analytics engines, but Elasticsearch has several key advantages. Elasticsearch boasts a more mature and feature-rich development history, translating to a better user experience, more features, and continuous optimizations. Our testing has consistently shown that Elasticsearch delivers faster performance while using fewer compute resources than OpenSearch. Additionally, Elasticsearch\\u2019s comprehensive documentation and active community forums provide invaluable resources for troubleshooting and further optimization. Elastic, the company behind Elasticsearch, offers dedicated support, ensuring enterprise-grade reliability and performance. These factors collectively make Elasticsearch a more versatile, efficient, and dependable choice for organizations requiring sophisticated search and analytics capabilities. Related Articles How to Easily Upgrade Elasticsearch Versions How to Handle Recurring RED Status Backblaze Optimized OpenSearch Back to all articles Product AutoOps for Elasticsearch Community Tools Tools for the Community Company About Our Customers info@opster.com Resources Documentation Blog Guides Elasticsearch Error Messages Elasticsearch Log Errors Taking Care of Your Entire Search Operation. Opster\\u2019s solutions reduce the time and cost of running Elasticsearch. Get Improved performance & stability with less hardware. Contact Us \\u00a9 2025 Opster Privacy Policy Terms of Use We use cookies to ensure that we give you the best experience on our website. By continuing to browse this site, you agree to our Privacy Policy and Terms of Use. Agree Close GDPR Cookie Settings Privacy Overview Strictly Necessary Cookies Powered by GDPR Cookie Compliance Privacy Overview This website uses cookies so that we can provide you with the best user experience possible. Cookie information is stored in your browser and performs functions such as recognising you when you return to our website and helping our team to understand which sections of the website you find most interesting and useful. Strictly Necessary Cookies Strictly Necessary Cookie should be enabled at all times so that we can save your preferences for cookie settings. Enable or Disable Cookies Enabled Disabled Enable All Save Settings\\\"},{\\\"url\\\":\\\"https://docs.opensearch.org/latest/install-and-configure/configuring-opensearch/circuit-breaker/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Regular expression syntax Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Using UBI in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Configuring OpenSearch Circuit breaker settings Circuit breaker settings Circuit breakers prevent OpenSearch from causing a Java OutOfMemoryError. The parent circuit breaker specifies the total available amount of memory for all child circuit breakers. The child circuit breakers specify the total available amount of memory for themselves. To learn more about static and dynamic settings, see Configuring OpenSearch. Parent circuit breaker settings OpenSearch supports the following parent circuit breaker settings: indices.breaker.total.use_real_memory (Static, Boolean): If true, the parent circuit breaker considers the actual memory usage. Otherwise, the parent circuit breaker considers the amount of memory reserved by the child circuit breakers. Default is true. indices.breaker.total.limit (Dynamic, percentage): Specifies the initial memory limit for the parent circuit breaker. If indices.breaker.total.use_real_memory is true, defaults to 95% of the JVM heap. If indices.breaker.total.use_real_memory is false, defaults to 70% of the JVM heap. Field data circuit breaker settings The field data circuit breaker limits the heap memory required to load a field into the field data cache. OpenSearch supports the following field data circuit breaker settings: indices.breaker.fielddata.limit (Dynamic, percentage): Specifies the memory limit for the field data circuit breaker. Default is 40% of the JVM heap. indices.breaker.fielddata.overhead (Dynamic, double): A constant by which the field data estimations are multiplied to determine the final estimation. Default is 1.03. Request circuit breaker settings The request circuit breaker limits the memory required to build data structures that are needed for a request (for example, when calculating aggregations). OpenSearch supports the following request circuit breaker settings: indices.breaker.request.limit (Dynamic, percentage): Specifies the memory limit for the request circuit breaker. Default is 60% of the JVM heap. indices.breaker.request.overhead (Dynamic, double): A constant by which the request estimations are multiplied to determine the final estimation. Default is 1. In-flight request circuit breaker settings The in-flight request circuit breaker limits the memory usage for all currently running incoming requests on transport and HTTP level. The memory usage for a request is based on the content length of the request and includes memory needed for the raw request and a structured object representing the request. OpenSearch supports the following in-flight request circuit breaker settings: network.breaker.inflight_requests.limit (Dynamic, percentage): Specifies the memory limit for the in-flight request circuit breaker. Default is 100% of JVM heap (thus, the memory usage limit for an in-flight request is determined by the memory limit of the parent circuit breaker). network.breaker.inflight_requests.overhead (Dynamic, double): A constant by which the in-flight request estimations are multiplied to determine the final estimation. Default is 2. Script compilation circuit breaker settings The script compilation circuit breaker limits the number of inline script compilations within a time interval. OpenSearch supports the following script compilation circuit breaker setting: script.max_compilations_rate (Dynamic, rate): The maximum number of unique dynamic scripts compiled within a time interval for a given context. Default is 150 every 5 minutes (150/5m). Regular expression circuit breaker settings The regular expression circuit breaker enables or disables regular expressions and limits their complexity. OpenSearch supports the following regular expression circuit breaker settings: script.painless.regex.enabled (Static, string): Enables regular expressions in Painless scripts. Valid values are: limited: Enables regular expressions and limits their complexity using the script.painless.regex.limit-factor setting. true: Enables regular expressions. Turns off the regular expression circuit breaker and does not limit regular expression complexity. false: Disables regular expressions. If a Painless script contains a regular expression, it returns an error. Default is limited. script.painless.regex.limit-factor (Static, integer): Applied only if script.painless.regex.enabled is set to limited. Limits the number of characters a regular expression in a Painless script. The character limit is calculated by multiplying the number of characters in the script input by script.painless.regex.limit-factor. Default is 6 (thus, if the input has 5 characters, the maximum number of characters in a regular expression is 5 \\u00b7 6 = 30). Parent circuit breaker settings Field data circuit breaker settings Request circuit breaker settings In-flight request circuit breaker settings Script compilation circuit breaker settings Regular expression circuit breaker settings WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright \\u00a9 OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\\\"},{\\\"url\\\":\\\"https://repost.aws/knowledge-center/opensearch-circuit-breaker-exception\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to content By using AWS re:Post, you agree to the AWS re:Post Terms of Use re:Post Search About re:Post English EnglishDeutschEspa\\u00f1olFran\\u00e7aisItaliano\\u65e5\\u672c\\u8a9e\\ud55c\\uad6d\\uc5b4Portugu\\u00eas\\u4e2d\\u6587 (\\u7b80\\u4f53)\\u4e2d\\u6587 (\\u7e41\\u9ad4) Resources Sign in Home Questions Knowledge Center Articles Selections Tags Topics Community Groups AWS Support Official AWS Trust & Safety Center Ask question / How do I troubleshoot a circuit breaker exception in OpenSearch Service?lg.../ How do I troubleshoot a circuit breaker exception in OpenSearch Service? 6 minute read 1 I want to send data to my Amazon OpenSearch Service cluster. However, I receive a circuit breaking exception error that states that my data is too large. Short description When a request reaches OpenSearch Service nodes, circuit breakers estimate the amount of memory required to load the data. OpenSearch Service then compares the estimated size with the configured heap size quota. If the estimated size of the data is greater than the available heap size, then OpenSearch Service terminates the query. To prevent overloading the node, OpenSearch Service shows a CircuitBreakerException error. To resolve circuit breaking exception errors, first identify the circuit breaking exemption. Then, to reduce the load on your data nodes in the future, reduce high Java virtual machine (JVM) pressure. Resolution Identify the circuit breaking exemption OpenSearch Service uses the following circuit breakers to prevent JVM OutofMemoryError exceptions: Request Field data In flight requests Accounting Parent Important: Identify each of the five circuit breakers that raises the exception. Each circuit breaker has its own tuning needs. For more information about circuit breaker types, see Circuit breaker settings on the Elasticsearch website. To get the current memory usage per node and per breaker, run the following command: GET _nodes/stats/breaker Note that circuit breakers are a best-effort mechanism. Circuit breakers provide limited resiliency against overloading nodes. However, you might still receive an OutOfMemoryError. Circuit breakers can track memory only if it's explicitly reserved. It's not always possible to estimate the exact memory usage in advance. For example, if you have a small amount of memory heap, then the relative overhead of untracked memory is larger. For more information about circuit breakers and node resiliency, see Improving node resiliency with the real memory circuit breaker on the Elasticsearch website. If you reach the circuit breaker quota and use Elasticsearch version 7.x or higher with 16 GB of heap, then you receive the following error: {\\\\n    \\\\\\\"error\\\\\\\": {\\\\n\\\\n        \\\\\\\"root_cause\\\\\\\": [{\\\\n\\\\n            \\\\\\\"type\\\\\\\": \\\\\\\"circuit_breaking_exception\\\\\\\",\\\\n\\\\n            \\\\\\\"reason\\\\\\\": \\\\\\\"[parent] Data too large, data for [<http_request>] would be [16355096754/15.2gb], which is larger than the limit of [16213167308/15gb]\\\\\\\",\\\\n\\\\n            \\\\\\\"bytes_wanted\\\\\\\": 16355096754,\\\\n\\\\n            \\\\\\\"bytes_limit\\\\\\\": 16213167308\\\\n\\\\n        }],\\\\n\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"circuit_breaking_exception\\\\\\\",\\\\n\\\\n        \\\\\\\"reason\\\\\\\": \\\\\\\"[parent] Data too large, data for [<http_request>] would be [16355096754/15.2gb], which is larger than the limit of [16213167308/15gb]\\\\\\\",\\\\n\\\\n        \\\\\\\"bytes_wanted\\\\\\\": 16355096754,\\\\n\\\\n        \\\\\\\"bytes_limit\\\\\\\": 16213167308\\\\n\\\\n    },\\\\n\\\\n    \\\\\\\"status\\\\\\\": 503\\\\n\\\\n} The preceding example output shows that the data is too large for the parent circuit breaker to process. The parent circuit breaker manages the overall memory usage of your cluster. When a parent circuit breaker exception occurs, the total memory used across all circuit breakers exceeds the set limit. A parent breaker throws an exception when the cluster exceeds 95% of 16 GB (15.2 GB of heap). To verify the logic, calculate the difference between memory usage and set circuit breaker limit. That is, with this example output, subtract the real usage of [15283269136/14.2gb] from the limit of [16213167308/15gb]. The example request needs 1.02 GB of new bytes reserved memory to process the request. However, the cluster has less than 0.8 GB of available free memory heap when the data request is received. As a result, the circuit breaker trips. To interpret the circuit breaker exception message, use the following guidelines: data for [<http_request>]: The client sends an HTTP request to a node in your cluster. OpenSearch Service either processes the request locally or passes it to another node for additional processing. would be [#]: The heap size when the request is processed. limit of [#]: The current circuit breaker limit. real usage: The actual use of the JVM heap. new bytes reserved: The actual memory needed to process the request. Reduce high JVM memory pressure High JVM pressure often causes circuit breaking exemptions. JVM memory pressure is the percentage of Java heap that all data nodes in your cluster use. Check the JVMMemoryPressure metric in Amazon CloudWatch to determine your current usage. Note: The JVM heap size of a data node is set to half the size of physical memory (RAM) per node, up to 32 GB. For example, if the physical memory is 30 GB per node, then the heap size is 15 GB. If the physical memory is 128 GB per node, then the heap size is 32 GB. To resolve high JVM memory pressure, take one or more of the following actions: Reduce incoming traffic to your cluster, especially if you have a heavy workload. An increase in the number of requests to the cluster can cause high JVM pressure. Check the IndexRate and SearchRate metrics in CloudWatch to determine your current load. Scale the cluster to get more JVM memory to support your workload. If you can't scale the cluster, then delete old or unused indices to reduce the number of shards. Shard metadata is stored in memory. When you reduce the number of shards, you reduce the overall memory usage. To identify faulty requests, turn on slow logs. Note: Before you make configuration changes, to avoid additional overhead to existing resources, verify that JVM memory pressure is below 85%. Optimize search and indexing requests, and choose the correct number of shards for your use case. Unbalanced shard allocation across nodes or too many shards in a cluster can cause high JVM pressure. For more information about indexing and shard count, see Get started with Amazon OpenSearch Service: How many shards do I need? Turn off and don't use the fielddata data structure to query data. By default, fielddata is set to false on a text field unless explicitly defined otherwise in index mappings. Fielddata can consume a large amount of heap space, and remains in the heap for the lifetime of a segment. As a result, when you use fielddata, JVM memory pressure remains high on the cluster. For more information, see fielddata on the Elasticsearch website. Change your index type to a keyword. For more information, see Reindex API or Create or update index template API on the Elasticsearch website. You can use the keyword type as an alternative to aggregations and sorting on text fields. To prevent increases in field data, avoid aggregating on text fields. When you use more field data, you consume more heap space. Use the cluster stats API operation on the Elasticsearch website to check your field data. Remove aggregation, wildcards, and wide time ranges from your queries. Clear the fielddata cache. Run the following API call: POST /index_name/_cache/clear?fielddata=true (index-level cache)POST */_cache/clear?fielddata=true (cluster-level cache) Important: If you clear the fielddata cache, then you might disrupt in-progress queries. For more information, see How do I troubleshoot high JVM memory pressure on my OpenSearch Service cluster? Related information Operational best practices for Amazon OpenSearch Service How can I improve the indexing performance on my Amazon OpenSearch Service cluster? Follow Share Topics Analytics Tags Amazon OpenSearch Service Language English AWS OFFICIALUpdated a year ago No comments Comment on this article Clear Post comment Relevant content resetting knn circuit breaker triggered Accepted Answer iamlmt asked 2 years ago Error deploying service: ECS Deployment Circuit Breaker was triggered Accepted Answer mertt asked 2 years ago Always this errorECS Deployment Circuit Breaker was triggered Accepted Answer Orlando Parra asked 2 years ago Error occurred during operation 'ECS Deployment Circuit Breaker was triggered rePost-User-3108449 asked 2 years ago ECS Circuit Breaker is not preventing deployment loop Sam asked 10 months ago Why did the Amazon ECS deployment circuit breaker set my deployment state to FAILED? AWS OFFICIALUpdated 9 months ago Why is OpenSearch Dashboards in red status on my Amazon OpenSearch Service domain? AWS OFFICIALUpdated 2 years ago How do I configure and monitor the Amazon ECS deployment circuit breaker? AWS OFFICIALUpdated a year ago How do I troubleshoot high JVM memory pressure on my OpenSearch Service cluster? AWS OFFICIALUpdated 3 months ago ECS Deployment Circuit Breaker was triggered. EXPERT Chethangowda B C published 7 months ago FEEDBACK Privacy| Site Terms| Cookie Preferences | Sitemap| Legal| \\u00a9 2025, Amazon Web Services, Inc. or its affiliates. All rights reserved. Community Guidelines\\\"},{\\\"url\\\":\\\"https://medium.com/@antstack/how-to-handle-the-circuit-breaker-exception-in-opensearch-be1872ed98ac\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Sitemap Open in app Sign up Sign in Medium Logo Write Search Sign up Sign in Press enter or click to view image in full size How to Handle the Circuit Breaker Exception in OpenSearch AntStack Inc. 6 min read \\u00b7 Nov 11, 2024 -- Listen Share We had a search functionality requirement in one of the projects and that\\u2019s how I got to know about Amazon OpenSearch Service, It provides a quick, relevant search experience and makes it easier to add a search feature to your applications. The only hiccup is sizing the OpenSearch is a tricky and long-term process, and it often takes many iterations to make sure that you get the right specifications according to your workload. It also needs monitoring so as to be aware of future problems. You make an initial estimate of the resources, test them, and verify their performance. If the performance is not good, then you need to resize it and iterate. In this process, you often face many challenges. Some of them are listed below: Red / Yellow Cluster Status Exceeded maximum shard limit JVM OutOfMemoryError Failed cluster nodes While I was working with OpenSearch, I faced one such issue, which I will cover in this post. Our cluster was ready to go after going through the estimation process and performance testing, but after a while, we started seeing CircuitBreakerException in our logs. I find it difficult to understand, so I thought to write about it. I hope this blog helps you understand it better. Before we get into the topic, I would like to explain a little about clusters and nodes in OpenSearch. OpenSearch cluster is made up of one or more nodes, which are servers that handle search queries and store your data. As the cluster grows we can subdivide the responsibilities among different nodes(Master, Data, and more). Now, Let\\u2019s dive into the issue. What is a circuit breaker? In data nodes, 50 % of the available memory up to 32GB is used by the JVM heap and the rest is used for other operations. Circuit breakers are limitations put on a node to stop operations with the risk of resulting in JVM OutofMemoryError, which could cause the node to crash completely. The amount of memory each circuit breaker can utilize is specified. In response to requests, the breakers calculate how much memory the activity requires and compare the calculated size to the specified heap size limit. The query is aborted if the anticipated size exceeds the available heap size. In order to avoid overloading the node, a CircuitBreakerException is raised. Types of Circuit breakers There are many types of circuit breakers and a few of them are as follows: Parent circuit breaker \\u2014 It specifies the maximum amount of memory that all breakers can utilize. If the combined memory utilization results in more than the specified limit the parent circuit exception will occur. It is configured using the below settings. indices.breaker.total.use_real_memory (default to true) \\u2014 Determines whether the parent breaker should take real memory usage into account (true) or only consider the amount that is reserved by child circuit breakers (false). indices.breaker.total.limit (default \\u2014 95% of JVM heap) \\u2014 Limit for overall parent breaker. If indices.breaker.total.use_real_memory is false then 70% JVM heap otherwise 95% of the JVM heap. Field Data circuit breaker \\u2014 It is anticipated how much heap memory will be required to load a field into the field data cache. The circuit breaker terminates the operation and reports an error if loading the field will cause the cache to use more memory than was allowed. The field data cache contains field data (to allow text fields to be available for aggregations, sorting, and scripting) and global ordinals (It is an internal data structure used in elasticsearch for pre-computing and optimizing the performance of terms aggregations). indices.breaker.fielddata.limit \\u2014 Limit for fielddata breaker. Defaults to 40% of the JVM heap. indices.breaker.fielddata.overhead \\u2014 A constant (1.03) that all field data estimations are multiplied to determine a final estimation. Request circuit breaker \\u2014 It is estimated how much heap memory will be required to process a request. It also includes the memory used for calculating aggregations during a request. If the memory usage is more than the limit, the request is terminated and an exception is raised. indices.breaker.request.limit \\u2014 Defaults to 60% of the JVM heap. indices.breaker.request.overhead \\u2014 A constant (1) that all request estimations are multiplied to determine a final estimation. In-flight requests circuit breaker \\u2014 It is caused when the memory usage of all active incoming requests exceeds the configured threshold on a node. network.breaker.inflight_requests.limit \\u2014 Defaults to 100% of JVM heap. This means that it is bound by the limit configured for the parent circuit breaker. network.breaker.inflight_requests.overhead \\u2014 A constant (2) that is multiplied to determine a final estimation. Accounting circuit breaker \\u2014 It is a limit to prevent items from using too much memory that isn\\u2019t released when a request is finished, such as Lucene segment memory. A segment is an inverted index. indices.breaker.accounting.limit \\u2014 Limit for accounting breaker, defaults to 100% of JVM heap. This means that it is bound by the limit configured for the parent circuit breaker. indices.breaker.accounting.overhead \\u2014 A constant (1) that is multiplied to determine a final estimation. Useful Commands GET /_nodes/stats/breaker To retrieve the current memory use per node and per breaker. GET _cat/nodes?v=true&h=id,r,ram,heap* To obtain information about heap and memory details per node. GET /_cluster/settings?include_defaults=true It will return explicitly defined and default setting in the cluster including breaker settings. GET _nodes/stats?filter_path=nodes..jvm.mem.pools.old To calculate the JVM memory pressure of each node. Use the response to calculate memory pressure as JVM Memory Pressure = used_in_bytes / max_in_bytes. Circuit Breaker Exception Example Press enter or click to view image in full size Above is an example of a circuit breaker error message which I had encountered while working with AWS OpenSearch Service. The error will result in a 429 status code. Let\\u2019s look into the error more closely and try to understand what is happening here. type \\u2014 It specifies the type of the exception raised. reason \\u2014 More detailed information about the reason which led to the mentioned exception. [parent] \\u2014 It specifies that the parent circuit breaker exception has resulted in the error. The default parent circuit breaker setting is 95%. real usage \\u2014 It defines the current heap usage. new bytes reserved \\u2014 It specifies the number of new bytes required. limit of \\u2014 It is the maximum memory allocation for the parent circuit breaker. If the real usage + new bytes reserved exceeds the limit of, the parent circuit breaker will be triggered. durability \\u2014 It specifies if the issue that triggered the circuit breaker eventually resolves itself (TRANSIENT) or calls for manual intervention (PERMANENT). Suggestions Reduce JVM memory pressure \\u2014 High JVM memory pressure often causes circuit breaker errors. Check the JVM memory pressure and try to reduce it using the following suggestions. Reduce the shard numbers of each index- For search latency workloads use a shard size between 10\\u201330 GiB. For write-heavy workloads use a shard size between 30\\u201350 GiB. On a given node, have no more than 20 shards per GiB of Java heap. Avoid searches that might be very expensive (Using large size in pagination). Enable slow logs for identifying expensive search queries. Aggregation, wildcards, and wide time ranges in your queries might also result in high JVM pressure. A mapping explosion, which consumes a lot of memory, might result from defining too many fields or nesting fields too deeply. Avoid sending a large number of requests at the same time or tuning bulk size according to your workload. Increase the cluster\\u2019s size to get an extra JVM heap to handle yours. Disable and avoid using fielddata as it can consume a large amount of heap space. Monitoring OpenSearch cluster metrics with Amazon CloudWatch and create alarms for various cluster metrics. Enable logs for better observability of the errors and issues. Author(s) Somya Sharma Backend Dev currently focusing on AWS Services, Algorithms, and Serverless Application Development. AWS Elasticsearch Opensearch Circuit Breakers -- -- Written by AntStack Inc. 12 followers \\u00b71 following AntStack is one of the leading full-stack serverless companies aiming at disrupting the cloud computing space by providing holistic solutions to get you up No responses yet Help Status About Careers Press Blog Privacy Rules Terms Text to speech\\\"},{\\\"url\\\":\\\"https://socprime.com/blog/opensearch-circuit-breakers/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Platform Threat Detection Marketplace Your Home for Threat Detection Attack Detective Industry-First SaaS for Advanced Threat Hunting Uncoder AI Single IDE for Detection Engineering Shift-Left Detection Run Sigma rules on Kafka Ecosystem Use Cases Fortify SIEM Posture Audit your SIEM posture to maximize threat visibility & address detection coverage gaps. Obtain Rules for Alerting Get prioritized SIEM use cases ready-to-deploy as low-noise and high-value alerts. Advance Threat Detection Access the world\\u2019s largest rule feed for emerging threats, manage & deploy detections at scale. Elevate Detection Engineering Save time and costs, obtain CTI-enriched use cases, adapt CI/CD workflows. Accelerate MDR Services Reduce customer churn, address technical debt in threat detection, and save on SIEM costs. Hyperscale SIEM Migration Accelerate time-to-value and maximize the ROI of your SIEM migration project. Enable Bear Fence For Your MDE Maximize your Microsoft Defender for Endpoint with automated hunting for APT28 (Fancy Bear) and other Russian APTs. Services Professional Services Overview Explore our on-demand services and training. MITRE ATT&CK Audit Minimize blind spots and ensure comprehensive data visibility. Custom Content Engineering Adopt out-of-the-box detection engineering capability to identify threats challenging your business. SIEM Migration Services Accelerate time-to-value and maximize the ROI of your SIEM migration project. Resources Blog Research, guides, interviews News Headlines in cyberspace Events Stay tuned to our cybersecurity events Data Sheets Explore our data sheets for detailed insights Threat Bounty Monetize your Threat Detection content Customer Success Stories Learn how global organizations trust SOC Prime Detection as Code Explore our latest innovation reports Roota Open-Source Language for Collective Cyber Defence Sigma History of Sigma Evolution Industry Expertise Center of Excellence for Microsoft Sentinel Center of Excellence for Amazon Web Services Splunk Migration & Support Tools Uncoder.IO The Prime Hunt browser extension: Chrome Firefox Edge Company Why SOC Prime? Collective cyber defense for a secure tomorrow About Us Our story and mission Industry Recognition Verified value for cybersecurity Leadership Biography and DNA Careers Job opportunities at SOC Prime Privacy SOC Prime\\u2019s privacy-centric mindset SOC 2 Type II Compliance Benchmark for security compliance Partner Programs for Universities Sigma & MITRE ATT&CK\\u00ae Education Pricing Log In Request a Demo Request a Demo Request a Demo Blog/Knowledge Bits/This article OpenSearch Circuit Breakers WRITTEN BY Oleksii K. DevOps Engineer [post-views] December 04, 2024 \\u00b7 2 min read Table of contents: Types of Circuit Breakers in OpenSearch Handling Circuit Breaker Exceptions OpenSearch employs circuit breakers to prevent nodes from running out of Java Virtual Machine (JVM) heap memory, which could lead to crashes. These circuit breakers estimate the memory required for operations and compare it to the available heap size. If an operation exceeds the configured limit, OpenSearch throws a CircuitBreakerException to avoid potential OutOfMemoryErrors. Types of Circuit Breakers in OpenSearch Parent Circuit Breaker: This breaker sets the overall memory limit for all child circuit breakers. By default, it is configured to 95% of the JVM heap size. It\\u2019s crucial to ensure that the indices.breaker.request.limit is set lower than the parent breaker to prevent the parent breaker from being triggered prematurely. Fielddata Circuit Breaker: This breaker limits the memory used to load fields into the fielddata cache, which is essential for operations like aggregations and sorting. The default limit is 40% of the JVM heap. To adjust this limit, you can use the following command: PUT /_cluster/settings\\\\n{\\\\n  \\\\\\\"persistent\\\\\\\": {\\\\n    \\\\\\\"indices.breaker.fielddata.limit\\\\\\\": \\\\\\\"60%\\\\\\\"\\\\n  }\\\\n} Request Circuit Breaker: This breaker estimates the memory required to process a request, including memory for aggregations. The default limit is 60% of the JVM heap. If a request exceeds this limit, it is terminated to prevent memory overload. In-Flight Requests Circuit Breaker: This breaker monitors the memory usage of active incoming requests. The default limit is set to 100% of the JVM heap, which is effectively controlled by the parent circuit breaker. Script Compilation Circuit Breaker: This breaker limits the number of inline script compilations within a specified time interval. The default setting allows 150 compilations every 5 minutes. To adjust this limit, you can modify the script.max_compilations_rate setting. Handling Circuit Breaker Exceptions When a circuit breaker is triggered, OpenSearch throws a CircuitBreakerException, often accompanied by a 429 status code indicating \\u201cdata too large.\\u201d To handle these exceptions effectively: Review Query and Mapping: Examine your queries and index mappings to identify operations that consume excessive memory. For instance, using large size values in aggregations can lead to high memory usage. Optimize Fielddata Usage: Avoid enabling fielddata on text fields unless absolutely necessary, as it can consume significant memory. Instead, use keyword fields for aggregations and sorting. Adjust Circuit Breaker Settings: While it\\u2019s generally advisable to keep default settings to prevent OutOfMemoryErrors, you can adjust circuit breaker limits if you have a clear understanding of your workload and memory requirements. For example, to increase the fielddata limit to 60%, use the command mentioned earlier. Scale Your Cluster: If your workload consistently exceeds memory limits, consider scaling your cluster by adding more nodes or increasing the JVM heap size to accommodate the increased memory demands. Table of Contents Types of Circuit Breakers in OpenSearch Handling Circuit Breaker Exceptions Was this article helpful? Like and share it with your peers. Join SOC Prime's Detection as Code platform to improve visibility into threats most relevant to your business. To help you get started and drive immediate value, book a meeting now with SOC Prime experts. Join for Free Book a Meeting Call with SOC Prime \\u00d7 Related Posts Apr 25/2025 2 min read SOC Prime Platform Rule Deployment into a Data Plane by Steven Edwards Apr 25/2025 2 min read SOC Prime Platform Translate from Sigma into 48 Languages by Steven Edwards Dec 4/2024 2 min read Knowledge Bits Splunk: How to Write a Query to Monitor Multiple Sources and Send Alert if they Stop Coming by Oleh P. All News Boost Your Cyber Defense with Threat Detection Marketplace The leading platform for Detection as Code and Continuous Security Intelligence Join Now Platform Threat Detection Marketplace Attack Detective Uncoder AI Shift-Left Detection Ecosystem Use Cases Fortify SIEM Posture Obtain Rules for Alerting Advance Threat Detection Elevate Detection Engineering Accelerate MDR Services Hyperscale SIEM Migration Enable Bear Fence For Your MDE Services Professional Services Overview MITRE ATT&CK Audit Custom Content Engineering SIEM Migration Services Industry Expertise Center of Excellence for Microsoft Sentinel Center of Excellence for Amazon Web Services Splunk Migration & Support Tools Uncoder.IO The Prime Hunt for: Chrome Firefox Edge Resources Blog News Events Data Sheets Threat Bounty Customer Success Stories Detection as Code Roota Sigma Company Why SOC Prime? About Us Industry Recognition Leadership Careers Privacy SOC 2 Type II Compliance Partner Programs for Universities PRICING Cookie Policy Privacy Policy LEGAL NOTICE (IMPRESSUM) SOC PRIME PLATFORM TERMS OF SERVICE Privacy FAQ Engage WIth Us SOC Prime, SOC Prime Logo and Threat Detection Marketplace are registered trademarks of SOC Prime, Inc. All other trademarks are the property of their respective owners. This website uses cookies (small text files that are stored by the web browser on the user's device) to improve the user experience while you navigate through the website for the statistical analysis of traffic and to adapt the content of the website to your individual needs. It also lets us improve your overall experience of the website. These cookies will only be stored in your browser with your consent. However, if you would like to, you can opt-out of these cookies in your browser settings at any time. But opting out of some of these cookies may have a negative impact on your viewing experience. More information can be found in our Cookie Policy, and for a detailed list of the cookies we use, see our Cookie Settings. Accept and Close Cookie Settings Cookie Settings Below is a detailed list of the cookies we use on our Site. We classify cookies in the following categories: Strictly Necessary Cookies Performance Cookies Functional Cookies Targeting Cookies Strictly Necessary Cookies Cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information. Name Descripiton PHPSESSID Preserves user session state across page requests. Cookie generated by applications based on the PHP language. This is a general purpose identifier used to maintain user session variables. It is normally a random generated number, how it is used can be specific to the site, but a good example is maintaining a logged-in status for a user between pages. sp_i Used to store information about authenticated User. sp_r Used to store information about authenticated User. sp_a Used to store information about authenticated User. Performance Cookies These cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site. All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site, and will not be able to monitor its performance. Name Descripiton tuuid Collects anonymous data related to the user's visits to the website, such as the number of visits, average time spent on the website and what pages have been loaded. tuuid_last_update Collects anonymous data related to the user's visits to the website, such as the number of visits, average time spent on the website and what pages have been loaded. um Collects anonymous data related to the user's visits to the website, such as the number of visits, average time spent on the website and what pages have been loaded. umeh Collects anonymous data related to the user's visits to the website, such as the number of visits, average time spent on the website and what pages have been loaded. na_sc_x Used by the social sharing platform AddThis to keep a record of parts of the site that has been visited in order to recommend other parts of the site. APID Collects anonymous data related to the user's visits to the website. IDSYNC Collects anonymous data related to the user's visits to the website. _cc_aud Collects anonymous statistical data related to the user's website visits, such as the number of visits, average time spent on the website and what pages have been loaded. The purpose is to segment the website's users according to factors such as demographics and geographical location, in order to enable media and marketing agencies to structure and understand their target groups to enable customised online advertising. _cc_cc Collects anonymous statistical data related to the user's website visits, such as the number of visits, average time spent on the website and what pages have been loaded. The purpose is to segment the website's users according to factors such as demographics and geographical location, in order to enable media and marketing agencies to structure and understand their target groups to enable customised online advertising. _cc_dc Collects anonymous statistical data related to the user's website visits, such as the number of visits, average time spent on the website and what pages have been loaded. The purpose is to segment the website's users according to factors such as demographics and geographical location, in order to enable media and marketing agencies to structure and understand their target groups to enable customised online advertising. _cc_id Collects anonymous statistical data related to the user's website visits, such as the number of visits, average time spent on the website and what pages have been loaded. The purpose is to segment the website's users according to factors such as demographics and geographical location, in order to enable media and marketing agencies to structure and understand their target groups to enable customised online advertising. dpm Via a unique ID that is used for semantic content analysis, the user's navigation on the website is registered and linked to offline data from surveys and similar registrations to display targeted ads. acs Collects anonymous data related to the user's visits to the website, such as the number of visits, average time spent on the website and what pages have been loaded, with the purpose of displaying targeted ads. clid Collects anonymous data related to the user's visits to the website, such as the number of visits, average time spent on the website and what pages have been loaded, with the purpose of displaying targeted ads. KRTBCOOKIE_# Registers a unique ID that identifies the user's device during return visits across websites that use the same ad network. The ID is used to allow targeted ads. PUBMDCID Registers a unique ID that identifies the user's device during return visits across websites that use the same ad network. The ID is used to allow targeted ads. PugT Registers a unique ID that identifies the user's device during return visits across websites that use the same ad network. The ID is used to allow targeted ads. ssi Registers a unique ID that identifies a returning user's device. The ID is used for targeted ads. _tmid Registers a unique ID that identifies the user's device upon return visits. The ID is used to target ads in video clips. wam-sync Used by the advertising platform Weborama to determine the visitor's interests based on pages visits, content clicked and other actions on the website. wui Used by the advertising platform Weborama to determine the visitor's interests based on pages visits, content clicked and other actions on the website. AFFICHE_W Used by the advertising platform Weborama to determine the visitor's interests based on pages visits, content clicked and other actions on the website. B Collects anonymous data related to the user's website visits, such as the number of visits, average time spent on the website and what pages have been loaded. The registered data is used to categorise the users' interest and demographical profiles with the purpose of customising the website content depending on the visitor. 1P_JAR These cookies are used to gather website statistics, and track conversion rates. APISID Google set a number of cookies on any page that includes a Google reCAPTCHA. While we have no control over the cookies set by Google, they appear to include a mixture of pieces of information to measure the number and behaviour of Google reCAPTCHA users. HSID Google set a number of cookies on any page that includes a Google reCAPTCHA. While we have no control over the cookies set by Google, they appear to include a mixture of pieces of information to measure the number and behaviour of Google reCAPTCHA users. NID Google set a number of cookies on any page that includes a Google reCAPTCHA. While we have no control over the cookies set by Google, they appear to include a mixture of pieces of information to measure the number and behaviour of Google reCAPTCHA users. SAPISID Google set a number of cookies on any page that includes a Google reCAPTCHA. While we have no control over the cookies set by Google, they appear to include a mixture of pieces of information to measure the number and behaviour of Google reCAPTCHA users. SID Google set a number of cookies on any page that includes a Google reCAPTCHA. While we have no control over the cookies set by Google, they appear to include a mixture of pieces of information to measure the number and behaviour of Google reCAPTCHA users. SIDCC Security cookie to protect users data from unauthorised access. SSID Google set a number of cookies on any page that includes a Google reCAPTCHA. While we have no control over the cookies set by Google, they appear to include a mixture of pieces of information to measure the number and behaviour of Google reCAPTCHA users. __utmx This cookie is associated with Google Website Optimizer, a tool designed to help site owners improve their wbesites. It is used to distinguish between two varaitions a webpage that might be shown to a visitor as part of an A/B split test. This helps site owners to detemine which version of a page performs better, and therefore helps to improve the website. __utmxx This cookie is associated with Google Website Optimizer, a tool designed to help site owners improve their wbesites. It is used to distinguish between two varaitions a webpage that might be shown to a visitor as part of an A/B split test. This helps site owners to detemine which version of a page performs better, and therefore helps to improve the website. Functional Cookies These cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages. If you do not allow these cookies then some or all of these services may not function properly. Name Descripiton _hjid Hotjar cookie. This cookie is set when the customer first lands on a page with the Hotjar script. It is used to persist the random user ID, unique to that site on the browser. This ensures that behavior in subsequent visits to the same site will be attributed to the same user ID. _hjIncludedInSample This cookie is associated with web analytics functionality and services from Hot Jar, a Malta based company. It uniquely identifies a visitor during a single browser session and indicates they are included in an audience sample. intercom-id-[xxx] This cookie is used by Intercom as a session so that users can continue a chat as they move through the site. intercom-session-[xxx] Used to keeping track of sessions and remember logins and conversations. demdex Via a unique ID that is used for semantic content analysis, the user's navigation on the website is registered and linked to offline data from surveys and similar registrations to display targeted ads. CookieConsent Stores the user's cookie consent state for the current domain. __cfduid Used by the content network, Cloudflare, to identify trusted web traffic. ss These cookies enable the website to provide enhanced functionality and personalisation . They may be set by us or by third party providers whose services we have added to our pages. These services may include the Live Chat facility, Contact Us form(s), the Product Quotation forms and submission process, and the Email Newsletter sign up functionality . Targeting Cookies These cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. They do not store directly personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising. Name Descripiton _ga This cookie name is asssociated with Google Universal Analytics - which is a significant update to Google's more commonly used analytics service. This cookie is used to distinguish unique users by assigning a randomly generated number as a client identifier. It is included in each page. Registers a unique ID that is used to generate statistical data on how the visitor uses the website. request in a site and used to calculate visitor, session and campaign data for the sites analytics reports. By default it is set to expire after 2 years, although this is customisable by website owners. _gat Used by Google Analytics to throttle request rate. This cookie name is associated with Google Universal Analytics, according to documentation it is used to throttle the request rate - limiting the collection of data on high traffic sites. It expires after 10 minutes. _gid This cookie name is asssociated with Google Universal Analytics. This appears to be a new cookie and as of Spring 2017 no information is available from Google. It appears to store and update a unique value for each page visited. Registers a unique ID that is used to generate statistical data on how the visitor uses the website. IDE Used by Google DoubleClick to register and report the website user's actions after viewing or clicking one of the advertiser's ads with the purpose of measuring the efficacy of an ad and to present targeted ads to the user. r/collect Used by Google DoubleClick to register and report the website user's actions after viewing or clicking one of the advertiser's ads with the purpose of measuring the efficacy of an ad and to present targeted ads to the user. test_cookie Used to check if the user's browser supports cookies. collect Used to send data to Google Analytics about the visitor's device and behaviour. Tracks the visitor across devices and marketing channels. ads/user-lists/# These cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. c Registers anonymised user data, such as IP address, geographical location, visited websites, and what ads the user has clicked, with the purpose of optimising ad display based on the user's movement on websites that use the same ad network. khaos Registers anonymised user data, such as IP address, geographical location, visited websites, and what ads the user has clicked, with the purpose of optimising ad display based on the user's movement on websites that use the same ad network. put_# Registers anonymised user data, such as IP address, geographical location, visited websites, and what ads the user has clicked, with the purpose of optimising ad display based on the user's movement on websites that use the same ad network. rpb Registers anonymised user data, such as IP address, geographical location, visited websites, and what ads the user has clicked, with the purpose of optimising ad display based on the user's movement on websites that use the same ad network. rpx Registers anonymised user data, such as IP address, geographical location, visited websites, and what ads the user has clicked, with the purpose of optimising ad display based on the user's movement on websites that use the same ad network. tap.php Registers anonymised user data, such as IP address, geographical location, visited websites, and what ads the user has clicked, with the purpose of optimising ad display based on the user's movement on websites that use the same ad network.\\\"},{\\\"url\\\":\\\"https://www.bookstack.cn/read/opensearch-3.0-en/e7d13147ebaa1f74.md\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"\\u00d7 \\u601d\\u7ef4\\u5bfc\\u56fe\\u5907\\u6ce8 \\u5173\\u95ed OpenSearch v3.0 Documentation \\u9996\\u9875 \\u767d\\u5929 \\u591c\\u95f4 \\u5c0f\\u7a0b\\u5e8f \\u9605\\u8bfb \\u4e66\\u7b7e \\u6211\\u7684\\u4e66\\u7b7e \\u6dfb\\u52a0\\u4e66\\u7b7e \\u79fb\\u9664\\u4e66\\u7b7e Circuit breaker settings GitHub \\u6765\\u6e90:OpenSearch \\u6d4f\\u89c8 84 \\u626b\\u7801 \\u5206\\u4eab 2025-05-09 14:10:24 Circuit breaker settings Parent circuit breaker settings Field data circuit breaker settings Request circuit breaker settings In-flight request circuit breaker settings Script compilation circuit breaker settings Regular expression circuit breaker settings Circuit breaker settings Circuit breakers prevent OpenSearch from causing a Java OutOfMemoryError. The parent circuit breaker specifies the total available amount of memory for all child circuit breakers. The child circuit breakers specify the total available amount of memory for themselves. To learn more about static and dynamic settings, see Configuring OpenSearch. Parent circuit breaker settings OpenSearch supports the following parent circuit breaker settings: indices.breaker.total.use_real_memory (Static, Boolean): If true, the parent circuit breaker considers the actual memory usage. Otherwise, the parent circuit breaker considers the amount of memory reserved by the child circuit breakers. Default is true. indices.breaker.total.limit (Dynamic, percentage): Specifies the initial memory limit for the parent circuit breaker. If indices.breaker.total.use_real_memory is true, defaults to 95% of the JVM heap. If indices.breaker.total.use_real_memory is false, defaults to 70% of the JVM heap. Field data circuit breaker settings The field data circuit breaker limits the heap memory required to load a field into the field data cache. OpenSearch supports the following field data circuit breaker settings: indices.breaker.fielddata.limit (Dynamic, percentage): Specifies the memory limit for the field data circuit breaker. Default is 40% of the JVM heap. indices.breaker.fielddata.overhead (Dynamic, double): A constant by which the field data estimations are multiplied to determine the final estimation. Default is 1.03. Request circuit breaker settings The request circuit breaker limits the memory required to build data structures that are needed for a request (for example, when calculating aggregations). OpenSearch supports the following request circuit breaker settings: indices.breaker.request.limit (Dynamic, percentage): Specifies the memory limit for the request circuit breaker. Default is 60% of the JVM heap. indices.breaker.request.overhead (Dynamic, double): A constant by which the request estimations are multiplied to determine the final estimation. Default is 1. In-flight request circuit breaker settings The in-flight request circuit breaker limits the memory usage for all currently running incoming requests on transport and HTTP level. The memory usage for a request is based on the content length of the request and includes memory needed for the raw request and a structured object representing the request. OpenSearch supports the following in-flight request circuit breaker settings: network.breaker.inflight_requests.limit (Dynamic, percentage): Specifies the memory limit for the in-flight request circuit breaker. Default is 100% of JVM heap (thus, the memory usage limit for an in-flight request is determined by the memory limit of the parent circuit breaker). network.breaker.inflight_requests.overhead (Dynamic, double): A constant by which the in-flight request estimations are multiplied to determine the final estimation. Default is 2. Script compilation circuit breaker settings The script compilation circuit breaker limits the number of inline script compilations within a time interval. OpenSearch supports the following script compilation circuit breaker setting: script.max_compilations_rate (Dynamic, rate): The maximum number of unique dynamic scripts compiled within a time interval for a given context. Default is 150 every 5 minutes (150/5m). Regular expression circuit breaker settings The regular expression circuit breaker enables or disables regular expressions and limits their complexity. OpenSearch supports the following regular expression circuit breaker settings: script.painless.regex.enabled (Static, string): Enables regular expressions in Painless scripts. Valid values are: limited: Enables regular expressions and limits their complexity using the script.painless.regex.limit-factor setting. true: Enables regular expressions. Turns off the regular expression circuit breaker and does not limit regular expression complexity. false: Disables regular expressions. If a Painless script contains a regular expression, it returns an error. Default is limited. script.painless.regex.limit-factor (Static, integer): Applied only if script.painless.regex.enabled is set to limited. Limits the number of characters a regular expression in a Painless script. The character limit is calculated by multiplying the number of characters in the script input by script.painless.regex.limit-factor. Default is 6 (thus, if the input has 5 characters, the maximum number of characters in a regular expression is 5 \\u00b7 6 = 30). \\u5f53\\u524d\\u5185\\u5bb9\\u7248\\u6743\\u5f52 OpenSearch \\u6216\\u5176\\u5173\\u8054\\u65b9\\u6240\\u6709\\uff0c\\u5982\\u9700\\u5bf9\\u5185\\u5bb9\\u6216\\u5185\\u5bb9\\u76f8\\u5173\\u8054\\u5f00\\u6e90\\u9879\\u76ee\\u8fdb\\u884c\\u5173\\u6ce8\\u4e0e\\u8d44\\u52a9\\uff0c\\u8bf7\\u8bbf\\u95ee OpenSearch . \\u4e0a\\u4e00\\u7bc7: \\u4e0b\\u4e00\\u7bc7: \\u7248\\u672c OpenSearch v3.0 Documentation OpenSearch v2.19 Documentation OpenSearch v2.18 Documentation OpenSearch v2.17 Documentation OpenSearch v2.16 Documentation OpenSearch v2.15 Documentation OpenSearch v2.14 Documentation OpenSearch v2.13 Documentation OpenSearch v2.12 Documentation OpenSearch v2.11 Documentation OpenSearch v2.10 Documentation OpenSearch v2.9 Documentation OpenSearch v2.8 Documentation OpenSearch v2.7 Documentation OpenSearch v2.6 Documentation OpenSearch v2.5 Documentation OpenSearch v2.4 Documentation OpenSearch v2.3 Documentation OpenSearch v2.2 Documentation OpenSearch v2.1 Documentation OpenSearch v2.0 Documentation OpenSearch v1.3 Documentation OpenSearch v1.2 Documentation OpenSearch v1.1 Documentation OpenSearch v1.0 Documentation About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Getting started with OpenSearch security Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Creating and customizing AI search workflows Model guardrails Amazon Bedrock model guardrails Install and upgrade Installing OpenSearch Docker Helm Tarball RPM Debian Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Circuit breaker settings Cluster settings Index settings Search settings Availability and recovery settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Upgrading OpenSearch Rolling Upgrade Upgrades appendix Rolling upgrade lab Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Workload management Workload Group Lifecycle API Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Reindex data Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings Index management security Refresh search analyzer ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Ingest Pipelines Create pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove_by_pattern Remove Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data Time filter Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dev Tools Running queries in the Dev Tools console Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security in OpenSearch Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings and field types Mapping parameters Analyzer Boost Coerce Copy_to Doc values Dynamic Eager global ordinals Enabled Ignore above Ignore malformed Format Index Index options Fields Meta Normalizer Norms Null value Properties Search analyzer Store Term vector Supported field types Alias Binary Numeric field types Unsigned long Boolean k-NN vector Spaces Methods and engines Memory-optimized vectors Date field types Date Date nanoseconds IP address Range field types Object field types Object Nested Flat object Join String field types Keyword Text Match-only text Wildcard Token count Constant keyword Autocomplete field types Completion Search as you type Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Rank field types Star-tree Derived Percolator Metadata fields Field names ID Ignored Index Meta Routing Source Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Exists Fuzzy IDs Prefix Range Regexp Term Terms Terms set Wildcard Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Distance feature k-NN k-NN query explain Neural Neural sparse Script score Template Minimum should match Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Range Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Search features Search options Paginate results Point in Time Point in Time API Sort results Filter results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Comparing search results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI client data structures Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines Search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Subsearch Identifiers Data Types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Neural sparse search using raw vectors Conversational search with RAG Building AI search workflows in OpenSearch Dashboards Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Specialized vector search Nested field search Radial search Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Index Mapping tool List Index tool Log Pattern Tool ML Model tool Neural Sparse Search tool PPL tool RAG tool Search Alerts tool CreateAnomalyDetectorTool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web search tool Using MCP tools Connecting to an external MCP server OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Execute agent Get agent Search agent Delete agent MCP server APIs Register MCP tools Remove MCP tools MCP SSE session MCP SSE message Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI OpenSearch Kubernetes Operator Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Index APIs Alias Create or update alias Blocks Clear cache Clone index Open index Index exists Close index Create index Delete index Get index Shrink index Create or update index template Get index template Delete index template Simulate index templates Create or update mappings Create or update component template Dangling indexes Flush Force merge Recovery Get settings Update settings Scale Refresh index Resolve index Roll over index Segment Split index Stats Analyze API Analysis API Terminology CAT API CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster routing and awareness Cluster decommission Cluster health Cluster settings Cluster stats Count Document APIs Index document Get document Update document Delete document Reindex document Bulk Streaming bulk Multi-get document Delete by query Update by query Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) Explain Ingest APIs List API List shards List indices Multi-search Multi-search Template Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Profile Ranking evaluation Remote cluster information Script APIs Create or Update Stored Script Execute Painless stored script Get Stored Script Delete Script Get Stored Script Contexts Get Script Language Execute Painless script Scroll Search Search templates Snapshot APIs Register Snapshot Repository Get Snapshot Repository Delete Snapshot Repository Verify Snaphot Repository Create Snapshot Get Snapshot Delete Snapshot Get Snapshot Status Restore Snapshot Clone snapshot Cleanup Snapshot Repository Render Template Tasks API List tasks Get task Cancel tasks Validate Query Supported units Common REST Parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions \\u6682\\u65e0\\u76f8\\u5173\\u641c\\u7d22\\u7ed3\\u679c\\uff01 \\u672c\\u6587\\u6863\\u4f7f\\u7528 BookStack \\u6784\\u5efa \\u00d7 \\u5206\\u4eab\\uff0c\\u8ba9\\u77e5\\u8bc6\\u4f20\\u627f\\u66f4\\u4e45\\u8fdc \\u53d6\\u6d88\\u5206\\u4eab \\u00d7 \\u6587\\u7ae0\\u4e8c\\u7ef4\\u7801 \\u624b\\u673a\\u626b\\u4e00\\u626b\\uff0c\\u8f7b\\u677e\\u638c\\u4e0a\\u8bfb \\u5173\\u95ed \\u00d7 \\u6587\\u6863\\u4e0b\\u8f7d \\u666e\\u901a\\u4e0b\\u8f7d \\u4e0b\\u8f7d\\u7801\\u4e0b\\u8f7d(\\u514d\\u767b\\u5f55\\u65e0\\u9650\\u4e0b\\u8f7d) \\u4f60\\u4e0e\\u5927\\u795e\\u7684\\u8ddd\\u79bb\\uff0c\\u53ea\\u5dee\\u4e00\\u4e2aAPP \\u8bf7\\u4e0b\\u8f7d\\u60a8\\u9700\\u8981\\u7684\\u683c\\u5f0f\\u7684\\u6587\\u6863\\uff0c\\u968f\\u65f6\\u968f\\u5730\\uff0c\\u4eab\\u53d7\\u6c72\\u53d6\\u77e5\\u8bc6\\u7684\\u4e50\\u8da3\\uff01 PDF\\u6587\\u6863 EPUB\\u6587\\u6863 MOBI\\u6587\\u6863 \\u6e29\\u99a8\\u63d0\\u793a \\u6bcf\\u5929\\u6bcf\\u5728\\u7f51\\u7ad9\\u9605\\u8bfb\\u5b66\\u4e60\\u4e00\\u5206\\u949f\\u65f6\\u957f\\u53ef\\u4e0b\\u8f7d\\u4e00\\u672c\\u7535\\u5b50\\u4e66\\uff0c\\u6bcf\\u5929\\u8fde\\u7eed\\u7b7e\\u5230\\u53ef\\u589e\\u52a0\\u9605\\u8bfb\\u65f6\\u957f \\u4e0b\\u8f7d\\u7801\\u65b9\\u5f0f\\u4e0b\\u8f7d\\uff1a\\u514d\\u8d39\\u3001\\u514d\\u767b\\u5f55\\u3001\\u65e0\\u9650\\u5236\\u3002 \\u514d\\u8d39\\u83b7\\u53d6\\u4e0b\\u8f7d\\u7801 \\u4e0b\\u8f7d\\u7801 \\u6587\\u6863\\u683c\\u5f0f PDF EPUB MOBI \\u7801\\u4e0a\\u4e0b\\u8f7d \\u5173\\u95ed\\u7a97\\u53e3 \\u00d7 \\u5fae\\u4fe1\\u5c0f\\u7a0b\\u5e8f\\u9605\\u8bfb \\u60a8\\u4e0e\\u4ed6\\u4eba\\u7684\\u85aa\\u8d44\\u5dee\\u8ddd\\uff0c\\u53ea\\u5dee\\u4e00\\u4e2a\\u968f\\u65f6\\u968f\\u5730\\u5b66\\u4e60\\u7684\\u5c0f\\u7a0b\\u5e8f \\u5173\\u95ed\\u7a97\\u53e3 \\u00d7 \\u4e66\\u7b7e\\u5217\\u8868 \\u5173\\u95ed \\u00d7 \\u9605\\u8bfb\\u8bb0\\u5f55 \\u9605\\u8bfb\\u8fdb\\u5ea6: 0.00% ( 0/0 ) \\u91cd\\u7f6e\\u9605\\u8bfb\\u8fdb\\u5ea6 \\u5173\\u95ed \\u6b22\\u8fce\\u4f7f\\u7528\\u3010\\u7801\\u7075\\u85af\\u00b7CoderBot\\u3011 \\u7801\\u7075\\u85af\\u00b7CoderBot \\u5168\\u5c4f \\u7f29\\u5c0f \\u9690\\u85cf \\u65b0\\u6807\\u7b7e\\\"},{\\\"url\\\":\\\"https://opster.com/guides/opensearch/opensearch-basics/opensearch-circuit-breakers/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Product BUILT FOR ELASTICSEARCH AutoOps Prevent & resolve issues, cut down administration time & hardware costs. Community Tools Tools For The Community Check-Up, Search Log Analyzer & OpsGPT Resources Guides Technical guides on Elasticsearch & Opensearch Blog Insights, Opster news, blogs and more Documentation Opster product documentation Error Messages Error Repository About About Our story & vision Login AutoOps Login Contact Login Contact Running self-managed Elasticsearch just got easier. Announcing AutoOps for your clusters. Read the announcement \\ud83c\\udf89\\ud83c\\udf89 Opensearch Guides > OpenSearch Basics Elasticsearch OpenSearch Circuit Breakers By Opster Team Updated: Jun 19, 2024 | 2 min read Overview OpenSearch has the concept of circuit breakers to deal with OutOfMemory errors that cause nodes to crash. When a request reaches OpenSearch nodes, the circuit breakers first estimate the amount of memory needed to load the required data. They then compare the estimated size with the configured heap size limit. If the estimated size is greater than the heap size, the query is terminated and an exception is thrown to avoid the node loading more than the available heap size. What they are used for OpenSearch has several circuit breakers available such as fielddata, requests, network, indices and script compilation. Each breaker is used to limit the memory an operation can use. In addition, OpenSearch has a parent circuit breaker which is used to limit the combined memory used by all the other circuit breakers. Examples Increasing circuit breaker size for fielddata limit \\u2013 The default limit for fielddata breakers is 40%. The following command can be used to increase it to 60%: PUT /_cluster/settings\\\\n{\\\\n  \\\\\\\"persistent\\\\\\\": {\\\\n    \\\\\\\"indices.breaker.fielddata.limit\\\\\\\": \\\\\\\"60%\\\\\\\"\\\\n  }\\\\n} Notes Each breaker ships with default limits and their limits can be modified as well. But this is an expert level setting and you should understand the pitfalls carefully before changing the limits, otherwise the node may start throwing OOM exceptions. Sometimes it is better to fail a query instead of getting an OOM exception, because when OOM appears JVM becomes unresponsive. It is important to keep indices.breaker.request.limit lower than indices.breaker.total.limit so that request circuit breakers trip before the total circuit breaker. Common problems The most common error resulting from circuit breakers is \\u201cdata too large\\u201d with 429 status code. The application should be ready to handle such exceptions. If the application starts throwing exceptions because of circuit breaker limits, it is important to review the queries and memory requirements. In most cases, a scaling is required by adding more resources to the cluster. Check out this guide to learn more about OpenSearch circuit breaker exceptions and how to handle circuit breakers: https://opster.com/guides/opensearch/opensearch-basics/opensearch-circuit-breaker-exceptions-how-to-handle-circuit-breakers/ Additional notes Elasticsearch and OpenSearch are both powerful search and analytics engines, but Elasticsearch has several key advantages. Elasticsearch boasts a more mature and feature-rich development history, translating to a better user experience, more features, and continuous optimizations. Our testing has consistently shown that Elasticsearch delivers faster performance while using fewer compute resources than OpenSearch. Additionally, Elasticsearch\\u2019s comprehensive documentation and active community forums provide invaluable resources for troubleshooting and further optimization. Elastic, the company behind Elasticsearch, offers dedicated support, ensuring enterprise-grade reliability and performance. These factors collectively make Elasticsearch a more versatile, efficient, and dependable choice for organizations requiring sophisticated search and analytics capabilities. Related Articles How to Increase Primary Shard Count in Elasticsearch Elasticsearch Large Cluster State - How to Discover & Prevent BMC Launched a New Feature Based on OpenSearch Back to all articles Product AutoOps for Elasticsearch Community Tools Tools for the Community Company About Our Customers info@opster.com Resources Documentation Blog Guides Elasticsearch Error Messages Elasticsearch Log Errors Taking Care of Your Entire Search Operation. Opster\\u2019s solutions reduce the time and cost of running Elasticsearch. Get Improved performance & stability with less hardware. Contact Us \\u00a9 2025 Opster Privacy Policy Terms of Use We use cookies to ensure that we give you the best experience on our website. By continuing to browse this site, you agree to our Privacy Policy and Terms of Use. Agree Close GDPR Cookie Settings Privacy Overview Strictly Necessary Cookies Powered by GDPR Cookie Compliance Privacy Overview This website uses cookies so that we can provide you with the best user experience possible. Cookie information is stored in your browser and performs functions such as recognising you when you return to our website and helping our team to understand which sections of the website you find most interesting and useful. Strictly Necessary Cookies Strictly Necessary Cookie should be enabled at all times so that we can save your preferences for cookie settings. Enable or Disable Cookies Enabled Disabled Enable All Save Settings\\\"},{\\\"url\\\":\\\"https://www.antstack.com/blog/how-to-handle-the-circuit-breaker-exception-in-open-search/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Services UX & Design UI Engineering Application Development Application Modernization Data Engineering & Modernization AI Engineering Industries SME Healthcare QSR Media & Entertainment BFSI SaaS Logistics Case Studies Blogs About us Talk to us Somya Sharma 7 min read Dec 8, 2022 aws elasticsearch opensearch Subscribe to newsletter How to Handle the Circuit Breaker Exception in OpenSearch Summarize Chat GPT Perplexity Gemini Claude AI aws elasticsearch opensearch We had a search functionality requirement in one of the projects and that\\u2019s how I got to know about Amazon OpenSearch Service, It provides a quick, relevant search experience and makes it easier to add a search feature to your applications. The only hiccup is sizing the OpenSearch is a tricky and long-term process, and it often takes many iterations to make sure that you get the right specifications according to your workload. It also needs monitoring so as to be aware of future problems. You make an initial estimate of the resources, test them, and verify their performance. If the performance is not good, then you need to resize it and iterate. In this process, you often face many challenges. Some of them are listed below: Red / Yellow Cluster Status Exceeded maximum shard limit JVM OutOfMemoryError Failed cluster nodes While I was working with OpenSearch, I faced one such issue, which I will cover in this post. Our cluster was ready to go after going through the estimation process and performance testing, but after a while, we started seeing CircuitBreakerException in our logs. I find it difficult to understand, so I thought to write about it. I hope this blog helps you understand it better. Before we get into the topic, I would like to explain a little about clusters and nodes in OpenSearch. OpenSearch cluster is made up of one or more nodes, which are servers that handle search queries and store your data. As the cluster grows we can subdivide the responsibilities among different nodes(Master, Data, and more). Now, Let\\u2019s dive into the issue. What is a circuit breaker? In data nodes, 50 % of the available memory up to 32GB is used by the JVM heap and the rest is used for other operations. Circuit breakers are limitations put on a node to stop operations with the risk of resulting in JVM OutofMemoryError, which could cause the node to crash completely. The amount of memory each circuit breaker can utilize is specified. In response to requests, the breakers calculate how much memory the activity requires and compare the calculated size to the specified heap size limit. The query is aborted if the anticipated size exceeds the available heap size. In order to avoid overloading the node, a CircuitBreakerException is raised. Types of Circuit breakers There are many types of circuit breakers and a few of them are as follows: Parent circuit breaker - It specifies the maximum amount of memory that all breakers can utilize. If the combined memory utilization results in more than the specified limit the parent circuit exception will occur. It is configured using the below settings. indices.breaker.total.use_real_memory (default to true) - Determines whether the parent breaker should take real memory usage into account (true) or only consider the amount that is reserved by child circuit breakers (false). indices.breaker.total.limit (default - 95% of JVM heap) - Limit for overall parent breaker. If indices.breaker.total.use_real_memory is false then 70% JVM heap otherwise 95% of the JVM heap. Field Data circuit breaker - It is anticipated how much heap memory will be required to load a field into the field data cache. The circuit breaker terminates the operation and reports an error if loading the field will cause the cache to use more memory than was allowed. The field data cache contains field data (to allow text fields to be available for aggregations, sorting, and scripting) and global ordinals (It is an internal data structure used in elasticsearch for pre-computing and optimizing the performance of terms aggregations). indices.breaker.fielddata.limit - Limit for fielddata breaker. Defaults to 40% of the JVM heap. indices.breaker.fielddata.overhead - A constant (1.03) that all field data estimations are multiplied to determine a final estimation. Request circuit breaker - It is estimated how much heap memory will be required to process a request. It also includes the memory used for calculating aggregations during a request. If the memory usage is more than the limit, the request is terminated and an exception is raised. indices.breaker.request.limit - Defaults to 60% of the JVM heap. indices.breaker.request.overhead - A constant (1) that all request estimations are multiplied to determine a final estimation. In-flight requests circuit breaker - It is caused when the memory usage of all active incoming requests exceeds the configured threshold on a node. network.breaker.inflight_requests.limit - Defaults to 100% of JVM heap. This means that it is bound by the limit configured for the parent circuit breaker. network.breaker.inflight_requests.overhead - A constant (2) that is multiplied to determine a final estimation. Accounting circuit breaker - It is a limit to prevent items from using too much memory that isn\\u2019t released when a request is finished, such as Lucene segment memory. A segment is an inverted index. indices.breaker.accounting.limit - Limit for accounting breaker, defaults to 100% of JVM heap. This means that it is bound by the limit configured for the parent circuit breaker. indices.breaker.accounting.overhead - A constant (1) that is multiplied to determine a final estimation. Useful Commands GET /_nodes/stats/breaker To retrieve the current memory use per node and per breaker. GET _cat/nodes?v=true&h=id,r,ram,heap* To obtain information about heap and memory details per node. GET /_cluster/settings?include_defaults=true It will return explicitly defined and default setting in the cluster including breaker settings. GET _nodes/stats?filter_path=nodes..jvm.mem.pools.old To calculate the JVM memory pressure of each node. Use the response to calculate memory pressure as JVM Memory Pressure = used_in_bytes / max_in_bytes. Circuit Breaker Exception Example Above is an example of a circuit breaker error message which I had encountered while working with AWS OpenSearch Service. The error will result in a 429 status code. Let\\u2019s look into the error more closely and try to understand what is happening here. type - It specifies the type of the exception raised. reason - More detailed information about the reason which led to the mentioned exception. [parent] - It specifies that the parent circuit breaker exception has resulted in the error. The default parent circuit breaker setting is 95%. real usage - It defines the current heap usage. new bytes reserved - It specifies the number of new bytes required. limit of - It is the maximum memory allocation for the parent circuit breaker. If the real usage + new bytes reserved exceeds the limit of, the parent circuit breaker will be triggered. durability - It specifies if the issue that triggered the circuit breaker eventually resolves itself (TRANSIENT) or calls for manual intervention (PERMANENT). Suggestions Reduce JVM memory pressure - High JVM memory pressure often causes circuit breaker errors. Check the JVM memory pressure and try to reduce it using the following suggestions. Reduce the shard numbers of each index- For search latency workloads use a shard size between 10\\u201330 GiB. For write-heavy workloads use a shard size between 30\\u201350 GiB. On a given node, have no more than 20 shards per GiB of Java heap. Avoid searches that might be very expensive (Using large size in pagination). Enable slow logs for identifying expensive search queries. Aggregation, wildcards, and wide time ranges in your queries might also result in high JVM pressure. A mapping explosion, which consumes a lot of memory, might result from defining too many fields or nesting fields too deeply. Avoid sending a large number of requests at the same time or tuning bulk size according to your workload. Increase the cluster\\u2019s size to get an extra JVM heap to handle yours. Disable and avoid using fielddata as it can consume a large amount of heap space. Monitoring OpenSearch cluster metrics with Amazon CloudWatch and create alarms for various cluster metrics. Enable logs for better observability of the errors and issues. Innovate faster, and go farther with serverless-native application development. Explore limitless possibilities with AntStack's serverless solutions. Empowering your business to achieve your most audacious goals. Talk to us Author(s) Somya Sharma Backend Dev currently focusing on AWS Services, Algorithms, and Serverless Application Development. Tags aws elasticsearch opensearch Share this blog Subscribe to newsletter Your Digital Journey deserves a great story. Build one with us. Talk to us Recommended Blogs Krishna Muddi 6 min read Oct 20, 2025 Managing Roles and Permissions in Amazon OpenSearch with AWS SSO Oct 20, 2025 Krishna Muddi 5 min read Sep 15, 2025 Integrating Amazon OpenSearch with AWS SSO for Secure Authentication Sep 15, 2025 Jeevan Dongre 5 min read Jul 11, 2025 Why Your Menu API Is Slowing Down Your QSR Jul 11, 2025 Jeevan Dongre 6 min read Jun 12, 2025 The Hidden Cost of Status Quo: Why Healthcare CTOs Can't Afford to Delay Modernization Jun 12, 2025 Vishwasa Navada K 5 min read Jun 2, 2025 Comparison of LLM Prompt Caching: Cloudflare AI Gateway, Portkey, and Amazon Bedrock Jun 2, 2025 Jeevan Dongre 6 min read May 29, 2025 Breaking Through the 3 Major Roadblocks to Healthcare Modernization: The Serverless Way May 29, 2025 This website stores cookies on your computer. These cookies are used to collect information about how you interact with this website and allow us to remember you. We use this information to improve and customize your browsing experience, as well as for analytics. If you decline, your information won\\u2019t be tracked when you visit this website. A single cookie will be used in your browser to remember your preference. Decline Accept Services DesignUI EngineeringApplication DevelopmentApplication ModernizationData Engineering & ModernizationAI Engineering Industries Small and mid level enterprisesHealthcareQSRMedia & EntertainmentBFSISaaSLogistics Quick links BlogEventsCase StudiesGuidesTalksServerlessServerless ToolsServerless Architecture Company About usAntVerseCareersPrivacy PolicyBrand GuidelinesTrust Center Headquarters AntStack Inc. 8 The Green STE D, Dover, Kent, 19901, USA. +1 (650) 305-6238 Delivery Centre AntStack Technologies Private Limited #620, 3rd Floor, Dr Rajkumar Rd, 2nd Block, 1st Main, Rajajinagar, Bengaluru, Karnataka 560010 080-41330449 / +91-9353139419 Follow Subscribe to our newsletter Our bi-weekly newsletter delivers serverless, AI, tech trends, podcasts and blogs straight to your inbox. Subscribe \\u00a9 2019 - 2025 AntStack. All Rights Reserved.\\\"},{\\\"url\\\":\\\"https://forum.opensearch.org/t/opensearch-high-memory-usage-circuit-breaker-exceptions/26416\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"OpenSearch OpenSearch - High Memory usage / Circuit Breaker Exceptions OpenSearch troubleshoot aidevelop46 August 18, 2025, 9:46am 1 Versions (relevant - OpenSearch/Dashboard/Server OS/Browser): OpenSearch 2.11 Describe the issue: In my case, my cluster started triggering numerous circuit breaker exception alerts. More informations about my cluster/operation: In this case where the circuit_breaker occurred the document size was 3.57 KB. I have some documents bigger than this, but i dont think the average are \\u201ctoo big\\u201d. In this case where the circuit_breaker error occurred, the document contained neither nested nor parent-child. In my system we have several bulk requests, I also wouldn\\u2019t know how big these requests are and how many are occurring at the same time. Configuration: 6 Nodes with this current configuration showed in the image below Relevant Logs or Screenshots: image628\\u00d7850 138 KB Despite my limited experience with Elastic, I truly believe that the reason the cluster are triggering so many circuit_breaker requests has more to do with how I\\u2019m using Elastic than with my cluster\\u2019s configuration, which I think is \\u201cnormal/good.\\u201d I think the biggest problem is that Elastic is the single source of truth for my entire system. I don\\u2019t think Elastic is designed for that. This means I have thousands of read/write operations occurring simultaneously. Do you agree with this? Thanks for all! Leeroy August 18, 2025, 5:44pm 2 Hey @aidevelop46 , Looking at what you provided it looks that you\\u2019re using Elasticsearch? Could you confirm this? Ram usage being high might indicate that additional ram is required especially if you\\u2019re seeing issues with circuit_breaker or high heap usage. However it is hard to say much without first knowing more about the issue, so I first would like to ask a few questions. What version of Elasticsearch? Opensearch? are you using? Are you using roles? If so how many nodes of each are you using and what are their specs? - Creating a cluster - OpenSearch Documentation How many documents are you updating over say 15 minutes? Has this recently grown in number? Are updates being pushed in bulk? Bulk - OpenSearch Documentation Leeroy. Related topics Topic Replies Views Activity How to Solve Circuit Breaker Exception [Data too large] Performance Analyzer troubleshoot 6 22371 April 26, 2022 Circuit_breaking_exception error on kubernetes General Feedback 1 2015 January 3, 2020 Heap Memory Issues Open Source Elasticsearch and Kibana 6 4403 April 6, 2021 Essential Memory Metrics to monitor? DevOps troubleshoot 4 25 November 1, 2025 Parents circuit breaker tripping for the same node after upgrade to opensearch 2.16.0 OpenSearch troubleshoot , configure , upgrade 3 276 August 31, 2024 Home Categories Guidelines Terms of Service Privacy Policy Powered by Discourse, best viewed with JavaScript enabled\\\"},{\\\"url\\\":\\\"https://github.com/opensearch-project/OpenSearch/issues/12475\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to content Navigation Menu Toggle navigation Sign in Appearance settings Platform AI CODE CREATION GitHub CopilotWrite better code with AI GitHub SparkBuild and deploy intelligent apps GitHub ModelsManage and compare prompts MCP RegistryNewDiscover and integrate external tools DEVELOPER WORKFLOWS ActionsAutomate any workflow CodespacesInstant dev environments IssuesPlan and track work Code ReviewManage code changes APPLICATION SECURITY GitHub Advanced SecurityFind and fix vulnerabilities Code securitySecure your code as you build Secret protectionStop leaks before they start EXPLORE Why GitHub Documentation Blog Changelog Marketplace View all features Solutions BY COMPANY SIZE Enterprises Small and medium teams Startups Nonprofits BY USE CASE App Modernization DevSecOps DevOps CI/CD View all use cases BY INDUSTRY Healthcare Financial services Manufacturing Government View all industries View all solutions Resources EXPLORE BY TOPIC AI Software Development DevOps Security View all topics EXPLORE BY TYPE Customer stories Events & webinars Ebooks & reports Business insights GitHub Skills SUPPORT & SERVICES Documentation Customer support Community forum Trust center Partners Open Source COMMUNITY GitHub SponsorsFund open source developers PROGRAMS Security Lab Maintainer Community Accelerator Archive Program REPOSITORIES Topics Trending Collections Enterprise ENTERPRISE SOLUTIONS Enterprise platformAI-powered developer platform AVAILABLE ADD-ONS GitHub Advanced SecurityEnterprise-grade security features Copilot for BusinessEnterprise-grade AI features Premium SupportEnterprise-grade 24/7 support Pricing Search or jump to... Search code, repositories, users, issues, pull requests... Search Clear Search syntax tips Provide feedback We read every piece of feedback, and take your input very seriously. Include my email address so I can be contacted Cancel Submit feedback Saved searches Use saved searches to filter your results more quickly Name Query To see all available qualifiers, see our documentation. Cancel Create saved search Sign in Sign up Appearance settings Resetting focus You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert {{ message }} opensearch-project / OpenSearch Public Notifications You must be signed in to change notification settings Fork 2.3k Star 11.8k Code Issues 2.2k Pull requests 275 Actions Projects 3 Wiki Security Uh oh! There was an error while loading. Please reload this page. Insights Additional navigation options Code Issues Pull requests Actions Projects Wiki Security Insights [BUG] Circuit breaker exceptions due to misconfigured fielddata cache size and circuit breaker for fieldcache #12475 New issue Copy link New issue Copy link Open Open [BUG] Circuit breaker exceptions due to misconfigured fielddata cache size and circuit breaker for fieldcache#12475 Copy link Labels SearchSearch query, autocomplete ...etcSearch query, autocomplete ...etcSearch:ResiliencybugSomething isn't workingSomething isn't workinglucene Description vikasvb90 opened on Feb 27, 2024 Issue body actions Describe the bug We allow users to configure setting indices.breaker.fielddata.limit lesser than indices.fielddata.cache.size. If this happens and if fielddata cache is enabled on one or more fields then it is possible for fielddata cache to grow beyond fielddata breaker limit. This can happen if there is a sudden burst of heavy search queries which can fill up the cache with more field data than CB limit before circuit breaker starts kicking in. Due to this, subsequent search queries or aggregations on fielddata cache enabled fields will start failing with circuit breaker exceptions. [2024-02-25T09:00:44,638][DEBUG][o.o.a.s.TransportSearchAction] [f92acfa0c58f3643980f1cada9df945d] [l3F63B3JR0KY7qbJ5cyJAg][.opendistro-ism-config][1]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[.opendistro-ism-config], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, expand_wildcards_hidden=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], routing='null', preference='_shards:1|_primary', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=null, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={\\\\\\\"size\\\\\\\":100,\\\\\\\"query\\\\\\\":{\\\\\\\"match_all\\\\\\\":{\\\\\\\"boost\\\\\\\":1.0}},\\\\\\\"version\\\\\\\":true,\\\\\\\"seq_no_primary_term\\\\\\\":true,\\\\\\\"sort\\\\\\\":[{\\\\\\\"_id\\\\\\\":{\\\\\\\"order\\\\\\\":\\\\\\\"asc\\\\\\\",\\\\\\\"missing\\\\\\\":\\\\\\\"_last\\\\\\\",\\\\\\\"unmapped_type\\\\\\\":\\\\\\\"keyword\\\\\\\"}}],\\\\\\\"search_after\\\\\\\":[\\\\\\\"\\\\\\\"]}, cancelAfterTimeInterval=null, pipeline=null}] lastShard [true][2024-02-25T09:00:44,638][DEBUG][o.o.a.s.TransportSearchAction] [f92acfa0c58f3643980f1cada9df945d] #[org.opensearch.OpenSearchException,java.util.concurrent.ExecutionException,org.opensearch.core.common.breaker.CircuitBreakingException]#All shards failed for phase: [query]\\\\nOpenSearchException[java.util.concurrent.ExecutionException: CircuitBreakingException[[fielddata] Data too large, data for [_id] would be [3469348057/3.2gb], which is larger than the limit of [515396075/491.5mb]]]; nested: ExecutionException[CircuitBreakingException[[fielddata] Data too large, data for [_id] would be [3469348057/3.2gb], which is larger than the limit of [515396075/491.5mb]]]; nested: CircuitBreakingException[[fielddata] Data too large, data for [_id] would be [3469348057/3.2gb], which is larger than the limit of [515396075/491.5mb]];\\\\n        at org.opensearch.index.fielddata.plain.AbstractIndexOrdinalsFieldData.load(AbstractIndexOrdinalsFieldData.java:116)\\\\n        at org.opensearch.index.fielddata.plain.AbstractIndexOrdinalsFieldData.load(AbstractIndexOrdinalsFieldData.java:62)\\\\n        at org.opensearch.index.mapper.IdFieldMapper$IdFieldType$1$1.load(IdFieldMapper.java:209)\\\\n        at org.opensearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource.getValues(BytesRefFieldComparatorSource.java:91)\\\\n        at org.opensearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$2.getBinaryDocValues(BytesRefFieldComparatorSource.java:141)\\\\n        at org.apache.lucene.search.FieldComparator$TermValComparator.getLeafComparator(FieldComparator.java:280)\\\\n        at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:176)\\\\n        at org.apache.lucene.search.TopFieldCollector$TopFieldLeafCollector.<init>(TopFieldCollector.java:64)\\\\n        at org.apache.lucene.search.TopFieldCollector$PagingFieldCollector$1.<init>(TopFieldCollector.java:254)\\\\n        at org.apache.lucene.search.TopFieldCollector$PagingFieldCollector.getLeafCollector(TopFieldCollector.java:254)\\\\n        at org.opensearch.search.internal.ContextIndexSearcher.searchLeaf(ContextIndexSearcher.java:306)\\\\n        at org.opensearch.search.internal.ContextIndexSearcher.search(ContextIndexSearcher.java:281)\\\\n        at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:551)\\\\n        at org.opensearch.search.query.QueryPhase.searchWithCollector(QueryPhase.java:360)\\\\n        at org.opensearch.search.query.QueryPhase$DefaultQueryPhaseSearcher.searchWithCollector(QueryPhase.java:447)\\\\n        at org.opensearch.search.query.QueryPhase$DefaultQueryPhaseSearcher.searchWith(QueryPhase.java:431)\\\\n        at org.opensearch.search.query.QueryPhaseSearcherWrapper.searchWith(QueryPhaseSearcherWrapper.java:65)\\\\n        at org.opensearch.neuralsearch.search.query.HybridQueryPhaseSearcher.searchWith(HybridQueryPhaseSearcher.java:66)\\\\n        at org.opensearch.search.query.QueryPhase.executeInternal(QueryPhase.java:282)\\\\n        at org.opensearch.search.query.QueryPhase.execute(QueryPhase.java:155)\\\\n        at org.opensearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:533)\\\\n        at org.opensearch.search.SearchService.executeQueryPhase(SearchService.java:597)\\\\n        at org.opensearch.search.SearchService$2.lambda$onResponse$0(SearchService.java:566)\\\\n        at org.opensearch.action.ActionRunnable.lambda$supply$0(ActionRunnable.java:74)\\\\n        at org.opensearch.action.ActionRunnable$2.doRun(ActionRunnable.java:89)\\\\n        at org.opensearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:917)\\\\n        at org.opensearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:52)\\\\n        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\\\\n        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\\\\n        at java.base/java.lang.Thread.run(Thread.java:833)\\\\n Related component Search:Resiliency To Reproduce One way to potentially reproduce this is Create an index with field data cache enabled on some of the text value fields. Ingest data till field data cache reaches (say 20%). Use GET /_cat/fielddata for monitoring. Set breaker limit to 1%. Execute heavy search queries (resulting in >1% of data size) on fields with field data cache enabled. Expected behavior A validation should be added in OpenSearch to reject update setting request if indices.breaker.fielddata.limit is less than indices.fielddata.cache.size. Default value of indices.breaker.fielddata.limit is 40% of JVM and default cache size is unbounded. We should also consider setting the default cache size to be less than default breaker limit (say 38%). Additional Details Plugins Please list all plugins currently enabled. Screenshots If applicable, add screenshots to help explain your problem. Host/Environment (please complete the following information): OS: [e.g. iOS] Version [e.g. 22] Additional context Add any other context about the problem here. Metadata Metadata Assignees No one assigned Labels SearchSearch query, autocomplete ...etcSearch query, autocomplete ...etcSearch:ResiliencybugSomething isn't workingSomething isn't workinglucene Type No type Projects Search Project Board Status Later (6 months plus) Show more project fields Milestone No milestone Relationships None yet Development No branches or pull requests Issue actions Footer \\u00a9 2025 GitHub, Inc. Footer navigation Terms Privacy Security Status Community Docs Contact Manage cookies Do not share my personal information You can\\u2019t perform that action at this time.\\\"}]}\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Search for error resolution\n",
    "parameters = {\n",
    "    \"question\": \"How to fix circuit breaker errors in OpenSearch\"\n",
    "}\n",
    "\n",
    "print(\"‚ùì Question: How to fix circuit breaker errors in OpenSearch\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "response = execute_agent(client, agent_id, parameters)\n",
    "\n",
    "print(\"\\nüîß Troubleshooting Information:\")\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12812a91",
   "metadata": {},
   "source": [
    "## üí° Alternative Configuration: Google Custom Search\n",
    "\n",
    "If you have Google Custom Search credentials, you can use this configuration:\n",
    "\n",
    "```python\n",
    "# Google Custom Search configuration (requires API key)\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"WebSearchTool\",\n",
    "        \"parameters\": {\n",
    "            \"engine\": \"google\",\n",
    "            \"engine_id\": \"your_google_engine_id\",\n",
    "            \"api_key\": \"your_google_api_key\",\n",
    "            \"input\": \"${parameters.question}\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "### Getting Google Custom Search Credentials:\n",
    "1. Create a Google Custom Search Engine at: https://programmablesearchengine.google.com/\n",
    "2. Get your Engine ID from the control panel\n",
    "3. Get an API key from: https://developers.google.com/custom-search/v1/overview\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea8fc77",
   "metadata": {},
   "source": [
    "## üí° Alternative Configuration: Custom Search API\n",
    "\n",
    "For custom search endpoints:\n",
    "\n",
    "```python\n",
    "# Custom search API configuration\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"WebSearchTool\",\n",
    "        \"parameters\": {\n",
    "            \"engine\": \"custom\",\n",
    "            \"endpoint\": \"https://api.your-search-engine.com/search\",\n",
    "            \"custom_res_url_jsonpath\": \"$.data[*].link\",\n",
    "            \"Authorization\": \"Bearer your_api_token\",\n",
    "            \"query_key\": \"q\",\n",
    "            \"offset_key\": \"offset\",\n",
    "            \"limit_key\": \"limit\",\n",
    "            \"input\": \"${parameters.question}\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "### Custom API Parameters:\n",
    "- **endpoint**: Your search API URL\n",
    "- **custom_res_url_jsonpath**: JSONPath to extract result URLs\n",
    "- **Authorization**: Authentication header\n",
    "- **query_key**: URL parameter name for search query\n",
    "- **offset_key**: URL parameter for pagination offset\n",
    "- **limit_key**: URL parameter for result limit\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f193498",
   "metadata": {},
   "source": [
    "## üéì Key Takeaways\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **WebSearchTool Capabilities**:\n",
    "   - ‚úÖ **DuckDuckGo**: No API key, easy setup, good for testing\n",
    "   - ‚úÖ **Google Custom Search**: More results, requires credentials\n",
    "   - ‚úÖ **Custom APIs**: Integrate any search endpoint\n",
    "   - ‚úÖ External knowledge augmentation for agents\n",
    "\n",
    "2. **Search Engine Comparison**:\n",
    "   | Engine | API Key | Cost | Results Quality | Setup |\n",
    "   |--------|---------|------|-----------------|-------|\n",
    "   | DuckDuckGo | ‚ùå Not Required | Free | Good | Easy |\n",
    "   | Google | ‚úÖ Required | Free tier + paid | Excellent | Moderate |\n",
    "   | Custom | ‚úÖ Required | Varies | Varies | Complex |\n",
    "\n",
    "3. **Practical Use Cases**:\n",
    "   - üìö **Documentation Lookup**: Find external docs and guides\n",
    "   - üì∞ **Current Events**: Get real-time information\n",
    "   - üîç **Research**: Gather external context for queries\n",
    "   - üéì **Learning**: Help users find educational content\n",
    "   - üîß **Troubleshooting**: Find solutions to technical problems\n",
    "\n",
    "4. **Integration Patterns**:\n",
    "   ```python\n",
    "   # Hybrid agent: Internal + External search\n",
    "   tools = [\n",
    "       {\"type\": \"VectorDBTool\", ...},    # Internal semantic search\n",
    "       {\"type\": \"WebSearchTool\", ...},   # External web search\n",
    "       {\"type\": \"MLModelTool\", ...}      # Synthesize answers\n",
    "   ]\n",
    "   ```\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "- ‚úÖ **Start with DuckDuckGo** for development (no credentials needed)\n",
    "- ‚úÖ **Cache Results** to avoid repeated API calls\n",
    "- ‚úÖ **Rate Limiting** respect search engine limits\n",
    "- ‚úÖ **Fallback Strategy** have backup search engines\n",
    "- ‚úÖ **Result Filtering** parse and validate search results\n",
    "\n",
    "### Security Considerations:\n",
    "\n",
    "- üîí **API Keys**: Store in environment variables, not code\n",
    "- üîí **Input Validation**: Sanitize user queries\n",
    "- üîí **Result Verification**: Validate external content\n",
    "- üîí **Privacy**: Be aware of data sent to external services\n",
    "\n",
    "### Performance Tips:\n",
    "\n",
    "- ‚ö° **Parallel Searches**: Run internal and external searches concurrently\n",
    "- ‚ö° **Result Limits**: Fetch only what you need\n",
    "- ‚ö° **Timeout Configuration**: Set appropriate timeouts\n",
    "- ‚ö° **Error Handling**: Gracefully handle search failures\n",
    "\n",
    "### Combining Internal and External Search:\n",
    "\n",
    "```python\n",
    "# Example workflow:\n",
    "# 1. Search internal indices (VectorDBTool)\n",
    "# 2. If no results, search web (WebSearchTool)\n",
    "# 3. Synthesize answer from both sources (MLModelTool)\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"VectorDBTool\",\n",
    "        \"parameters\": {\n",
    "            \"index\": \"knowledge_base\",\n",
    "            \"embedding_field\": \"embedding\",\n",
    "            \"source_field\": [\"content\"],\n",
    "            \"input\": \"${parameters.question}\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"WebSearchTool\",\n",
    "        \"parameters\": {\n",
    "            \"engine\": \"duckduckgo\",\n",
    "            \"input\": \"${parameters.question}\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8ba1ac",
   "metadata": {},
   "source": [
    "## üßπ Cleanup (Optional)\n",
    "\n",
    "Uncomment and run this cell to clean up resources created in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b581321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delete the flow agent\n",
    "# cleanup_resources(\n",
    "#     client=client,\n",
    "#     agent_ids=[agent_id]\n",
    "# )\n",
    "\n",
    "# print(\"‚úÖ Cleanup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33ad019",
   "metadata": {},
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "Now that you understand WebSearchTool, explore:\n",
    "- **RAGTool**: Combine web search with retrieval-augmented generation\n",
    "- **MLModelTool**: Synthesize information from multiple sources\n",
    "- **AgentTool**: Build multi-agent systems with specialized search agents\n",
    "- **VectorDBTool**: Combine semantic search with web search\n",
    "\n",
    "---\n",
    "\n",
    "üìö **Resources**:\n",
    "- [DuckDuckGo Instant Answer API](https://duckduckgo.com/api)\n",
    "- [Google Custom Search](https://developers.google.com/custom-search/v1/overview)\n",
    "- [ML Commons Agent Tools](https://opensearch.org/docs/latest/ml-commons-plugin/agents-tools/)\n",
    "- [Web Search Tool Documentation](https://opensearch.org/docs/latest/ml-commons-plugin/agents-tools/tools/web-search-tool/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-ml-search-with-opensearch (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
