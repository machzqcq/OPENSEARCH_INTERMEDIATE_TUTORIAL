{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbdd9d4e",
   "metadata": {},
   "source": [
    "# üåê WebSearchTool - Integrate External Web Search\n",
    "\n",
    "```mermaid\n",
    "%%{init: {'theme':'base', 'themeVariables': { 'primaryColor':'#3498DB', 'primaryTextColor':'#fff', 'primaryBorderColor':'#2980B9', 'lineColor':'#F39C12', 'secondaryColor':'#E67E22', 'tertiaryColor':'#27AE60', 'fontSize':'16px'}}}%%\n",
    "graph TB\n",
    "    A[üë§ User Query<br/>OpenSearch features] --> B[ü§ñ Flow Agent]\n",
    "    B --> C{üåê WebSearchTool}\n",
    "    C --> D[üîç DuckDuckGo API]\n",
    "    D --> E[üåç Web Search]\n",
    "    E --> F[üìÑ Top Results]\n",
    "    F --> G[üì§ Formatted Response]\n",
    "    \n",
    "    style A fill:#3498DB,stroke:#2980B9,color:#fff\n",
    "    style C fill:#3498DB,stroke:#2980B9,color:#fff\n",
    "    style D fill:#E67E22,stroke:#D35400,color:#fff\n",
    "    style E fill:#1ABC9C,stroke:#16A085,color:#fff\n",
    "    style G fill:#27AE60,stroke:#229954,color:#fff\n",
    "```\n",
    "\n",
    "## üìö Learning Objectives\n",
    "\n",
    "In this notebook, you'll learn:\n",
    "1. ‚úÖ How to use **WebSearchTool** to integrate external web search\n",
    "2. ‚úÖ Using **DuckDuckGo** for web search (no API key required)\n",
    "3. ‚úÖ Configuring **Google Custom Search** (when API key available)\n",
    "4. ‚úÖ Integrating **custom search APIs**\n",
    "5. ‚úÖ Building agents that combine internal and external knowledge\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ What is WebSearchTool?\n",
    "\n",
    "**WebSearchTool** enables OpenSearch agents to search the external web using various search engines. This is essential for:\n",
    "- üåç **External Knowledge**: Access information beyond your indices\n",
    "- üì∞ **Real-Time Data**: Get current information not in your database\n",
    "- üîó **Augmented Answers**: Combine internal data with web sources\n",
    "- üéì **Research Automation**: Gather external context automatically\n",
    "\n",
    "**Key Features**:\n",
    "- **DuckDuckGo**: No API key required, simple setup\n",
    "- **Google Custom Search**: More results, requires API key\n",
    "- **Custom APIs**: Integrate any HTTP search endpoint\n",
    "- No LLM required for search execution\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913e052d",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35143e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "\n",
    "# Add parent directory to path to import helper functions\n",
    "sys.path.append('..')\n",
    "from agent_helpers import (\n",
    "    get_os_client,\n",
    "    create_flow_agent,\n",
    "    execute_agent,\n",
    "    cleanup_resources\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c92d51",
   "metadata": {},
   "source": [
    "## Step 2: Initialize OpenSearch Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c84be0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to OpenSearch cluster: docker-cluster\n",
      "üìä Version: 3.3.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenSearch client\n",
    "client = get_os_client()\n",
    "\n",
    "# Verify connection\n",
    "info = client.info()\n",
    "print(f\"‚úÖ Connected to OpenSearch cluster: {info['cluster_name']}\")\n",
    "print(f\"üìä Version: {info['version']['number']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285a2f77",
   "metadata": {},
   "source": [
    "## Step 3: Create Flow Agent with WebSearchTool (DuckDuckGo)\n",
    "\n",
    "We'll start with DuckDuckGo since it doesn't require an API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca35426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Registering flow agent: Web_Search_Agent_DDG...\n",
      "   ‚úì Agent registered: 31tWiZsBLQ1mV2UNGyhA\n",
      "‚úÖ Flow agent created with ID: 31tWiZsBLQ1mV2UNGyhA\n",
      "üîß Tool configured: WebSearchTool\n",
      "üîç Search Engine: DuckDuckGo (no API key required)\n"
     ]
    }
   ],
   "source": [
    "# Define the tool configuration for DuckDuckGo\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"WebSearchTool\",\n",
    "        \"parameters\": {\n",
    "            \"engine\": \"duckduckgo\",\n",
    "            \"input\": \"${parameters.question}\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create the flow agent\n",
    "agent_id = create_flow_agent(\n",
    "    client,\n",
    "    \"Web_Search_Agent_DDG\",\n",
    "    \"An agent that searches the web using DuckDuckGo to find external information\",\n",
    "    tools\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Flow agent created with ID: {agent_id}\")\n",
    "print(f\"üîß Tool configured: WebSearchTool\")\n",
    "print(f\"üîç Search Engine: DuckDuckGo (no API key required)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a3108b",
   "metadata": {},
   "source": [
    "## Step 4: Test Case 1 - Search for OpenSearch Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eaef3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì Question: How to create an index pattern in OpenSearch?\n",
      "============================================================\n",
      "\n",
      "üåê Web Search Results:\n",
      "{\n",
      "  \"inference_results\": [\n",
      "    {\n",
      "      \"output\": [\n",
      "        {\n",
      "          \"name\": \"response\",\n",
      "          \"result\": \"{\\\"next_page\\\":\\\"https://duckduckgo.com/html?q=How+to+create+an+index+pattern+in+OpenSearch?&s=10&nextParams=&v=l&o=json&dc=11&api=d.js&vqd=4-321194528568791297759673578127466998176&kl=wt-wt\\\",\\\"items\\\":[{\\\"url\\\":\\\"https://docs.opensearch.org/latest/dashboards/management/index-patterns/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Discovery and cluster formation Node discovery and seed hosts Voting and quorum Voting configuration management Cluster bootstrapping Discovery and cluster formation settings Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Remote segment warmer Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Similarity Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Resource access management Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates OpenSearch FIPS configuration Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control Defining users and roles Permissions Default action groups REST layer authorization Document-level security Field-level security Field masking User impersonation Resource sharing and access control Resource sharing APIs API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Version Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Mapping explosion Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Rescore Regular expression syntax SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic queries Complex queries Functions JSON support Metadata queries Aggregate functions Delete JDBC driver ODBC driver PPL Subsearch Commands PPL syntax ad addcoltotals addtotals append appendcol appendpipe bin chart dedup describe eval eventstats expand explain fields fillnull flatten grok head join kmeans lookup ml multisearch parse patterns rare regex rename replace reverse rex search show datasources sort spath stats streamstats subquery table timechart top trendline where Identifiers Data types Functions Full-text search Settings Troubleshooting Monitoring Limitations Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Collecting UBI-formatted data in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Model access control through resource sharing Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller ML Tasks APIs Get ML task Search ML tasks Delete ML task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow access control Workflow settings Workflow state access control Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detector access control Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecaster access control Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions OpenSearch Dashboards Dashboards Management Index patterns Index patterns Index patterns are essential for accessing OpenSearch data. An index pattern references one or more indexes, data streams, or index aliases. For example, an index pattern can point you to your log data from yesterday or all indexes that contain that data. If you store data in multiple indexes, creating an index pattern enables your visualizations to retrieve data from all indexes that match the index pattern. You need to create index patterns to define how data is retrieved and fields are formatted so that you can query, search, and display data. Get started In this tutorial, you\\u2019ll learn to create index patterns. Note To create or modify index patterns, you must have create, manage, and delete permissions. Contact your administrator for support. For more information, refer to Multi-tenancy configuration. Prerequisites Before you can create an index pattern, your data must be indexed. To learn about indexing your data in OpenSearch, see Managing indexes. Best practices Consider the following best practices when creating index patterns: Make your index patterns specific. Instead of creating an index pattern that matches all indexes, create an index pattern that matches all indexes starting with a certain prefix, for example, my-index-. The more specific your index patterns, the better it will be to query and analyze your data. Use wildcards sparingly. Wildcards can be useful for matching multiple indexes, but they can also make it more difficult to manage your index patterns. Try to use wildcards as specifically as possible. Test your index patterns. Make sure to test your index patterns to ensure that they match the correct indexes. Creating an index pattern If you added sample data, you have index patterns that you can use to analyze that data. To create an index pattern for your own data, follow these steps. Step 1: Define the index pattern Go to OpenSearch Dashboards, and select Management > Dashboards Management > Index patterns. Select Create index pattern. From the Create index pattern window, define the index pattern by entering a name for your index pattern in the Index pattern name field. Dashboards automatically adds a wildcard, *, once you start typing. Using a wildcard is helpful for matching an index pattern to multiple sources or indexes. A dropdown list displaying all the indexes that match your index pattern appears when you start typing. Select Next step. An example of step 1 is shown in the following image. Note that the index pattern security* matches three indexes. By defining the pattern with a wildcard *, you can query and visualize all the data in your indexes. Step 2: Configure the settings Select @timestamp from the dropdown menu to specify the time field for OpenSearch to use when filtering documents based on time. Selecting this time filter determines which field the time filter is applied to. It can be the timestamp of a request or any relevant timestamp field. If you don\\u2019t want to use a time filter, select that option from the dropdown menu. If you select this option, OpenSearch returns all of the data in the indexes that match the pattern. Select Create index pattern. An example is shown in the following image. Once the index pattern has been created, you can view the mapping of the matching indexes. Within the table, you can see the list of fields, along with their data type and properties. An example is shown in the following image. Next steps Understand your data through visuals. Dig into your data. Get started Prerequisites Best practices Creating an index pattern Step 1: Define the index pattern Step 2: Configure the settings Next steps WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright \\u00a9 OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\\\"},{\\\"url\\\":\\\"https://github.com/opensearch-project/opensearch-py/blob/main/guides/index_template.md\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to content Navigation Menu Toggle navigation Sign in Appearance settings Platform AI CODE CREATION GitHub CopilotWrite better code with AI GitHub SparkBuild and deploy intelligent apps GitHub ModelsManage and compare prompts MCP RegistryNewIntegrate external tools DEVELOPER WORKFLOWS ActionsAutomate any workflow CodespacesInstant dev environments IssuesPlan and track work Code ReviewManage code changes APPLICATION SECURITY GitHub Advanced SecurityFind and fix vulnerabilities Code securitySecure your code as you build Secret protectionStop leaks before they start EXPLORE Why GitHub Documentation Blog Changelog Marketplace View all features Solutions BY COMPANY SIZE Enterprises Small and medium teams Startups Nonprofits BY USE CASE App Modernization DevSecOps DevOps CI/CD View all use cases BY INDUSTRY Healthcare Financial services Manufacturing Government View all industries View all solutions Resources EXPLORE BY TOPIC AI Software Development DevOps Security View all topics EXPLORE BY TYPE Customer stories Events & webinars Ebooks & reports Business insights GitHub Skills SUPPORT & SERVICES Documentation Customer support Community forum Trust center Partners Open Source COMMUNITY GitHub SponsorsFund open source developers PROGRAMS Security Lab Maintainer Community Accelerator Archive Program REPOSITORIES Topics Trending Collections Enterprise ENTERPRISE SOLUTIONS Enterprise platformAI-powered developer platform AVAILABLE ADD-ONS GitHub Advanced SecurityEnterprise-grade security features Copilot for BusinessEnterprise-grade AI features Premium SupportEnterprise-grade 24/7 support Pricing Search or jump to... Search code, repositories, users, issues, pull requests... Search Clear Search syntax tips Provide feedback We read every piece of feedback, and take your input very seriously. Include my email address so I can be contacted Cancel Submit feedback Saved searches Use saved searches to filter your results more quickly Name Query To see all available qualifiers, see our documentation. Cancel Create saved search Sign in Sign up Appearance settings Resetting focus You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert {{ message }} opensearch-project / opensearch-py Public generated from amazon-archives/__template_Custom Notifications You must be signed in to change notification settings Fork 213 Star 450 Code Issues 77 Pull requests 12 Actions Projects 0 Security Uh oh! There was an error while loading. Please reload this page. Insights Additional navigation options Code Issues Pull requests Actions Projects Security Insights Footer \\u00a9 2026 GitHub, Inc. Footer navigation Terms Privacy Security Status Community Docs Contact Manage cookies Do not share my personal information You can\\u2019t perform that action at this time.\\\"},{\\\"url\\\":\\\"https://www.youtube.com/watch?v=pbABIerUYQI\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"AboutPressCopyrightContact usCreatorsAdvertiseDevelopersTermsPrivacyPolicy & SafetyHow YouTube worksTest new featuresNFL Sunday Ticket \\u00a9 2026 Google LLC\\\"},{\\\"url\\\":\\\"https://www.bookstack.cn/read/opensearch-2.19-en/4ce9edd150bec500.md\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"\\u00d7 \\u601d\\u7ef4\\u5bfc\\u56fe\\u5907\\u6ce8 \\u5173\\u95ed OpenSearch v2.19 Documentation \\u9996\\u9875 AI\\u52a9\\u624b \\u767d\\u5929 \\u591c\\u95f4 \\u5c0f\\u7a0b\\u5e8f \\u9605\\u8bfb \\u4e66\\u7b7e \\u6211\\u7684\\u4e66\\u7b7e \\u6dfb\\u52a0\\u4e66\\u7b7e \\u79fb\\u9664\\u4e66\\u7b7e Index patterns GitHub \\u6765\\u6e90:OpenSearch \\u6d4f\\u89c8 199 \\u626b\\u7801 2025-05-09 14:09:39 Index patterns Get started Prerequisites Best practices Creating an index pattern Step 1: Define the index pattern Step 2: Configure the settings Next steps You\\u2019re viewing version 2.19 of the OpenSearch documentation. For the latest version, see the current documentation. For information about OpenSearch version maintenance, see Release Schedule and Maintenance Policy. Index patterns Index patterns are essential for accessing OpenSearch data. An index pattern references one or more indexes, data streams, or index aliases. For example, an index pattern can point you to your log data from yesterday or all indexes that contain that data. If you store data in multiple indexes, creating an index pattern enables your visualizations to retrieve data from all indexes that match the index pattern. You need to create index patterns to define how data is retrieved and fields are formatted so that you can query, search, and display data. Get started In this tutorial, you\\u2019ll learn to create index patterns. Note To create or modify index patterns, you must have create, manage, and delete permissions. Contact your administrator for support. For more information, refer to Multi-tenancy configuration. Prerequisites Before you can create an index pattern, your data must be indexed. To learn about indexing your data in OpenSearch, see Managing indexes. Best practices Consider the following best practices when creating index patterns: Make your index patterns specific. Instead of creating an index pattern that matches all indexes, create an index pattern that matches all indexes starting with a certain prefix, for example, my-index-. The more specific your index patterns, the better it will be to query and analyze your data. Use wildcards sparingly. Wildcards can be useful for matching multiple indexes, but they can also make it more difficult to manage your index patterns. Try to use wildcards as specifically as possible. Test your index patterns. Make sure to test your index patterns to ensure that they match the correct indexes. Creating an index pattern If you added sample data, you have index patterns that you can use to analyze that data. To create an index pattern for your own data, follow these steps. Step 1: Define the index pattern Go to OpenSearch Dashboards, and select Management > Dashboards Management > Index patterns. Select Create index pattern. From the Create index pattern window, define the index pattern by entering a name for your index pattern in the Index pattern name field. Dashboards automatically adds a wildcard, *, once you start typing. Using a wildcard is helpful for matching an index pattern to multiple sources or indexes. A dropdown list displaying all the indexes that match your index pattern appears when you start typing. Select Next step. An example of step 1 is shown in the following image. Note that the index pattern security* matches three indexes. By defining the pattern with a wildcard *, you can query and visualize all the data in your indexes. Step 2: Configure the settings Select @timestamp from the dropdown menu to specify the time field for OpenSearch to use when filtering documents based on time. Selecting this time filter determines which field the time filter is applied to. It can be the timestamp of a request or any relevant timestamp field. If you don\\u2019t want to use a time filter, select that option from the dropdown menu. If you select this option, OpenSearch returns all of the data in the indexes that match the pattern. Select Create index pattern. An example is shown in the following image. Once the index pattern has been created, you can view the mapping of the matching indexes. Within the table, you can see the list of fields, along with their data type and properties. An example is shown in the following image. Next steps Understand your data through visuals. Dig into your data. \\u5f53\\u524d\\u5185\\u5bb9\\u7248\\u6743\\u5f52 OpenSearch \\u6216\\u5176\\u5173\\u8054\\u65b9\\u6240\\u6709\\uff0c\\u5982\\u9700\\u5bf9\\u5185\\u5bb9\\u6216\\u5185\\u5bb9\\u76f8\\u5173\\u8054\\u5f00\\u6e90\\u9879\\u76ee\\u8fdb\\u884c\\u5173\\u6ce8\\u4e0e\\u8d44\\u52a9\\uff0c\\u8bf7\\u8bbf\\u95ee OpenSearch . \\u4e0a\\u4e00\\u7bc7: \\u4e0b\\u4e00\\u7bc7: \\u7248\\u672c OpenSearch v3.0 Documentation OpenSearch v2.19 Documentation OpenSearch v2.18 Documentation OpenSearch v2.17 Documentation OpenSearch v2.16 Documentation OpenSearch v2.15 Documentation OpenSearch v2.14 Documentation OpenSearch v2.13 Documentation OpenSearch v2.12 Documentation OpenSearch v2.11 Documentation OpenSearch v2.10 Documentation OpenSearch v2.9 Documentation OpenSearch v2.8 Documentation OpenSearch v2.7 Documentation OpenSearch v2.6 Documentation OpenSearch v2.5 Documentation OpenSearch v2.4 Documentation OpenSearch v2.3 Documentation OpenSearch v2.2 Documentation OpenSearch v2.1 Documentation OpenSearch v2.0 Documentation OpenSearch v1.3 Documentation OpenSearch v1.2 Documentation OpenSearch v1.1 Documentation OpenSearch v1.0 Documentation About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Getting started with OpenSearch security Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Chatbots and agents RAG chatbot Build your own chatbot RAG chatbot with a conversational flow agent AI search workflows Creating and customizing AI search workflows Model guardrails Amazon Bedrock model guardrails Install and upgrade Installing OpenSearch Docker Helm Tarball RPM Debian Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Circuit breaker settings Cluster settings Index settings Search settings Availability and recovery settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Upgrading OpenSearch Rolling Upgrade Upgrades appendix Rolling upgrade lab Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Managing Indexes Index templates Index aliases Data streams Index context Reindex data Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings Index management security Refresh search analyzer ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Ingest Pipelines Create pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove_by_pattern Remove Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data Time filter Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers Gantt charts TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dev Tools Running queries in the Dev Tools console Query Workbench Custom branding Dashboards Query Language (DQL) Configuring CSP rules for frame ancestors Search telemetry OpenSearch Integrations Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Workload management Query Group Lifecycle API Tuning for indexing speed Security in OpenSearch Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings and field types Mapping parameters Analyzer Boost Coerce Copy_to Doc values Dynamic Eager global ordinals Enabled Ignore above Ignore malformed Format Index Index options Fields Meta Normalizer Norms Null value Properties Search analyzer Store Term vector Supported field types Alias Binary Numeric field types Unsigned long Boolean k-NN vector Spaces Methods and engines Memory-optimized vectors Date field types Date Date nanoseconds IP address Range field types Object field types Object Nested Flat object Join String field types Keyword Text Match-only text Wildcard Token count Constant keyword Autocomplete field types Completion Search as you type Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Rank field types Star-tree Derived Percolator Metadata fields Field names ID Ignored Index Meta Routing Source Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Exists Fuzzy IDs Prefix Range Regexp Term Terms Terms set Wildcard Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Distance feature k-NN Neural Neural sparse Script score Template Minimum should match Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Range Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Search features Search options Paginate results Point in Time Point in Time API Sort results Filter results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Comparing search results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI client data structures Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines Search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Identifiers Data Types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Hybrid search with post-filtering Combining hybrid search and aggregations Using sorting with a hybrid query Hybrid search with search_after Hybrid search explain Paginating hybrid query results Multimodal search Neural sparse search Generating sparse vector embeddings automatically Neural sparse search using raw vectors Conversational search with RAG Building AI search workflows in OpenSearch Dashboards Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Specialized vector search Nested field search Radial search Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Performance tuning Indexing performance tuning Search performance tuning LLM framework integration Vector search API k-NN API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Tools Agent tool CAT Index tool Connector tool Index Mapping tool ML Model tool Neural Sparse Search tool PPL tool RAG tool Search Alerts tool CreateAnomalyDetectorTool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Execute agent Get agent Search agent Delete agent Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI OpenSearch Kubernetes Operator Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Index APIs Alias Create or update alias Blocks Clear cache Clone index Open index Index exists Close index Create index Delete index Get index Shrink index Create or update index template Get index template Delete index template Simulate index templates Create or update mappings Create or update component template Dangling indexes Flush Force merge Recovery Get settings Update settings Refresh index Resolve index Roll over index Segment Split index Stats Analyze API Analysis API Terminology CAT API CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster routing and awareness Cluster decommission Cluster health Cluster settings Cluster stats Count Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get document Delete by query Update by query Reindex document Explain Ingest APIs List API List shards List indices Multi-search Multi-search Template Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Profile Ranking evaluation Remote cluster information Script APIs Create or Update Stored Script Execute Painless stored script Get Stored Script Delete Script Get Stored Script Contexts Get Script Language Execute Painless script Scroll Search Search templates Snapshot APIs Register Snapshot Repository Get Snapshot Repository Delete Snapshot Repository Verify Snaphot Repository Create Snapshot Get Snapshot Delete Snapshot Get Snapshot Status Restore Snapshot Clone snapshot Cleanup Snapshot Repository Render Template Security APIs Tasks API List tasks Get task Cancel tasks Validate Query Supported units Common REST Parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions \\u6682\\u65e0\\u76f8\\u5173\\u641c\\u7d22\\u7ed3\\u679c\\uff01 \\u672c\\u6587\\u6863\\u4f7f\\u7528 BookStack \\u6784\\u5efa \\u00d7 \\u6587\\u7ae0\\u4e8c\\u7ef4\\u7801 \\u624b\\u673a\\u626b\\u4e00\\u626b\\uff0c\\u8f7b\\u677e\\u638c\\u4e0a\\u8bfb \\u5173\\u95ed \\u00d7 \\u6587\\u6863\\u4e0b\\u8f7d \\u666e\\u901a\\u4e0b\\u8f7d \\u4e0b\\u8f7d\\u7801\\u4e0b\\u8f7d(\\u514d\\u767b\\u5f55\\u65e0\\u9650\\u4e0b\\u8f7d) \\u4f60\\u4e0e\\u5927\\u795e\\u7684\\u8ddd\\u79bb\\uff0c\\u53ea\\u5dee\\u4e00\\u4e2aAPP \\u8bf7\\u4e0b\\u8f7d\\u60a8\\u9700\\u8981\\u7684\\u683c\\u5f0f\\u7684\\u6587\\u6863\\uff0c\\u968f\\u65f6\\u968f\\u5730\\uff0c\\u4eab\\u53d7\\u6c72\\u53d6\\u77e5\\u8bc6\\u7684\\u4e50\\u8da3\\uff01 PDF\\u6587\\u6863 EPUB\\u6587\\u6863 MOBI\\u6587\\u6863 \\u6e29\\u99a8\\u63d0\\u793a \\u6bcf\\u5929\\u6bcf\\u5728\\u7f51\\u7ad9\\u9605\\u8bfb\\u5b66\\u4e60\\u4e00\\u5206\\u949f\\u65f6\\u957f\\u53ef\\u4e0b\\u8f7d\\u4e00\\u672c\\u7535\\u5b50\\u4e66\\uff0c\\u6bcf\\u5929\\u8fde\\u7eed\\u7b7e\\u5230\\u53ef\\u589e\\u52a0\\u9605\\u8bfb\\u65f6\\u957f \\u4e0b\\u8f7d\\u7801\\u65b9\\u5f0f\\u4e0b\\u8f7d\\uff1a\\u514d\\u8d39\\u3001\\u514d\\u767b\\u5f55\\u3001\\u65e0\\u9650\\u5236\\u3002 \\u514d\\u8d39\\u83b7\\u53d6\\u4e0b\\u8f7d\\u7801 \\u4e0b\\u8f7d\\u7801 \\u6587\\u6863\\u683c\\u5f0f PDF EPUB MOBI \\u7801\\u4e0a\\u4e0b\\u8f7d \\u5173\\u95ed\\u7a97\\u53e3 \\u00d7 \\u5fae\\u4fe1\\u5c0f\\u7a0b\\u5e8f\\u9605\\u8bfb \\u60a8\\u4e0e\\u4ed6\\u4eba\\u7684\\u85aa\\u8d44\\u5dee\\u8ddd\\uff0c\\u53ea\\u5dee\\u4e00\\u4e2a\\u968f\\u65f6\\u968f\\u5730\\u5b66\\u4e60\\u7684\\u5c0f\\u7a0b\\u5e8f \\u5173\\u95ed\\u7a97\\u53e3 \\u00d7 \\u4e66\\u7b7e\\u5217\\u8868 \\u5173\\u95ed \\u00d7 \\u9605\\u8bfb\\u8bb0\\u5f55 \\u9605\\u8bfb\\u8fdb\\u5ea6: 0.00% ( 0/0 ) \\u91cd\\u7f6e\\u9605\\u8bfb\\u8fdb\\u5ea6 \\u5173\\u95ed \\u6b22\\u8fce\\u4f7f\\u7528AI\\u52a9\\u624b AI\\u52a9\\u624b \\u5168\\u5c4f \\u7f29\\u5c0f \\u9690\\u85cf \\u6e05\\u7a7a\\\"},{\\\"url\\\":\\\"https://deepwiki.com/johnny-chivers/amazon-opensearch-service/3.1-index-patterns\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Loading... Index your code with Devin DeepWiki DeepWiki johnny-chivers/amazon-opensearch-service Index your code with Devin Edit Wiki Share Loading... Last indexed: 25 May 2025 (924181) Overview Getting Started Tutorial Domain Setup Data Upload and Indexing Search Operations Cleanup and Domain Deletion Index Management Index Patterns Field Configuration Security and Access Control Access Control Systems Access Policies System Architecture Data Node Architecture Network Configuration Development and Testing Menu Index Patterns Relevant source files pictures/12-define-index-pattern.png pictures/13-createe-index-pattern.png Purpose and Scope This document covers the creation and configuration of index patterns in Amazon OpenSearch Service, specifically focusing on how they enable data discovery and visualization through the OpenSearch Dashboards interface. Index patterns define how OpenSearch Dashboards connects to and interprets the data stored in your OpenSearch indices. This guide specifically covers the index pattern workflow for the movies dataset used in the tutorial. For information about the underlying index field configuration and data types, see Field Configuration. For the broader context of data upload and indexing operations, see Data Upload and Indexing. Overview of Index Patterns Index patterns in OpenSearch Dashboards serve as a bridge between raw index data and the visualization layer. They define which indices contain the data you want to explore and specify how that data should be interpreted for search and analysis operations. In the context of this tutorial, index patterns enable access to the movies index that contains the bulk movie dataset from bulk_movies.json. Sources: Based on tutorial workflow and OpenSearch Dashboards architecture patterns. Index Pattern Creation Workflow The index pattern creation process follows a specific sequence within the OpenSearch Dashboards interface, as documented in the tutorial screenshots. Sources: Tutorial workflow sequence and OpenSearch Dashboards interface patterns. Pattern Definition and Configuration Index patterns use wildcard matching to identify which indices they should include. For the movies dataset, the pattern typically follows this structure: Pattern Element Purpose Example Index Name Base index identifier movies Wildcard Pattern matching movies* Time Field Timestamp field for time-based data Not applicable for movies dataset Field Discovery Automatic field detection Enabled The pattern configuration process involves several key steps: Sources: OpenSearch Dashboards index pattern creation workflow and field detection mechanisms. Field Mapping and Data Types Once an index pattern is created, OpenSearch Dashboards automatically discovers and maps the fields from the underlying movies index. This process examines the data structure from the documents uploaded via bulk_movies.json. The field mapping process identifies several categories of data: Field Category Examples from Movies Data OpenSearch Type Text Fields title, director, genre text or keyword Numeric Fields year, rating integer or float Date Fields release_date date Boolean Fields available boolean Sources: OpenSearch field mapping documentation and movies dataset structure analysis. Integration with Discovery Interface Index patterns enable the Discover interface to provide search and exploration capabilities across the movie dataset. The integration allows for both simple and complex query operations. The discovery workflow leverages the index pattern to: Field-based Filtering: Use detected fields for creating search filters Time-based Navigation: Handle temporal data if time fields are configured Aggregation Operations: Support grouping and statistical operations Export Functionality: Enable data export based on search results Sources: OpenSearch Dashboards Discover interface capabilities and query processing architecture. Pattern Management and Maintenance Index patterns require ongoing management as data structures evolve. The tutorial demonstrates basic pattern creation, but production environments often need pattern updates and field refresh operations. Key maintenance operations include: Field Refresh: Update field mappings when new fields are added to indices Pattern Modification: Adjust pattern matching rules for new indices Performance Optimization: Configure field settings for optimal query performance Access Control: Manage pattern visibility and permissions The movies dataset provides a stable example for learning these concepts, as the data structure remains consistent throughout the tutorial workflow. Sources: OpenSearch index pattern management best practices and tutorial documentation structure. Dismiss Refresh this wiki Enter email to refresh On this page Index Patterns Purpose and Scope Overview of Index Patterns Index Pattern Creation Workflow Pattern Definition and Configuration Field Mapping and Data Types Integration with Discovery Interface Pattern Management and Maintenance\\\"},{\\\"url\\\":\\\"https://docs.opensearch.org/latest/api-reference/index-apis/create-index-template/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Discovery and cluster formation Node discovery and seed hosts Voting and quorum Voting configuration management Cluster bootstrapping Discovery and cluster formation settings Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Remote segment warmer Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Similarity Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Resource access management Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates OpenSearch FIPS configuration Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control Defining users and roles Permissions Default action groups REST layer authorization Document-level security Field-level security Field masking User impersonation Resource sharing and access control Resource sharing APIs API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Version Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Mapping explosion Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Rescore Regular expression syntax SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic queries Complex queries Functions JSON support Metadata queries Aggregate functions Delete JDBC driver ODBC driver PPL Subsearch Commands PPL syntax ad addcoltotals addtotals append appendcol appendpipe bin chart dedup describe eval eventstats expand explain fields fillnull flatten grok head join kmeans lookup ml multisearch parse patterns rare regex rename replace reverse rex search show datasources sort spath stats streamstats subquery table timechart top trendline where Identifiers Data types Functions Full-text search Settings Troubleshooting Monitoring Limitations Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Collecting UBI-formatted data in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Model access control through resource sharing Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller ML Tasks APIs Get ML task Search ML tasks Delete ML task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow access control Workflow settings Workflow state access control Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detector access control Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecaster access control Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions API reference Index APIs Index templates Create or update index template Create Or Update Index Template API You can use the Create or Update Index Template API to create indexes with predefined mappings and settings as well as update existing index templates. Endpoints PUT _index_template/<template-name>\\\\nPOST _index_template/<template-name>\\\\n Path parameters Parameter Data type Description template-name String The name of the index template. Query parameters The following optional query parameters are supported. Parameter Data type Description create Boolean When true, the API cannot replace or update any existing index templates. Default is false. cluster_manager_timeout Time The amount of time to wait for a connection to the cluster manager node. Default is 30s. Request body fields The following options can be used in the request body to customize the index template. Parameter Type Description index_patterns String array An array of wildcard expressions that match the names of data streams and indexes created during template creation. Required. composed_of String array An ordered list of component template names. These templates are merged using the specified order. For more information, see Using multiple component templates. Optional. data_stream Object When used, the request creates data streams and any backing indexes based on the template. This setting requires a matching index template. It can also be used with the hidden setting, which, when set to true, hides the data stream backing indexes. Optional. _meta Object Optional metadata that provides details about the index template. Optional. priority Integer A number that determines which index templates take precedence during the creation of a new index or data stream. OpenSearch chooses the template with the highest priority. When no priority is given, the template is assigned a 0, signifying the lowest priority. Optional. template Object The template that includes the aliases, mappings, or settings for the index. For more information, see [#template]. Optional. version Integer The version number used to manage index templates. Version numbers are not automatically set by OpenSearch. Optional. context Object (Experimental) The context parameter provides use-case-specific predefined templates that can be applied to an index. Among all settings and mappings declared for a template, context templates hold the highest priority. For more information, see index-context. Template You can use the following objects with the template option in the request body. alias The name of the alias to associate with the template as a key. Required when the template option exists in the request body. This option supports multiple aliases. The object body contains the following optional alias parameters. Parameter Data type Description filter Query DSL object The query that limits the number of documents that the alias can access. index_routing String The value that routes indexing operations to a specific shard. When specified, overwrites the routing value for indexing operations. is_hidden Boolean When true, the alias is hidden. Default is false. All alias indexes must have matching values for this setting. is_write_index Boolean When true, the index is the write index for the alias. Default is false. routing String The value used to route index and search operations to a specific shard. search_routing String The value used to write specific search operations to a specific shard. When specified, this option overwrites the routing value for search operations. mappings The field mappings that exist in the index. For more information, see Mappings and field types. Optional. settings Any configuration options for the index. For more information, see Index settings. Example requests The following examples show how to use the Create or Update Index Template API. Index template with index aliases The following example request includes index aliases in the template: REST Python PUT /_index_template/alias-template\\\\n{\\\\n  \\\\\\\"index_patterns\\\\\\\": [\\\\n    \\\\\\\"sh*\\\\\\\"\\\\n  ],\\\\n  \\\\\\\"template\\\\\\\": {\\\\n    \\\\\\\"settings\\\\\\\": {\\\\n      \\\\\\\"number_of_shards\\\\\\\": 1\\\\n    },\\\\n    \\\\\\\"aliases\\\\\\\": {\\\\n      \\\\\\\"alias1\\\\\\\": {},\\\\n      \\\\\\\"alias2\\\\\\\": {\\\\n        \\\\\\\"filter\\\\\\\": {\\\\n          \\\\\\\"term\\\\\\\": {\\\\n            \\\\\\\"user.id\\\\\\\": \\\\\\\"hamlet\\\\\\\"\\\\n          }\\\\n        },\\\\n        \\\\\\\"routing\\\\\\\": \\\\\\\"shard-1\\\\\\\"\\\\n      },\\\\n      \\\\\\\"{index}-alias\\\\\\\": {}\\\\n    }\\\\n  }\\\\n} Copy Copy as cURL response = client.indices.put_index_template(\\\\n  name = \\\\\\\"alias-template\\\\\\\",\\\\n  body =   {\\\\n    \\\\\\\"index_patterns\\\\\\\": [\\\\n      \\\\\\\"sh*\\\\\\\"\\\\n    ],\\\\n    \\\\\\\"template\\\\\\\": {\\\\n      \\\\\\\"settings\\\\\\\": {\\\\n        \\\\\\\"number_of_shards\\\\\\\": 1\\\\n      },\\\\n      \\\\\\\"aliases\\\\\\\": {\\\\n        \\\\\\\"alias1\\\\\\\": {},\\\\n        \\\\\\\"alias2\\\\\\\": {\\\\n          \\\\\\\"filter\\\\\\\": {\\\\n            \\\\\\\"term\\\\\\\": {\\\\n              \\\\\\\"user.id\\\\\\\": \\\\\\\"hamlet\\\\\\\"\\\\n            }\\\\n          },\\\\n          \\\\\\\"routing\\\\\\\": \\\\\\\"shard-1\\\\\\\"\\\\n        },\\\\n        \\\\\\\"{index}-alias\\\\\\\": {}\\\\n      }\\\\n    }\\\\n  }\\\\n) Copy Using multiple matching templates When multiple index templates match the name of a new index or data stream, the template with the highest priority is used. For example, the following two requests create index templates with different priorities: PUT /_index_template/template_one\\\\n{\\\\n  \\\\\\\"index_patterns\\\\\\\" : [\\\\\\\"h*\\\\\\\"],\\\\n  \\\\\\\"priority\\\\\\\" : 0,\\\\n  \\\\\\\"template\\\\\\\": {\\\\n    \\\\\\\"settings\\\\\\\" : {\\\\n      \\\\\\\"number_of_shards\\\\\\\" : 1,\\\\n      \\\\\\\"number_of_replicas\\\\\\\": 0\\\\n    },\\\\n    \\\\\\\"mappings\\\\\\\" : {\\\\n      \\\\\\\"_source\\\\\\\" : { \\\\\\\"enabled\\\\\\\" : false }\\\\n    }\\\\n  }\\\\n}\\\\n\\\\nPUT /_index_template/template_two\\\\n{\\\\n  \\\\\\\"index_patterns\\\\\\\" : [\\\\\\\"ha*\\\\\\\"],\\\\n  \\\\\\\"priority\\\\\\\" : 1,\\\\n  \\\\\\\"template\\\\\\\": {\\\\n    \\\\\\\"settings\\\\\\\" : {\\\\n      \\\\\\\"number_of_shards\\\\\\\" : 2\\\\n    },\\\\n    \\\\\\\"mappings\\\\\\\" : {\\\\n      \\\\\\\"_source\\\\\\\" : { \\\\\\\"enabled\\\\\\\" : true }\\\\n    }\\\\n  }\\\\n}\\\\n copy For indexes that start with ha, the _source is enabled. Because only template_two is applied, the index will have two primary shards and one replica. Overlapping index patterns given the same priority are not allowed. An error will occur when attempting to create a template matching an existing index template with identical priorities. Adding template versioning The following example request adds a version number to an index template, which simplifies template management for external systems: REST Python PUT /_index_template/template_one\\\\n{\\\\n  \\\\\\\"index_patterns\\\\\\\": [\\\\n    \\\\\\\"mac\\\\\\\",\\\\n    \\\\\\\"cheese\\\\\\\"\\\\n  ],\\\\n  \\\\\\\"priority\\\\\\\": 0,\\\\n  \\\\\\\"template\\\\\\\": {\\\\n    \\\\\\\"settings\\\\\\\": {\\\\n      \\\\\\\"number_of_shards\\\\\\\": 1\\\\n    }\\\\n  },\\\\n  \\\\\\\"version\\\\\\\": 1\\\\n} Copy Copy as cURL response = client.indices.put_index_template(\\\\n  name = \\\\\\\"template_one\\\\\\\",\\\\n  body =   {\\\\n    \\\\\\\"index_patterns\\\\\\\": [\\\\n      \\\\\\\"mac\\\\\\\",\\\\n      \\\\\\\"cheese\\\\\\\"\\\\n    ],\\\\n    \\\\\\\"priority\\\\\\\": 0,\\\\n    \\\\\\\"template\\\\\\\": {\\\\n      \\\\\\\"settings\\\\\\\": {\\\\n        \\\\\\\"number_of_shards\\\\\\\": 1\\\\n      }\\\\n    },\\\\n    \\\\\\\"version\\\\\\\": 1\\\\n  }\\\\n) Copy Adding template metadata The following example request uses the meta parameter to add metadata to the index template. All metadata is stored in the cluster state: REST Python PUT /_index_template/template_one\\\\n{\\\\n  \\\\\\\"index_patterns\\\\\\\": [\\\\n    \\\\\\\"rom\\\\\\\",\\\\n    \\\\\\\"juliet\\\\\\\"\\\\n  ],\\\\n  \\\\\\\"template\\\\\\\": {\\\\n    \\\\\\\"settings\\\\\\\": {\\\\n      \\\\\\\"number_of_shards\\\\\\\": 2\\\\n    }\\\\n  },\\\\n  \\\\\\\"_meta\\\\\\\": {\\\\n    \\\\\\\"description\\\\\\\": \\\\\\\"Where art thou\\\\\\\",\\\\n    \\\\\\\"serialization\\\\\\\": {\\\\n      \\\\\\\"class\\\\\\\": \\\\\\\"MyIndexTemplate\\\\\\\",\\\\n      \\\\\\\"id\\\\\\\": 12\\\\n    }\\\\n  }\\\\n} Copy Copy as cURL response = client.indices.put_index_template(\\\\n  name = \\\\\\\"template_one\\\\\\\",\\\\n  body =   {\\\\n    \\\\\\\"index_patterns\\\\\\\": [\\\\n      \\\\\\\"rom\\\\\\\",\\\\n      \\\\\\\"juliet\\\\\\\"\\\\n    ],\\\\n    \\\\\\\"template\\\\\\\": {\\\\n      \\\\\\\"settings\\\\\\\": {\\\\n        \\\\\\\"number_of_shards\\\\\\\": 2\\\\n      }\\\\n    },\\\\n    \\\\\\\"_meta\\\\\\\": {\\\\n      \\\\\\\"description\\\\\\\": \\\\\\\"Where art thou\\\\\\\",\\\\n      \\\\\\\"serialization\\\\\\\": {\\\\n        \\\\\\\"class\\\\\\\": \\\\\\\"MyIndexTemplate\\\\\\\",\\\\n        \\\\\\\"id\\\\\\\": 12\\\\n      }\\\\n    }\\\\n  }\\\\n) Copy Data stream definition Include a data_stream object to use an index template for data streams, as shown in the following example request: REST Python PUT /_index_template/template_1\\\\n{\\\\n  \\\\\\\"index_patterns\\\\\\\": [\\\\n    \\\\\\\"logs-*\\\\\\\"\\\\n  ],\\\\n  \\\\\\\"data_stream\\\\\\\": {}\\\\n} Copy Copy as cURL response = client.indices.put_index_template(\\\\n  name = \\\\\\\"template_1\\\\\\\",\\\\n  body =   {\\\\n    \\\\\\\"index_patterns\\\\\\\": [\\\\n      \\\\\\\"logs-*\\\\\\\"\\\\n    ],\\\\n    \\\\\\\"data_stream\\\\\\\": {}\\\\n  }\\\\n) Copy Using multiple component templates When using multiple component templates with the composed_of field, the component templates are merged in the specified order. Next, all mappings, settings, and aliases from the parent index template of the component are merged. Lastly, any configuration options added to the index requests are merged. In the following example request, an index with h* has two merged primary shards. If the order in the request body were reversed, then the index would have one primary shard: PUT /_component_template/template_with_1_shard\\\\n{\\\\n  \\\\\\\"template\\\\\\\": {\\\\n    \\\\\\\"settings\\\\\\\": {\\\\n      \\\\\\\"index.number_of_shards\\\\\\\": 1\\\\n    }\\\\n  }\\\\n}\\\\n\\\\nPUT /_component_template/template_with_2_shards\\\\n{\\\\n  \\\\\\\"template\\\\\\\": {\\\\n    \\\\\\\"settings\\\\\\\": {\\\\n      \\\\\\\"index.number_of_shards\\\\\\\": 2\\\\n    }\\\\n  }\\\\n}\\\\n\\\\nPUT /_index_template/template_1\\\\n{\\\\n  \\\\\\\"index_patterns\\\\\\\": [\\\\\\\"h*\\\\\\\"],\\\\n  \\\\\\\"composed_of\\\\\\\": [\\\\\\\"template_with_1_shard\\\\\\\", \\\\\\\"template_with_2_shards\\\\\\\"]\\\\n}\\\\n copy Recursive merging is used for mapping definition and root options such as dynamic_templates and meta, meaning that when an earlier component contains a meta block, new meta entries are added to the end of the metadata in the index. Any entries containing a preexisting key are overwritten. Endpoints Path parameters Query parameters Request body fields Template Example requests Index template with index aliases Using multiple matching templates Adding template versioning Adding template metadata Data stream definition Using multiple component templates WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright \\u00a9 OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\\\"},{\\\"url\\\":\\\"https://opensearch.isharkfly.com/dashboards/management/index-patterns/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu OpenSearchCon 2024 - Stay Informed Sessions Speakers Exhibitors Workshops Unconference CFP is closed Download About Releases Roadmap FAQ Community Blog Forum Slack Events Partners Projects Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home API Style Guide Formatting Guide OpenSearch Documentation Website 2.10.0 Release Notes OpenSearch Documentation Website 2.11.0 Release Notes OpenSearch Documentation Website 2.12.0 Release Notes OpenSearch Documentation Website 2.4.0 Release Notes OpenSearch Documentation Website 2.5.0 Release Notes OpenSearch Documentation Website 2.6.0 Release Notes OpenSearch Documentation Website 2.7.0 Release Notes OpenSearch Documentation Website 2.8.0 Release Notes OpenSearch Documentation Website 2.9.0 Release Notes OpenSearch Project Style Guidelines OpenSearch terms Overview About OpenSearch Intro to OpenSearch Quickstart Version history Breaking changes Install and upgrade Installing OpenSearch Docker Helm Tarball RPM Debian Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Circuit breaker settings Cluster settings Index settings Search settings Availability and recovery settings Plugin settings Experimental feature flags Logs Configuring OpenSearch Dashboards Upgrading OpenSearch Rolling Upgrade Upgrades appendix Rolling upgrade lab Installing plugins Managing OpenSearch Dashboards plugins Migrate to OpenSearch Using snapshots to migrate data Migrating from Elasticsearch OSS to OpenSearch Migrating Docker clusters to OpenSearch Migrating from Kibana OSS to OpenSearch Dashboards Managing Indexes Index templates Index aliases Data streams Reindex data Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings Index management security Refresh search analyzer ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Ingest Pipelines Create pipeline Simulate pipeline Get pipeline Delete pipeline Handling pipeline failures Ingest processors Append Bytes Convert Copy CSV Date Date index name Dissect Dot expander Drop IP2Geo Grok KV Lowercase Remove_by_pattern Remove Sparse encoding Text embedding Text/image embedding Uppercase OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Analyzing data Time filter Creating dashboards Building data visualizations Using area charts Using coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using the self-host maps server Using Gantt charts Using VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimize query performance using OpenSearch indexing Dev Tools Running queries in the Dev Tools console Query Workbench Custom branding Dashboards Query Language (DQL) Search telemetry OpenSearch Integrations Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Tuning for indexing speed Security in OpenSearch Configuration Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files API rate limiting Configuring sign-in options Disabling security OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Access control REST layer authorization Document-level security Users and roles Field-level security Field masking User impersonation Cross-cluster search Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Creating detectors Supported log types Creating correlation rules Creating custom log types Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Security Analytics settings Mappings and field types Supported field types Alias Binary Numeric field types Unsigned long Boolean Date field types Date Date nanoseconds IP address Range field types Object field types Object Nested Flat object Join String field types Keyword Text Match-only text Token count Autocomplete field types Completion Search as you type Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape k-NN vector Rank field types Percolator Text analysis Language analyzers Index analyzers Search analyzers Tokenizers Token filters Delimited term frequency Normalizers Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Exists Fuzzy IDs Prefix Range Regexp Term Terms Terms set Wildcard Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box xy Span queries Match all queries Specialized queries Neural Neural sparse Script score Minimum should match Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Matrix stats Maximum Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Bucket aggregations Adjacency matrix Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Range Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Search Searching data Paginate results Point in Time Point in Time API Sort results Highlight query matches Autocomplete Did-you-mean Keyword search k-NN search k-NN index Exact k-NN with scoring script Approximate k-NN search k-NN search with filters k-NN search with nested fields k-NN Painless extensions API JNI libraries Settings Performance tuning Neural search Neural search tutorial Semantic search Multimodal search Neural sparse search Hybrid search Conversational search Search relevance Comparing search results Reranking search results Querqy Search pipelines Creating a search pipeline Using a search pipeline Retrieving search pipelines Search processors Collapse Filter query Neural query enricher Normalization Oversample Personalize search ranking Retrieval-augmented generation Rename field Rerank Script Truncate hits Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Identifiers Data Types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Machine learning ML Commons cluster settings Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Connector blueprints Agents and tools Agents and tools tutorial Tools Agent tool CAT Index tool Index Mapping tool ML Model tool Neural Sparse Search tool PPL tool RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool OpenSearch Assistant Toolkit Managing ML models in OpenSearch Dashboards Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Model group APIs Register model group Update model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Execute agent Get agent Search agent Delete agent Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Execute algorithm Tasks APIs Get task Search task Delete task Train and Predict APIs Train and predict Train Predict Profile Stats Automating configurations Workflow steps Workflow tutorial Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Monitoring your cluster Job Scheduler Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metrics analytics Query insights Top N queries Trace Analytics Getting Started OpenSearch Dashboards plugin Analyzing Jaeger trace data Distrbuted tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI OpenSearch Kubernetes Operator Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana API reference Analyze API Analysis API Terminology CAT API CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices operation CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster routing and awareness Cluster decommission Cluster health Cluster settings Cluster stats Count Document APIs Index document Get document Update document Delete document Bulk Multi-get document Delete by query Update by query Reindex document Explain Index APIs Alias Clear cache Clone index Close index Create index Create or update mappings Dangling indexes Delete index Force merge Get index Get settings Index exists Open index Shrink index Split index Stats Update settings Ingest APIs Multi-search Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Profile Ranking evaluation Remote cluster information Script APIs Create or Update Stored Script Execute Painless stored script Get Stored Script Delete Script Get Stored Script Contexts Get Script Language Execute Painless script Scroll Search Search templates Snapshot APIs Register Snapshot Repository Get Snapshot Repository Delete Snapshot Repository Verify Snaphot Repository Create Snapshot Get Snapshot Delete Snapshot Get Snapshot Status Restore Snapshot Tasks Supported units Common REST Parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Extensions Dashboards Management Index patterns Index patterns Index patterns are essential for accessing OpenSearch data. An index pattern references one or more indexes, data streams, or index aliases. For example, an index pattern can point you to your log data from yesterday or all indexes that contain that data. If you store data in multiple indexes, creating an index pattern enables your visualizations to retrieve data from all indexes that match the index pattern. You need to create index patterns to define how data is retrieved and fields are formatted so that you can query, search, and display data. Get started In this tutorial, you\\u2019ll learn to create index patterns. Note To create or modify index patterns, you must have create, manage, and delete permissions. Contact your administrator for support. For more information, refer to Multi-tenancy configuration. Prerequisites Before you can create an index pattern, your data must be indexed. To learn about indexing your data in OpenSearch, see Managing indexes. Best practices Consider the following best practices when creating index patterns: Make your index patterns specific. Instead of creating an index pattern that matches all indexes, create an index pattern that matches all indexes starting with a certain prefix, for example, my-index-. The more specific your index patterns, the better it will be to query and analyze your data. Use wildcards sparingly. Wildcards can be useful for matching multiple indexes, but they can also make it more difficult to manage your index patterns. Try to use wildcards as specifically as possible. Test your index patterns. Make sure to test your index patterns to ensure that they match the correct indexes. Creating an index pattern If you added sample data, you have index patterns that you can use to analyze that data. To create an index pattern for your own data, follow these steps. Step 1: Define the index pattern Go to OpenSearch Dashboards, and select Management > Dashboards Management > Index patterns. Select Create index pattern. From the Create index pattern window, define the index pattern by entering a name for your index pattern in the Index pattern name field. Dashboards automatically adds a wildcard, *, once you start typing. Using a wildcard is helpful for matching an index pattern to multiple sources or indexes. A dropdown list displaying all the indexes that match your index pattern appears when you start typing. Select Next step. An example of step 1 is shown in the following image. Note that the index pattern security* matches three indexes. By defining the pattern with a wildcard *, you can query and visualize all the data in your indexes. Step 2: Configure the settings Select @timestamp from the dropdown menu to specify the time field for OpenSearch to use when filtering documents based on time. Selecting this time filter determines which field the time filter is applied to. It can be the timestamp of a request or any relevant timestamp field. If you don\\u2019t want to use a time filter, select that option from the dropdown menu. If you select this option, OpenSearch returns all of the data in the indexes that match the pattern. Select Create index pattern. An example is shown in the following image. Once the index pattern has been created, you can view the mapping of the matching indexes. Within the table, you can see the list of fields, along with their data type and properties. An example is shown in the following image. Next steps Understand your data through visuals. Dig into your data. Get started Prerequisites Best practices Creating an index pattern Step 1: Define the index pattern Step 2: Configure the settings Next steps WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links \\u53c2\\u4e0e\\u9879\\u76ee\\uff08Get Involved\\uff09 Code of Conduct OpenSearch \\u4e2d\\u6587\\u8bba\\u575b \\u5b98\\u65b9\\u8bba\\u575b \\u4e2d\\u6587\\u6587\\u6863\\u4ee3\\u7801\\u4ed3\\u5e93 \\u5b98\\u65b9 Github Slack \\u793e\\u533a\\u9879\\u76ee \\u8d44\\u6e90\\uff08Resources\\uff09 About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy \\u8054\\u7cfb\\u6211\\u4eec\\uff08Contact Us\\uff09 \\u8054\\u7cfb\\uff08Connect\\uff09 Twitter LinkedIn YouTube Meetup Facebook \\u00a9 OpenSearch contributors, 2024. OpenSearch is a registered trademark of Amazon Web Services. \\u00a9 2005-2021 Django Software Foundation and individual contributors. Django is a registered trademark of the Django Software Foundation. This website was forked from the BSD-licensed djangoproject.com originally designed by Threespot & andrevv.\\\"},{\\\"url\\\":\\\"https://repost.aws/knowledge-center/opensearch-index-pattern\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to content By using AWS re:Post, you agree to the AWS re:Post Terms of Use re:Post Search About re:Post English EnglishDeutschEspa\\u00f1olFran\\u00e7aisItaliano\\u65e5\\u672c\\u8a9e\\ud55c\\uad6d\\uc5b4Portugu\\u00eas\\u4e2d\\u6587 (\\u7b80\\u4f53)\\u4e2d\\u6587 (\\u7e41\\u9ad4) Resources Sign in Home Questions Knowledge Center Articles Selections Tags Topics Community Groups AWS Support Official AWS Trust & Safety Center Ask question AWS re:Post Knowledge Center Feedback Survey Help us improve the AWS re:Post Knowledge Center by sharing your feedback in a brief survey. Your input can influence how we create and update our content to better support your AWS journey. / How do I create an index pattern in my OpenSearch Service cluster?lg.../ How do I create an index pattern in my OpenSearch Service cluster? 5 minute read 1 I want to create an index pattern in my Amazon OpenSearch Service cluster. Resolution Prerequisites: The AWS Identity and Access Management (IAM) user must have PUT and POST permissions to create an index pattern. Example access policy: {  \\\\\\\"Version\\\\\\\": \\\\\\\"2012-10-17\\\\\\\",\\\\n  \\\\\\\"Statement\\\\\\\": [\\\\n    {\\\\n      \\\\\\\"Sid\\\\\\\": \\\\\\\"VisualEditor0\\\\\\\",\\\\n      \\\\\\\"Effect\\\\\\\": \\\\\\\"Allow\\\\\\\",\\\\n      \\\\\\\"Action\\\\\\\": [\\\\n        \\\\\\\"es:ESHttpHead\\\\\\\",\\\\n        \\\\\\\"es:ESHttpPost\\\\\\\",\\\\n        \\\\\\\"es:ESHttpGet\\\\\\\",\\\\n        \\\\\\\"es:ESHttpDelete\\\\\\\",\\\\n        \\\\\\\"es:ESHttpPut\\\\\\\"\\\\n      ],\\\\n      \\\\\\\"Resource\\\\\\\": \\\\\\\"arn:aws:es:region:account-id:domain/domain-name/*\\\\\\\"\\\\n    }\\\\n  ]\\\\n} Note: Replace region with your AWS Region, account-id with your AWS account, and domain-name with your domain name. Your cluster version must allow index patterns. Create the index pattern Use OpenSearch Dashboards You can use OpenSearch Dashboards to create an index pattern for OpenSearch Service or Elasticsearch clusters with or without fine-grained access control. For instructions, see Creating an index pattern on the OpenSearch website. Use curl commands To create an index pattern for clusters without fine-grained access control, run the following command based on the cluster type. Elasticsearch clusters: curl -X POST  https://elasticsearch-end-point/_plugin/kibana/api/saved_objects/index-pattern/ \\\\\\\\\\\\n-H \\\\\\\"kbn-xsrf: true\\\\\\\" \\\\\\\\\\\\n\\\\n-H \\\\\\\"content-type: application/json\\\\\\\" \\\\\\\\\\\\n\\\\n-d '{ \\\\\\\"attributes\\\\\\\": { \\\\\\\"title\\\\\\\": \\\\\\\"sample-index*\\\\\\\" } }' Note: Replace sample-index with your index name or pattern. OpenSearch Service clusters: curl -X POST  https://opensearch-end-point/_dashboards/api/saved_objects/index-pattern/ \\\\\\\\\\\\n-H \\\\\\\"kbn-xsrf: true\\\\\\\" \\\\\\\\\\\\n\\\\n-H \\\\\\\"content-type: application/json\\\\\\\" \\\\\\\\\\\\n\\\\n-d '{ \\\\\\\"attributes\\\\\\\": { \\\\\\\"title\\\\\\\": \\\\\\\"sample-index*\\\\\\\" } }' Note: Replace sample-index with your index name or pattern. For clusters with fine-grained access control, complete the following steps: To generate authorization cookies in the auth.txt file, run the following command based on the cluster type. Elasticsearch clusters: curl -X POST  https://elasticsearch-end-point/_plugin/kibana/auth/login  \\\\\\\\\\\\n-H \\\\\\\"kbn-xsrf: true\\\\\\\" \\\\\\\\\\\\n-H \\\\\\\"content-type: application/json\\\\\\\" \\\\\\\\\\\\n-d '{\\\\\\\"username\\\\\\\":\\\\\\\"usernameexample\\\\\\\", \\\\\\\"password\\\\\\\":\\\\\\\"passwordexample\\\\\\\"}' \\\\\\\\\\\\n-c auth.txt Note: Replace usernameexample with your username and passwordexample with your password. OpenSearch Service clusters: curl -X POST  https://opensearch-end-point/_dashboards/auth/login  \\\\\\\\\\\\n-H \\\\\\\"kbn-xsrf: true\\\\\\\" \\\\\\\\\\\\n-H \\\\\\\"content-type: application/json\\\\\\\" \\\\\\\\\\\\n-d '{\\\\\\\"username\\\\\\\":\\\\\\\"usernameexample\\\\\\\", \\\\\\\"password\\\\\\\":\\\\\\\"passwordexample\\\\\\\"}' \\\\\\\\\\\\n-c auth.txt Note: Replace usernameexample with your username and passwordexample with your password. To submit the index pattern creation request, run the following command based on your cluster type: Elasticsearch clusters: curl -X POST  https://elasticsearch-end-point/_plugin/kibana/api/saved_objects/index-pattern/test  \\\\\\\\\\\\n-H \\\\\\\"kbn-xsrf: true\\\\\\\" \\\\\\\\\\\\n-H \\\\\\\"content-type: application/json\\\\\\\" \\\\\\\\\\\\n-d '{ \\\\\\\"attributes\\\\\\\": { \\\\\\\"title\\\\\\\": \\\\\\\"sample-index*\\\\\\\" } }' \\\\\\\\\\\\n-b auth.txt Note: Replace sample-index with your index name or pattern. OpenSearch Service clusters: curl -X POST  https://opensearch-end-point/_dashboards/api/saved_objects/index-pattern/  \\\\\\\\\\\\n-H \\\\\\\"kbn-xsrf: true\\\\\\\" \\\\\\\\\\\\n-H \\\\\\\"content-type: application/json\\\\\\\" \\\\\\\\\\\\n-d '{ \\\\\\\"attributes\\\\\\\": { \\\\\\\"title\\\\\\\": \\\\\\\"sample-index*\\\\\\\" } }' \\\\\\\\\\\\n-b auth.txt Note: Replace sample-index with your index name or pattern. Use Python Prerequisites: Map the role that runs the Python code to the backend role for fine-grained access control clusters. Run the following commands to install the required dependencies: pip install boto3\\\\npip install opensearch-py\\\\npip install requests\\\\npip install requests-aws4auth Run the following Python command to create the index pattern for OpenSearch Service clusters: import boto3\\\\nimport requests\\\\nfrom requests_aws4auth import AWS4Auth\\\\n\\\\nhost = 'https://domain-endpoint/' # include trailing /\\\\nregion = 'aos-region' # example us-west-1\\\\nservice = 'es'\\\\ncredentials = boto3.Session().get_credentials()\\\\nawsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)\\\\n\\\\n\\\\npath = '_dashboards/api/saved_objects/index-pattern' # _plugin/kibana/api/saved_objects/index-pattern for es versions\\\\nurl = host + path\\\\npayload = {\\\\\\\"attributes\\\\\\\":{\\\\\\\"title\\\\\\\":\\\\\\\"multi-logs-*\\\\\\\",\\\\\\\"fields\\\\\\\":\\\\\\\"[]\\\\\\\"}}\\\\nheaders = {\\\\\\\"Content-Type\\\\\\\": \\\\\\\"application/json\\\\\\\", \\\\\\\"osd-xsrf\\\\\\\": \\\\\\\"true\\\\\\\", \\\\\\\"security_tenant\\\\\\\": \\\\\\\"global\\\\\\\" }\\\\nr = requests.post (url, auth=awsauth, json=payload, headers=headers)\\\\nprint(r.status_code)\\\\nprint(r.text) Note: Replace domain-endpoint with your domain endpoint, and aos-region with your Region. For Elasticsearch clusters, replace _dashboards/api/saved_objects/index-pattern with _plugin/kibana/api/saved_objects/index-pattern. Troubleshoot index pattern creation issues You use fine-grained access control with SAML 2.0 or Amazon Cognito authentication If the domain for your cluster uses SAML 2.0 or Amazon Cognito for authentication, then create an internal user to manage the index pattern. Note: For clusters where you activated fine-grained access control, the user must have ESHttpPut and ESHttpPost permissions to create an index pattern. You can't create the index pattern in the Global tenant By default, OpenSearch Dashboards creates index patterns under the Global tenant. To create an index pattern outside of the Global tenant, run the following command: curl -s -X POST https://opensearch-end-point/_dashboards/api/saved_objects/index-pattern/sample-index -d '{\\\\\\\"attributes\\\\\\\": {\\\\\\\"title\\\\\\\": \\\\\\\"sample-index*\\\\\\\"}}' \\\\\\\\\\\\n-H \\\\\\\"osd-xsrf:true\\\\\\\" \\\\\\\\\\\\n-H \\\\\\\"securitytenant: private\\\\\\\" \\\\\\\\\\\\n-H \\\\\\\"content-type:application/json\\\\\\\" \\\\\\\\\\\\n-b auth.txt Note: Replace sample-index with your index name or pattern. You didn't include the .kibana alias in the cluster To troubleshoot this issue, complete the following steps: To check whether the .kibana alias exists in the cluster, run the following command: curl -XGET https://opensearch-end-point/_cat/aliases Note: For clusters with fine-grained access control, include the -u flag with your username and password. Example command: curl -XPOST -u 'master-user:master-user-password' 'domain-endpoint/_cat/indices If the .kibana index doesn't exist, then proceed to step 4. To create a backup of .kibana index, run the following command: curl -XPOST \\\\\\\"https://domain-endpoint/_reindex\\\\\\\" -H 'Content-Type: application/json' -d'{\\\\n  \\\\\\\"source\\\\\\\": {\\\\n    \\\\\\\"index\\\\\\\": \\\\\\\".kibana\\\\\\\"\\\\n  },\\\\n  \\\\\\\"dest\\\\\\\": {\\\\n \\\\\\\"index\\\\\\\": \\\\\\\".kibana_backup\\\\\\\"\\\\n  }\\\\n}' Note: Replace domain-endpoint with your domain endpoint. For clusters with fine-grained access control, include the -u flag with your username and password. To delete the .kibana index, run the following command: curl -XDELETE \\\\\\\"https://domain-endpoint/.kibana\\\\\\\" Note: Replace domain-endpoint with your domain endpoint. For clusters with fine-grained access control, include the -u flag with your username and password. To create a .kibana alias and point it to the .kibana_backup index, run the following command: curl -XPOST \\\\\\\"https://domain-endpoint/_aliases\\\\\\\" -H 'Content-Type: application/json' -d'{\\\\n  \\\\\\\"actions\\\\\\\": [\\\\n    {\\\\n      \\\\\\\"add\\\\\\\": {\\\\n        \\\\\\\"index\\\\\\\": \\\\\\\".kibana_backup\\\\\\\",\\\\n        \\\\\\\"alias\\\\\\\": \\\\\\\".kibana\\\\\\\"\\\\n      }\\\\n    }\\\\n  ]\\\\n}' Note: Replace domain-endpoint with your domain endpoint. For clusters with fine-grained access control, include the -u flag with your username and password. Related information Export and import Kibana dashboards with OpenSearch Service Why does the rollover index action in my ISM policy keep failing in OpenSearch Service? Follow Share Topics Analytics Tags Amazon OpenSearch Service Language English Related videos Watch Sujata's video to learn more (3:59) AWS OFFICIALUpdated 4 months ago 2 Comments This can also be done using basic auth using session object without signing the request if that is the use case. [+] Session Object = https://requests.readthedocs.io/en/latest/user/advanced/#session-objects #! /bin/python3\\\\nimport requests\\\\nhost = 'https://<domain_endpoint_ending_with_slash>/'\\\\npath = '_dashboards/auth/login'\\\\nregion = 'us-east-1'\\\\nurl = host + path;\\\\n# Set headers as mentioned. Here we will create index pattern in global tenant hence the value is global\\\\nheaders = {\\\\\\\"Content-Type\\\\\\\": \\\\\\\"application/json\\\\\\\",\\\\\\\"kbn-xsrf\\\\\\\": \\\\\\\"true\\\\\\\",\\\\\\\"osd-xsrf\\\\\\\":\\\\\\\"true\\\\\\\",\\\\\\\"security_tenant\\\\\\\":\\\\\\\"global\\\\\\\"};\\\\npayload = {\\\\n \\\\\\\"username\\\\\\\":\\\\\\\"username\\\\\\\",\\\\n    \\\\\\\"password\\\\\\\":\\\\\\\"password\\\\\\\"\\\\n}\\\\n\\\\n#Creating a session because requests wont store the cookie\\\\n\\\\nsession=requests.Session();\\\\n\\\\nr=session.post(url,headers=headers,json=payload);\\\\n# You can skip these lines with print. Basically the above line will do a post request with my credentials and will create a cookie and will store it\\\\nprint(r.text);\\\\nprint(r.status_code);\\\\n\\\\n# title is the name of my index pattern\\\\n\\\\npayload={\\\\n\\\\\\\"attributes\\\\\\\": { \\\\\\\"title\\\\\\\": \\\\\\\"random*\\\\\\\" } \\\\n\\\\n}\\\\n\\\\npath=\\\\\\\"_dashboards/api/saved_objects/index-pattern/random*\\\\\\\";\\\\nurl=host+path;\\\\n\\\\n#Changed the path variable to the one which is mentioned above. Notice the end of the URL, my index pattern name will be random*\\\\n\\\\nr=session.post(url,headers=headers,json=payload);\\\\n\\\\nprint(r.text);\\\\nprint(r.status_code);\\\\nsession.close();\\\\n Share rePost-User-6420587 replied 2 years ago Thank you for your comment. We'll review and update the Knowledge Center article as needed. Share MODERATOR AWS Official replied 2 years ago Comment on this article Clear Post comment Relevant content Got an error \\\\\\\"Request Entity Too Large\\\\\\\" when creating index pattern in AWS Opensearch soop_minjaeoh asked 2 years ago How to create and configure an Open Search Serverless index via API? Zach asked a year ago OpenSearch Dashboards Index Pattern and Discover issues mdkail asked 4 years ago Access denied (403) when creating an index in OpenSearch Serverless. AlwaysLearning asked 2 years ago Index is not created inside the Amazon OpenSearch cluster Accepted Answer stratosb asked 2 years ago Why does the rollover index action in my ISM policy fail in OpenSearch Service? AWS OFFICIALUpdated 3 months ago Why can't I delete an index or upgrade my OpenSearch Service cluster? AWS OFFICIALUpdated 2 years ago How do I resolve the 403 \\\\\\\"index_create_block_exception\\\\\\\" or \\\\\\\"cluster_block_exception\\\\\\\" error in OpenSearch Service? AWS OFFICIALUpdated 3 years ago How do I use ISM to manage low storage space in Amazon OpenSearch Service? AWS OFFICIALUpdated 3 months ago How to Configure Metadata Filtering with Bedrock Knowledge Bases on OpenSearch Managed Cluster SUPPORT ENGINEER Emiliano Lozano published a month ago FEEDBACK Privacy| Site Terms| Cookie Preferences | Sitemap| Legal| \\u00a9 2026, Amazon Web Services, Inc. or its affiliates. All rights reserved. Community Guidelines\\\"},{\\\"url\\\":\\\"https://stackoverflow.com/questions/71816340/how-to-create-an-index-pattern-in-opensearch-using-api\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to main content Stack Overflow About Products For Teams Stack Internal Implement a knowledge platform layer to power your enterprise and AI tools. Stack Data Licensing Get access to top-class technical expertise with trusted & attributed content. Stack Ads Connect your brand to the world\\u2019s most trusted technologist communities. Releases Keep up-to-date on features we add to Stack Overflow and Stack Internal. About the company Visit the blog Loading\\u2026 current community Stack Overflow help chat Meta Stack Overflow your communities Sign up or log in to customize your list. more stack exchange communities company blog Log in Sign up Home Questions AI Assist Tags Challenges Chat Articles Users Jobs Companies Collectives Communities for your favorite technologies. Explore all Collectives Stack Internal Stack Overflow for Teams is now called Stack Internal. Bring the best of human thought and AI automation together at your work. Try for free Learn more Stack Internal Bring the best of human thought and AI automation together at your work. Learn more Collectives\\u2122 on Stack Overflow Find centralized, trusted content and collaborate around the technologies you use most. Learn more about Collectives Stack Internal Knowledge at work Bring the best of human thought and AI automation together at your work. Explore Stack Internal How to create an index pattern in Opensearch using API? Ask Question Asked 3 years, 9 months ago Modified 1 year, 1 month ago Viewed 15k times Part of AWS Collective 5 I want to create an index pattern using Opensearch API. I tried to replicate what could be made graphically in the following image window, using as index pattern name cwl-* and then as time field @timestamp. My domain has OpenSearch 1.2 installed. Using curl (directly modifiend the command in kibana doc): curl -u '****:*****' -X POST \\\\\\\"https://******.eu-central-1.es.amazonaws.com/api/index_patterns/index_pattern\\\\\\\" -H 'osd-xsrf: true' -H 'Content-Type: application/json' -d'\\\\n{\\\\n  \\\\\\\"index_pattern\\\\\\\": {\\\\n     \\\\\\\"title\\\\\\\": \\\\\\\"cwl-*\\\\\\\",\\\\n     \\\\\\\"timeFieldName\\\\\\\": \\\\\\\"@timestamp\\\\\\\"\\\\n  }\\\\n}'\\\\n but I receive {\\\\\\\"error\\\\\\\":{\\\\\\\"root_cause\\\\\\\":[{\\\\\\\"type\\\\\\\":\\\\\\\"illegal_argument_exception\\\\\\\",\\\\\\\"reason\\\\\\\":\\\\\\\"Rejecting mapping update to [api] as the final mapping would have more than 1 type: [_doc, index_patterns]\\\\\\\"}],\\\\\\\"type\\\\\\\":\\\\\\\"illegal_argument_exception\\\\\\\",\\\\\\\"reason\\\\\\\":\\\\\\\"Rejecting mapping update to [api] as the final mapping would have more than 1 type: [_doc, index_patterns]\\\\\\\"},\\\\\\\"status\\\\\\\":400}\\\\n amazon-web-services shell aws-elasticsearch opensearch Share Improve this question Follow edited Apr 10, 2022 at 17:50 asked Apr 10, 2022 at 11:54 Dresult 31311 gold badge22 silver badges1212 bronze badges 9 Are you using any sort of IAM authentication? Ermiya Eskandary \\u2013 Ermiya Eskandary 2022-04-10 15:58:49 +00:00 Commented Apr 10, 2022 at 15:58 @ErmiyaEskandary just the Fine-grained access control but it works because I don't have any problem in performing other requests... Dresult \\u2013 Dresult 2022-04-10 16:01:55 +00:00 Commented Apr 10, 2022 at 16:01 Ahhhhhh - remove saved_objects from your URL. Ermiya Eskandary \\u2013 Ermiya Eskandary 2022-04-10 16:10:33 +00:00 Commented Apr 10, 2022 at 16:10 @ErmiyaEskandary Unfortunately I had already tried, it says {\\\\\\\"statusCode\\\\\\\":404,\\\\\\\"error\\\\\\\":\\\\\\\"Not Found\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Not Found\\\\\\\"} Dresult \\u2013 Dresult 2022-04-10 16:13:39 +00:00 Commented Apr 10, 2022 at 16:13 Your URL is somehow wrong - I don't have docs in front of me right now but try removing _dashboards from the URL and if that doesn't work, also remove api Ermiya Eskandary \\u2013 Ermiya Eskandary 2022-04-10 16:17:22 +00:00 Commented Apr 10, 2022 at 16:17 | Show 4 more comments 3 Answers 3 Sorted by: Reset to default Highest score (default) Trending (recent votes count more) Date modified (newest first) Date created (oldest first) 3 Tested with the latest OpenSearch version 2.18.0. To simply create an index pattern via the API, a POST request should be used:     curl -XPOST \\\\\\\"http://localhost:5601/api/saved_objects/index-pattern\\\\\\\" \\\\\\\\\\\\n-u \\\\\\\"user:pass\\\\\\\" \\\\\\\\\\\\n-H 'osd-xsrf: true' \\\\\\\\\\\\n-H 'Content-Type: application/json' \\\\\\\\\\\\n-d ' \\\\n{\\\\n  \\\\\\\"attributes\\\\\\\": {\\\\n    \\\\\\\"title\\\\\\\": \\\\\\\"pattern-*\\\\\\\",\\\\n    \\\\\\\"timeFieldName\\\\\\\": \\\\\\\"@timestamp\\\\\\\"\\\\n  }\\\\n}'\\\\n If you want to create an OpenSearch index pattern with a specific ID, you can generate it or copy it from another source (in my case, I copied the ID of the missing pattern from the broken Dashboard) and include it as part of the request: curl -XPOST \\\\\\\"http://localhost:5601/api/saved_objects/index-pattern/90bd9a00-ad57-41a0-b16a-b134a8c51e98\\\\\\\" \\\\\\\\\\\\n-u \\\\\\\"user:pass\\\\\\\" \\\\\\\\\\\\n-H 'osd-xsrf: true' \\\\\\\\\\\\n-H 'Content-Type: application/json' \\\\\\\\\\\\n-d ' \\\\n{\\\\n  \\\\\\\"attributes\\\\\\\": {\\\\n    \\\\\\\"title\\\\\\\": \\\\\\\"pattern-*\\\\\\\",\\\\n    \\\\\\\"timeFieldName\\\\\\\": \\\\\\\"@timestamp\\\\\\\"\\\\n  }\\\\n}'\\\\n If you need to update existing index pattern, a PUT request should be used, with existing ID: curl -XPUT \\\\\\\"http://localhost:5601/api/saved_objects/index-pattern/90bd9a00-ad57-41a0-b16a-b134a8c51e98\\\\\\\" \\\\\\\\\\\\n-u \\\\\\\"user:pass\\\\\\\" \\\\\\\\\\\\n-H 'osd-xsrf: true' \\\\\\\\\\\\n-H 'Content-Type: application/json' \\\\\\\\\\\\n-d ' \\\\n{\\\\n  \\\\\\\"attributes\\\\\\\": {\\\\n    \\\\\\\"title\\\\\\\": \\\\\\\"pattern-*\\\\\\\",\\\\n    \\\\\\\"timeFieldName\\\\\\\": \\\\\\\"@timestamp\\\\\\\"\\\\n  }\\\\n}'\\\\n Share Improve this answer Follow answered Nov 26, 2024 at 21:35 nmishin 3,22255 gold badges2222 silver badges3737 bronze badges Sign up to request clarification or add additional context in comments. Comments Add a comment 1 curl -u '****:*****' -X POST \\\\\\\"https://******.eu-central-1.es.amazonaws.com/api/index_patterns/cwl-*\\\\\\\" -H 'osd-xsrf: true' -H 'Content-Type: application/json' -d'\\\\n{\\\\n  \\\\\\\"index_pattern\\\\\\\": {\\\\n     \\\\\\\"title\\\\\\\": \\\\\\\"cwl-*\\\\\\\",\\\\n     \\\\\\\"timeFieldName\\\\\\\": \\\\\\\"@timestamp\\\\\\\"\\\\n  }\\\\n}'\\\\n change api/index_patterns/index_pattern to api/index_patterns/cwl-* and try again? Share Improve this answer Follow answered Apr 14, 2022 at 8:33 doge76 2122 bronze badges 4 Comments Add a comment Dresult Dresult Over a year ago It works in a sense that the command creates something but I cannot see anything among saved objects and seams that in this way only an index which name is \\\\\\\"api\\\\\\\" is created not an index pattern therefore each time I access the dashboard, once it finds data, it ask me if I want to create it. 2022-04-15T11:15:21.423Z+00:00 0 Reply Copy link doge76 doge76 Over a year ago if you want the index-pattern to be global, try to add this attribute in header: securitytenant: \\\\\\\"global\\\\\\\"? 2022-04-15T12:03:44.13Z+00:00 0 Reply Copy link Dresult Dresult Over a year ago already done, I've added -H 'securitytenant: global' to the curl string 2022-04-15T13:56:58.873Z+00:00 0 Reply Copy link Kasami Kasami Over a year ago @Dresult Did you ever manage to figure this out? I am encountering the same issue, it seems. 2022-10-10T22:50:32.3Z+00:00 2 Reply Copy link Add a comment 0 It worked for me in OpenSearch 1.3 when I added an ID in the URI and used saved_objects instead of index_patterns. So your cURL-request should work when looking like this. curl -u '****:*****' -X POST \\\\\\\"https://<opensearch-dashboards-host>.eu-central-1.es.amazonaws.com/api/saved_objects/index-pattern/<ID>\\\\\\\" \\\\n-H 'osd-xsrf: true' \\\\n-H 'Content-Type: application/json' \\\\n-d \\\\n   '{\\\\n      \\\\\\\"index_pattern\\\\\\\": {\\\\n         \\\\\\\"title\\\\\\\": \\\\\\\"cwl-*\\\\\\\",\\\\n         \\\\\\\"timeFieldName\\\\\\\": \\\\\\\"@timestamp\\\\\\\"\\\\n      }\\\\n    }'\\\\n Share Improve this answer Follow edited Dec 16, 2022 at 13:09 answered Aug 25, 2022 at 8:51 mgr110 111 bronze badge 3 Comments Add a comment K.Thanvi K.Thanvi Over a year ago I am getting no handler found for uri [/api/saved_objects/index-pattern/cwl-*] and method [POST] error for this.. using opensearch1.3. 2022-12-14T17:09:27.72Z+00:00 0 Reply Copy link mgr110 mgr110 Over a year ago @K.Thanvi This is probably because you are sending the request to the OpenSearch-host. The request is meant to be sent to the OpenSearch Dashboards-host (or Kibana-host if you use that). Using the Dev Tools will send the request to the OpenSearch-host. 2022-12-15T11:44:04.903Z+00:00 1 Reply Copy link K.Thanvi K.Thanvi Over a year ago Thanks! Yes that was the issue. i had to send the request to my <opensearch_domain>/_dashboards/api/saved_objects/index-pattern endpoint. 2023-01-09T17:07:40.23Z+00:00 1 Reply Copy link Add a comment Your Answer Thanks for contributing an answer to Stack Overflow! Please be sure to answer the question. Provide details and share your research! But avoid \\u2026 Asking for help, clarification, or responding to other answers. Making statements based on opinion; back them up with references or personal experience. To learn more, see our tips on writing great answers. Draft saved Draft discarded Sign up or log in Sign up using Google Sign up using Email and Password Submit Post as a guest Name Email Required, but never shown Post as a guest Name Email Required, but never shown Post Your Answer Discard By clicking \\u201cPost Your Answer\\u201d, you agree to our terms of service and acknowledge you have read our privacy policy. Start asking to get answers Find the answer to your question by asking. Ask question Explore related questions amazon-web-services shell aws-elasticsearch opensearch See similar questions with these tags. AWS Collective See more This question is in a collective: a subcommunity defined by tags with relevant content and experts. The Overflow Blog The most dangerous shortcuts in software A new worst coder has entered the chat: vibe coding without code knowledge Featured on Meta Native Ads coming soon to Stack Overflow and Stack Exchange A proposal for bringing back Community Promotion & Open Source Ads Modernizing curation: A proposal for The Workshop and The Archive Policy: Generative AI (e.g., ChatGPT) is banned Stack Overflow chat opening up to all users in January; Stack Exchange chat... Related 1 Create Index - Elastic Search - Java API 14 Create index in Elastic Search by Java API 0 How to do an automated index creation at ElasticSearch? 21 How to configure index pattern in Kibana 2 How does one create an Index Pattern in Kibana? 3 Is there API based method to create an index pattern in Kibana if its index is present in ES 0 How to create new index pattern with custom pattern ID from the elastic API? 1 How to create Index pattern using API and Index Name 0 How to create an ElasticSearch Index as curl 0 How to create index pattern in elastic seach programmatically Hot Network Questions Portrait of Takuro Shintani How do I recreate a bootable ISO after making changes to its extracted files? Is wearing synthetic gloves an explosion risk when refueling at freezing temperatures? Simple LED vs LED Bulb Significance of the n\\u0101majapa of \\u015aiva Conversationally, how do French people distinguish between a straight question and one that expresses dismay? Expected radius of the smallest concentric circle having 2 points inside Why does a linear least squares fit appear to have a bias when applied to simple test data? taxes on the sale of gifted gold coins What was man (Adam) guarding Eden from? Minimize the number of pieces to form a square. The Stack'O'Mounts? Searching for tabulation Help a newbie with fixing a bike! Current source refuses to maintain set current circuitikz: internal node annotations (maybe 'path picture'?) to a styled 'muxdemux' How can text be added to the inner side header keyword? RPG in generic medieval fantasy; last party member is named Aquamaryann(e) Is there a word to describe a webinar which is like \\\\\\\"attend-now-or-miss-out\\\\\\\" Are \\u904b{\\u306f\\u3053}\\u3076 and \\u7bb1{\\u306f\\u3053} related? Physics-Informed Neural Network for 2D Wave Equation Produces Non-Circular / Distorted Wavefronts The road trip of the century Reasons for nations remaining in the Promised Land Bathtub leaks when draining full tub but not while showering more hot questions Question feed Subscribe to RSS Question feed To subscribe to this RSS feed, copy and paste this URL into your RSS reader. lang-bash Stack Overflow Questions Help Chat Business Stack Internal Stack Data Licensing Stack Ads Company About Press Work Here Legal Privacy Policy Terms of Service Contact Us Your Privacy Choices Cookie Policy Stack Exchange Network Technology Culture & recreation Life & arts Science Professional Business API Data Blog Facebook Twitter LinkedIn Instagram Site design / logo \\u00a9 2026 Stack Exchange Inc; user contributions licensed under CC BY-SA . rev 2025.12.22.38265\\\"},{\\\"url\\\":\\\"https://docs.opensearch.org/latest/im-plugin/index-templates/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Discovery and cluster formation Node discovery and seed hosts Voting and quorum Voting configuration management Cluster bootstrapping Discovery and cluster formation settings Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Remote segment warmer Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Similarity Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Resource access management Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates OpenSearch FIPS configuration Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control Defining users and roles Permissions Default action groups REST layer authorization Document-level security Field-level security Field masking User impersonation Resource sharing and access control Resource sharing APIs API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Version Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Mapping explosion Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Rescore Regular expression syntax SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic queries Complex queries Functions JSON support Metadata queries Aggregate functions Delete JDBC driver ODBC driver PPL Subsearch Commands PPL syntax ad addcoltotals addtotals append appendcol appendpipe bin chart dedup describe eval eventstats expand explain fields fillnull flatten grok head join kmeans lookup ml multisearch parse patterns rare regex rename replace reverse rex search show datasources sort spath stats streamstats subquery table timechart top trendline where Identifiers Data types Functions Full-text search Settings Troubleshooting Monitoring Limitations Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Collecting UBI-formatted data in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Model access control through resource sharing Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller ML Tasks APIs Get ML task Search ML tasks Delete ML task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow access control Workflow settings Workflow state access control Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detector access control Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecaster access control Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Managing Indexes Index templates Index templates Index templates let you initialize new indexes with predefined mappings and settings. For example, if you continuously index log data, you can define an index template so that all of these indexes have the same number of shards and replicas. Create a template To create an index template, use a PUT or POST request: PUT _index_template/<template name>\\\\nPOST _index_template/<template name>\\\\n This command creates a template named daily_logs and applies it to any new index whose name matches the pattern logs-2020-01-* and also adds it to the my_logs alias: PUT _index_template/daily_logs\\\\n{\\\\n  \\\\\\\"index_patterns\\\\\\\": [\\\\n    \\\\\\\"logs-2020-01-*\\\\\\\"\\\\n  ],\\\\n  \\\\\\\"template\\\\\\\": {\\\\n    \\\\\\\"aliases\\\\\\\": {\\\\n      \\\\\\\"my_logs\\\\\\\": {}\\\\n    },\\\\n    \\\\\\\"settings\\\\\\\": {\\\\n      \\\\\\\"number_of_shards\\\\\\\": 2,\\\\n      \\\\\\\"number_of_replicas\\\\\\\": 1\\\\n    },\\\\n    \\\\\\\"mappings\\\\\\\": {\\\\n      \\\\\\\"properties\\\\\\\": {\\\\n        \\\\\\\"timestamp\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"date\\\\\\\",\\\\n          \\\\\\\"format\\\\\\\": \\\\\\\"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\\\\\\\"\\\\n        },\\\\n        \\\\\\\"value\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"double\\\\\\\"\\\\n        }\\\\n      }\\\\n    }\\\\n  }\\\\n}\\\\n You should see the following response: {\\\\n  \\\\\\\"acknowledged\\\\\\\": true\\\\n}\\\\n If you create an index named logs-2020-01-01, you can see that it has the mappings and settings from the template: PUT logs-2020-01-01\\\\nGET logs-2020-01-01\\\\n {\\\\n  \\\\\\\"logs-2020-01-01\\\\\\\": {\\\\n    \\\\\\\"aliases\\\\\\\": {\\\\n      \\\\\\\"my_logs\\\\\\\": {}\\\\n    },\\\\n    \\\\\\\"mappings\\\\\\\": {\\\\n      \\\\\\\"properties\\\\\\\": {\\\\n        \\\\\\\"timestamp\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"date\\\\\\\",\\\\n          \\\\\\\"format\\\\\\\": \\\\\\\"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\\\\\\\"\\\\n        },\\\\n        \\\\\\\"value\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"double\\\\\\\"\\\\n        }\\\\n      }\\\\n    },\\\\n    \\\\\\\"settings\\\\\\\": {\\\\n      \\\\\\\"index\\\\\\\": {\\\\n        \\\\\\\"creation_date\\\\\\\": \\\\\\\"1578107970779\\\\\\\",\\\\n        \\\\\\\"number_of_shards\\\\\\\": \\\\\\\"2\\\\\\\",\\\\n        \\\\\\\"number_of_replicas\\\\\\\": \\\\\\\"1\\\\\\\",\\\\n        \\\\\\\"uuid\\\\\\\": \\\\\\\"U1vMDMOHSAuS2IzPcPHpOA\\\\\\\",\\\\n        \\\\\\\"version\\\\\\\": {\\\\n          \\\\\\\"created\\\\\\\": \\\\\\\"7010199\\\\\\\"\\\\n        },\\\\n        \\\\\\\"provided_name\\\\\\\": \\\\\\\"logs-2020-01-01\\\\\\\"\\\\n      }\\\\n    }\\\\n  }\\\\n}\\\\n Any additional indexes that match this pattern\\u2014logs-2020-01-02, logs-2020-01-03, and so on\\u2014will inherit the same mappings and settings. Index patterns cannot contain any of the following characters: :, \\\\\\\", +, /, \\\\\\\\, |, ?, #, >, and <. Retrieve a template To list all index templates: GET _cat/templates\\\\nGET /_index_template\\\\n To find a template by its name: GET _index_template/daily_logs\\\\n To get a list of all templates that match a pattern: GET _index_template/daily*\\\\n To check if a specific template exists: HEAD _index_template/<name>\\\\n Configure multiple templates You can create multiple index templates for your indexes. If the index name matches more than one template, OpenSearch takes the mappings and settings from the template with the highest priority and applies it to the index. For example, say you have the following two templates that both match the logs-2020-01-02 index and there\\u2019s a conflict in the number_of_shards field: Template 1 PUT _index_template/template-01\\\\n{\\\\n  \\\\\\\"index_patterns\\\\\\\": [\\\\n    \\\\\\\"logs*\\\\\\\"\\\\n  ],\\\\n  \\\\\\\"priority\\\\\\\": 0,\\\\n  \\\\\\\"template\\\\\\\": {\\\\n    \\\\\\\"settings\\\\\\\": {\\\\n      \\\\\\\"number_of_shards\\\\\\\": 2,\\\\n      \\\\\\\"number_of_replicas\\\\\\\": 2\\\\n    }\\\\n  }\\\\n}\\\\n Template 2 PUT _index_template/template-02\\\\n{\\\\n  \\\\\\\"index_patterns\\\\\\\": [\\\\n    \\\\\\\"logs-2020-01-*\\\\\\\"\\\\n  ],\\\\n  \\\\\\\"priority\\\\\\\": 1,\\\\n  \\\\\\\"template\\\\\\\": {\\\\n    \\\\\\\"settings\\\\\\\": {\\\\n      \\\\\\\"number_of_shards\\\\\\\": 3\\\\n    }\\\\n  }\\\\n}\\\\n Because template-02 has a higher priority value, it takes precedence over template-01 . The logs-2020-01-02 index would have the number_of_shards value as 3 and the number_of_replicas as the default value 1. Delete a template You can delete an index template using its name: DELETE _index_template/daily_logs\\\\n Composable index templates Managing multiple index templates has the following challenges: If you have duplication between index templates, storing these index templates results in a bigger cluster state. If you want to make a change across all your index templates, you have to manually make the change for each template. You can use composable index templates to overcome these challenges. Composable index templates let you abstract common settings, mappings, and aliases into a reusable building block called a component template. You can combine component templates to compose an index template. Settings and mappings that you specify directly in the create index request override any settings or mappings specified in an index template and its component templates. Create a component template Let\\u2019s define two component templates\\u2060\\u2014component_template_1 and component_template_2: Component template 1 PUT _component_template/component_template_1\\\\n{\\\\n  \\\\\\\"template\\\\\\\": {\\\\n    \\\\\\\"mappings\\\\\\\": {\\\\n      \\\\\\\"properties\\\\\\\": {\\\\n        \\\\\\\"@timestamp\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"date\\\\\\\"\\\\n        }\\\\n      }\\\\n    }\\\\n  }\\\\n}\\\\n Component template 2 PUT _component_template/component_template_2\\\\n{\\\\n  \\\\\\\"template\\\\\\\": {\\\\n    \\\\\\\"mappings\\\\\\\": {\\\\n      \\\\\\\"properties\\\\\\\": {\\\\n        \\\\\\\"ip_address\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"ip\\\\\\\"\\\\n        }\\\\n      }\\\\n    }\\\\n  }\\\\n}\\\\n Use component templates to create an index template When creating index templates, you need to include the component templates in a composed_of list. OpenSearch applies the component templates in the order in which you specify them within the index template. The settings, mappings, and aliases that you specify inside the index template are applied last. PUT _index_template/daily_logs\\\\n{\\\\n  \\\\\\\"index_patterns\\\\\\\": [\\\\n    \\\\\\\"logs-2020-01-*\\\\\\\"\\\\n  ],\\\\n  \\\\\\\"template\\\\\\\": {\\\\n    \\\\\\\"aliases\\\\\\\": {\\\\n      \\\\\\\"my_logs\\\\\\\": {}\\\\n    },\\\\n    \\\\\\\"settings\\\\\\\": {\\\\n      \\\\\\\"number_of_shards\\\\\\\": 2,\\\\n      \\\\\\\"number_of_replicas\\\\\\\": 1\\\\n    },\\\\n    \\\\\\\"mappings\\\\\\\": {\\\\n      \\\\\\\"properties\\\\\\\": {\\\\n        \\\\\\\"timestamp\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"date\\\\\\\",\\\\n          \\\\\\\"format\\\\\\\": \\\\\\\"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\\\\\\\"\\\\n        },\\\\n        \\\\\\\"value\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"double\\\\\\\"\\\\n        }\\\\n      }\\\\n    }\\\\n  },\\\\n  \\\\\\\"priority\\\\\\\": 200,\\\\n  \\\\\\\"composed_of\\\\\\\": [\\\\n    \\\\\\\"component_template_1\\\\\\\",\\\\n    \\\\\\\"component_template_2\\\\\\\"\\\\n  ],\\\\n  \\\\\\\"version\\\\\\\": 3,\\\\n  \\\\\\\"_meta\\\\\\\": {\\\\n    \\\\\\\"description\\\\\\\": \\\\\\\"using component templates\\\\\\\"\\\\n  }\\\\n}\\\\n If you create an index named logs-2020-01-01, you can see that it derives its mappings and settings from both the component templates: PUT logs-2020-01-01\\\\nGET logs-2020-01-01\\\\n Example response {\\\\n  \\\\\\\"logs-2020-01-01\\\\\\\": {\\\\n    \\\\\\\"aliases\\\\\\\": {\\\\n      \\\\\\\"my_logs\\\\\\\": {}\\\\n    },\\\\n    \\\\\\\"mappings\\\\\\\": {\\\\n      \\\\\\\"properties\\\\\\\": {\\\\n        \\\\\\\"@timestamp\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"date\\\\\\\"\\\\n        },\\\\n        \\\\\\\"ip_address\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"ip\\\\\\\"\\\\n        },\\\\n        \\\\\\\"timestamp\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"date\\\\\\\",\\\\n          \\\\\\\"format\\\\\\\": \\\\\\\"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\\\\\\\"\\\\n        },\\\\n        \\\\\\\"value\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"double\\\\\\\"\\\\n        }\\\\n      }\\\\n    },\\\\n    \\\\\\\"settings\\\\\\\": {\\\\n      \\\\\\\"index\\\\\\\": {\\\\n        \\\\\\\"creation_date\\\\\\\": \\\\\\\"1625382479459\\\\\\\",\\\\n        \\\\\\\"number_of_shards\\\\\\\": \\\\\\\"2\\\\\\\",\\\\n        \\\\\\\"number_of_replicas\\\\\\\": \\\\\\\"1\\\\\\\",\\\\n        \\\\\\\"uuid\\\\\\\": \\\\\\\"rYUlpOXDSUSuZifQLPfa5A\\\\\\\",\\\\n        \\\\\\\"version\\\\\\\": {\\\\n          \\\\\\\"created\\\\\\\": \\\\\\\"7100299\\\\\\\"\\\\n        },\\\\n        \\\\\\\"provided_name\\\\\\\": \\\\\\\"logs-2020-01-01\\\\\\\"\\\\n      }\\\\n    }\\\\n  }\\\\n}\\\\n Index template options You can specify the following template options: Option Type Description Required template Object Specify index settings, mappings, and aliases. No priority Integer The priority of the index template. No composed_of String array The names of component templates applied on a new index together with the current template. No version Integer Specify a version number to simplify template management. Default is null. No _meta Object Specify meta information about the template. No Create a template Retrieve a template Configure multiple templates Delete a template Create a component template Use component templates to create an index template WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright \\u00a9 OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\\\"}]}\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Search for OpenSearch documentation\n",
    "parameters = {\n",
    "    \"question\": \"How to create an index pattern in OpenSearch?\"\n",
    "}\n",
    "\n",
    "print(\"‚ùì Question: How to create an index pattern in OpenSearch?\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "response = execute_agent(client, agent_id, parameters)\n",
    "\n",
    "print(\"\\nüåê Web Search Results:\")\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b75e24",
   "metadata": {},
   "source": [
    "## Formatting the output - Markdown\n",
    "- One result content out of many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3478713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# üìÑ OpenSearch Index Pattern Guide\n",
       "\n",
       "## Overview\n",
       "Index patterns are essential for accessing OpenSearch data. They reference one or more indexes, data streams, or index aliases.\n",
       "\n",
       "## Step 1: 1: Define the index pattern Go to OpenSearch Dashboards, and select Management > Dashboards Management > Index patterns\n",
       "Select Create index pattern. From the Create index pattern window, define the index pattern by entering a name for your index pattern in the Index pattern name field. Dashboards automatically adds a wildcard, *, once you start typing. Using a wildcard is helpful for matching an index pattern to multiple sources or indexes. A dropdown list displaying all the indexes that match your index pattern appears when you start typing. Select Next step. An example of step 1 is shown in the following image. Note that the index pattern security* matches three indexes. By defining the pattern with a wildcard *, you can query and visualize all the data in your indexes. \n",
       "\n",
       "## Step 2: 2: Configure the settings Select @timestamp from the dropdown menu to specify the time field for OpenSearch to use when filtering documents based on time\n",
       "Selecting this time filter determines which field the time filter is applied to. It can be the timestamp of a request or any relevant timestamp field. If you don‚Äôt want to use a time filter, select that option from the dropdown menu. If you select this option, OpenSearch returns all of the data in the indexes that match the pattern. Select Create index pattern. An example is shown in the following image. Once the index pattern has been created, you can view the mapping of the matching indexes. Within the table, you can see the list of fields, along with their data type and properties. An example is shown in the following image. Next steps Understand your data through visuals. Dig into your data. Get started Prerequisites Best practices Creating an index pattern \n",
       "\n",
       "## Step 4: 2: Configure the settings Next steps WAS THIS PAGE HELPFUL? ‚úî Yes ‚úñ No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum\n",
       "Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright ¬© OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import JSON, display, HTML, Markdown\n",
    "\n",
    "result1 = json.loads(response['inference_results'][0]['output'][0]['result'])['items'][0]['content']\n",
    "\n",
    "# Extract key sections from the content\n",
    "sections = result1.split('Step ')\n",
    "\n",
    "# Create formatted output\n",
    "output = \"# üìÑ OpenSearch Index Pattern Guide\\n\\n\"\n",
    "\n",
    "# Add introduction\n",
    "output += \"## Overview\\n\"\n",
    "output += \"Index patterns are essential for accessing OpenSearch data. They reference one or more indexes, data streams, or index aliases.\\n\\n\"\n",
    "\n",
    "# Parse and format the steps\n",
    "for i, section in enumerate(sections[1:], 1):\n",
    "    lines = section.split('. ', 1)\n",
    "    if len(lines) > 1:\n",
    "        output += f\"## Step {i}: {lines[0]}\\n\"\n",
    "        output += f\"{lines[1]}\\n\\n\"\n",
    "\n",
    "# Display as markdown\n",
    "display(Markdown(output))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cb3ebc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# üåê All Web Search Results\n",
       "\n",
       "**Total Results:** 10  \n",
       "**Query:** How to create an index pattern in OpenSearch?\n",
       "\n",
       "---\n",
       "\n",
       "## Result 1: Link Search Menu Expand Document Documentation Menu\n",
       "\n",
       "**üîó Source:** [https://docs.opensearch.org/latest/dashboards/management/index-patterns/](https://docs.opensearch.org/latest/dashboards/management/index-patterns/)\n",
       "\n",
       "**Overview:**\n",
       "Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards ‚Üê Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Discovery and cluster formation Node discovery and seed hosts Voting and quorum Voting configuration management Cluster bootstrapping Discovery and cluster formation settings Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Remote segment warmer Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Similarity Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Resource access management Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates OpenSearch FIPS configuration Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control Defining users and roles Permissions Default action groups REST layer authorization Document-level security Field-level security Field masking User impersonation Resource sharing and access control Resource sharing APIs API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Version Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Mapping explosion Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Rescore Regular expression syntax SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic queries Complex queries Functions JSON support Metadata queries Aggregate functions Delete JDBC driver ODBC driver PPL Subsearch Commands PPL syntax ad addcoltotals addtotals append appendcol appendpipe bin chart dedup describe eval eventstats expand explain fields fillnull flatten grok head join kmeans lookup ml multisearch parse patterns rare regex rename replace reverse rex search show datasources sort spath stats streamstats subquery table timechart top trendline where Identifiers Data types Functions Full-text search Settings Troubleshooting Monitoring Limitations Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Collecting UBI-formatted data in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Model access control through resource sharing Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller ML Tasks APIs Get ML task Search ML tasks Delete ML task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow access control Workflow settings Workflow state access control Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detector access control Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecaster access control Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions OpenSearch Dashboards Dashboards Management Index patterns Index patterns Index patterns are essential for accessing OpenSearch data. An index pattern references one or more indexes, data streams, or index aliases. For example, an index pattern can point you to your log data from yesterday or all indexes that contain that data. If you store data in multiple indexes, creating an index pattern enables your visualizations to retrieve data from all indexes that match the index pattern. You need to create index patterns to define how data is retrieved and fields are formatted so that you can query, search, and display data. Get started In this tutorial, you‚Äôll learn to create index patterns. Note To create or modify index patterns, you must have create, manage, and delete permissions. Contact your administrator for support. For more information, refer to Multi-tenancy configuration. Prerequisites Before you can create an index pattern, your data must be indexed. To learn about indexing your data in OpenSearch, see Managing indexes. Best practices Consider the following best practices when creating index patterns: Make your index patterns specific. Instead of creating an index pattern that matches all indexes, create an index pattern that matches all indexes starting with a certain prefix, for example, my-index-. The more specific your index patterns, the better it will be to query and analyze your data. Use wildcards sparingly. Wildcards can be useful for matching multiple indexes, but they can also make it more difficult to manage your index patterns. Try to use wildcards as specifically as possible. Test your index patterns. Make sure to test your index patterns to ensure that they match the correct indexes. Creating an index pattern If you added sample data, you have index patterns that you can use to analyze that data. To create an index pattern for your own data, follow these steps.\n",
       "\n",
       "### Step 1: 1: Define the index pattern Go to OpenSearch Dashboards, and select Management > Dashboards Management > Index patterns\n",
       "Select Create index pattern. From the Create index pattern window, define the index pattern by entering a name for your index pattern in the Index pattern name field. Dashboards automatically adds a wildcard, *, once you start typing. Using a wildcard is helpful for matching an index pattern to multiple sources or indexes. A dropdown list displaying all the indexes that match your index pattern appears when you start typing. Select Next step. An example of step 1 is shown in the following image. Note that the index pattern security* matches three indexes. By defining the pattern with a wildcard *, you can query and visualize all the data in your indexes. \n",
       "\n",
       "### Step 2: 2: Configure the settings Select @timestamp from the dropdown menu to specify the time field for OpenSearch to use when filtering documents based on time\n",
       "Selecting this time filter determines which field the time filter is applied to. It can be the timestamp of a request or any relevant timestamp field. If you don‚Äôt want to use a time filter, select that option from the dropdown menu. If you select this option, OpenSearch returns all of the data in the indexes that match the pattern. Select Create index pattern. An example is shown in the following image. Once the index pattern has been created, you can view the mapping of the matching indexes. Within the table, you can see the list of fields, along with their data type and properties. An example is shown in the following image. Next steps Understand your data through visuals. Dig into your data. Get started Prerequisites Best practices Creating an index pattern \n",
       "\n",
       "1: Define the index pattern\n",
       "\n",
       "### Step 4: 2: Configure the settings Next steps WAS THIS PAGE HELPFUL? ‚úî Yes ‚úñ No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum\n",
       "Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright ¬© OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\n",
       "\n",
       "---\n",
       "\n",
       "## Result 2: \n",
       "\n",
       "**üîó Source:** [https://github.com/opensearch-project/opensearch-py/blob/main/guides/index_template.md](https://github.com/opensearch-project/opensearch-py/blob/main/guides/index_template.md)\n",
       "\n",
       "**Overview:**\n",
       "Skip to content Navigation Menu Toggle navigation Sign in Appearance settings Platform AI CODE CREATION GitHub CopilotWrite better code with AI GitHub SparkBuild and deploy intelligent apps GitHub ModelsManage and compare prompts MCP RegistryNewIntegrate external tools DEVELOPER WORKFLOWS ActionsAutomate any workflow CodespacesInstant dev environments IssuesPlan and track work Code ReviewManage code changes APPLICATION SECURITY GitHub Advanced SecurityFind and fix vulnerabilities Code securitySecure your code as you build Secret protectionStop leaks before they start EXPLORE Why GitHub Documentation Blog Changelog Marketplace View all features Solutions BY COMPANY SIZE Enterprises Small and medium teams Startups Nonprofits BY USE CASE App Modernization DevSecOps DevOps CI/CD View all use cases BY INDUSTRY Healthcare Financial services Manufacturing Government View all industries View all solutions Resources EXPLORE BY TOPIC AI Software Development DevOps Security View all topics EXPLORE BY TYPE Customer stories Events & webinars Ebooks & reports Business insights GitHub Skills SUPPORT & SERVICES Documentation Customer support Community forum Trust center Partners Open Source COMMUNITY GitHub SponsorsFund open source developers PROGRAMS Security Lab Maintainer Community Accelerator Archive Program REPOSITORIES Topics Trending Collections Enterprise ENTERPRISE SOLUTIONS Enterprise platformAI-powered developer platform AVAILABLE ADD-ONS GitHub Advanced SecurityEnterprise-grade security features Copilot for BusinessEnterprise-grade AI features Premium SupportEnterprise-grade 24/7 support Pricing Search or jump to... Search code, repositories, users, issues, pull requests... Search Clear Search syntax tips Provide feedback We read every piece of feedback, and take your input very seriously. Include my email address so I can be contacted Cancel Submit feedback Saved searches Use saved searches to filter your results more quickly Name Query To see all available qualifiers, see our documentation. Cancel Create saved search Sign in Sign up Appearance settings Resetting focus You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert {{ message }} opensearch-project / opensearch-py Public generated from amazon-archives/__template_Custom Notifications You must be signed in to change notification settings Fork 213 Star 450 Code Issues 77 Pull requests 12 Actions Projects 0 Security Uh oh! There was an error while loading. Please reload this page. Insights Additional navigation options Code Issues Pull requests Actions Projects Security Insights Footer ¬© 2026 GitHub, Inc. Footer navigation Terms Privacy Security Status Community Docs Contact Manage cookies Do not share my personal information You can‚Äôt perform that action at this time.\n",
       "\n",
       "---\n",
       "\n",
       "## Result 3: \n",
       "\n",
       "**üîó Source:** [https://www.youtube.com/watch?v=pbABIerUYQI](https://www.youtube.com/watch?v=pbABIerUYQI)\n",
       "\n",
       "**Overview:**\n",
       "AboutPressCopyrightContact usCreatorsAdvertiseDevelopersTermsPrivacyPolicy & SafetyHow YouTube worksTest new featuresNFL Sunday Ticket ¬© 2026 Google LLC\n",
       "\n",
       "---\n",
       "\n",
       "## Result 4: \n",
       "\n",
       "**üîó Source:** [https://www.bookstack.cn/read/opensearch-2.19-en/4ce9edd150bec500.md](https://www.bookstack.cn/read/opensearch-2.19-en/4ce9edd150bec500.md)\n",
       "\n",
       "**Overview:**\n",
       "√ó ÊÄùÁª¥ÂØºÂõæÂ§áÊ≥® ÂÖ≥Èó≠ OpenSearch v2.19 Documentation È¶ñÈ°µ AIÂä©Êâã ÁôΩÂ§© Â§úÈó¥ Â∞èÁ®ãÂ∫è ÈòÖËØª ‰π¶Á≠æ ÊàëÁöÑ‰π¶Á≠æ Ê∑ªÂä†‰π¶Á≠æ ÁßªÈô§‰π¶Á≠æ Index patterns GitHub Êù•Ê∫ê:OpenSearch ÊµèËßà 199 Êâ´Á†Å 2025-05-09 14:09:39 Index patterns Get started Prerequisites Best practices Creating an index pattern\n",
       "\n",
       "1: Define the index pattern\n",
       "\n",
       "### Step 2: 2: Configure the settings Next steps You‚Äôre viewing version 2.19 of the OpenSearch documentation\n",
       "For the latest version, see the current documentation. For information about OpenSearch version maintenance, see Release Schedule and Maintenance Policy. Index patterns Index patterns are essential for accessing OpenSearch data. An index pattern references one or more indexes, data streams, or index aliases. For example, an index pattern can point you to your log data from yesterday or all indexes that contain that data. If you store data in multiple indexes, creating an index pattern enables your visualizations to retrieve data from all indexes that match the index pattern. You need to create index patterns to define how data is retrieved and fields are formatted so that you can query, search, and display data. Get started In this tutorial, you‚Äôll learn to create index patterns. Note To create or modify index patterns, you must have create, manage, and delete permissions. Contact your administrator for support. For more information, refer to Multi-tenancy configuration. Prerequisites Before you can create an index pattern, your data must be indexed. To learn about indexing your data in OpenSearch, see Managing indexes. Best practices Consider the following best practices when creating index patterns: Make your index patterns specific. Instead of creating an index pattern that matches all indexes, create an index pattern that matches all indexes starting with a certain prefix, for example, my-index-. The more specific your index patterns, the better it will be to query and analyze your data. Use wildcards sparingly. Wildcards can be useful for matching multiple indexes, but they can also make it more difficult to manage your index patterns. Try to use wildcards as specifically as possible. Test your index patterns. Make sure to test your index patterns to ensure that they match the correct indexes. Creating an index pattern If you added sample data, you have index patterns that you can use to analyze that data. To create an index pattern for your own data, follow these steps. \n",
       "\n",
       "### Step 3: 1: Define the index pattern Go to OpenSearch Dashboards, and select Management > Dashboards Management > Index patterns\n",
       "Select Create index pattern. From the Create index pattern window, define the index pattern by entering a name for your index pattern in the Index pattern name field. Dashboards automatically adds a wildcard, *, once you start typing. Using a wildcard is helpful for matching an index pattern to multiple sources or indexes. A dropdown list displaying all the indexes that match your index pattern appears when you start typing. Select Next step. An example of step 1 is shown in the following image. Note that the index pattern security* matches three indexes. By defining the pattern with a wildcard *, you can query and visualize all the data in your indexes. \n",
       "\n",
       "### Step 4: 2: Configure the settings Select @timestamp from the dropdown menu to specify the time field for OpenSearch to use when filtering documents based on time\n",
       "Selecting this time filter determines which field the time filter is applied to. It can be the timestamp of a request or any relevant timestamp field. If you don‚Äôt want to use a time filter, select that option from the dropdown menu. If you select this option, OpenSearch returns all of the data in the indexes that match the pattern. Select Create index pattern. An example is shown in the following image. Once the index pattern has been created, you can view the mapping of the matching indexes. Within the table, you can see the list of fields, along with their data type and properties. An example is shown in the following image. Next steps Understand your data through visuals. Dig into your data. ÂΩìÂâçÂÜÖÂÆπÁâàÊùÉÂΩí OpenSearch ÊàñÂÖ∂ÂÖ≥ËÅîÊñπÊâÄÊúâÔºåÂ¶ÇÈúÄÂØπÂÜÖÂÆπÊàñÂÜÖÂÆπÁõ∏ÂÖ≥ËÅîÂºÄÊ∫êÈ°πÁõÆËøõË°åÂÖ≥Ê≥®‰∏éËµÑÂä©ÔºåËØ∑ËÆøÈóÆ OpenSearch . ‰∏ä‰∏ÄÁØá: ‰∏ã‰∏ÄÁØá: ÁâàÊú¨ OpenSearch v3.0 Documentation OpenSearch v2.19 Documentation OpenSearch v2.18 Documentation OpenSearch v2.17 Documentation OpenSearch v2.16 Documentation OpenSearch v2.15 Documentation OpenSearch v2.14 Documentation OpenSearch v2.13 Documentation OpenSearch v2.12 Documentation OpenSearch v2.11 Documentation OpenSearch v2.10 Documentation OpenSearch v2.9 Documentation OpenSearch v2.8 Documentation OpenSearch v2.7 Documentation OpenSearch v2.6 Documentation OpenSearch v2.5 Documentation OpenSearch v2.4 Documentation OpenSearch v2.3 Documentation OpenSearch v2.2 Documentation OpenSearch v2.1 Documentation OpenSearch v2.0 Documentation OpenSearch v1.3 Documentation OpenSearch v1.2 Documentation OpenSearch v1.1 Documentation OpenSearch v1.0 Documentation About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Getting started with OpenSearch security Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Chatbots and agents RAG chatbot Build your own chatbot RAG chatbot with a conversational flow agent AI search workflows Creating and customizing AI search workflows Model guardrails Amazon Bedrock model guardrails Install and upgrade Installing OpenSearch Docker Helm Tarball RPM Debian Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Circuit breaker settings Cluster settings Index settings Search settings Availability and recovery settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Upgrading OpenSearch Rolling Upgrade Upgrades appendix Rolling upgrade lab Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Managing Indexes Index templates Index aliases Data streams Index context Reindex data Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings Index management security Refresh search analyzer ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Ingest Pipelines Create pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove_by_pattern Remove Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data Time filter Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers Gantt charts TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dev Tools Running queries in the Dev Tools console Query Workbench Custom branding Dashboards Query Language (DQL) Configuring CSP rules for frame ancestors Search telemetry OpenSearch Integrations Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Workload management Query Group Lifecycle API Tuning for indexing speed Security in OpenSearch Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings and field types Mapping parameters Analyzer Boost Coerce Copy_to Doc values Dynamic Eager global ordinals Enabled Ignore above Ignore malformed Format Index Index options Fields Meta Normalizer Norms Null value Properties Search analyzer Store Term vector Supported field types Alias Binary Numeric field types Unsigned long Boolean k-NN vector Spaces Methods and engines Memory-optimized vectors Date field types Date Date nanoseconds IP address Range field types Object field types Object Nested Flat object Join String field types Keyword Text Match-only text Wildcard Token count Constant keyword Autocomplete field types Completion Search as you type Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Rank field types Star-tree Derived Percolator Metadata fields Field names ID Ignored Index Meta Routing Source Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Exists Fuzzy IDs Prefix Range Regexp Term Terms Terms set Wildcard Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Distance feature k-NN Neural Neural sparse Script score Template Minimum should match Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Range Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Search features Search options Paginate results Point in Time Point in Time API Sort results Filter results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Comparing search results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI client data structures Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines Search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Identifiers Data Types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Hybrid search with post-filtering Combining hybrid search and aggregations Using sorting with a hybrid query Hybrid search with search_after Hybrid search explain Paginating hybrid query results Multimodal search Neural sparse search Generating sparse vector embeddings automatically Neural sparse search using raw vectors Conversational search with RAG Building AI search workflows in OpenSearch Dashboards Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Specialized vector search Nested field search Radial search Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Performance tuning Indexing performance tuning Search performance tuning LLM framework integration Vector search API k-NN API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Tools Agent tool CAT Index tool Connector tool Index Mapping tool ML Model tool Neural Sparse Search tool PPL tool RAG tool Search Alerts tool CreateAnomalyDetectorTool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Execute agent Get agent Search agent Delete agent Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI OpenSearch Kubernetes Operator Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Index APIs Alias Create or update alias Blocks Clear cache Clone index Open index Index exists Close index Create index Delete index Get index Shrink index Create or update index template Get index template Delete index template Simulate index templates Create or update mappings Create or update component template Dangling indexes Flush Force merge Recovery Get settings Update settings Refresh index Resolve index Roll over index Segment Split index Stats Analyze API Analysis API Terminology CAT API CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster routing and awareness Cluster decommission Cluster health Cluster settings Cluster stats Count Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get document Delete by query Update by query Reindex document Explain Ingest APIs List API List shards List indices Multi-search Multi-search Template Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Profile Ranking evaluation Remote cluster information Script APIs Create or Update Stored Script Execute Painless stored script Get Stored Script Delete Script Get Stored Script Contexts Get Script Language Execute Painless script Scroll Search Search templates Snapshot APIs Register Snapshot Repository Get Snapshot Repository Delete Snapshot Repository Verify Snaphot Repository Create Snapshot Get Snapshot Delete Snapshot Get Snapshot Status Restore Snapshot Clone snapshot Cleanup Snapshot Repository Render Template Security APIs Tasks API List tasks Get task Cancel tasks Validate Query Supported units Common REST Parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions ÊöÇÊó†Áõ∏ÂÖ≥ÊêúÁ¥¢ÁªìÊûúÔºÅ Êú¨ÊñáÊ°£‰ΩøÁî® BookStack ÊûÑÂª∫ √ó ÊñáÁ´†‰∫åÁª¥Á†Å ÊâãÊú∫Êâ´‰∏ÄÊâ´ÔºåËΩªÊùæÊéå‰∏äËØª ÂÖ≥Èó≠ √ó ÊñáÊ°£‰∏ãËΩΩ ÊôÆÈÄö‰∏ãËΩΩ ‰∏ãËΩΩÁ†Å‰∏ãËΩΩ(ÂÖçÁôªÂΩïÊó†Èôê‰∏ãËΩΩ) ‰Ω†‰∏éÂ§ßÁ•ûÁöÑË∑ùÁ¶ªÔºåÂè™Â∑Æ‰∏Ä‰∏™APP ËØ∑‰∏ãËΩΩÊÇ®ÈúÄË¶ÅÁöÑÊ†ºÂºèÁöÑÊñáÊ°£ÔºåÈöèÊó∂ÈöèÂú∞Ôºå‰∫´ÂèóÊ±≤ÂèñÁü•ËØÜÁöÑ‰πêË∂£ÔºÅ PDFÊñáÊ°£ EPUBÊñáÊ°£ MOBIÊñáÊ°£ Ê∏©È¶®ÊèêÁ§∫ ÊØèÂ§©ÊØèÂú®ÁΩëÁ´ôÈòÖËØªÂ≠¶‰π†‰∏ÄÂàÜÈíüÊó∂ÈïøÂèØ‰∏ãËΩΩ‰∏ÄÊú¨ÁîµÂ≠ê‰π¶ÔºåÊØèÂ§©ËøûÁª≠Á≠æÂà∞ÂèØÂ¢ûÂä†ÈòÖËØªÊó∂Èïø ‰∏ãËΩΩÁ†ÅÊñπÂºè‰∏ãËΩΩÔºöÂÖçË¥π„ÄÅÂÖçÁôªÂΩï„ÄÅÊó†ÈôêÂà∂„ÄÇ ÂÖçË¥πËé∑Âèñ‰∏ãËΩΩÁ†Å ‰∏ãËΩΩÁ†Å ÊñáÊ°£Ê†ºÂºè PDF EPUB MOBI Á†Å‰∏ä‰∏ãËΩΩ ÂÖ≥Èó≠Á™óÂè£ √ó ÂæÆ‰ø°Â∞èÁ®ãÂ∫èÈòÖËØª ÊÇ®‰∏é‰ªñ‰∫∫ÁöÑËñ™ËµÑÂ∑ÆË∑ùÔºåÂè™Â∑Æ‰∏Ä‰∏™ÈöèÊó∂ÈöèÂú∞Â≠¶‰π†ÁöÑÂ∞èÁ®ãÂ∫è ÂÖ≥Èó≠Á™óÂè£ √ó ‰π¶Á≠æÂàóË°® ÂÖ≥Èó≠ √ó ÈòÖËØªËÆ∞ÂΩï ÈòÖËØªËøõÂ∫¶: 0.00% ( 0/0 ) ÈáçÁΩÆÈòÖËØªËøõÂ∫¶ ÂÖ≥Èó≠ Ê¨¢Ëøé‰ΩøÁî®AIÂä©Êâã AIÂä©Êâã ÂÖ®Â±è Áº©Â∞è ÈöêËóè Ê∏ÖÁ©∫\n",
       "\n",
       "---\n",
       "\n",
       "## Result 5: \n",
       "\n",
       "**üîó Source:** [https://deepwiki.com/johnny-chivers/amazon-opensearch-service/3.1-index-patterns](https://deepwiki.com/johnny-chivers/amazon-opensearch-service/3.1-index-patterns)\n",
       "\n",
       "**Overview:**\n",
       "Loading... Index your code with Devin DeepWiki DeepWiki johnny-chivers/amazon-opensearch-service Index your code with Devin Edit Wiki Share Loading... Last indexed: 25 May 2025 (924181) Overview Getting Started Tutorial Domain Setup Data Upload and Indexing Search Operations Cleanup and Domain Deletion Index Management Index Patterns Field Configuration Security and Access Control Access Control Systems Access Policies System Architecture Data Node Architecture Network Configuration Development and Testing Menu Index Patterns Relevant source files pictures/12-define-index-pattern.png pictures/13-createe-index-pattern.png Purpose and Scope This document covers the creation and configuration of index patterns in Amazon OpenSearch Service, specifically focusing on how they enable data discovery and visualization through the OpenSearch Dashboards interface. Index patterns define how OpenSearch Dashboards connects to and interprets the data stored in your OpenSearch indices. This guide specifically covers the index pattern workflow for the movies dataset used in the tutorial. For information about the underlying index field configuration and data types, see Field Configuration. For the broader context of data upload and indexing operations, see Data Upload and Indexing. Overview of Index Patterns Index patterns in OpenSearch Dashboards serve as a bridge between raw index data and the visualization layer. They define which indices contain the data you want to explore and specify how that data should be interpreted for search and analysis operations. In the context of this tutorial, index patterns enable access to the movies index that contains the bulk movie dataset from bulk_movies.json. Sources: Based on tutorial workflow and OpenSearch Dashboards architecture patterns. Index Pattern Creation Workflow The index pattern creation process follows a specific sequence within the OpenSearch Dashboards interface, as documented in the tutorial screenshots. Sources: Tutorial workflow sequence and OpenSearch Dashboards interface patterns. Pattern Definition and Configuration Index patterns use wildcard matching to identify which indices they should include. For the movies dataset, the pattern typically follows this structure: Pattern Element Purpose Example Index Name Base index identifier movies Wildcard Pattern matching movies* Time Field Timestamp field for time-based data Not applicable for movies dataset Field Discovery Automatic field detection Enabled The pattern configuration process involves several key steps: Sources: OpenSearch Dashboards index pattern creation workflow and field detection mechanisms. Field Mapping and Data Types Once an index pattern is created, OpenSearch Dashboards automatically discovers and maps the fields from the underlying movies index. This process examines the data structure from the documents uploaded via bulk_movies.json. The field mapping process identifies several categories of data: Field Category Examples from Movies Data OpenSearch Type Text Fields title, director, genre text or keyword Numeric Fields year, rating integer or float Date Fields release_date date Boolean Fields available boolean Sources: OpenSearch field mapping documentation and movies dataset structure analysis. Integration with Discovery Interface Index patterns enable the Discover interface to provide search and exploration capabilities across the movie dataset. The integration allows for both simple and complex query operations. The discovery workflow leverages the index pattern to: Field-based Filtering: Use detected fields for creating search filters Time-based Navigation: Handle temporal data if time fields are configured Aggregation Operations: Support grouping and statistical operations Export Functionality: Enable data export based on search results Sources: OpenSearch Dashboards Discover interface capabilities and query processing architecture. Pattern Management and Maintenance Index patterns require ongoing management as data structures evolve. The tutorial demonstrates basic pattern creation, but production environments often need pattern updates and field refresh operations. Key maintenance operations include: Field Refresh: Update field mappings when new fields are added to indices Pattern Modification: Adjust pattern matching rules for new indices Performance Optimization: Configure field settings for optimal query performance Access Control: Manage pattern visibility and permissions The movies dataset provides a stable example for learning these concepts, as the data structure remains consistent throughout the tutorial workflow. Sources: OpenSearch index pattern management best practices and tutorial documentation structure. Dismiss Refresh this wiki Enter email to refresh On this page Index Patterns Purpose and Scope Overview of Index Patterns Index Pattern Creation Workflow Pattern Definition and Configuration Field Mapping and Data Types Integration with Discovery Interface Pattern Management and Maintenance\n",
       "\n",
       "---\n",
       "\n",
       "## Result 6: Link Search Menu Expand Document Documentation Menu\n",
       "\n",
       "**üîó Source:** [https://docs.opensearch.org/latest/api-reference/index-apis/create-index-template/](https://docs.opensearch.org/latest/api-reference/index-apis/create-index-template/)\n",
       "\n",
       "**Overview:**\n",
       "Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards ‚Üê Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Discovery and cluster formation Node discovery and seed hosts Voting and quorum Voting configuration management Cluster bootstrapping Discovery and cluster formation settings Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Remote segment warmer Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Similarity Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Resource access management Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates OpenSearch FIPS configuration Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control Defining users and roles Permissions Default action groups REST layer authorization Document-level security Field-level security Field masking User impersonation Resource sharing and access control Resource sharing APIs API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Version Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Mapping explosion Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Rescore Regular expression syntax SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic queries Complex queries Functions JSON support Metadata queries Aggregate functions Delete JDBC driver ODBC driver PPL Subsearch Commands PPL syntax ad addcoltotals addtotals append appendcol appendpipe bin chart dedup describe eval eventstats expand explain fields fillnull flatten grok head join kmeans lookup ml multisearch parse patterns rare regex rename replace reverse rex search show datasources sort spath stats streamstats subquery table timechart top trendline where Identifiers Data types Functions Full-text search Settings Troubleshooting Monitoring Limitations Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Collecting UBI-formatted data in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Model access control through resource sharing Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller ML Tasks APIs Get ML task Search ML tasks Delete ML task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow access control Workflow settings Workflow state access control Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detector access control Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecaster access control Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions API reference Index APIs Index templates Create or update index template Create Or Update Index Template API You can use the Create or Update Index Template API to create indexes with predefined mappings and settings as well as update existing index templates. Endpoints PUT _index_template/<template-name>\n",
       "POST _index_template/<template-name>\n",
       " Path parameters Parameter Data type Description template-name String The name of the index template. Query parameters The following optional query parameters are supported. Parameter Data type Description create Boolean When true, the API cannot replace or update any existing index templates. Default is false. cluster_manager_timeout Time The amount of time to wait for a connection to the cluster manager node. Default is 30s. Request body fields The following options can be used in the request body to customize the index template. Parameter Type Description index_patterns String array An array of wildcard expressions that match the names of data streams and indexes created during template creation. Required. composed_of String array An ordered list of component template names. These templates are merged using the specified order. For more information, see Using multiple component templates. Optional. data_stream Object When used, the request creates data streams and any backing indexes based on the template. This setting requires a matching index template. It can also be used with the hidden setting, which, when set to true, hides the data stream backing indexes. Optional. _meta Object Optional metadata that provides details about the index template. Optional. priority Integer A number that determines which index templates take precedence during the creation of a new index or data stream. OpenSearch chooses the template with the highest priority. When no priority is given, the template is assigned a 0, signifying the lowest priority. Optional. template Object The template that includes the aliases, mappings, or settings for the index. For more information, see [#template]. Optional. version Integer The version number used to manage index templates. Version numbers are not automatically set by OpenSearch. Optional. context Object (Experimental) The context parameter provides use-case-specific predefined templates that can be applied to an index. Among all settings and mappings declared for a template, context templates hold the highest priority. For more information, see index-context. Template You can use the following objects with the template option in the request body. alias The name of the alias to associate with the template as a key. Required when the template option exists in the request body. This option supports multiple aliases. The object body contains the following optional alias parameters. Parameter Data type Description filter Query DSL object The query that limits the number of documents that the alias can access. index_routing String The value that routes indexing operations to a specific shard. When specified, overwrites the routing value for indexing operations. is_hidden Boolean When true, the alias is hidden. Default is false. All alias indexes must have matching values for this setting. is_write_index Boolean When true, the index is the write index for the alias. Default is false. routing String The value used to route index and search operations to a specific shard. search_routing String The value used to write specific search operations to a specific shard. When specified, this option overwrites the routing value for search operations. mappings The field mappings that exist in the index. For more information, see Mappings and field types. Optional. settings Any configuration options for the index. For more information, see Index settings. Example requests The following examples show how to use the Create or Update Index Template API. Index template with index aliases The following example request includes index aliases in the template: REST Python PUT /_index_template/alias-template\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"sh*\"\n",
       "  ],\n",
       "  \"template\": {\n",
       "    \"settings\": {\n",
       "      \"number_of_shards\": 1\n",
       "    },\n",
       "    \"aliases\": {\n",
       "      \"alias1\": {},\n",
       "      \"alias2\": {\n",
       "        \"filter\": {\n",
       "          \"term\": {\n",
       "            \"user.id\": \"hamlet\"\n",
       "          }\n",
       "        },\n",
       "        \"routing\": \"shard-1\"\n",
       "      },\n",
       "      \"{index}-alias\": {}\n",
       "    }\n",
       "  }\n",
       "} Copy Copy as cURL response = client.indices.put_index_template(\n",
       "  name = \"alias-template\",\n",
       "  body =   {\n",
       "    \"index_patterns\": [\n",
       "      \"sh*\"\n",
       "    ],\n",
       "    \"template\": {\n",
       "      \"settings\": {\n",
       "        \"number_of_shards\": 1\n",
       "      },\n",
       "      \"aliases\": {\n",
       "        \"alias1\": {},\n",
       "        \"alias2\": {\n",
       "          \"filter\": {\n",
       "            \"term\": {\n",
       "              \"user.id\": \"hamlet\"\n",
       "            }\n",
       "          },\n",
       "          \"routing\": \"shard-1\"\n",
       "        },\n",
       "        \"{index}-alias\": {}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       ") Copy Using multiple matching templates When multiple index templates match the name of a new index or data stream, the template with the highest priority is used. For example, the following two requests create index templates with different priorities: PUT /_index_template/template_one\n",
       "{\n",
       "  \"index_patterns\" : [\"h*\"],\n",
       "  \"priority\" : 0,\n",
       "  \"template\": {\n",
       "    \"settings\" : {\n",
       "      \"number_of_shards\" : 1,\n",
       "      \"number_of_replicas\": 0\n",
       "    },\n",
       "    \"mappings\" : {\n",
       "      \"_source\" : { \"enabled\" : false }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "PUT /_index_template/template_two\n",
       "{\n",
       "  \"index_patterns\" : [\"ha*\"],\n",
       "  \"priority\" : 1,\n",
       "  \"template\": {\n",
       "    \"settings\" : {\n",
       "      \"number_of_shards\" : 2\n",
       "    },\n",
       "    \"mappings\" : {\n",
       "      \"_source\" : { \"enabled\" : true }\n",
       "    }\n",
       "  }\n",
       "}\n",
       " copy For indexes that start with ha, the _source is enabled. Because only template_two is applied, the index will have two primary shards and one replica. Overlapping index patterns given the same priority are not allowed. An error will occur when attempting to create a template matching an existing index template with identical priorities. Adding template versioning The following example request adds a version number to an index template, which simplifies template management for external systems: REST Python PUT /_index_template/template_one\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"mac\",\n",
       "    \"cheese\"\n",
       "  ],\n",
       "  \"priority\": 0,\n",
       "  \"template\": {\n",
       "    \"settings\": {\n",
       "      \"number_of_shards\": 1\n",
       "    }\n",
       "  },\n",
       "  \"version\": 1\n",
       "} Copy Copy as cURL response = client.indices.put_index_template(\n",
       "  name = \"template_one\",\n",
       "  body =   {\n",
       "    \"index_patterns\": [\n",
       "      \"mac\",\n",
       "      \"cheese\"\n",
       "    ],\n",
       "    \"priority\": 0,\n",
       "    \"template\": {\n",
       "      \"settings\": {\n",
       "        \"number_of_shards\": 1\n",
       "      }\n",
       "    },\n",
       "    \"version\": 1\n",
       "  }\n",
       ") Copy Adding template metadata The following example request uses the meta parameter to add metadata to the index template. All metadata is stored in the cluster state: REST Python PUT /_index_template/template_one\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"rom\",\n",
       "    \"juliet\"\n",
       "  ],\n",
       "  \"template\": {\n",
       "    \"settings\": {\n",
       "      \"number_of_shards\": 2\n",
       "    }\n",
       "  },\n",
       "  \"_meta\": {\n",
       "    \"description\": \"Where art thou\",\n",
       "    \"serialization\": {\n",
       "      \"class\": \"MyIndexTemplate\",\n",
       "      \"id\": 12\n",
       "    }\n",
       "  }\n",
       "} Copy Copy as cURL response = client.indices.put_index_template(\n",
       "  name = \"template_one\",\n",
       "  body =   {\n",
       "    \"index_patterns\": [\n",
       "      \"rom\",\n",
       "      \"juliet\"\n",
       "    ],\n",
       "    \"template\": {\n",
       "      \"settings\": {\n",
       "        \"number_of_shards\": 2\n",
       "      }\n",
       "    },\n",
       "    \"_meta\": {\n",
       "      \"description\": \"Where art thou\",\n",
       "      \"serialization\": {\n",
       "        \"class\": \"MyIndexTemplate\",\n",
       "        \"id\": 12\n",
       "      }\n",
       "    }\n",
       "  }\n",
       ") Copy Data stream definition Include a data_stream object to use an index template for data streams, as shown in the following example request: REST Python PUT /_index_template/template_1\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"logs-*\"\n",
       "  ],\n",
       "  \"data_stream\": {}\n",
       "} Copy Copy as cURL response = client.indices.put_index_template(\n",
       "  name = \"template_1\",\n",
       "  body =   {\n",
       "    \"index_patterns\": [\n",
       "      \"logs-*\"\n",
       "    ],\n",
       "    \"data_stream\": {}\n",
       "  }\n",
       ") Copy Using multiple component templates When using multiple component templates with the composed_of field, the component templates are merged in the specified order. Next, all mappings, settings, and aliases from the parent index template of the component are merged. Lastly, any configuration options added to the index requests are merged. In the following example request, an index with h* has two merged primary shards. If the order in the request body were reversed, then the index would have one primary shard: PUT /_component_template/template_with_1_shard\n",
       "{\n",
       "  \"template\": {\n",
       "    \"settings\": {\n",
       "      \"index.number_of_shards\": 1\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "PUT /_component_template/template_with_2_shards\n",
       "{\n",
       "  \"template\": {\n",
       "    \"settings\": {\n",
       "      \"index.number_of_shards\": 2\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "PUT /_index_template/template_1\n",
       "{\n",
       "  \"index_patterns\": [\"h*\"],\n",
       "  \"composed_of\": [\"template_with_1_shard\", \"template_with_2_shards\"]\n",
       "}\n",
       " copy Recursive merging is used for mapping definition and root options such as dynamic_templates and meta, meaning that when an earlier component contains a meta block, new meta entries are added to the end of the metadata in the index. Any entries containing a preexisting key are overwritten. Endpoints Path parameters Query parameters Request body fields Template Example requests Index template with index aliases Using multiple matching templates Adding template versioning Adding template metadata Data stream definition Using multiple component templates WAS THIS PAGE HELPFUL? ‚úî Yes ‚úñ No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright ¬© OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\n",
       "\n",
       "---\n",
       "\n",
       "## Result 7: Link Search Menu Expand Document Documentation Menu\n",
       "\n",
       "**üîó Source:** [https://opensearch.isharkfly.com/dashboards/management/index-patterns/](https://opensearch.isharkfly.com/dashboards/management/index-patterns/)\n",
       "\n",
       "**Overview:**\n",
       "Link Search Menu Expand Document Documentation Menu OpenSearch Menu OpenSearchCon 2024 - Stay Informed Sessions Speakers Exhibitors Workshops Unconference CFP is closed Download About Releases Roadmap FAQ Community Blog Forum Slack Events Partners Projects Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Documentation OpenSearch and OpenSearch Dashboards ‚Üê Back to docs home API Style Guide Formatting Guide OpenSearch Documentation Website 2.10.0 Release Notes OpenSearch Documentation Website 2.11.0 Release Notes OpenSearch Documentation Website 2.12.0 Release Notes OpenSearch Documentation Website 2.4.0 Release Notes OpenSearch Documentation Website 2.5.0 Release Notes OpenSearch Documentation Website 2.6.0 Release Notes OpenSearch Documentation Website 2.7.0 Release Notes OpenSearch Documentation Website 2.8.0 Release Notes OpenSearch Documentation Website 2.9.0 Release Notes OpenSearch Project Style Guidelines OpenSearch terms Overview About OpenSearch Intro to OpenSearch Quickstart Version history Breaking changes Install and upgrade Installing OpenSearch Docker Helm Tarball RPM Debian Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Circuit breaker settings Cluster settings Index settings Search settings Availability and recovery settings Plugin settings Experimental feature flags Logs Configuring OpenSearch Dashboards Upgrading OpenSearch Rolling Upgrade Upgrades appendix Rolling upgrade lab Installing plugins Managing OpenSearch Dashboards plugins Migrate to OpenSearch Using snapshots to migrate data Migrating from Elasticsearch OSS to OpenSearch Migrating Docker clusters to OpenSearch Migrating from Kibana OSS to OpenSearch Dashboards Managing Indexes Index templates Index aliases Data streams Reindex data Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings Index management security Refresh search analyzer ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Ingest Pipelines Create pipeline Simulate pipeline Get pipeline Delete pipeline Handling pipeline failures Ingest processors Append Bytes Convert Copy CSV Date Date index name Dissect Dot expander Drop IP2Geo Grok KV Lowercase Remove_by_pattern Remove Sparse encoding Text embedding Text/image embedding Uppercase OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Analyzing data Time filter Creating dashboards Building data visualizations Using area charts Using coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using the self-host maps server Using Gantt charts Using VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimize query performance using OpenSearch indexing Dev Tools Running queries in the Dev Tools console Query Workbench Custom branding Dashboards Query Language (DQL) Search telemetry OpenSearch Integrations Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Tuning for indexing speed Security in OpenSearch Configuration Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files API rate limiting Configuring sign-in options Disabling security OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Access control REST layer authorization Document-level security Users and roles Field-level security Field masking User impersonation Cross-cluster search Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Creating detectors Supported log types Creating correlation rules Creating custom log types Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Security Analytics settings Mappings and field types Supported field types Alias Binary Numeric field types Unsigned long Boolean Date field types Date Date nanoseconds IP address Range field types Object field types Object Nested Flat object Join String field types Keyword Text Match-only text Token count Autocomplete field types Completion Search as you type Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape k-NN vector Rank field types Percolator Text analysis Language analyzers Index analyzers Search analyzers Tokenizers Token filters Delimited term frequency Normalizers Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Exists Fuzzy IDs Prefix Range Regexp Term Terms Terms set Wildcard Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box xy Span queries Match all queries Specialized queries Neural Neural sparse Script score Minimum should match Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Matrix stats Maximum Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Bucket aggregations Adjacency matrix Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Range Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Search Searching data Paginate results Point in Time Point in Time API Sort results Highlight query matches Autocomplete Did-you-mean Keyword search k-NN search k-NN index Exact k-NN with scoring script Approximate k-NN search k-NN search with filters k-NN search with nested fields k-NN Painless extensions API JNI libraries Settings Performance tuning Neural search Neural search tutorial Semantic search Multimodal search Neural sparse search Hybrid search Conversational search Search relevance Comparing search results Reranking search results Querqy Search pipelines Creating a search pipeline Using a search pipeline Retrieving search pipelines Search processors Collapse Filter query Neural query enricher Normalization Oversample Personalize search ranking Retrieval-augmented generation Rename field Rerank Script Truncate hits Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Identifiers Data Types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Machine learning ML Commons cluster settings Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Connector blueprints Agents and tools Agents and tools tutorial Tools Agent tool CAT Index tool Index Mapping tool ML Model tool Neural Sparse Search tool PPL tool RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool OpenSearch Assistant Toolkit Managing ML models in OpenSearch Dashboards Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Model group APIs Register model group Update model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Execute agent Get agent Search agent Delete agent Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Execute algorithm Tasks APIs Get task Search task Delete task Train and Predict APIs Train and predict Train Predict Profile Stats Automating configurations Workflow steps Workflow tutorial Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Monitoring your cluster Job Scheduler Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metrics analytics Query insights Top N queries Trace Analytics Getting Started OpenSearch Dashboards plugin Analyzing Jaeger trace data Distrbuted tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI OpenSearch Kubernetes Operator Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana API reference Analyze API Analysis API Terminology CAT API CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices operation CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster routing and awareness Cluster decommission Cluster health Cluster settings Cluster stats Count Document APIs Index document Get document Update document Delete document Bulk Multi-get document Delete by query Update by query Reindex document Explain Index APIs Alias Clear cache Clone index Close index Create index Create or update mappings Dangling indexes Delete index Force merge Get index Get settings Index exists Open index Shrink index Split index Stats Update settings Ingest APIs Multi-search Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Profile Ranking evaluation Remote cluster information Script APIs Create or Update Stored Script Execute Painless stored script Get Stored Script Delete Script Get Stored Script Contexts Get Script Language Execute Painless script Scroll Search Search templates Snapshot APIs Register Snapshot Repository Get Snapshot Repository Delete Snapshot Repository Verify Snaphot Repository Create Snapshot Get Snapshot Delete Snapshot Get Snapshot Status Restore Snapshot Tasks Supported units Common REST Parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Extensions Dashboards Management Index patterns Index patterns Index patterns are essential for accessing OpenSearch data. An index pattern references one or more indexes, data streams, or index aliases. For example, an index pattern can point you to your log data from yesterday or all indexes that contain that data. If you store data in multiple indexes, creating an index pattern enables your visualizations to retrieve data from all indexes that match the index pattern. You need to create index patterns to define how data is retrieved and fields are formatted so that you can query, search, and display data. Get started In this tutorial, you‚Äôll learn to create index patterns. Note To create or modify index patterns, you must have create, manage, and delete permissions. Contact your administrator for support. For more information, refer to Multi-tenancy configuration. Prerequisites Before you can create an index pattern, your data must be indexed. To learn about indexing your data in OpenSearch, see Managing indexes. Best practices Consider the following best practices when creating index patterns: Make your index patterns specific. Instead of creating an index pattern that matches all indexes, create an index pattern that matches all indexes starting with a certain prefix, for example, my-index-. The more specific your index patterns, the better it will be to query and analyze your data. Use wildcards sparingly. Wildcards can be useful for matching multiple indexes, but they can also make it more difficult to manage your index patterns. Try to use wildcards as specifically as possible. Test your index patterns. Make sure to test your index patterns to ensure that they match the correct indexes. Creating an index pattern If you added sample data, you have index patterns that you can use to analyze that data. To create an index pattern for your own data, follow these steps.\n",
       "\n",
       "### Step 1: 1: Define the index pattern Go to OpenSearch Dashboards, and select Management > Dashboards Management > Index patterns\n",
       "Select Create index pattern. From the Create index pattern window, define the index pattern by entering a name for your index pattern in the Index pattern name field. Dashboards automatically adds a wildcard, *, once you start typing. Using a wildcard is helpful for matching an index pattern to multiple sources or indexes. A dropdown list displaying all the indexes that match your index pattern appears when you start typing. Select Next step. An example of step 1 is shown in the following image. Note that the index pattern security* matches three indexes. By defining the pattern with a wildcard *, you can query and visualize all the data in your indexes. \n",
       "\n",
       "### Step 2: 2: Configure the settings Select @timestamp from the dropdown menu to specify the time field for OpenSearch to use when filtering documents based on time\n",
       "Selecting this time filter determines which field the time filter is applied to. It can be the timestamp of a request or any relevant timestamp field. If you don‚Äôt want to use a time filter, select that option from the dropdown menu. If you select this option, OpenSearch returns all of the data in the indexes that match the pattern. Select Create index pattern. An example is shown in the following image. Once the index pattern has been created, you can view the mapping of the matching indexes. Within the table, you can see the list of fields, along with their data type and properties. An example is shown in the following image. Next steps Understand your data through visuals. Dig into your data. Get started Prerequisites Best practices Creating an index pattern \n",
       "\n",
       "1: Define the index pattern\n",
       "\n",
       "### Step 4: 2: Configure the settings Next steps WAS THIS PAGE HELPFUL? ‚úî Yes ‚úñ No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum\n",
       "Want to contribute? Edit this page or create an issue. OpenSearch Links ÂèÇ‰∏éÈ°πÁõÆÔºàGet InvolvedÔºâ Code of Conduct OpenSearch ‰∏≠ÊñáËÆ∫Âùõ ÂÆòÊñπËÆ∫Âùõ ‰∏≠ÊñáÊñáÊ°£‰ª£Á†Å‰ªìÂ∫ì ÂÆòÊñπ Github Slack Á§æÂå∫È°πÁõÆ ËµÑÊ∫êÔºàResourcesÔºâ About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy ËÅîÁ≥ªÊàë‰ª¨ÔºàContact UsÔºâ ËÅîÁ≥ªÔºàConnectÔºâ Twitter LinkedIn YouTube Meetup Facebook ¬© OpenSearch contributors, 2024. OpenSearch is a registered trademark of Amazon Web Services. ¬© 2005-2021 Django Software Foundation and individual contributors. Django is a registered trademark of the Django Software Foundation. This website was forked from the BSD-licensed djangoproject.com originally designed by Threespot & andrevv.\n",
       "\n",
       "---\n",
       "\n",
       "## Result 8: \n",
       "\n",
       "**üîó Source:** [https://repost.aws/knowledge-center/opensearch-index-pattern](https://repost.aws/knowledge-center/opensearch-index-pattern)\n",
       "\n",
       "**Overview:**\n",
       "Skip to content By using AWS re:Post, you agree to the AWS re:Post Terms of Use re:Post Search About re:Post English EnglishDeutschEspa√±olFran√ßaisItalianoÊó•Êú¨Ë™ûÌïúÍµ≠Ïñ¥Portugu√™s‰∏≠Êñá (ÁÆÄ‰Ωì)‰∏≠Êñá (ÁπÅÈ´î) Resources Sign in Home Questions Knowledge Center Articles Selections Tags Topics Community Groups AWS Support Official AWS Trust & Safety Center Ask question AWS re:Post Knowledge Center Feedback Survey Help us improve the AWS re:Post Knowledge Center by sharing your feedback in a brief survey. Your input can influence how we create and update our content to better support your AWS journey. / How do I create an index pattern in my OpenSearch Service cluster?lg.../ How do I create an index pattern in my OpenSearch Service cluster? 5 minute read 1 I want to create an index pattern in my Amazon OpenSearch Service cluster. Resolution Prerequisites: The AWS Identity and Access Management (IAM) user must have PUT and POST permissions to create an index pattern. Example access policy: {  \"Version\": \"2012-10-17\",\n",
       "  \"Statement\": [\n",
       "    {\n",
       "      \"Sid\": \"VisualEditor0\",\n",
       "      \"Effect\": \"Allow\",\n",
       "      \"Action\": [\n",
       "        \"es:ESHttpHead\",\n",
       "        \"es:ESHttpPost\",\n",
       "        \"es:ESHttpGet\",\n",
       "        \"es:ESHttpDelete\",\n",
       "        \"es:ESHttpPut\"\n",
       "      ],\n",
       "      \"Resource\": \"arn:aws:es:region:account-id:domain/domain-name/*\"\n",
       "    }\n",
       "  ]\n",
       "} Note: Replace region with your AWS Region, account-id with your AWS account, and domain-name with your domain name. Your cluster version must allow index patterns. Create the index pattern Use OpenSearch Dashboards You can use OpenSearch Dashboards to create an index pattern for OpenSearch Service or Elasticsearch clusters with or without fine-grained access control. For instructions, see Creating an index pattern on the OpenSearch website. Use curl commands To create an index pattern for clusters without fine-grained access control, run the following command based on the cluster type. Elasticsearch clusters: curl -X POST  https://elasticsearch-end-point/_plugin/kibana/api/saved_objects/index-pattern/ \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "\n",
       "-H \"content-type: application/json\" \\\n",
       "\n",
       "-d '{ \"attributes\": { \"title\": \"sample-index*\" } }' Note: Replace sample-index with your index name or pattern. OpenSearch Service clusters: curl -X POST  https://opensearch-end-point/_dashboards/api/saved_objects/index-pattern/ \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "\n",
       "-H \"content-type: application/json\" \\\n",
       "\n",
       "-d '{ \"attributes\": { \"title\": \"sample-index*\" } }' Note: Replace sample-index with your index name or pattern. For clusters with fine-grained access control, complete the following steps: To generate authorization cookies in the auth.txt file, run the following command based on the cluster type. Elasticsearch clusters: curl -X POST  https://elasticsearch-end-point/_plugin/kibana/auth/login  \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "-H \"content-type: application/json\" \\\n",
       "-d '{\"username\":\"usernameexample\", \"password\":\"passwordexample\"}' \\\n",
       "-c auth.txt Note: Replace usernameexample with your username and passwordexample with your password. OpenSearch Service clusters: curl -X POST  https://opensearch-end-point/_dashboards/auth/login  \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "-H \"content-type: application/json\" \\\n",
       "-d '{\"username\":\"usernameexample\", \"password\":\"passwordexample\"}' \\\n",
       "-c auth.txt Note: Replace usernameexample with your username and passwordexample with your password. To submit the index pattern creation request, run the following command based on your cluster type: Elasticsearch clusters: curl -X POST  https://elasticsearch-end-point/_plugin/kibana/api/saved_objects/index-pattern/test  \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "-H \"content-type: application/json\" \\\n",
       "-d '{ \"attributes\": { \"title\": \"sample-index*\" } }' \\\n",
       "-b auth.txt Note: Replace sample-index with your index name or pattern. OpenSearch Service clusters: curl -X POST  https://opensearch-end-point/_dashboards/api/saved_objects/index-pattern/  \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "-H \"content-type: application/json\" \\\n",
       "-d '{ \"attributes\": { \"title\": \"sample-index*\" } }' \\\n",
       "-b auth.txt Note: Replace sample-index with your index name or pattern. Use Python Prerequisites: Map the role that runs the Python code to the backend role for fine-grained access control clusters. Run the following commands to install the required dependencies: pip install boto3\n",
       "pip install opensearch-py\n",
       "pip install requests\n",
       "pip install requests-aws4auth Run the following Python command to create the index pattern for OpenSearch Service clusters: import boto3\n",
       "import requests\n",
       "from requests_aws4auth import AWS4Auth\n",
       "\n",
       "host = 'https://domain-endpoint/' # include trailing /\n",
       "region = 'aos-region' # example us-west-1\n",
       "service = 'es'\n",
       "credentials = boto3.Session().get_credentials()\n",
       "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)\n",
       "\n",
       "\n",
       "path = '_dashboards/api/saved_objects/index-pattern' # _plugin/kibana/api/saved_objects/index-pattern for es versions\n",
       "url = host + path\n",
       "payload = {\"attributes\":{\"title\":\"multi-logs-*\",\"fields\":\"[]\"}}\n",
       "headers = {\"Content-Type\": \"application/json\", \"osd-xsrf\": \"true\", \"security_tenant\": \"global\" }\n",
       "r = requests.post (url, auth=awsauth, json=payload, headers=headers)\n",
       "print(r.status_code)\n",
       "print(r.text) Note: Replace domain-endpoint with your domain endpoint, and aos-region with your Region. For Elasticsearch clusters, replace _dashboards/api/saved_objects/index-pattern with _plugin/kibana/api/saved_objects/index-pattern. Troubleshoot index pattern creation issues You use fine-grained access control with SAML 2.0 or Amazon Cognito authentication If the domain for your cluster uses SAML 2.0 or Amazon Cognito for authentication, then create an internal user to manage the index pattern. Note: For clusters where you activated fine-grained access control, the user must have ESHttpPut and ESHttpPost permissions to create an index pattern. You can't create the index pattern in the Global tenant By default, OpenSearch Dashboards creates index patterns under the Global tenant. To create an index pattern outside of the Global tenant, run the following command: curl -s -X POST https://opensearch-end-point/_dashboards/api/saved_objects/index-pattern/sample-index -d '{\"attributes\": {\"title\": \"sample-index*\"}}' \\\n",
       "-H \"osd-xsrf:true\" \\\n",
       "-H \"securitytenant: private\" \\\n",
       "-H \"content-type:application/json\" \\\n",
       "-b auth.txt Note: Replace sample-index with your index name or pattern. You didn't include the .kibana alias in the cluster To troubleshoot this issue, complete the following steps: To check whether the .kibana alias exists in the cluster, run the following command: curl -XGET https://opensearch-end-point/_cat/aliases Note: For clusters with fine-grained access control, include the -u flag with your username and password. Example command: curl -XPOST -u 'master-user:master-user-password' 'domain-endpoint/_cat/indices If the .kibana index doesn't exist, then proceed to step 4. To create a backup of .kibana index, run the following command: curl -XPOST \"https://domain-endpoint/_reindex\" -H 'Content-Type: application/json' -d'{\n",
       "  \"source\": {\n",
       "    \"index\": \".kibana\"\n",
       "  },\n",
       "  \"dest\": {\n",
       " \"index\": \".kibana_backup\"\n",
       "  }\n",
       "}' Note: Replace domain-endpoint with your domain endpoint. For clusters with fine-grained access control, include the -u flag with your username and password. To delete the .kibana index, run the following command: curl -XDELETE \"https://domain-endpoint/.kibana\" Note: Replace domain-endpoint with your domain endpoint. For clusters with fine-grained access control, include the -u flag with your username and password. To create a .kibana alias and point it to the .kibana_backup index, run the following command: curl -XPOST \"https://domain-endpoint/_aliases\" -H 'Content-Type: application/json' -d'{\n",
       "  \"actions\": [\n",
       "    {\n",
       "      \"add\": {\n",
       "        \"index\": \".kibana_backup\",\n",
       "        \"alias\": \".kibana\"\n",
       "      }\n",
       "    }\n",
       "  ]\n",
       "}' Note: Replace domain-endpoint with your domain endpoint. For clusters with fine-grained access control, include the -u flag with your username and password. Related information Export and import Kibana dashboards with OpenSearch Service Why does the rollover index action in my ISM policy keep failing in OpenSearch Service? Follow Share Topics Analytics Tags Amazon OpenSearch Service Language English Related videos Watch Sujata's video to learn more (3:59) AWS OFFICIALUpdated 4 months ago 2 Comments This can also be done using basic auth using session object without signing the request if that is the use case. [+] Session Object = https://requests.readthedocs.io/en/latest/user/advanced/#session-objects #! /bin/python3\n",
       "import requests\n",
       "host = 'https://<domain_endpoint_ending_with_slash>/'\n",
       "path = '_dashboards/auth/login'\n",
       "region = 'us-east-1'\n",
       "url = host + path;\n",
       "# Set headers as mentioned. Here we will create index pattern in global tenant hence the value is global\n",
       "headers = {\"Content-Type\": \"application/json\",\"kbn-xsrf\": \"true\",\"osd-xsrf\":\"true\",\"security_tenant\":\"global\"};\n",
       "payload = {\n",
       " \"username\":\"username\",\n",
       "    \"password\":\"password\"\n",
       "}\n",
       "\n",
       "#Creating a session because requests wont store the cookie\n",
       "\n",
       "session=requests.Session();\n",
       "\n",
       "r=session.post(url,headers=headers,json=payload);\n",
       "# You can skip these lines with print. Basically the above line will do a post request with my credentials and will create a cookie and will store it\n",
       "print(r.text);\n",
       "print(r.status_code);\n",
       "\n",
       "# title is the name of my index pattern\n",
       "\n",
       "payload={\n",
       "\"attributes\": { \"title\": \"random*\" } \n",
       "\n",
       "}\n",
       "\n",
       "path=\"_dashboards/api/saved_objects/index-pattern/random*\";\n",
       "url=host+path;\n",
       "\n",
       "#Changed the path variable to the one which is mentioned above. Notice the end of the URL, my index pattern name will be random*\n",
       "\n",
       "r=session.post(url,headers=headers,json=payload);\n",
       "\n",
       "print(r.text);\n",
       "print(r.status_code);\n",
       "session.close();\n",
       " Share rePost-User-6420587 replied 2 years ago Thank you for your comment. We'll review and update the Knowledge Center article as needed. Share MODERATOR AWS Official replied 2 years ago Comment on this article Clear Post comment Relevant content Got an error \"Request Entity Too Large\" when creating index pattern in AWS Opensearch soop_minjaeoh asked 2 years ago How to create and configure an Open Search Serverless index via API? Zach asked a year ago OpenSearch Dashboards Index Pattern and Discover issues mdkail asked 4 years ago Access denied (403) when creating an index in OpenSearch Serverless. AlwaysLearning asked 2 years ago Index is not created inside the Amazon OpenSearch cluster Accepted Answer stratosb asked 2 years ago Why does the rollover index action in my ISM policy fail in OpenSearch Service? AWS OFFICIALUpdated 3 months ago Why can't I delete an index or upgrade my OpenSearch Service cluster? AWS OFFICIALUpdated 2 years ago How do I resolve the 403 \"index_create_block_exception\" or \"cluster_block_exception\" error in OpenSearch Service? AWS OFFICIALUpdated 3 years ago How do I use ISM to manage low storage space in Amazon OpenSearch Service? AWS OFFICIALUpdated 3 months ago How to Configure Metadata Filtering with Bedrock Knowledge Bases on OpenSearch Managed Cluster SUPPORT ENGINEER Emiliano Lozano published a month ago FEEDBACK Privacy| Site Terms| Cookie Preferences | Sitemap| Legal| ¬© 2026, Amazon Web Services, Inc. or its affiliates. All rights reserved. Community Guidelines\n",
       "\n",
       "---\n",
       "\n",
       "## Result 9: \n",
       "\n",
       "**üîó Source:** [https://stackoverflow.com/questions/71816340/how-to-create-an-index-pattern-in-opensearch-using-api](https://stackoverflow.com/questions/71816340/how-to-create-an-index-pattern-in-opensearch-using-api)\n",
       "\n",
       "**Overview:**\n",
       "Skip to main content Stack Overflow About Products For Teams Stack Internal Implement a knowledge platform layer to power your enterprise and AI tools. Stack Data Licensing Get access to top-class technical expertise with trusted & attributed content. Stack Ads Connect your brand to the world‚Äôs most trusted technologist communities. Releases Keep up-to-date on features we add to Stack Overflow and Stack Internal. About the company Visit the blog Loading‚Ä¶ current community Stack Overflow help chat Meta Stack Overflow your communities Sign up or log in to customize your list. more stack exchange communities company blog Log in Sign up Home Questions AI Assist Tags Challenges Chat Articles Users Jobs Companies Collectives Communities for your favorite technologies. Explore all Collectives Stack Internal Stack Overflow for Teams is now called Stack Internal. Bring the best of human thought and AI automation together at your work. Try for free Learn more Stack Internal Bring the best of human thought and AI automation together at your work. Learn more Collectives‚Ñ¢ on Stack Overflow Find centralized, trusted content and collaborate around the technologies you use most. Learn more about Collectives Stack Internal Knowledge at work Bring the best of human thought and AI automation together at your work. Explore Stack Internal How to create an index pattern in Opensearch using API? Ask Question Asked 3 years, 9 months ago Modified 1 year, 1 month ago Viewed 15k times Part of AWS Collective 5 I want to create an index pattern using Opensearch API. I tried to replicate what could be made graphically in the following image window, using as index pattern name cwl-* and then as time field @timestamp. My domain has OpenSearch 1.2 installed. Using curl (directly modifiend the command in kibana doc): curl -u '****:*****' -X POST \"https://******.eu-central-1.es.amazonaws.com/api/index_patterns/index_pattern\" -H 'osd-xsrf: true' -H 'Content-Type: application/json' -d'\n",
       "{\n",
       "  \"index_pattern\": {\n",
       "     \"title\": \"cwl-*\",\n",
       "     \"timeFieldName\": \"@timestamp\"\n",
       "  }\n",
       "}'\n",
       " but I receive {\"error\":{\"root_cause\":[{\"type\":\"illegal_argument_exception\",\"reason\":\"Rejecting mapping update to [api] as the final mapping would have more than 1 type: [_doc, index_patterns]\"}],\"type\":\"illegal_argument_exception\",\"reason\":\"Rejecting mapping update to [api] as the final mapping would have more than 1 type: [_doc, index_patterns]\"},\"status\":400}\n",
       " amazon-web-services shell aws-elasticsearch opensearch Share Improve this question Follow edited Apr 10, 2022 at 17:50 asked Apr 10, 2022 at 11:54 Dresult 31311 gold badge22 silver badges1212 bronze badges 9 Are you using any sort of IAM authentication? Ermiya Eskandary ‚Äì Ermiya Eskandary 2022-04-10 15:58:49 +00:00 Commented Apr 10, 2022 at 15:58 @ErmiyaEskandary just the Fine-grained access control but it works because I don't have any problem in performing other requests... Dresult ‚Äì Dresult 2022-04-10 16:01:55 +00:00 Commented Apr 10, 2022 at 16:01 Ahhhhhh - remove saved_objects from your URL. Ermiya Eskandary ‚Äì Ermiya Eskandary 2022-04-10 16:10:33 +00:00 Commented Apr 10, 2022 at 16:10 @ErmiyaEskandary Unfortunately I had already tried, it says {\"statusCode\":404,\"error\":\"Not Found\",\"message\":\"Not Found\"} Dresult ‚Äì Dresult 2022-04-10 16:13:39 +00:00 Commented Apr 10, 2022 at 16:13 Your URL is somehow wrong - I don't have docs in front of me right now but try removing _dashboards from the URL and if that doesn't work, also remove api Ermiya Eskandary ‚Äì Ermiya Eskandary 2022-04-10 16:17:22 +00:00 Commented Apr 10, 2022 at 16:17 | Show 4 more comments 3 Answers 3 Sorted by: Reset to default Highest score (default) Trending (recent votes count more) Date modified (newest first) Date created (oldest first) 3 Tested with the latest OpenSearch version 2.18.0. To simply create an index pattern via the API, a POST request should be used:     curl -XPOST \"http://localhost:5601/api/saved_objects/index-pattern\" \\\n",
       "-u \"user:pass\" \\\n",
       "-H 'osd-xsrf: true' \\\n",
       "-H 'Content-Type: application/json' \\\n",
       "-d ' \n",
       "{\n",
       "  \"attributes\": {\n",
       "    \"title\": \"pattern-*\",\n",
       "    \"timeFieldName\": \"@timestamp\"\n",
       "  }\n",
       "}'\n",
       " If you want to create an OpenSearch index pattern with a specific ID, you can generate it or copy it from another source (in my case, I copied the ID of the missing pattern from the broken Dashboard) and include it as part of the request: curl -XPOST \"http://localhost:5601/api/saved_objects/index-pattern/90bd9a00-ad57-41a0-b16a-b134a8c51e98\" \\\n",
       "-u \"user:pass\" \\\n",
       "-H 'osd-xsrf: true' \\\n",
       "-H 'Content-Type: application/json' \\\n",
       "-d ' \n",
       "{\n",
       "  \"attributes\": {\n",
       "    \"title\": \"pattern-*\",\n",
       "    \"timeFieldName\": \"@timestamp\"\n",
       "  }\n",
       "}'\n",
       " If you need to update existing index pattern, a PUT request should be used, with existing ID: curl -XPUT \"http://localhost:5601/api/saved_objects/index-pattern/90bd9a00-ad57-41a0-b16a-b134a8c51e98\" \\\n",
       "-u \"user:pass\" \\\n",
       "-H 'osd-xsrf: true' \\\n",
       "-H 'Content-Type: application/json' \\\n",
       "-d ' \n",
       "{\n",
       "  \"attributes\": {\n",
       "    \"title\": \"pattern-*\",\n",
       "    \"timeFieldName\": \"@timestamp\"\n",
       "  }\n",
       "}'\n",
       " Share Improve this answer Follow answered Nov 26, 2024 at 21:35 nmishin 3,22255 gold badges2222 silver badges3737 bronze badges Sign up to request clarification or add additional context in comments. Comments Add a comment 1 curl -u '****:*****' -X POST \"https://******.eu-central-1.es.amazonaws.com/api/index_patterns/cwl-*\" -H 'osd-xsrf: true' -H 'Content-Type: application/json' -d'\n",
       "{\n",
       "  \"index_pattern\": {\n",
       "     \"title\": \"cwl-*\",\n",
       "     \"timeFieldName\": \"@timestamp\"\n",
       "  }\n",
       "}'\n",
       " change api/index_patterns/index_pattern to api/index_patterns/cwl-* and try again? Share Improve this answer Follow answered Apr 14, 2022 at 8:33 doge76 2122 bronze badges 4 Comments Add a comment Dresult Dresult Over a year ago It works in a sense that the command creates something but I cannot see anything among saved objects and seams that in this way only an index which name is \"api\" is created not an index pattern therefore each time I access the dashboard, once it finds data, it ask me if I want to create it. 2022-04-15T11:15:21.423Z+00:00 0 Reply Copy link doge76 doge76 Over a year ago if you want the index-pattern to be global, try to add this attribute in header: securitytenant: \"global\"? 2022-04-15T12:03:44.13Z+00:00 0 Reply Copy link Dresult Dresult Over a year ago already done, I've added -H 'securitytenant: global' to the curl string 2022-04-15T13:56:58.873Z+00:00 0 Reply Copy link Kasami Kasami Over a year ago @Dresult Did you ever manage to figure this out? I am encountering the same issue, it seems. 2022-10-10T22:50:32.3Z+00:00 2 Reply Copy link Add a comment 0 It worked for me in OpenSearch 1.3 when I added an ID in the URI and used saved_objects instead of index_patterns. So your cURL-request should work when looking like this. curl -u '****:*****' -X POST \"https://<opensearch-dashboards-host>.eu-central-1.es.amazonaws.com/api/saved_objects/index-pattern/<ID>\" \n",
       "-H 'osd-xsrf: true' \n",
       "-H 'Content-Type: application/json' \n",
       "-d \n",
       "   '{\n",
       "      \"index_pattern\": {\n",
       "         \"title\": \"cwl-*\",\n",
       "         \"timeFieldName\": \"@timestamp\"\n",
       "      }\n",
       "    }'\n",
       " Share Improve this answer Follow edited Dec 16, 2022 at 13:09 answered Aug 25, 2022 at 8:51 mgr110 111 bronze badge 3 Comments Add a comment K.Thanvi K.Thanvi Over a year ago I am getting no handler found for uri [/api/saved_objects/index-pattern/cwl-*] and method [POST] error for this.. using opensearch1.3. 2022-12-14T17:09:27.72Z+00:00 0 Reply Copy link mgr110 mgr110 Over a year ago @K.Thanvi This is probably because you are sending the request to the OpenSearch-host. The request is meant to be sent to the OpenSearch Dashboards-host (or Kibana-host if you use that). Using the Dev Tools will send the request to the OpenSearch-host. 2022-12-15T11:44:04.903Z+00:00 1 Reply Copy link K.Thanvi K.Thanvi Over a year ago Thanks! Yes that was the issue. i had to send the request to my <opensearch_domain>/_dashboards/api/saved_objects/index-pattern endpoint. 2023-01-09T17:07:40.23Z+00:00 1 Reply Copy link Add a comment Your Answer Thanks for contributing an answer to Stack Overflow! Please be sure to answer the question. Provide details and share your research! But avoid ‚Ä¶ Asking for help, clarification, or responding to other answers. Making statements based on opinion; back them up with references or personal experience. To learn more, see our tips on writing great answers. Draft saved Draft discarded Sign up or log in Sign up using Google Sign up using Email and Password Submit Post as a guest Name Email Required, but never shown Post as a guest Name Email Required, but never shown Post Your Answer Discard By clicking ‚ÄúPost Your Answer‚Äù, you agree to our terms of service and acknowledge you have read our privacy policy. Start asking to get answers Find the answer to your question by asking. Ask question Explore related questions amazon-web-services shell aws-elasticsearch opensearch See similar questions with these tags. AWS Collective See more This question is in a collective: a subcommunity defined by tags with relevant content and experts. The Overflow Blog The most dangerous shortcuts in software A new worst coder has entered the chat: vibe coding without code knowledge Featured on Meta Native Ads coming soon to Stack Overflow and Stack Exchange A proposal for bringing back Community Promotion & Open Source Ads Modernizing curation: A proposal for The Workshop and The Archive Policy: Generative AI (e.g., ChatGPT) is banned Stack Overflow chat opening up to all users in January; Stack Exchange chat... Related 1 Create Index - Elastic Search - Java API 14 Create index in Elastic Search by Java API 0 How to do an automated index creation at ElasticSearch? 21 How to configure index pattern in Kibana 2 How does one create an Index Pattern in Kibana? 3 Is there API based method to create an index pattern in Kibana if its index is present in ES 0 How to create new index pattern with custom pattern ID from the elastic API? 1 How to create Index pattern using API and Index Name 0 How to create an ElasticSearch Index as curl 0 How to create index pattern in elastic seach programmatically Hot Network Questions Portrait of Takuro Shintani How do I recreate a bootable ISO after making changes to its extracted files? Is wearing synthetic gloves an explosion risk when refueling at freezing temperatures? Simple LED vs LED Bulb Significance of the nƒÅmajapa of ≈öiva Conversationally, how do French people distinguish between a straight question and one that expresses dismay? Expected radius of the smallest concentric circle having 2 points inside Why does a linear least squares fit appear to have a bias when applied to simple test data? taxes on the sale of gifted gold coins What was man (Adam) guarding Eden from? Minimize the number of pieces to form a square. The Stack'O'Mounts? Searching for tabulation Help a newbie with fixing a bike! Current source refuses to maintain set current circuitikz: internal node annotations (maybe 'path picture'?) to a styled 'muxdemux' How can text be added to the inner side header keyword? RPG in generic medieval fantasy; last party member is named Aquamaryann(e) Is there a word to describe a webinar which is like \"attend-now-or-miss-out\" Are ÈÅã{„ÅØ„Åì}„Å∂ and ÁÆ±{„ÅØ„Åì} related? Physics-Informed Neural Network for 2D Wave Equation Produces Non-Circular / Distorted Wavefronts The road trip of the century Reasons for nations remaining in the Promised Land Bathtub leaks when draining full tub but not while showering more hot questions Question feed Subscribe to RSS Question feed To subscribe to this RSS feed, copy and paste this URL into your RSS reader. lang-bash Stack Overflow Questions Help Chat Business Stack Internal Stack Data Licensing Stack Ads Company About Press Work Here Legal Privacy Policy Terms of Service Contact Us Your Privacy Choices Cookie Policy Stack Exchange Network Technology Culture & recreation Life & arts Science Professional Business API Data Blog Facebook Twitter LinkedIn Instagram Site design / logo ¬© 2026 Stack Exchange Inc; user contributions licensed under CC BY-SA . rev 2025.12.22.38265\n",
       "\n",
       "---\n",
       "\n",
       "## Result 10: Link Search Menu Expand Document Documentation Menu\n",
       "\n",
       "**üîó Source:** [https://docs.opensearch.org/latest/im-plugin/index-templates/](https://docs.opensearch.org/latest/im-plugin/index-templates/)\n",
       "\n",
       "**Overview:**\n",
       "Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards ‚Üê Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Discovery and cluster formation Node discovery and seed hosts Voting and quorum Voting configuration management Cluster bootstrapping Discovery and cluster formation settings Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Remote segment warmer Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Similarity Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Resource access management Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates OpenSearch FIPS configuration Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control Defining users and roles Permissions Default action groups REST layer authorization Document-level security Field-level security Field masking User impersonation Resource sharing and access control Resource sharing APIs API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Version Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Mapping explosion Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Rescore Regular expression syntax SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic queries Complex queries Functions JSON support Metadata queries Aggregate functions Delete JDBC driver ODBC driver PPL Subsearch Commands PPL syntax ad addcoltotals addtotals append appendcol appendpipe bin chart dedup describe eval eventstats expand explain fields fillnull flatten grok head join kmeans lookup ml multisearch parse patterns rare regex rename replace reverse rex search show datasources sort spath stats streamstats subquery table timechart top trendline where Identifiers Data types Functions Full-text search Settings Troubleshooting Monitoring Limitations Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Collecting UBI-formatted data in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Model access control through resource sharing Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller ML Tasks APIs Get ML task Search ML tasks Delete ML task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow access control Workflow settings Workflow state access control Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detector access control Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecaster access control Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Managing Indexes Index templates Index templates Index templates let you initialize new indexes with predefined mappings and settings. For example, if you continuously index log data, you can define an index template so that all of these indexes have the same number of shards and replicas. Create a template To create an index template, use a PUT or POST request: PUT _index_template/<template name>\n",
       "POST _index_template/<template name>\n",
       " This command creates a template named daily_logs and applies it to any new index whose name matches the pattern logs-2020-01-* and also adds it to the my_logs alias: PUT _index_template/daily_logs\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"logs-2020-01-*\"\n",
       "  ],\n",
       "  \"template\": {\n",
       "    \"aliases\": {\n",
       "      \"my_logs\": {}\n",
       "    },\n",
       "    \"settings\": {\n",
       "      \"number_of_shards\": 2,\n",
       "      \"number_of_replicas\": 1\n",
       "    },\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"timestamp\": {\n",
       "          \"type\": \"date\",\n",
       "          \"format\": \"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\"\n",
       "        },\n",
       "        \"value\": {\n",
       "          \"type\": \"double\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       " You should see the following response: {\n",
       "  \"acknowledged\": true\n",
       "}\n",
       " If you create an index named logs-2020-01-01, you can see that it has the mappings and settings from the template: PUT logs-2020-01-01\n",
       "GET logs-2020-01-01\n",
       " {\n",
       "  \"logs-2020-01-01\": {\n",
       "    \"aliases\": {\n",
       "      \"my_logs\": {}\n",
       "    },\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"timestamp\": {\n",
       "          \"type\": \"date\",\n",
       "          \"format\": \"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\"\n",
       "        },\n",
       "        \"value\": {\n",
       "          \"type\": \"double\"\n",
       "        }\n",
       "      }\n",
       "    },\n",
       "    \"settings\": {\n",
       "      \"index\": {\n",
       "        \"creation_date\": \"1578107970779\",\n",
       "        \"number_of_shards\": \"2\",\n",
       "        \"number_of_replicas\": \"1\",\n",
       "        \"uuid\": \"U1vMDMOHSAuS2IzPcPHpOA\",\n",
       "        \"version\": {\n",
       "          \"created\": \"7010199\"\n",
       "        },\n",
       "        \"provided_name\": \"logs-2020-01-01\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Any additional indexes that match this pattern‚Äîlogs-2020-01-02, logs-2020-01-03, and so on‚Äîwill inherit the same mappings and settings. Index patterns cannot contain any of the following characters: :, \", +, /, \\, |, ?, #, >, and <. Retrieve a template To list all index templates: GET _cat/templates\n",
       "GET /_index_template\n",
       " To find a template by its name: GET _index_template/daily_logs\n",
       " To get a list of all templates that match a pattern: GET _index_template/daily*\n",
       " To check if a specific template exists: HEAD _index_template/<name>\n",
       " Configure multiple templates You can create multiple index templates for your indexes. If the index name matches more than one template, OpenSearch takes the mappings and settings from the template with the highest priority and applies it to the index. For example, say you have the following two templates that both match the logs-2020-01-02 index and there‚Äôs a conflict in the number_of_shards field: Template 1 PUT _index_template/template-01\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"logs*\"\n",
       "  ],\n",
       "  \"priority\": 0,\n",
       "  \"template\": {\n",
       "    \"settings\": {\n",
       "      \"number_of_shards\": 2,\n",
       "      \"number_of_replicas\": 2\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Template 2 PUT _index_template/template-02\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"logs-2020-01-*\"\n",
       "  ],\n",
       "  \"priority\": 1,\n",
       "  \"template\": {\n",
       "    \"settings\": {\n",
       "      \"number_of_shards\": 3\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Because template-02 has a higher priority value, it takes precedence over template-01 . The logs-2020-01-02 index would have the number_of_shards value as 3 and the number_of_replicas as the default value 1. Delete a template You can delete an index template using its name: DELETE _index_template/daily_logs\n",
       " Composable index templates Managing multiple index templates has the following challenges: If you have duplication between index templates, storing these index templates results in a bigger cluster state. If you want to make a change across all your index templates, you have to manually make the change for each template. You can use composable index templates to overcome these challenges. Composable index templates let you abstract common settings, mappings, and aliases into a reusable building block called a component template. You can combine component templates to compose an index template. Settings and mappings that you specify directly in the create index request override any settings or mappings specified in an index template and its component templates. Create a component template Let‚Äôs define two component templates‚Å†‚Äîcomponent_template_1 and component_template_2: Component template 1 PUT _component_template/component_template_1\n",
       "{\n",
       "  \"template\": {\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"@timestamp\": {\n",
       "          \"type\": \"date\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Component template 2 PUT _component_template/component_template_2\n",
       "{\n",
       "  \"template\": {\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"ip_address\": {\n",
       "          \"type\": \"ip\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Use component templates to create an index template When creating index templates, you need to include the component templates in a composed_of list. OpenSearch applies the component templates in the order in which you specify them within the index template. The settings, mappings, and aliases that you specify inside the index template are applied last. PUT _index_template/daily_logs\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"logs-2020-01-*\"\n",
       "  ],\n",
       "  \"template\": {\n",
       "    \"aliases\": {\n",
       "      \"my_logs\": {}\n",
       "    },\n",
       "    \"settings\": {\n",
       "      \"number_of_shards\": 2,\n",
       "      \"number_of_replicas\": 1\n",
       "    },\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"timestamp\": {\n",
       "          \"type\": \"date\",\n",
       "          \"format\": \"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\"\n",
       "        },\n",
       "        \"value\": {\n",
       "          \"type\": \"double\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  },\n",
       "  \"priority\": 200,\n",
       "  \"composed_of\": [\n",
       "    \"component_template_1\",\n",
       "    \"component_template_2\"\n",
       "  ],\n",
       "  \"version\": 3,\n",
       "  \"_meta\": {\n",
       "    \"description\": \"using component templates\"\n",
       "  }\n",
       "}\n",
       " If you create an index named logs-2020-01-01, you can see that it derives its mappings and settings from both the component templates: PUT logs-2020-01-01\n",
       "GET logs-2020-01-01\n",
       " Example response {\n",
       "  \"logs-2020-01-01\": {\n",
       "    \"aliases\": {\n",
       "      \"my_logs\": {}\n",
       "    },\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"@timestamp\": {\n",
       "          \"type\": \"date\"\n",
       "        },\n",
       "        \"ip_address\": {\n",
       "          \"type\": \"ip\"\n",
       "        },\n",
       "        \"timestamp\": {\n",
       "          \"type\": \"date\",\n",
       "          \"format\": \"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\"\n",
       "        },\n",
       "        \"value\": {\n",
       "          \"type\": \"double\"\n",
       "        }\n",
       "      }\n",
       "    },\n",
       "    \"settings\": {\n",
       "      \"index\": {\n",
       "        \"creation_date\": \"1625382479459\",\n",
       "        \"number_of_shards\": \"2\",\n",
       "        \"number_of_replicas\": \"1\",\n",
       "        \"uuid\": \"rYUlpOXDSUSuZifQLPfa5A\",\n",
       "        \"version\": {\n",
       "          \"created\": \"7100299\"\n",
       "        },\n",
       "        \"provided_name\": \"logs-2020-01-01\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Index template options You can specify the following template options: Option Type Description Required template Object Specify index settings, mappings, and aliases. No priority Integer The priority of the index template. No composed_of String array The names of component templates applied on a new index together with the current template. No version Integer Specify a version number to simplify template management. Default is null. No _meta Object Specify meta information about the template. No Create a template Retrieve a template Configure multiple templates Delete a template Create a component template Use component templates to create an index template WAS THIS PAGE HELPFUL? ‚úî Yes ‚úñ No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright ¬© OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\n",
       "\n",
       "---\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parse and display all content blocks from the entire response in Markdown format\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# Extract all items from the response\n",
    "all_items = json.loads(response['inference_results'][0]['output'][0]['result'])['items']\n",
    "\n",
    "# Create formatted markdown output\n",
    "output = f\"# üåê All Web Search Results\\n\\n\"\n",
    "output += f\"**Total Results:** {len(all_items)}  \\n\"\n",
    "output += f\"**Query:** {parameters.get('question', 'N/A')}\\n\\n\"\n",
    "output += \"---\\n\\n\"\n",
    "\n",
    "# Parse and display each result\n",
    "for idx, item in enumerate(all_items, 1):\n",
    "    title = item.get('title', 'No Title')\n",
    "    url = item.get('url', 'No URL')\n",
    "    content = item.get('content', 'No Content')\n",
    "    \n",
    "    output += f\"## Result {idx}: {title}\\n\\n\"\n",
    "    output += f\"**üîó Source:** [{url}]({url})\\n\\n\"\n",
    "    \n",
    "    # Parse content by steps (same logic as original cell)\n",
    "    sections = content.split('Step ')\n",
    "    \n",
    "    # Add first section as overview if it exists\n",
    "    if sections[0].strip():\n",
    "        output += f\"**Overview:**\\n{sections[0].strip()}\\n\\n\"\n",
    "    \n",
    "    # Parse and format remaining steps\n",
    "    for step_num, section in enumerate(sections[1:], 1):\n",
    "        lines = section.split('. ', 1)\n",
    "        if len(lines) > 1:\n",
    "            step_title = lines[0]\n",
    "            step_content = lines[1]\n",
    "            output += f\"### Step {step_num}: {step_title}\\n\"\n",
    "            output += f\"{step_content}\\n\\n\"\n",
    "        elif section.strip():\n",
    "            output += f\"{section.strip()}\\n\\n\"\n",
    "    \n",
    "    output += \"---\\n\\n\"\n",
    "\n",
    "# Display as markdown\n",
    "display(Markdown(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315a5bb2",
   "metadata": {},
   "source": [
    "## Format output - HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "204a6cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "<style>\n",
       "    * {\n",
       "        box-sizing: border-box;\n",
       "    }\n",
       "\n",
       "    .html-container {\n",
       "        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;\n",
       "        max-width: 1000px;\n",
       "        margin: 0 auto;\n",
       "        color: #333;\n",
       "        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);\n",
       "        padding: 30px 20px;\n",
       "    }\n",
       "\n",
       "    .header {\n",
       "        text-align: center;\n",
       "        margin-bottom: 40px;\n",
       "        color: #2c3e50;\n",
       "    }\n",
       "\n",
       "    .header h1 {\n",
       "        font-size: 32px;\n",
       "        margin: 0 0 10px 0;\n",
       "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
       "        -webkit-background-clip: text;\n",
       "        -webkit-text-fill-color: transparent;\n",
       "    }\n",
       "\n",
       "    .stats {\n",
       "        background: white;\n",
       "        padding: 20px;\n",
       "        border-radius: 8px;\n",
       "        margin-bottom: 30px;\n",
       "        box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n",
       "        display: flex;\n",
       "        gap: 20px;\n",
       "        flex-wrap: wrap;\n",
       "    }\n",
       "\n",
       "    .stat-item {\n",
       "        flex: 1;\n",
       "        min-width: 200px;\n",
       "    }\n",
       "\n",
       "    .stat-label {\n",
       "        font-size: 12px;\n",
       "        color: #7f8c8d;\n",
       "        text-transform: uppercase;\n",
       "        font-weight: bold;\n",
       "        margin-bottom: 5px;\n",
       "    }\n",
       "\n",
       "    .stat-value {\n",
       "        font-size: 20px;\n",
       "        color: #2c3e50;\n",
       "        font-weight: bold;\n",
       "    }\n",
       "\n",
       "    .results-container {\n",
       "        display: grid;\n",
       "        gap: 25px;\n",
       "    }\n",
       "\n",
       "    .result-card {\n",
       "        background: white;\n",
       "        border-radius: 12px;\n",
       "        overflow: hidden;\n",
       "        box-shadow: 0 4px 15px rgba(0,0,0,0.1);\n",
       "        transition: transform 0.3s ease, box-shadow 0.3s ease;\n",
       "    }\n",
       "\n",
       "    .result-card:hover {\n",
       "        transform: translateY(-5px);\n",
       "        box-shadow: 0 8px 25px rgba(0,0,0,0.15);\n",
       "    }\n",
       "\n",
       "    .result-header {\n",
       "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
       "        color: white;\n",
       "        padding: 20px;\n",
       "        display: flex;\n",
       "        align-items: center;\n",
       "        gap: 15px;\n",
       "    }\n",
       "\n",
       "    .result-number {\n",
       "        background: rgba(255,255,255,0.2);\n",
       "        width: 40px;\n",
       "        height: 40px;\n",
       "        border-radius: 50%;\n",
       "        display: flex;\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        font-weight: bold;\n",
       "        font-size: 16px;\n",
       "        flex-shrink: 0;\n",
       "    }\n",
       "\n",
       "    .result-title {\n",
       "        flex: 1;\n",
       "        font-size: 18px;\n",
       "        font-weight: bold;\n",
       "    }\n",
       "\n",
       "    .result-url {\n",
       "        background: white;\n",
       "        padding: 15px 20px;\n",
       "        border-bottom: 1px solid #ecf0f1;\n",
       "        color: #3498db;\n",
       "        text-decoration: none;\n",
       "        font-size: 12px;\n",
       "        word-break: break-all;\n",
       "        font-family: 'Courier New', monospace;\n",
       "    }\n",
       "\n",
       "    .result-url a {\n",
       "        color: #3498db;\n",
       "        text-decoration: none;\n",
       "    }\n",
       "\n",
       "    .result-url a:hover {\n",
       "        text-decoration: underline;\n",
       "    }\n",
       "\n",
       "    .result-body {\n",
       "        padding: 25px;\n",
       "    }\n",
       "\n",
       "    .overview {\n",
       "        background: #f8f9fa;\n",
       "        padding: 15px;\n",
       "        border-radius: 6px;\n",
       "        margin-bottom: 20px;\n",
       "        border-left: 4px solid #667eea;\n",
       "        font-size: 14px;\n",
       "        line-height: 1.7;\n",
       "        color: #555;\n",
       "    }\n",
       "\n",
       "    .steps-container {\n",
       "        display: grid;\n",
       "        gap: 15px;\n",
       "    }\n",
       "\n",
       "    .step {\n",
       "        border-left: 4px solid #764ba2;\n",
       "        padding-left: 15px;\n",
       "        padding-top: 10px;\n",
       "        padding-bottom: 10px;\n",
       "    }\n",
       "\n",
       "    .step-title {\n",
       "        font-weight: bold;\n",
       "        color: #764ba2;\n",
       "        font-size: 15px;\n",
       "        margin-bottom: 8px;\n",
       "        display: flex;\n",
       "        align-items: center;\n",
       "        gap: 8px;\n",
       "    }\n",
       "\n",
       "    .step-number {\n",
       "        display: inline-block;\n",
       "        background: #764ba2;\n",
       "        color: white;\n",
       "        width: 24px;\n",
       "        height: 24px;\n",
       "        border-radius: 50%;\n",
       "        display: flex;\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        font-size: 12px;\n",
       "        font-weight: bold;\n",
       "    }\n",
       "\n",
       "    .step-content {\n",
       "        color: #555;\n",
       "        font-size: 13px;\n",
       "        line-height: 1.8;\n",
       "    }\n",
       "</style>\n",
       "</head>\n",
       "<body>\n",
       "<div class=\"html-container\">\n",
       "    <div class=\"header\">\n",
       "        <h1>üåê Web Search Results</h1>\n",
       "        <p>Comprehensive detailed view of all search results</p>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"stats\">\n",
       "        <div class=\"stat-item\">\n",
       "            <div class=\"stat-label\">üìä Total Results</div>\n",
       "            <div class=\"stat-value\">10</div>\n",
       "        </div>\n",
       "        <div class=\"stat-item\">\n",
       "            <div class=\"stat-label\">‚ùì Query</div>\n",
       "            <div class=\"stat-value\">How to create an index pattern in OpenSearch?</div>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"results-container\">\n",
       "\n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\">\n",
       "                <div class=\"result-number\">1</div>\n",
       "                <div class=\"result-title\">Link Search Menu Expand Document Documentation Menu</div>\n",
       "            </div>\n",
       "            <div class=\"result-url\">\n",
       "                <strong>üîó Source:</strong> <a href=\"https://docs.opensearch.org/latest/dashboards/management/index-patterns/\" target=\"_blank\">https://docs.opensearch.org/latest/dashboards/management/index-patterns/</a>\n",
       "            </div>\n",
       "            <div class=\"result-body\">\n",
       "    \n",
       "                <div class=\"overview\">\n",
       "                    <strong>Overview:</strong><br>\n",
       "                    Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards ‚Üê Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Discovery and cluster formation Node discovery and seed hosts Voting and quorum Voting configuration management Cluster bootstrapping Discovery and cluster formation settings Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Remote segment warmer Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Similarity Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Resource access management Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates OpenSearch FIPS configuration Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control Defining users and roles Permissions Default action groups REST layer authorization Document-level security Field-level security Field masking User impersonation Resource sharing and access control Resource sharing APIs API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Version Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Mapping explosion Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Rescore Regular expression syntax SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic queries Complex queries Functions JSON support Metadata queries Aggregate functions Delete JDBC driver ODBC driver PPL Subsearch Commands PPL syntax ad addcoltotals addtotals append appendcol appendpipe bin chart dedup describe eval eventstats expand explain fields fillnull flatten grok head join kmeans lookup ml multisearch parse patterns rare regex rename replace reverse rex search show datasources sort spath stats streamstats subquery table timechart top trendline where Identifiers Data types Functions Full-text search Settings Troubleshooting Monitoring Limitations Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Collecting UBI-formatted data in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Model access control through resource sharing Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller ML Tasks APIs Get ML task Search ML tasks Delete ML task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow access control Workflow settings Workflow state access control Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detector access control Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecaster access control Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions OpenSearch Dashboards Dashboards Management Index patterns Index patterns Index patterns are essential for accessing OpenSearch data. An index pattern references one or more indexes, data streams, or index aliases. For example, an index pattern can point you to your log data from yesterday or all indexes that contain that data. If you store data in multiple indexes, creating an index pattern enables your visualizations to retrieve data from all indexes that match the index pattern. You need to create index patterns to define how data is retrieved and fields are formatted so that you can query, search, and display data. Get started In this tutorial, you‚Äôll learn to create index patterns. Note To create or modify index patterns, you must have create, manage, and delete permissions. Contact your administrator for support. For more information, refer to Multi-tenancy configuration. Prerequisites Before you can create an index pattern, your data must be indexed. To learn about indexing your data in OpenSearch, see Managing indexes. Best practices Consider the following best practices when creating index patterns: Make your index patterns specific. Instead of creating an index pattern that matches all indexes, create an index pattern that matches all indexes starting with a certain prefix, for example, my-index-. The more specific your index patterns, the better it will be to query and analyze your data. Use wildcards sparingly. Wildcards can be useful for matching multiple indexes, but they can also make it more difficult to manage your index patterns. Try to use wildcards as specifically as possible. Test your index patterns. Make sure to test your index patterns to ensure that they match the correct indexes. Creating an index pattern If you added sample data, you have index patterns that you can use to analyze that data. To create an index pattern for your own data, follow these steps.\n",
       "                </div>\n",
       "        \n",
       "                <div class=\"steps-container\">\n",
       "        \n",
       "                    <div class=\"step\">\n",
       "                        <div class=\"step-title\">\n",
       "                            <span class=\"step-number\">1</span>\n",
       "                            1: Define the index pattern Go to OpenSearch Dashboards, and select Management > Dashboards Management > Index patterns\n",
       "                        </div>\n",
       "                        <div class=\"step-content\">Select Create index pattern. From the Create index pattern window, define the index pattern by entering a name for your index pattern in the Index pattern name field. Dashboards automatically adds a wildcard, *, once you start typing. Using a wildcard is helpful for matching an index pattern to multiple sources or indexes. A dropdown list displaying all the indexes that match your index pattern appears when you start typing. Select Next step. An example of step 1 is shown in the following image. Note that the index pattern security* matches three indexes. By defining the pattern with a wildcard *, you can query and visualize all the data in your indexes. </div>\n",
       "                    </div>\n",
       "                \n",
       "                    <div class=\"step\">\n",
       "                        <div class=\"step-title\">\n",
       "                            <span class=\"step-number\">2</span>\n",
       "                            2: Configure the settings Select @timestamp from the dropdown menu to specify the time field for OpenSearch to use when filtering documents based on time\n",
       "                        </div>\n",
       "                        <div class=\"step-content\">Selecting this time filter determines which field the time filter is applied to. It can be the timestamp of a request or any relevant timestamp field. If you don‚Äôt want to use a time filter, select that option from the dropdown menu. If you select this option, OpenSearch returns all of the data in the indexes that match the pattern. Select Create index pattern. An example is shown in the following image. Once the index pattern has been created, you can view the mapping of the matching indexes. Within the table, you can see the list of fields, along with their data type and properties. An example is shown in the following image. Next steps Understand your data through visuals. Dig into your data. Get started Prerequisites Best practices Creating an index pattern </div>\n",
       "                    </div>\n",
       "                \n",
       "                    <div class=\"step\">\n",
       "                        <div class=\"step-content\">1: Define the index pattern</div>\n",
       "                    </div>\n",
       "                \n",
       "                    <div class=\"step\">\n",
       "                        <div class=\"step-title\">\n",
       "                            <span class=\"step-number\">4</span>\n",
       "                            2: Configure the settings Next steps WAS THIS PAGE HELPFUL? ‚úî Yes ‚úñ No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum\n",
       "                        </div>\n",
       "                        <div class=\"step-content\">Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright ¬© OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.</div>\n",
       "                    </div>\n",
       "                \n",
       "                </div>\n",
       "        \n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\">\n",
       "                <div class=\"result-number\">2</div>\n",
       "                <div class=\"result-title\"></div>\n",
       "            </div>\n",
       "            <div class=\"result-url\">\n",
       "                <strong>üîó Source:</strong> <a href=\"https://github.com/opensearch-project/opensearch-py/blob/main/guides/index_template.md\" target=\"_blank\">https://github.com/opensearch-project/opensearch-py/blob/main/guides/index_template.md</a>\n",
       "            </div>\n",
       "            <div class=\"result-body\">\n",
       "    \n",
       "                <div class=\"overview\">\n",
       "                    <strong>Overview:</strong><br>\n",
       "                    Skip to content Navigation Menu Toggle navigation Sign in Appearance settings Platform AI CODE CREATION GitHub CopilotWrite better code with AI GitHub SparkBuild and deploy intelligent apps GitHub ModelsManage and compare prompts MCP RegistryNewIntegrate external tools DEVELOPER WORKFLOWS ActionsAutomate any workflow CodespacesInstant dev environments IssuesPlan and track work Code ReviewManage code changes APPLICATION SECURITY GitHub Advanced SecurityFind and fix vulnerabilities Code securitySecure your code as you build Secret protectionStop leaks before they start EXPLORE Why GitHub Documentation Blog Changelog Marketplace View all features Solutions BY COMPANY SIZE Enterprises Small and medium teams Startups Nonprofits BY USE CASE App Modernization DevSecOps DevOps CI/CD View all use cases BY INDUSTRY Healthcare Financial services Manufacturing Government View all industries View all solutions Resources EXPLORE BY TOPIC AI Software Development DevOps Security View all topics EXPLORE BY TYPE Customer stories Events & webinars Ebooks & reports Business insights GitHub Skills SUPPORT & SERVICES Documentation Customer support Community forum Trust center Partners Open Source COMMUNITY GitHub SponsorsFund open source developers PROGRAMS Security Lab Maintainer Community Accelerator Archive Program REPOSITORIES Topics Trending Collections Enterprise ENTERPRISE SOLUTIONS Enterprise platformAI-powered developer platform AVAILABLE ADD-ONS GitHub Advanced SecurityEnterprise-grade security features Copilot for BusinessEnterprise-grade AI features Premium SupportEnterprise-grade 24/7 support Pricing Search or jump to... Search code, repositories, users, issues, pull requests... Search Clear Search syntax tips Provide feedback We read every piece of feedback, and take your input very seriously. Include my email address so I can be contacted Cancel Submit feedback Saved searches Use saved searches to filter your results more quickly Name Query To see all available qualifiers, see our documentation. Cancel Create saved search Sign in Sign up Appearance settings Resetting focus You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert {{ message }} opensearch-project / opensearch-py Public generated from amazon-archives/__template_Custom Notifications You must be signed in to change notification settings Fork 213 Star 450 Code Issues 77 Pull requests 12 Actions Projects 0 Security Uh oh! There was an error while loading. Please reload this page. Insights Additional navigation options Code Issues Pull requests Actions Projects Security Insights Footer ¬© 2026 GitHub, Inc. Footer navigation Terms Privacy Security Status Community Docs Contact Manage cookies Do not share my personal information You can‚Äôt perform that action at this time.\n",
       "                </div>\n",
       "        \n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\">\n",
       "                <div class=\"result-number\">3</div>\n",
       "                <div class=\"result-title\"></div>\n",
       "            </div>\n",
       "            <div class=\"result-url\">\n",
       "                <strong>üîó Source:</strong> <a href=\"https://www.youtube.com/watch?v=pbABIerUYQI\" target=\"_blank\">https://www.youtube.com/watch?v=pbABIerUYQI</a>\n",
       "            </div>\n",
       "            <div class=\"result-body\">\n",
       "    \n",
       "                <div class=\"overview\">\n",
       "                    <strong>Overview:</strong><br>\n",
       "                    AboutPressCopyrightContact usCreatorsAdvertiseDevelopersTermsPrivacyPolicy & SafetyHow YouTube worksTest new featuresNFL Sunday Ticket ¬© 2026 Google LLC\n",
       "                </div>\n",
       "        \n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\">\n",
       "                <div class=\"result-number\">4</div>\n",
       "                <div class=\"result-title\"></div>\n",
       "            </div>\n",
       "            <div class=\"result-url\">\n",
       "                <strong>üîó Source:</strong> <a href=\"https://www.bookstack.cn/read/opensearch-2.19-en/4ce9edd150bec500.md\" target=\"_blank\">https://www.bookstack.cn/read/opensearch-2.19-en/4ce9edd150bec500.md</a>\n",
       "            </div>\n",
       "            <div class=\"result-body\">\n",
       "    \n",
       "                <div class=\"overview\">\n",
       "                    <strong>Overview:</strong><br>\n",
       "                    √ó ÊÄùÁª¥ÂØºÂõæÂ§áÊ≥® ÂÖ≥Èó≠ OpenSearch v2.19 Documentation È¶ñÈ°µ AIÂä©Êâã ÁôΩÂ§© Â§úÈó¥ Â∞èÁ®ãÂ∫è ÈòÖËØª ‰π¶Á≠æ ÊàëÁöÑ‰π¶Á≠æ Ê∑ªÂä†‰π¶Á≠æ ÁßªÈô§‰π¶Á≠æ Index patterns GitHub Êù•Ê∫ê:OpenSearch ÊµèËßà 199 Êâ´Á†Å 2025-05-09 14:09:39 Index patterns Get started Prerequisites Best practices Creating an index pattern\n",
       "                </div>\n",
       "        \n",
       "                <div class=\"steps-container\">\n",
       "        \n",
       "                    <div class=\"step\">\n",
       "                        <div class=\"step-content\">1: Define the index pattern</div>\n",
       "                    </div>\n",
       "                \n",
       "                    <div class=\"step\">\n",
       "                        <div class=\"step-title\">\n",
       "                            <span class=\"step-number\">2</span>\n",
       "                            2: Configure the settings Next steps You‚Äôre viewing version 2.19 of the OpenSearch documentation\n",
       "                        </div>\n",
       "                        <div class=\"step-content\">For the latest version, see the current documentation. For information about OpenSearch version maintenance, see Release Schedule and Maintenance Policy. Index patterns Index patterns are essential for accessing OpenSearch data. An index pattern references one or more indexes, data streams, or index aliases. For example, an index pattern can point you to your log data from yesterday or all indexes that contain that data. If you store data in multiple indexes, creating an index pattern enables your visualizations to retrieve data from all indexes that match the index pattern. You need to create index patterns to define how data is retrieved and fields are formatted so that you can query, search, and display data. Get started In this tutorial, you‚Äôll learn to create index patterns. Note To create or modify index patterns, you must have create, manage, and delete permissions. Contact your administrator for support. For more information, refer to Multi-tenancy configuration. Prerequisites Before you can create an index pattern, your data must be indexed. To learn about indexing your data in OpenSearch, see Managing indexes. Best practices Consider the following best practices when creating index patterns: Make your index patterns specific. Instead of creating an index pattern that matches all indexes, create an index pattern that matches all indexes starting with a certain prefix, for example, my-index-. The more specific your index patterns, the better it will be to query and analyze your data. Use wildcards sparingly. Wildcards can be useful for matching multiple indexes, but they can also make it more difficult to manage your index patterns. Try to use wildcards as specifically as possible. Test your index patterns. Make sure to test your index patterns to ensure that they match the correct indexes. Creating an index pattern If you added sample data, you have index patterns that you can use to analyze that data. To create an index pattern for your own data, follow these steps. </div>\n",
       "                    </div>\n",
       "                \n",
       "                    <div class=\"step\">\n",
       "                        <div class=\"step-title\">\n",
       "                            <span class=\"step-number\">3</span>\n",
       "                            1: Define the index pattern Go to OpenSearch Dashboards, and select Management > Dashboards Management > Index patterns\n",
       "                        </div>\n",
       "                        <div class=\"step-content\">Select Create index pattern. From the Create index pattern window, define the index pattern by entering a name for your index pattern in the Index pattern name field. Dashboards automatically adds a wildcard, *, once you start typing. Using a wildcard is helpful for matching an index pattern to multiple sources or indexes. A dropdown list displaying all the indexes that match your index pattern appears when you start typing. Select Next step. An example of step 1 is shown in the following image. Note that the index pattern security* matches three indexes. By defining the pattern with a wildcard *, you can query and visualize all the data in your indexes. </div>\n",
       "                    </div>\n",
       "                \n",
       "                    <div class=\"step\">\n",
       "                        <div class=\"step-title\">\n",
       "                            <span class=\"step-number\">4</span>\n",
       "                            2: Configure the settings Select @timestamp from the dropdown menu to specify the time field for OpenSearch to use when filtering documents based on time\n",
       "                        </div>\n",
       "                        <div class=\"step-content\">Selecting this time filter determines which field the time filter is applied to. It can be the timestamp of a request or any relevant timestamp field. If you don‚Äôt want to use a time filter, select that option from the dropdown menu. If you select this option, OpenSearch returns all of the data in the indexes that match the pattern. Select Create index pattern. An example is shown in the following image. Once the index pattern has been created, you can view the mapping of the matching indexes. Within the table, you can see the list of fields, along with their data type and properties. An example is shown in the following image. Next steps Understand your data through visuals. Dig into your data. ÂΩìÂâçÂÜÖÂÆπÁâàÊùÉÂΩí OpenSearch ÊàñÂÖ∂ÂÖ≥ËÅîÊñπÊâÄÊúâÔºåÂ¶ÇÈúÄÂØπÂÜÖÂÆπÊàñÂÜÖÂÆπÁõ∏ÂÖ≥ËÅîÂºÄÊ∫êÈ°πÁõÆËøõË°åÂÖ≥Ê≥®‰∏éËµÑÂä©ÔºåËØ∑ËÆøÈóÆ OpenSearch . ‰∏ä‰∏ÄÁØá: ‰∏ã‰∏ÄÁØá: ÁâàÊú¨ OpenSearch v3.0 Documentation OpenSearch v2.19 Documentation OpenSearch v2.18 Documentation OpenSearch v2.17 Documentation OpenSearch v2.16 Documentation OpenSearch v2.15 Documentation OpenSearch v2.14 Documentation OpenSearch v2.13 Documentation OpenSearch v2.12 Documentation OpenSearch v2.11 Documentation OpenSearch v2.10 Documentation OpenSearch v2.9 Documentation OpenSearch v2.8 Documentation OpenSearch v2.7 Documentation OpenSearch v2.6 Documentation OpenSearch v2.5 Documentation OpenSearch v2.4 Documentation OpenSearch v2.3 Documentation OpenSearch v2.2 Documentation OpenSearch v2.1 Documentation OpenSearch v2.0 Documentation OpenSearch v1.3 Documentation OpenSearch v1.2 Documentation OpenSearch v1.1 Documentation OpenSearch v1.0 Documentation About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Getting started with OpenSearch security Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Chatbots and agents RAG chatbot Build your own chatbot RAG chatbot with a conversational flow agent AI search workflows Creating and customizing AI search workflows Model guardrails Amazon Bedrock model guardrails Install and upgrade Installing OpenSearch Docker Helm Tarball RPM Debian Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Circuit breaker settings Cluster settings Index settings Search settings Availability and recovery settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Upgrading OpenSearch Rolling Upgrade Upgrades appendix Rolling upgrade lab Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Managing Indexes Index templates Index aliases Data streams Index context Reindex data Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings Index management security Refresh search analyzer ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Ingest Pipelines Create pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove_by_pattern Remove Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data Time filter Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers Gantt charts TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dev Tools Running queries in the Dev Tools console Query Workbench Custom branding Dashboards Query Language (DQL) Configuring CSP rules for frame ancestors Search telemetry OpenSearch Integrations Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Workload management Query Group Lifecycle API Tuning for indexing speed Security in OpenSearch Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control REST layer authorization Document-level security Defining users and roles Field-level security Field masking User impersonation Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings and field types Mapping parameters Analyzer Boost Coerce Copy_to Doc values Dynamic Eager global ordinals Enabled Ignore above Ignore malformed Format Index Index options Fields Meta Normalizer Norms Null value Properties Search analyzer Store Term vector Supported field types Alias Binary Numeric field types Unsigned long Boolean k-NN vector Spaces Methods and engines Memory-optimized vectors Date field types Date Date nanoseconds IP address Range field types Object field types Object Nested Flat object Join String field types Keyword Text Match-only text Wildcard Token count Constant keyword Autocomplete field types Completion Search as you type Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Rank field types Star-tree Derived Percolator Metadata fields Field names ID Ignored Index Meta Routing Source Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Exists Fuzzy IDs Prefix Range Regexp Term Terms Terms set Wildcard Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Distance feature k-NN Neural Neural sparse Script score Template Minimum should match Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Range Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Search features Search options Paginate results Point in Time Point in Time API Sort results Filter results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Comparing search results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI client data structures Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines Search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Identifiers Data Types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Hybrid search with post-filtering Combining hybrid search and aggregations Using sorting with a hybrid query Hybrid search with search_after Hybrid search explain Paginating hybrid query results Multimodal search Neural sparse search Generating sparse vector embeddings automatically Neural sparse search using raw vectors Conversational search with RAG Building AI search workflows in OpenSearch Dashboards Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Specialized vector search Nested field search Radial search Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Performance tuning Indexing performance tuning Search performance tuning LLM framework integration Vector search API k-NN API Settings Machine learning Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Tools Agent tool CAT Index tool Connector tool Index Mapping tool ML Model tool Neural Sparse Search tool PPL tool RAG tool Search Alerts tool CreateAnomalyDetectorTool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Execute agent Get agent Search agent Delete agent Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Tasks APIs Get task Search task Delete task Asynchronous batch ingestion Execute algorithm Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI OpenSearch Kubernetes Operator Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Index APIs Alias Create or update alias Blocks Clear cache Clone index Open index Index exists Close index Create index Delete index Get index Shrink index Create or update index template Get index template Delete index template Simulate index templates Create or update mappings Create or update component template Dangling indexes Flush Force merge Recovery Get settings Update settings Refresh index Resolve index Roll over index Segment Split index Stats Analyze API Analysis API Terminology CAT API CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster routing and awareness Cluster decommission Cluster health Cluster settings Cluster stats Count Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get document Delete by query Update by query Reindex document Explain Ingest APIs List API List shards List indices Multi-search Multi-search Template Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Profile Ranking evaluation Remote cluster information Script APIs Create or Update Stored Script Execute Painless stored script Get Stored Script Delete Script Get Stored Script Contexts Get Script Language Execute Painless script Scroll Search Search templates Snapshot APIs Register Snapshot Repository Get Snapshot Repository Delete Snapshot Repository Verify Snaphot Repository Create Snapshot Get Snapshot Delete Snapshot Get Snapshot Status Restore Snapshot Clone snapshot Cleanup Snapshot Repository Render Template Security APIs Tasks API List tasks Get task Cancel tasks Validate Query Supported units Common REST Parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions ÊöÇÊó†Áõ∏ÂÖ≥ÊêúÁ¥¢ÁªìÊûúÔºÅ Êú¨ÊñáÊ°£‰ΩøÁî® BookStack ÊûÑÂª∫ √ó ÊñáÁ´†‰∫åÁª¥Á†Å ÊâãÊú∫Êâ´‰∏ÄÊâ´ÔºåËΩªÊùæÊéå‰∏äËØª ÂÖ≥Èó≠ √ó ÊñáÊ°£‰∏ãËΩΩ ÊôÆÈÄö‰∏ãËΩΩ ‰∏ãËΩΩÁ†Å‰∏ãËΩΩ(ÂÖçÁôªÂΩïÊó†Èôê‰∏ãËΩΩ) ‰Ω†‰∏éÂ§ßÁ•ûÁöÑË∑ùÁ¶ªÔºåÂè™Â∑Æ‰∏Ä‰∏™APP ËØ∑‰∏ãËΩΩÊÇ®ÈúÄË¶ÅÁöÑÊ†ºÂºèÁöÑÊñáÊ°£ÔºåÈöèÊó∂ÈöèÂú∞Ôºå‰∫´ÂèóÊ±≤ÂèñÁü•ËØÜÁöÑ‰πêË∂£ÔºÅ PDFÊñáÊ°£ EPUBÊñáÊ°£ MOBIÊñáÊ°£ Ê∏©È¶®ÊèêÁ§∫ ÊØèÂ§©ÊØèÂú®ÁΩëÁ´ôÈòÖËØªÂ≠¶‰π†‰∏ÄÂàÜÈíüÊó∂ÈïøÂèØ‰∏ãËΩΩ‰∏ÄÊú¨ÁîµÂ≠ê‰π¶ÔºåÊØèÂ§©ËøûÁª≠Á≠æÂà∞ÂèØÂ¢ûÂä†ÈòÖËØªÊó∂Èïø ‰∏ãËΩΩÁ†ÅÊñπÂºè‰∏ãËΩΩÔºöÂÖçË¥π„ÄÅÂÖçÁôªÂΩï„ÄÅÊó†ÈôêÂà∂„ÄÇ ÂÖçË¥πËé∑Âèñ‰∏ãËΩΩÁ†Å ‰∏ãËΩΩÁ†Å ÊñáÊ°£Ê†ºÂºè PDF EPUB MOBI Á†Å‰∏ä‰∏ãËΩΩ ÂÖ≥Èó≠Á™óÂè£ √ó ÂæÆ‰ø°Â∞èÁ®ãÂ∫èÈòÖËØª ÊÇ®‰∏é‰ªñ‰∫∫ÁöÑËñ™ËµÑÂ∑ÆË∑ùÔºåÂè™Â∑Æ‰∏Ä‰∏™ÈöèÊó∂ÈöèÂú∞Â≠¶‰π†ÁöÑÂ∞èÁ®ãÂ∫è ÂÖ≥Èó≠Á™óÂè£ √ó ‰π¶Á≠æÂàóË°® ÂÖ≥Èó≠ √ó ÈòÖËØªËÆ∞ÂΩï ÈòÖËØªËøõÂ∫¶: 0.00% ( 0/0 ) ÈáçÁΩÆÈòÖËØªËøõÂ∫¶ ÂÖ≥Èó≠ Ê¨¢Ëøé‰ΩøÁî®AIÂä©Êâã AIÂä©Êâã ÂÖ®Â±è Áº©Â∞è ÈöêËóè Ê∏ÖÁ©∫</div>\n",
       "                    </div>\n",
       "                \n",
       "                </div>\n",
       "        \n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\">\n",
       "                <div class=\"result-number\">5</div>\n",
       "                <div class=\"result-title\"></div>\n",
       "            </div>\n",
       "            <div class=\"result-url\">\n",
       "                <strong>üîó Source:</strong> <a href=\"https://deepwiki.com/johnny-chivers/amazon-opensearch-service/3.1-index-patterns\" target=\"_blank\">https://deepwiki.com/johnny-chivers/amazon-opensearch-service/3.1-index-patterns</a>\n",
       "            </div>\n",
       "            <div class=\"result-body\">\n",
       "    \n",
       "                <div class=\"overview\">\n",
       "                    <strong>Overview:</strong><br>\n",
       "                    Loading... Index your code with Devin DeepWiki DeepWiki johnny-chivers/amazon-opensearch-service Index your code with Devin Edit Wiki Share Loading... Last indexed: 25 May 2025 (924181) Overview Getting Started Tutorial Domain Setup Data Upload and Indexing Search Operations Cleanup and Domain Deletion Index Management Index Patterns Field Configuration Security and Access Control Access Control Systems Access Policies System Architecture Data Node Architecture Network Configuration Development and Testing Menu Index Patterns Relevant source files pictures/12-define-index-pattern.png pictures/13-createe-index-pattern.png Purpose and Scope This document covers the creation and configuration of index patterns in Amazon OpenSearch Service, specifically focusing on how they enable data discovery and visualization through the OpenSearch Dashboards interface. Index patterns define how OpenSearch Dashboards connects to and interprets the data stored in your OpenSearch indices. This guide specifically covers the index pattern workflow for the movies dataset used in the tutorial. For information about the underlying index field configuration and data types, see Field Configuration. For the broader context of data upload and indexing operations, see Data Upload and Indexing. Overview of Index Patterns Index patterns in OpenSearch Dashboards serve as a bridge between raw index data and the visualization layer. They define which indices contain the data you want to explore and specify how that data should be interpreted for search and analysis operations. In the context of this tutorial, index patterns enable access to the movies index that contains the bulk movie dataset from bulk_movies.json. Sources: Based on tutorial workflow and OpenSearch Dashboards architecture patterns. Index Pattern Creation Workflow The index pattern creation process follows a specific sequence within the OpenSearch Dashboards interface, as documented in the tutorial screenshots. Sources: Tutorial workflow sequence and OpenSearch Dashboards interface patterns. Pattern Definition and Configuration Index patterns use wildcard matching to identify which indices they should include. For the movies dataset, the pattern typically follows this structure: Pattern Element Purpose Example Index Name Base index identifier movies Wildcard Pattern matching movies* Time Field Timestamp field for time-based data Not applicable for movies dataset Field Discovery Automatic field detection Enabled The pattern configuration process involves several key steps: Sources: OpenSearch Dashboards index pattern creation workflow and field detection mechanisms. Field Mapping and Data Types Once an index pattern is created, OpenSearch Dashboards automatically discovers and maps the fields from the underlying movies index. This process examines the data structure from the documents uploaded via bulk_movies.json. The field mapping process identifies several categories of data: Field Category Examples from Movies Data OpenSearch Type Text Fields title, director, genre text or keyword Numeric Fields year, rating integer or float Date Fields release_date date Boolean Fields available boolean Sources: OpenSearch field mapping documentation and movies dataset structure analysis. Integration with Discovery Interface Index patterns enable the Discover interface to provide search and exploration capabilities across the movie dataset. The integration allows for both simple and complex query operations. The discovery workflow leverages the index pattern to: Field-based Filtering: Use detected fields for creating search filters Time-based Navigation: Handle temporal data if time fields are configured Aggregation Operations: Support grouping and statistical operations Export Functionality: Enable data export based on search results Sources: OpenSearch Dashboards Discover interface capabilities and query processing architecture. Pattern Management and Maintenance Index patterns require ongoing management as data structures evolve. The tutorial demonstrates basic pattern creation, but production environments often need pattern updates and field refresh operations. Key maintenance operations include: Field Refresh: Update field mappings when new fields are added to indices Pattern Modification: Adjust pattern matching rules for new indices Performance Optimization: Configure field settings for optimal query performance Access Control: Manage pattern visibility and permissions The movies dataset provides a stable example for learning these concepts, as the data structure remains consistent throughout the tutorial workflow. Sources: OpenSearch index pattern management best practices and tutorial documentation structure. Dismiss Refresh this wiki Enter email to refresh On this page Index Patterns Purpose and Scope Overview of Index Patterns Index Pattern Creation Workflow Pattern Definition and Configuration Field Mapping and Data Types Integration with Discovery Interface Pattern Management and Maintenance\n",
       "                </div>\n",
       "        \n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\">\n",
       "                <div class=\"result-number\">6</div>\n",
       "                <div class=\"result-title\">Link Search Menu Expand Document Documentation Menu</div>\n",
       "            </div>\n",
       "            <div class=\"result-url\">\n",
       "                <strong>üîó Source:</strong> <a href=\"https://docs.opensearch.org/latest/api-reference/index-apis/create-index-template/\" target=\"_blank\">https://docs.opensearch.org/latest/api-reference/index-apis/create-index-template/</a>\n",
       "            </div>\n",
       "            <div class=\"result-body\">\n",
       "    \n",
       "                <div class=\"overview\">\n",
       "                    <strong>Overview:</strong><br>\n",
       "                    Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards ‚Üê Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Discovery and cluster formation Node discovery and seed hosts Voting and quorum Voting configuration management Cluster bootstrapping Discovery and cluster formation settings Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Remote segment warmer Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Similarity Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Resource access management Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates OpenSearch FIPS configuration Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control Defining users and roles Permissions Default action groups REST layer authorization Document-level security Field-level security Field masking User impersonation Resource sharing and access control Resource sharing APIs API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Version Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Mapping explosion Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Rescore Regular expression syntax SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic queries Complex queries Functions JSON support Metadata queries Aggregate functions Delete JDBC driver ODBC driver PPL Subsearch Commands PPL syntax ad addcoltotals addtotals append appendcol appendpipe bin chart dedup describe eval eventstats expand explain fields fillnull flatten grok head join kmeans lookup ml multisearch parse patterns rare regex rename replace reverse rex search show datasources sort spath stats streamstats subquery table timechart top trendline where Identifiers Data types Functions Full-text search Settings Troubleshooting Monitoring Limitations Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Collecting UBI-formatted data in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Model access control through resource sharing Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller ML Tasks APIs Get ML task Search ML tasks Delete ML task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow access control Workflow settings Workflow state access control Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detector access control Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecaster access control Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions API reference Index APIs Index templates Create or update index template Create Or Update Index Template API You can use the Create or Update Index Template API to create indexes with predefined mappings and settings as well as update existing index templates. Endpoints PUT _index_template/<template-name>\n",
       "POST _index_template/<template-name>\n",
       " Path parameters Parameter Data type Description template-name String The name of the index template. Query parameters The following optional query parameters are supported. Parameter Data type Description create Boolean When true, the API cannot replace or update any existing index templates. Default is false. cluster_manager_timeout Time The amount of time to wait for a connection to the cluster manager node. Default is 30s. Request body fields The following options can be used in the request body to customize the index template. Parameter Type Description index_patterns String array An array of wildcard expressions that match the names of data streams and indexes created during template creation. Required. composed_of String array An ordered list of component template names. These templates are merged using the specified order. For more information, see Using multiple component templates. Optional. data_stream Object When used, the request creates data streams and any backing indexes based on the template. This setting requires a matching index template. It can also be used with the hidden setting, which, when set to true, hides the data stream backing indexes. Optional. _meta Object Optional metadata that provides details about the index template. Optional. priority Integer A number that determines which index templates take precedence during the creation of a new index or data stream. OpenSearch chooses the template with the highest priority. When no priority is given, the template is assigned a 0, signifying the lowest priority. Optional. template Object The template that includes the aliases, mappings, or settings for the index. For more information, see [#template]. Optional. version Integer The version number used to manage index templates. Version numbers are not automatically set by OpenSearch. Optional. context Object (Experimental) The context parameter provides use-case-specific predefined templates that can be applied to an index. Among all settings and mappings declared for a template, context templates hold the highest priority. For more information, see index-context. Template You can use the following objects with the template option in the request body. alias The name of the alias to associate with the template as a key. Required when the template option exists in the request body. This option supports multiple aliases. The object body contains the following optional alias parameters. Parameter Data type Description filter Query DSL object The query that limits the number of documents that the alias can access. index_routing String The value that routes indexing operations to a specific shard. When specified, overwrites the routing value for indexing operations. is_hidden Boolean When true, the alias is hidden. Default is false. All alias indexes must have matching values for this setting. is_write_index Boolean When true, the index is the write index for the alias. Default is false. routing String The value used to route index and search operations to a specific shard. search_routing String The value used to write specific search operations to a specific shard. When specified, this option overwrites the routing value for search operations. mappings The field mappings that exist in the index. For more information, see Mappings and field types. Optional. settings Any configuration options for the index. For more information, see Index settings. Example requests The following examples show how to use the Create or Update Index Template API. Index template with index aliases The following example request includes index aliases in the template: REST Python PUT /_index_template/alias-template\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"sh*\"\n",
       "  ],\n",
       "  \"template\": {\n",
       "    \"settings\": {\n",
       "      \"number_of_shards\": 1\n",
       "    },\n",
       "    \"aliases\": {\n",
       "      \"alias1\": {},\n",
       "      \"alias2\": {\n",
       "        \"filter\": {\n",
       "          \"term\": {\n",
       "            \"user.id\": \"hamlet\"\n",
       "          }\n",
       "        },\n",
       "        \"routing\": \"shard-1\"\n",
       "      },\n",
       "      \"{index}-alias\": {}\n",
       "    }\n",
       "  }\n",
       "} Copy Copy as cURL response = client.indices.put_index_template(\n",
       "  name = \"alias-template\",\n",
       "  body =   {\n",
       "    \"index_patterns\": [\n",
       "      \"sh*\"\n",
       "    ],\n",
       "    \"template\": {\n",
       "      \"settings\": {\n",
       "        \"number_of_shards\": 1\n",
       "      },\n",
       "      \"aliases\": {\n",
       "        \"alias1\": {},\n",
       "        \"alias2\": {\n",
       "          \"filter\": {\n",
       "            \"term\": {\n",
       "              \"user.id\": \"hamlet\"\n",
       "            }\n",
       "          },\n",
       "          \"routing\": \"shard-1\"\n",
       "        },\n",
       "        \"{index}-alias\": {}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       ") Copy Using multiple matching templates When multiple index templates match the name of a new index or data stream, the template with the highest priority is used. For example, the following two requests create index templates with different priorities: PUT /_index_template/template_one\n",
       "{\n",
       "  \"index_patterns\" : [\"h*\"],\n",
       "  \"priority\" : 0,\n",
       "  \"template\": {\n",
       "    \"settings\" : {\n",
       "      \"number_of_shards\" : 1,\n",
       "      \"number_of_replicas\": 0\n",
       "    },\n",
       "    \"mappings\" : {\n",
       "      \"_source\" : { \"enabled\" : false }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "PUT /_index_template/template_two\n",
       "{\n",
       "  \"index_patterns\" : [\"ha*\"],\n",
       "  \"priority\" : 1,\n",
       "  \"template\": {\n",
       "    \"settings\" : {\n",
       "      \"number_of_shards\" : 2\n",
       "    },\n",
       "    \"mappings\" : {\n",
       "      \"_source\" : { \"enabled\" : true }\n",
       "    }\n",
       "  }\n",
       "}\n",
       " copy For indexes that start with ha, the _source is enabled. Because only template_two is applied, the index will have two primary shards and one replica. Overlapping index patterns given the same priority are not allowed. An error will occur when attempting to create a template matching an existing index template with identical priorities. Adding template versioning The following example request adds a version number to an index template, which simplifies template management for external systems: REST Python PUT /_index_template/template_one\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"mac\",\n",
       "    \"cheese\"\n",
       "  ],\n",
       "  \"priority\": 0,\n",
       "  \"template\": {\n",
       "    \"settings\": {\n",
       "      \"number_of_shards\": 1\n",
       "    }\n",
       "  },\n",
       "  \"version\": 1\n",
       "} Copy Copy as cURL response = client.indices.put_index_template(\n",
       "  name = \"template_one\",\n",
       "  body =   {\n",
       "    \"index_patterns\": [\n",
       "      \"mac\",\n",
       "      \"cheese\"\n",
       "    ],\n",
       "    \"priority\": 0,\n",
       "    \"template\": {\n",
       "      \"settings\": {\n",
       "        \"number_of_shards\": 1\n",
       "      }\n",
       "    },\n",
       "    \"version\": 1\n",
       "  }\n",
       ") Copy Adding template metadata The following example request uses the meta parameter to add metadata to the index template. All metadata is stored in the cluster state: REST Python PUT /_index_template/template_one\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"rom\",\n",
       "    \"juliet\"\n",
       "  ],\n",
       "  \"template\": {\n",
       "    \"settings\": {\n",
       "      \"number_of_shards\": 2\n",
       "    }\n",
       "  },\n",
       "  \"_meta\": {\n",
       "    \"description\": \"Where art thou\",\n",
       "    \"serialization\": {\n",
       "      \"class\": \"MyIndexTemplate\",\n",
       "      \"id\": 12\n",
       "    }\n",
       "  }\n",
       "} Copy Copy as cURL response = client.indices.put_index_template(\n",
       "  name = \"template_one\",\n",
       "  body =   {\n",
       "    \"index_patterns\": [\n",
       "      \"rom\",\n",
       "      \"juliet\"\n",
       "    ],\n",
       "    \"template\": {\n",
       "      \"settings\": {\n",
       "        \"number_of_shards\": 2\n",
       "      }\n",
       "    },\n",
       "    \"_meta\": {\n",
       "      \"description\": \"Where art thou\",\n",
       "      \"serialization\": {\n",
       "        \"class\": \"MyIndexTemplate\",\n",
       "        \"id\": 12\n",
       "      }\n",
       "    }\n",
       "  }\n",
       ") Copy Data stream definition Include a data_stream object to use an index template for data streams, as shown in the following example request: REST Python PUT /_index_template/template_1\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"logs-*\"\n",
       "  ],\n",
       "  \"data_stream\": {}\n",
       "} Copy Copy as cURL response = client.indices.put_index_template(\n",
       "  name = \"template_1\",\n",
       "  body =   {\n",
       "    \"index_patterns\": [\n",
       "      \"logs-*\"\n",
       "    ],\n",
       "    \"data_stream\": {}\n",
       "  }\n",
       ") Copy Using multiple component templates When using multiple component templates with the composed_of field, the component templates are merged in the specified order. Next, all mappings, settings, and aliases from the parent index template of the component are merged. Lastly, any configuration options added to the index requests are merged. In the following example request, an index with h* has two merged primary shards. If the order in the request body were reversed, then the index would have one primary shard: PUT /_component_template/template_with_1_shard\n",
       "{\n",
       "  \"template\": {\n",
       "    \"settings\": {\n",
       "      \"index.number_of_shards\": 1\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "PUT /_component_template/template_with_2_shards\n",
       "{\n",
       "  \"template\": {\n",
       "    \"settings\": {\n",
       "      \"index.number_of_shards\": 2\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "PUT /_index_template/template_1\n",
       "{\n",
       "  \"index_patterns\": [\"h*\"],\n",
       "  \"composed_of\": [\"template_with_1_shard\", \"template_with_2_shards\"]\n",
       "}\n",
       " copy Recursive merging is used for mapping definition and root options such as dynamic_templates and meta, meaning that when an earlier component contains a meta block, new meta entries are added to the end of the metadata in the index. Any entries containing a preexisting key are overwritten. Endpoints Path parameters Query parameters Request body fields Template Example requests Index template with index aliases Using multiple matching templates Adding template versioning Adding template metadata Data stream definition Using multiple component templates WAS THIS PAGE HELPFUL? ‚úî Yes ‚úñ No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright ¬© OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\n",
       "                </div>\n",
       "        \n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\">\n",
       "                <div class=\"result-number\">7</div>\n",
       "                <div class=\"result-title\">Link Search Menu Expand Document Documentation Menu</div>\n",
       "            </div>\n",
       "            <div class=\"result-url\">\n",
       "                <strong>üîó Source:</strong> <a href=\"https://opensearch.isharkfly.com/dashboards/management/index-patterns/\" target=\"_blank\">https://opensearch.isharkfly.com/dashboards/management/index-patterns/</a>\n",
       "            </div>\n",
       "            <div class=\"result-body\">\n",
       "    \n",
       "                <div class=\"overview\">\n",
       "                    <strong>Overview:</strong><br>\n",
       "                    Link Search Menu Expand Document Documentation Menu OpenSearch Menu OpenSearchCon 2024 - Stay Informed Sessions Speakers Exhibitors Workshops Unconference CFP is closed Download About Releases Roadmap FAQ Community Blog Forum Slack Events Partners Projects Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Documentation OpenSearch and OpenSearch Dashboards ‚Üê Back to docs home API Style Guide Formatting Guide OpenSearch Documentation Website 2.10.0 Release Notes OpenSearch Documentation Website 2.11.0 Release Notes OpenSearch Documentation Website 2.12.0 Release Notes OpenSearch Documentation Website 2.4.0 Release Notes OpenSearch Documentation Website 2.5.0 Release Notes OpenSearch Documentation Website 2.6.0 Release Notes OpenSearch Documentation Website 2.7.0 Release Notes OpenSearch Documentation Website 2.8.0 Release Notes OpenSearch Documentation Website 2.9.0 Release Notes OpenSearch Project Style Guidelines OpenSearch terms Overview About OpenSearch Intro to OpenSearch Quickstart Version history Breaking changes Install and upgrade Installing OpenSearch Docker Helm Tarball RPM Debian Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Circuit breaker settings Cluster settings Index settings Search settings Availability and recovery settings Plugin settings Experimental feature flags Logs Configuring OpenSearch Dashboards Upgrading OpenSearch Rolling Upgrade Upgrades appendix Rolling upgrade lab Installing plugins Managing OpenSearch Dashboards plugins Migrate to OpenSearch Using snapshots to migrate data Migrating from Elasticsearch OSS to OpenSearch Migrating Docker clusters to OpenSearch Migrating from Kibana OSS to OpenSearch Dashboards Managing Indexes Index templates Index aliases Data streams Reindex data Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings Index management security Refresh search analyzer ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Ingest Pipelines Create pipeline Simulate pipeline Get pipeline Delete pipeline Handling pipeline failures Ingest processors Append Bytes Convert Copy CSV Date Date index name Dissect Dot expander Drop IP2Geo Grok KV Lowercase Remove_by_pattern Remove Sparse encoding Text embedding Text/image embedding Uppercase OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Analyzing data Time filter Creating dashboards Building data visualizations Using area charts Using coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using the self-host maps server Using Gantt charts Using VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimize query performance using OpenSearch indexing Dev Tools Running queries in the Dev Tools console Query Workbench Custom branding Dashboards Query Language (DQL) Search telemetry OpenSearch Integrations Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Tuning for indexing speed Security in OpenSearch Configuration Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files API rate limiting Configuring sign-in options Disabling security OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Access control REST layer authorization Document-level security Users and roles Field-level security Field masking User impersonation Cross-cluster search Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Creating detectors Supported log types Creating correlation rules Creating custom log types Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Security Analytics settings Mappings and field types Supported field types Alias Binary Numeric field types Unsigned long Boolean Date field types Date Date nanoseconds IP address Range field types Object field types Object Nested Flat object Join String field types Keyword Text Match-only text Token count Autocomplete field types Completion Search as you type Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape k-NN vector Rank field types Percolator Text analysis Language analyzers Index analyzers Search analyzers Tokenizers Token filters Delimited term frequency Normalizers Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Exists Fuzzy IDs Prefix Range Regexp Term Terms Terms set Wildcard Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box xy Span queries Match all queries Specialized queries Neural Neural sparse Script score Minimum should match Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Matrix stats Maximum Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Bucket aggregations Adjacency matrix Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Range Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Search Searching data Paginate results Point in Time Point in Time API Sort results Highlight query matches Autocomplete Did-you-mean Keyword search k-NN search k-NN index Exact k-NN with scoring script Approximate k-NN search k-NN search with filters k-NN search with nested fields k-NN Painless extensions API JNI libraries Settings Performance tuning Neural search Neural search tutorial Semantic search Multimodal search Neural sparse search Hybrid search Conversational search Search relevance Comparing search results Reranking search results Querqy Search pipelines Creating a search pipeline Using a search pipeline Retrieving search pipelines Search processors Collapse Filter query Neural query enricher Normalization Oversample Personalize search ranking Retrieval-augmented generation Rename field Rerank Script Truncate hits Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Identifiers Data Types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Machine learning ML Commons cluster settings Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Connector blueprints Agents and tools Agents and tools tutorial Tools Agent tool CAT Index tool Index Mapping tool ML Model tool Neural Sparse Search tool PPL tool RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool OpenSearch Assistant Toolkit Managing ML models in OpenSearch Dashboards Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Model group APIs Register model group Update model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Execute agent Get agent Search agent Delete agent Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Execute algorithm Tasks APIs Get task Search task Delete task Train and Predict APIs Train and predict Train Predict Profile Stats Automating configurations Workflow steps Workflow tutorial Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Monitoring your cluster Job Scheduler Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metrics analytics Query insights Top N queries Trace Analytics Getting Started OpenSearch Dashboards plugin Analyzing Jaeger trace data Distrbuted tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI OpenSearch Kubernetes Operator Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana API reference Analyze API Analysis API Terminology CAT API CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices operation CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster routing and awareness Cluster decommission Cluster health Cluster settings Cluster stats Count Document APIs Index document Get document Update document Delete document Bulk Multi-get document Delete by query Update by query Reindex document Explain Index APIs Alias Clear cache Clone index Close index Create index Create or update mappings Dangling indexes Delete index Force merge Get index Get settings Index exists Open index Shrink index Split index Stats Update settings Ingest APIs Multi-search Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Profile Ranking evaluation Remote cluster information Script APIs Create or Update Stored Script Execute Painless stored script Get Stored Script Delete Script Get Stored Script Contexts Get Script Language Execute Painless script Scroll Search Search templates Snapshot APIs Register Snapshot Repository Get Snapshot Repository Delete Snapshot Repository Verify Snaphot Repository Create Snapshot Get Snapshot Delete Snapshot Get Snapshot Status Restore Snapshot Tasks Supported units Common REST Parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Extensions Dashboards Management Index patterns Index patterns Index patterns are essential for accessing OpenSearch data. An index pattern references one or more indexes, data streams, or index aliases. For example, an index pattern can point you to your log data from yesterday or all indexes that contain that data. If you store data in multiple indexes, creating an index pattern enables your visualizations to retrieve data from all indexes that match the index pattern. You need to create index patterns to define how data is retrieved and fields are formatted so that you can query, search, and display data. Get started In this tutorial, you‚Äôll learn to create index patterns. Note To create or modify index patterns, you must have create, manage, and delete permissions. Contact your administrator for support. For more information, refer to Multi-tenancy configuration. Prerequisites Before you can create an index pattern, your data must be indexed. To learn about indexing your data in OpenSearch, see Managing indexes. Best practices Consider the following best practices when creating index patterns: Make your index patterns specific. Instead of creating an index pattern that matches all indexes, create an index pattern that matches all indexes starting with a certain prefix, for example, my-index-. The more specific your index patterns, the better it will be to query and analyze your data. Use wildcards sparingly. Wildcards can be useful for matching multiple indexes, but they can also make it more difficult to manage your index patterns. Try to use wildcards as specifically as possible. Test your index patterns. Make sure to test your index patterns to ensure that they match the correct indexes. Creating an index pattern If you added sample data, you have index patterns that you can use to analyze that data. To create an index pattern for your own data, follow these steps.\n",
       "                </div>\n",
       "        \n",
       "                <div class=\"steps-container\">\n",
       "        \n",
       "                    <div class=\"step\">\n",
       "                        <div class=\"step-title\">\n",
       "                            <span class=\"step-number\">1</span>\n",
       "                            1: Define the index pattern Go to OpenSearch Dashboards, and select Management > Dashboards Management > Index patterns\n",
       "                        </div>\n",
       "                        <div class=\"step-content\">Select Create index pattern. From the Create index pattern window, define the index pattern by entering a name for your index pattern in the Index pattern name field. Dashboards automatically adds a wildcard, *, once you start typing. Using a wildcard is helpful for matching an index pattern to multiple sources or indexes. A dropdown list displaying all the indexes that match your index pattern appears when you start typing. Select Next step. An example of step 1 is shown in the following image. Note that the index pattern security* matches three indexes. By defining the pattern with a wildcard *, you can query and visualize all the data in your indexes. </div>\n",
       "                    </div>\n",
       "                \n",
       "                    <div class=\"step\">\n",
       "                        <div class=\"step-title\">\n",
       "                            <span class=\"step-number\">2</span>\n",
       "                            2: Configure the settings Select @timestamp from the dropdown menu to specify the time field for OpenSearch to use when filtering documents based on time\n",
       "                        </div>\n",
       "                        <div class=\"step-content\">Selecting this time filter determines which field the time filter is applied to. It can be the timestamp of a request or any relevant timestamp field. If you don‚Äôt want to use a time filter, select that option from the dropdown menu. If you select this option, OpenSearch returns all of the data in the indexes that match the pattern. Select Create index pattern. An example is shown in the following image. Once the index pattern has been created, you can view the mapping of the matching indexes. Within the table, you can see the list of fields, along with their data type and properties. An example is shown in the following image. Next steps Understand your data through visuals. Dig into your data. Get started Prerequisites Best practices Creating an index pattern </div>\n",
       "                    </div>\n",
       "                \n",
       "                    <div class=\"step\">\n",
       "                        <div class=\"step-content\">1: Define the index pattern</div>\n",
       "                    </div>\n",
       "                \n",
       "                    <div class=\"step\">\n",
       "                        <div class=\"step-title\">\n",
       "                            <span class=\"step-number\">4</span>\n",
       "                            2: Configure the settings Next steps WAS THIS PAGE HELPFUL? ‚úî Yes ‚úñ No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum\n",
       "                        </div>\n",
       "                        <div class=\"step-content\">Want to contribute? Edit this page or create an issue. OpenSearch Links ÂèÇ‰∏éÈ°πÁõÆÔºàGet InvolvedÔºâ Code of Conduct OpenSearch ‰∏≠ÊñáËÆ∫Âùõ ÂÆòÊñπËÆ∫Âùõ ‰∏≠ÊñáÊñáÊ°£‰ª£Á†Å‰ªìÂ∫ì ÂÆòÊñπ Github Slack Á§æÂå∫È°πÁõÆ ËµÑÊ∫êÔºàResourcesÔºâ About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy ËÅîÁ≥ªÊàë‰ª¨ÔºàContact UsÔºâ ËÅîÁ≥ªÔºàConnectÔºâ Twitter LinkedIn YouTube Meetup Facebook ¬© OpenSearch contributors, 2024. OpenSearch is a registered trademark of Amazon Web Services. ¬© 2005-2021 Django Software Foundation and individual contributors. Django is a registered trademark of the Django Software Foundation. This website was forked from the BSD-licensed djangoproject.com originally designed by Threespot & andrevv.</div>\n",
       "                    </div>\n",
       "                \n",
       "                </div>\n",
       "        \n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\">\n",
       "                <div class=\"result-number\">8</div>\n",
       "                <div class=\"result-title\"></div>\n",
       "            </div>\n",
       "            <div class=\"result-url\">\n",
       "                <strong>üîó Source:</strong> <a href=\"https://repost.aws/knowledge-center/opensearch-index-pattern\" target=\"_blank\">https://repost.aws/knowledge-center/opensearch-index-pattern</a>\n",
       "            </div>\n",
       "            <div class=\"result-body\">\n",
       "    \n",
       "                <div class=\"overview\">\n",
       "                    <strong>Overview:</strong><br>\n",
       "                    Skip to content By using AWS re:Post, you agree to the AWS re:Post Terms of Use re:Post Search About re:Post English EnglishDeutschEspa√±olFran√ßaisItalianoÊó•Êú¨Ë™ûÌïúÍµ≠Ïñ¥Portugu√™s‰∏≠Êñá (ÁÆÄ‰Ωì)‰∏≠Êñá (ÁπÅÈ´î) Resources Sign in Home Questions Knowledge Center Articles Selections Tags Topics Community Groups AWS Support Official AWS Trust & Safety Center Ask question AWS re:Post Knowledge Center Feedback Survey Help us improve the AWS re:Post Knowledge Center by sharing your feedback in a brief survey. Your input can influence how we create and update our content to better support your AWS journey. / How do I create an index pattern in my OpenSearch Service cluster?lg.../ How do I create an index pattern in my OpenSearch Service cluster? 5 minute read 1 I want to create an index pattern in my Amazon OpenSearch Service cluster. Resolution Prerequisites: The AWS Identity and Access Management (IAM) user must have PUT and POST permissions to create an index pattern. Example access policy: {  \"Version\": \"2012-10-17\",\n",
       "  \"Statement\": [\n",
       "    {\n",
       "      \"Sid\": \"VisualEditor0\",\n",
       "      \"Effect\": \"Allow\",\n",
       "      \"Action\": [\n",
       "        \"es:ESHttpHead\",\n",
       "        \"es:ESHttpPost\",\n",
       "        \"es:ESHttpGet\",\n",
       "        \"es:ESHttpDelete\",\n",
       "        \"es:ESHttpPut\"\n",
       "      ],\n",
       "      \"Resource\": \"arn:aws:es:region:account-id:domain/domain-name/*\"\n",
       "    }\n",
       "  ]\n",
       "} Note: Replace region with your AWS Region, account-id with your AWS account, and domain-name with your domain name. Your cluster version must allow index patterns. Create the index pattern Use OpenSearch Dashboards You can use OpenSearch Dashboards to create an index pattern for OpenSearch Service or Elasticsearch clusters with or without fine-grained access control. For instructions, see Creating an index pattern on the OpenSearch website. Use curl commands To create an index pattern for clusters without fine-grained access control, run the following command based on the cluster type. Elasticsearch clusters: curl -X POST  https://elasticsearch-end-point/_plugin/kibana/api/saved_objects/index-pattern/ \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "\n",
       "-H \"content-type: application/json\" \\\n",
       "\n",
       "-d '{ \"attributes\": { \"title\": \"sample-index*\" } }' Note: Replace sample-index with your index name or pattern. OpenSearch Service clusters: curl -X POST  https://opensearch-end-point/_dashboards/api/saved_objects/index-pattern/ \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "\n",
       "-H \"content-type: application/json\" \\\n",
       "\n",
       "-d '{ \"attributes\": { \"title\": \"sample-index*\" } }' Note: Replace sample-index with your index name or pattern. For clusters with fine-grained access control, complete the following steps: To generate authorization cookies in the auth.txt file, run the following command based on the cluster type. Elasticsearch clusters: curl -X POST  https://elasticsearch-end-point/_plugin/kibana/auth/login  \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "-H \"content-type: application/json\" \\\n",
       "-d '{\"username\":\"usernameexample\", \"password\":\"passwordexample\"}' \\\n",
       "-c auth.txt Note: Replace usernameexample with your username and passwordexample with your password. OpenSearch Service clusters: curl -X POST  https://opensearch-end-point/_dashboards/auth/login  \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "-H \"content-type: application/json\" \\\n",
       "-d '{\"username\":\"usernameexample\", \"password\":\"passwordexample\"}' \\\n",
       "-c auth.txt Note: Replace usernameexample with your username and passwordexample with your password. To submit the index pattern creation request, run the following command based on your cluster type: Elasticsearch clusters: curl -X POST  https://elasticsearch-end-point/_plugin/kibana/api/saved_objects/index-pattern/test  \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "-H \"content-type: application/json\" \\\n",
       "-d '{ \"attributes\": { \"title\": \"sample-index*\" } }' \\\n",
       "-b auth.txt Note: Replace sample-index with your index name or pattern. OpenSearch Service clusters: curl -X POST  https://opensearch-end-point/_dashboards/api/saved_objects/index-pattern/  \\\n",
       "-H \"kbn-xsrf: true\" \\\n",
       "-H \"content-type: application/json\" \\\n",
       "-d '{ \"attributes\": { \"title\": \"sample-index*\" } }' \\\n",
       "-b auth.txt Note: Replace sample-index with your index name or pattern. Use Python Prerequisites: Map the role that runs the Python code to the backend role for fine-grained access control clusters. Run the following commands to install the required dependencies: pip install boto3\n",
       "pip install opensearch-py\n",
       "pip install requests\n",
       "pip install requests-aws4auth Run the following Python command to create the index pattern for OpenSearch Service clusters: import boto3\n",
       "import requests\n",
       "from requests_aws4auth import AWS4Auth\n",
       "\n",
       "host = 'https://domain-endpoint/' # include trailing /\n",
       "region = 'aos-region' # example us-west-1\n",
       "service = 'es'\n",
       "credentials = boto3.Session().get_credentials()\n",
       "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)\n",
       "\n",
       "\n",
       "path = '_dashboards/api/saved_objects/index-pattern' # _plugin/kibana/api/saved_objects/index-pattern for es versions\n",
       "url = host + path\n",
       "payload = {\"attributes\":{\"title\":\"multi-logs-*\",\"fields\":\"[]\"}}\n",
       "headers = {\"Content-Type\": \"application/json\", \"osd-xsrf\": \"true\", \"security_tenant\": \"global\" }\n",
       "r = requests.post (url, auth=awsauth, json=payload, headers=headers)\n",
       "print(r.status_code)\n",
       "print(r.text) Note: Replace domain-endpoint with your domain endpoint, and aos-region with your Region. For Elasticsearch clusters, replace _dashboards/api/saved_objects/index-pattern with _plugin/kibana/api/saved_objects/index-pattern. Troubleshoot index pattern creation issues You use fine-grained access control with SAML 2.0 or Amazon Cognito authentication If the domain for your cluster uses SAML 2.0 or Amazon Cognito for authentication, then create an internal user to manage the index pattern. Note: For clusters where you activated fine-grained access control, the user must have ESHttpPut and ESHttpPost permissions to create an index pattern. You can't create the index pattern in the Global tenant By default, OpenSearch Dashboards creates index patterns under the Global tenant. To create an index pattern outside of the Global tenant, run the following command: curl -s -X POST https://opensearch-end-point/_dashboards/api/saved_objects/index-pattern/sample-index -d '{\"attributes\": {\"title\": \"sample-index*\"}}' \\\n",
       "-H \"osd-xsrf:true\" \\\n",
       "-H \"securitytenant: private\" \\\n",
       "-H \"content-type:application/json\" \\\n",
       "-b auth.txt Note: Replace sample-index with your index name or pattern. You didn't include the .kibana alias in the cluster To troubleshoot this issue, complete the following steps: To check whether the .kibana alias exists in the cluster, run the following command: curl -XGET https://opensearch-end-point/_cat/aliases Note: For clusters with fine-grained access control, include the -u flag with your username and password. Example command: curl -XPOST -u 'master-user:master-user-password' 'domain-endpoint/_cat/indices If the .kibana index doesn't exist, then proceed to step 4. To create a backup of .kibana index, run the following command: curl -XPOST \"https://domain-endpoint/_reindex\" -H 'Content-Type: application/json' -d'{\n",
       "  \"source\": {\n",
       "    \"index\": \".kibana\"\n",
       "  },\n",
       "  \"dest\": {\n",
       " \"index\": \".kibana_backup\"\n",
       "  }\n",
       "}' Note: Replace domain-endpoint with your domain endpoint. For clusters with fine-grained access control, include the -u flag with your username and password. To delete the .kibana index, run the following command: curl -XDELETE \"https://domain-endpoint/.kibana\" Note: Replace domain-endpoint with your domain endpoint. For clusters with fine-grained access control, include the -u flag with your username and password. To create a .kibana alias and point it to the .kibana_backup index, run the following command: curl -XPOST \"https://domain-endpoint/_aliases\" -H 'Content-Type: application/json' -d'{\n",
       "  \"actions\": [\n",
       "    {\n",
       "      \"add\": {\n",
       "        \"index\": \".kibana_backup\",\n",
       "        \"alias\": \".kibana\"\n",
       "      }\n",
       "    }\n",
       "  ]\n",
       "}' Note: Replace domain-endpoint with your domain endpoint. For clusters with fine-grained access control, include the -u flag with your username and password. Related information Export and import Kibana dashboards with OpenSearch Service Why does the rollover index action in my ISM policy keep failing in OpenSearch Service? Follow Share Topics Analytics Tags Amazon OpenSearch Service Language English Related videos Watch Sujata's video to learn more (3:59) AWS OFFICIALUpdated 4 months ago 2 Comments This can also be done using basic auth using session object without signing the request if that is the use case. [+] Session Object = https://requests.readthedocs.io/en/latest/user/advanced/#session-objects #! /bin/python3\n",
       "import requests\n",
       "host = 'https://<domain_endpoint_ending_with_slash>/'\n",
       "path = '_dashboards/auth/login'\n",
       "region = 'us-east-1'\n",
       "url = host + path;\n",
       "# Set headers as mentioned. Here we will create index pattern in global tenant hence the value is global\n",
       "headers = {\"Content-Type\": \"application/json\",\"kbn-xsrf\": \"true\",\"osd-xsrf\":\"true\",\"security_tenant\":\"global\"};\n",
       "payload = {\n",
       " \"username\":\"username\",\n",
       "    \"password\":\"password\"\n",
       "}\n",
       "\n",
       "#Creating a session because requests wont store the cookie\n",
       "\n",
       "session=requests.Session();\n",
       "\n",
       "r=session.post(url,headers=headers,json=payload);\n",
       "# You can skip these lines with print. Basically the above line will do a post request with my credentials and will create a cookie and will store it\n",
       "print(r.text);\n",
       "print(r.status_code);\n",
       "\n",
       "# title is the name of my index pattern\n",
       "\n",
       "payload={\n",
       "\"attributes\": { \"title\": \"random*\" } \n",
       "\n",
       "}\n",
       "\n",
       "path=\"_dashboards/api/saved_objects/index-pattern/random*\";\n",
       "url=host+path;\n",
       "\n",
       "#Changed the path variable to the one which is mentioned above. Notice the end of the URL, my index pattern name will be random*\n",
       "\n",
       "r=session.post(url,headers=headers,json=payload);\n",
       "\n",
       "print(r.text);\n",
       "print(r.status_code);\n",
       "session.close();\n",
       " Share rePost-User-6420587 replied 2 years ago Thank you for your comment. We'll review and update the Knowledge Center article as needed. Share MODERATOR AWS Official replied 2 years ago Comment on this article Clear Post comment Relevant content Got an error \"Request Entity Too Large\" when creating index pattern in AWS Opensearch soop_minjaeoh asked 2 years ago How to create and configure an Open Search Serverless index via API? Zach asked a year ago OpenSearch Dashboards Index Pattern and Discover issues mdkail asked 4 years ago Access denied (403) when creating an index in OpenSearch Serverless. AlwaysLearning asked 2 years ago Index is not created inside the Amazon OpenSearch cluster Accepted Answer stratosb asked 2 years ago Why does the rollover index action in my ISM policy fail in OpenSearch Service? AWS OFFICIALUpdated 3 months ago Why can't I delete an index or upgrade my OpenSearch Service cluster? AWS OFFICIALUpdated 2 years ago How do I resolve the 403 \"index_create_block_exception\" or \"cluster_block_exception\" error in OpenSearch Service? AWS OFFICIALUpdated 3 years ago How do I use ISM to manage low storage space in Amazon OpenSearch Service? AWS OFFICIALUpdated 3 months ago How to Configure Metadata Filtering with Bedrock Knowledge Bases on OpenSearch Managed Cluster SUPPORT ENGINEER Emiliano Lozano published a month ago FEEDBACK Privacy| Site Terms| Cookie Preferences | Sitemap| Legal| ¬© 2026, Amazon Web Services, Inc. or its affiliates. All rights reserved. Community Guidelines\n",
       "                </div>\n",
       "        \n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\">\n",
       "                <div class=\"result-number\">9</div>\n",
       "                <div class=\"result-title\"></div>\n",
       "            </div>\n",
       "            <div class=\"result-url\">\n",
       "                <strong>üîó Source:</strong> <a href=\"https://stackoverflow.com/questions/71816340/how-to-create-an-index-pattern-in-opensearch-using-api\" target=\"_blank\">https://stackoverflow.com/questions/71816340/how-to-create-an-index-pattern-in-opensearch-using-api</a>\n",
       "            </div>\n",
       "            <div class=\"result-body\">\n",
       "    \n",
       "                <div class=\"overview\">\n",
       "                    <strong>Overview:</strong><br>\n",
       "                    Skip to main content Stack Overflow About Products For Teams Stack Internal Implement a knowledge platform layer to power your enterprise and AI tools. Stack Data Licensing Get access to top-class technical expertise with trusted & attributed content. Stack Ads Connect your brand to the world‚Äôs most trusted technologist communities. Releases Keep up-to-date on features we add to Stack Overflow and Stack Internal. About the company Visit the blog Loading‚Ä¶ current community Stack Overflow help chat Meta Stack Overflow your communities Sign up or log in to customize your list. more stack exchange communities company blog Log in Sign up Home Questions AI Assist Tags Challenges Chat Articles Users Jobs Companies Collectives Communities for your favorite technologies. Explore all Collectives Stack Internal Stack Overflow for Teams is now called Stack Internal. Bring the best of human thought and AI automation together at your work. Try for free Learn more Stack Internal Bring the best of human thought and AI automation together at your work. Learn more Collectives‚Ñ¢ on Stack Overflow Find centralized, trusted content and collaborate around the technologies you use most. Learn more about Collectives Stack Internal Knowledge at work Bring the best of human thought and AI automation together at your work. Explore Stack Internal How to create an index pattern in Opensearch using API? Ask Question Asked 3 years, 9 months ago Modified 1 year, 1 month ago Viewed 15k times Part of AWS Collective 5 I want to create an index pattern using Opensearch API. I tried to replicate what could be made graphically in the following image window, using as index pattern name cwl-* and then as time field @timestamp. My domain has OpenSearch 1.2 installed. Using curl (directly modifiend the command in kibana doc): curl -u '****:*****' -X POST \"https://******.eu-central-1.es.amazonaws.com/api/index_patterns/index_pattern\" -H 'osd-xsrf: true' -H 'Content-Type: application/json' -d'\n",
       "{\n",
       "  \"index_pattern\": {\n",
       "     \"title\": \"cwl-*\",\n",
       "     \"timeFieldName\": \"@timestamp\"\n",
       "  }\n",
       "}'\n",
       " but I receive {\"error\":{\"root_cause\":[{\"type\":\"illegal_argument_exception\",\"reason\":\"Rejecting mapping update to [api] as the final mapping would have more than 1 type: [_doc, index_patterns]\"}],\"type\":\"illegal_argument_exception\",\"reason\":\"Rejecting mapping update to [api] as the final mapping would have more than 1 type: [_doc, index_patterns]\"},\"status\":400}\n",
       " amazon-web-services shell aws-elasticsearch opensearch Share Improve this question Follow edited Apr 10, 2022 at 17:50 asked Apr 10, 2022 at 11:54 Dresult 31311 gold badge22 silver badges1212 bronze badges 9 Are you using any sort of IAM authentication? Ermiya Eskandary ‚Äì Ermiya Eskandary 2022-04-10 15:58:49 +00:00 Commented Apr 10, 2022 at 15:58 @ErmiyaEskandary just the Fine-grained access control but it works because I don't have any problem in performing other requests... Dresult ‚Äì Dresult 2022-04-10 16:01:55 +00:00 Commented Apr 10, 2022 at 16:01 Ahhhhhh - remove saved_objects from your URL. Ermiya Eskandary ‚Äì Ermiya Eskandary 2022-04-10 16:10:33 +00:00 Commented Apr 10, 2022 at 16:10 @ErmiyaEskandary Unfortunately I had already tried, it says {\"statusCode\":404,\"error\":\"Not Found\",\"message\":\"Not Found\"} Dresult ‚Äì Dresult 2022-04-10 16:13:39 +00:00 Commented Apr 10, 2022 at 16:13 Your URL is somehow wrong - I don't have docs in front of me right now but try removing _dashboards from the URL and if that doesn't work, also remove api Ermiya Eskandary ‚Äì Ermiya Eskandary 2022-04-10 16:17:22 +00:00 Commented Apr 10, 2022 at 16:17 | Show 4 more comments 3 Answers 3 Sorted by: Reset to default Highest score (default) Trending (recent votes count more) Date modified (newest first) Date created (oldest first) 3 Tested with the latest OpenSearch version 2.18.0. To simply create an index pattern via the API, a POST request should be used:     curl -XPOST \"http://localhost:5601/api/saved_objects/index-pattern\" \\\n",
       "-u \"user:pass\" \\\n",
       "-H 'osd-xsrf: true' \\\n",
       "-H 'Content-Type: application/json' \\\n",
       "-d ' \n",
       "{\n",
       "  \"attributes\": {\n",
       "    \"title\": \"pattern-*\",\n",
       "    \"timeFieldName\": \"@timestamp\"\n",
       "  }\n",
       "}'\n",
       " If you want to create an OpenSearch index pattern with a specific ID, you can generate it or copy it from another source (in my case, I copied the ID of the missing pattern from the broken Dashboard) and include it as part of the request: curl -XPOST \"http://localhost:5601/api/saved_objects/index-pattern/90bd9a00-ad57-41a0-b16a-b134a8c51e98\" \\\n",
       "-u \"user:pass\" \\\n",
       "-H 'osd-xsrf: true' \\\n",
       "-H 'Content-Type: application/json' \\\n",
       "-d ' \n",
       "{\n",
       "  \"attributes\": {\n",
       "    \"title\": \"pattern-*\",\n",
       "    \"timeFieldName\": \"@timestamp\"\n",
       "  }\n",
       "}'\n",
       " If you need to update existing index pattern, a PUT request should be used, with existing ID: curl -XPUT \"http://localhost:5601/api/saved_objects/index-pattern/90bd9a00-ad57-41a0-b16a-b134a8c51e98\" \\\n",
       "-u \"user:pass\" \\\n",
       "-H 'osd-xsrf: true' \\\n",
       "-H 'Content-Type: application/json' \\\n",
       "-d ' \n",
       "{\n",
       "  \"attributes\": {\n",
       "    \"title\": \"pattern-*\",\n",
       "    \"timeFieldName\": \"@timestamp\"\n",
       "  }\n",
       "}'\n",
       " Share Improve this answer Follow answered Nov 26, 2024 at 21:35 nmishin 3,22255 gold badges2222 silver badges3737 bronze badges Sign up to request clarification or add additional context in comments. Comments Add a comment 1 curl -u '****:*****' -X POST \"https://******.eu-central-1.es.amazonaws.com/api/index_patterns/cwl-*\" -H 'osd-xsrf: true' -H 'Content-Type: application/json' -d'\n",
       "{\n",
       "  \"index_pattern\": {\n",
       "     \"title\": \"cwl-*\",\n",
       "     \"timeFieldName\": \"@timestamp\"\n",
       "  }\n",
       "}'\n",
       " change api/index_patterns/index_pattern to api/index_patterns/cwl-* and try again? Share Improve this answer Follow answered Apr 14, 2022 at 8:33 doge76 2122 bronze badges 4 Comments Add a comment Dresult Dresult Over a year ago It works in a sense that the command creates something but I cannot see anything among saved objects and seams that in this way only an index which name is \"api\" is created not an index pattern therefore each time I access the dashboard, once it finds data, it ask me if I want to create it. 2022-04-15T11:15:21.423Z+00:00 0 Reply Copy link doge76 doge76 Over a year ago if you want the index-pattern to be global, try to add this attribute in header: securitytenant: \"global\"? 2022-04-15T12:03:44.13Z+00:00 0 Reply Copy link Dresult Dresult Over a year ago already done, I've added -H 'securitytenant: global' to the curl string 2022-04-15T13:56:58.873Z+00:00 0 Reply Copy link Kasami Kasami Over a year ago @Dresult Did you ever manage to figure this out? I am encountering the same issue, it seems. 2022-10-10T22:50:32.3Z+00:00 2 Reply Copy link Add a comment 0 It worked for me in OpenSearch 1.3 when I added an ID in the URI and used saved_objects instead of index_patterns. So your cURL-request should work when looking like this. curl -u '****:*****' -X POST \"https://<opensearch-dashboards-host>.eu-central-1.es.amazonaws.com/api/saved_objects/index-pattern/<ID>\" \n",
       "-H 'osd-xsrf: true' \n",
       "-H 'Content-Type: application/json' \n",
       "-d \n",
       "   '{\n",
       "      \"index_pattern\": {\n",
       "         \"title\": \"cwl-*\",\n",
       "         \"timeFieldName\": \"@timestamp\"\n",
       "      }\n",
       "    }'\n",
       " Share Improve this answer Follow edited Dec 16, 2022 at 13:09 answered Aug 25, 2022 at 8:51 mgr110 111 bronze badge 3 Comments Add a comment K.Thanvi K.Thanvi Over a year ago I am getting no handler found for uri [/api/saved_objects/index-pattern/cwl-*] and method [POST] error for this.. using opensearch1.3. 2022-12-14T17:09:27.72Z+00:00 0 Reply Copy link mgr110 mgr110 Over a year ago @K.Thanvi This is probably because you are sending the request to the OpenSearch-host. The request is meant to be sent to the OpenSearch Dashboards-host (or Kibana-host if you use that). Using the Dev Tools will send the request to the OpenSearch-host. 2022-12-15T11:44:04.903Z+00:00 1 Reply Copy link K.Thanvi K.Thanvi Over a year ago Thanks! Yes that was the issue. i had to send the request to my <opensearch_domain>/_dashboards/api/saved_objects/index-pattern endpoint. 2023-01-09T17:07:40.23Z+00:00 1 Reply Copy link Add a comment Your Answer Thanks for contributing an answer to Stack Overflow! Please be sure to answer the question. Provide details and share your research! But avoid ‚Ä¶ Asking for help, clarification, or responding to other answers. Making statements based on opinion; back them up with references or personal experience. To learn more, see our tips on writing great answers. Draft saved Draft discarded Sign up or log in Sign up using Google Sign up using Email and Password Submit Post as a guest Name Email Required, but never shown Post as a guest Name Email Required, but never shown Post Your Answer Discard By clicking ‚ÄúPost Your Answer‚Äù, you agree to our terms of service and acknowledge you have read our privacy policy. Start asking to get answers Find the answer to your question by asking. Ask question Explore related questions amazon-web-services shell aws-elasticsearch opensearch See similar questions with these tags. AWS Collective See more This question is in a collective: a subcommunity defined by tags with relevant content and experts. The Overflow Blog The most dangerous shortcuts in software A new worst coder has entered the chat: vibe coding without code knowledge Featured on Meta Native Ads coming soon to Stack Overflow and Stack Exchange A proposal for bringing back Community Promotion & Open Source Ads Modernizing curation: A proposal for The Workshop and The Archive Policy: Generative AI (e.g., ChatGPT) is banned Stack Overflow chat opening up to all users in January; Stack Exchange chat... Related 1 Create Index - Elastic Search - Java API 14 Create index in Elastic Search by Java API 0 How to do an automated index creation at ElasticSearch? 21 How to configure index pattern in Kibana 2 How does one create an Index Pattern in Kibana? 3 Is there API based method to create an index pattern in Kibana if its index is present in ES 0 How to create new index pattern with custom pattern ID from the elastic API? 1 How to create Index pattern using API and Index Name 0 How to create an ElasticSearch Index as curl 0 How to create index pattern in elastic seach programmatically Hot Network Questions Portrait of Takuro Shintani How do I recreate a bootable ISO after making changes to its extracted files? Is wearing synthetic gloves an explosion risk when refueling at freezing temperatures? Simple LED vs LED Bulb Significance of the nƒÅmajapa of ≈öiva Conversationally, how do French people distinguish between a straight question and one that expresses dismay? Expected radius of the smallest concentric circle having 2 points inside Why does a linear least squares fit appear to have a bias when applied to simple test data? taxes on the sale of gifted gold coins What was man (Adam) guarding Eden from? Minimize the number of pieces to form a square. The Stack'O'Mounts? Searching for tabulation Help a newbie with fixing a bike! Current source refuses to maintain set current circuitikz: internal node annotations (maybe 'path picture'?) to a styled 'muxdemux' How can text be added to the inner side header keyword? RPG in generic medieval fantasy; last party member is named Aquamaryann(e) Is there a word to describe a webinar which is like \"attend-now-or-miss-out\" Are ÈÅã{„ÅØ„Åì}„Å∂ and ÁÆ±{„ÅØ„Åì} related? Physics-Informed Neural Network for 2D Wave Equation Produces Non-Circular / Distorted Wavefronts The road trip of the century Reasons for nations remaining in the Promised Land Bathtub leaks when draining full tub but not while showering more hot questions Question feed Subscribe to RSS Question feed To subscribe to this RSS feed, copy and paste this URL into your RSS reader. lang-bash Stack Overflow Questions Help Chat Business Stack Internal Stack Data Licensing Stack Ads Company About Press Work Here Legal Privacy Policy Terms of Service Contact Us Your Privacy Choices Cookie Policy Stack Exchange Network Technology Culture & recreation Life & arts Science Professional Business API Data Blog Facebook Twitter LinkedIn Instagram Site design / logo ¬© 2026 Stack Exchange Inc; user contributions licensed under CC BY-SA . rev 2025.12.22.38265\n",
       "                </div>\n",
       "        \n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\">\n",
       "                <div class=\"result-number\">10</div>\n",
       "                <div class=\"result-title\">Link Search Menu Expand Document Documentation Menu</div>\n",
       "            </div>\n",
       "            <div class=\"result-url\">\n",
       "                <strong>üîó Source:</strong> <a href=\"https://docs.opensearch.org/latest/im-plugin/index-templates/\" target=\"_blank\">https://docs.opensearch.org/latest/im-plugin/index-templates/</a>\n",
       "            </div>\n",
       "            <div class=\"result-body\">\n",
       "    \n",
       "                <div class=\"overview\">\n",
       "                    <strong>Overview:</strong><br>\n",
       "                    Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards ‚Üê Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Discovery and cluster formation Node discovery and seed hosts Voting and quorum Voting configuration management Cluster bootstrapping Discovery and cluster formation settings Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Remote segment warmer Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Similarity Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Resource access management Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates OpenSearch FIPS configuration Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control Defining users and roles Permissions Default action groups REST layer authorization Document-level security Field-level security Field masking User impersonation Resource sharing and access control Resource sharing APIs API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Version Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Mapping explosion Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Rescore Regular expression syntax SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic queries Complex queries Functions JSON support Metadata queries Aggregate functions Delete JDBC driver ODBC driver PPL Subsearch Commands PPL syntax ad addcoltotals addtotals append appendcol appendpipe bin chart dedup describe eval eventstats expand explain fields fillnull flatten grok head join kmeans lookup ml multisearch parse patterns rare regex rename replace reverse rex search show datasources sort spath stats streamstats subquery table timechart top trendline where Identifiers Data types Functions Full-text search Settings Troubleshooting Monitoring Limitations Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Collecting UBI-formatted data in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Model access control through resource sharing Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller ML Tasks APIs Get ML task Search ML tasks Delete ML task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow access control Workflow settings Workflow state access control Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detector access control Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecaster access control Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Managing Indexes Index templates Index templates Index templates let you initialize new indexes with predefined mappings and settings. For example, if you continuously index log data, you can define an index template so that all of these indexes have the same number of shards and replicas. Create a template To create an index template, use a PUT or POST request: PUT _index_template/<template name>\n",
       "POST _index_template/<template name>\n",
       " This command creates a template named daily_logs and applies it to any new index whose name matches the pattern logs-2020-01-* and also adds it to the my_logs alias: PUT _index_template/daily_logs\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"logs-2020-01-*\"\n",
       "  ],\n",
       "  \"template\": {\n",
       "    \"aliases\": {\n",
       "      \"my_logs\": {}\n",
       "    },\n",
       "    \"settings\": {\n",
       "      \"number_of_shards\": 2,\n",
       "      \"number_of_replicas\": 1\n",
       "    },\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"timestamp\": {\n",
       "          \"type\": \"date\",\n",
       "          \"format\": \"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\"\n",
       "        },\n",
       "        \"value\": {\n",
       "          \"type\": \"double\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       " You should see the following response: {\n",
       "  \"acknowledged\": true\n",
       "}\n",
       " If you create an index named logs-2020-01-01, you can see that it has the mappings and settings from the template: PUT logs-2020-01-01\n",
       "GET logs-2020-01-01\n",
       " {\n",
       "  \"logs-2020-01-01\": {\n",
       "    \"aliases\": {\n",
       "      \"my_logs\": {}\n",
       "    },\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"timestamp\": {\n",
       "          \"type\": \"date\",\n",
       "          \"format\": \"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\"\n",
       "        },\n",
       "        \"value\": {\n",
       "          \"type\": \"double\"\n",
       "        }\n",
       "      }\n",
       "    },\n",
       "    \"settings\": {\n",
       "      \"index\": {\n",
       "        \"creation_date\": \"1578107970779\",\n",
       "        \"number_of_shards\": \"2\",\n",
       "        \"number_of_replicas\": \"1\",\n",
       "        \"uuid\": \"U1vMDMOHSAuS2IzPcPHpOA\",\n",
       "        \"version\": {\n",
       "          \"created\": \"7010199\"\n",
       "        },\n",
       "        \"provided_name\": \"logs-2020-01-01\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Any additional indexes that match this pattern‚Äîlogs-2020-01-02, logs-2020-01-03, and so on‚Äîwill inherit the same mappings and settings. Index patterns cannot contain any of the following characters: :, \", +, /, \\, |, ?, #, >, and <. Retrieve a template To list all index templates: GET _cat/templates\n",
       "GET /_index_template\n",
       " To find a template by its name: GET _index_template/daily_logs\n",
       " To get a list of all templates that match a pattern: GET _index_template/daily*\n",
       " To check if a specific template exists: HEAD _index_template/<name>\n",
       " Configure multiple templates You can create multiple index templates for your indexes. If the index name matches more than one template, OpenSearch takes the mappings and settings from the template with the highest priority and applies it to the index. For example, say you have the following two templates that both match the logs-2020-01-02 index and there‚Äôs a conflict in the number_of_shards field: Template 1 PUT _index_template/template-01\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"logs*\"\n",
       "  ],\n",
       "  \"priority\": 0,\n",
       "  \"template\": {\n",
       "    \"settings\": {\n",
       "      \"number_of_shards\": 2,\n",
       "      \"number_of_replicas\": 2\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Template 2 PUT _index_template/template-02\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"logs-2020-01-*\"\n",
       "  ],\n",
       "  \"priority\": 1,\n",
       "  \"template\": {\n",
       "    \"settings\": {\n",
       "      \"number_of_shards\": 3\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Because template-02 has a higher priority value, it takes precedence over template-01 . The logs-2020-01-02 index would have the number_of_shards value as 3 and the number_of_replicas as the default value 1. Delete a template You can delete an index template using its name: DELETE _index_template/daily_logs\n",
       " Composable index templates Managing multiple index templates has the following challenges: If you have duplication between index templates, storing these index templates results in a bigger cluster state. If you want to make a change across all your index templates, you have to manually make the change for each template. You can use composable index templates to overcome these challenges. Composable index templates let you abstract common settings, mappings, and aliases into a reusable building block called a component template. You can combine component templates to compose an index template. Settings and mappings that you specify directly in the create index request override any settings or mappings specified in an index template and its component templates. Create a component template Let‚Äôs define two component templates‚Å†‚Äîcomponent_template_1 and component_template_2: Component template 1 PUT _component_template/component_template_1\n",
       "{\n",
       "  \"template\": {\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"@timestamp\": {\n",
       "          \"type\": \"date\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Component template 2 PUT _component_template/component_template_2\n",
       "{\n",
       "  \"template\": {\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"ip_address\": {\n",
       "          \"type\": \"ip\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Use component templates to create an index template When creating index templates, you need to include the component templates in a composed_of list. OpenSearch applies the component templates in the order in which you specify them within the index template. The settings, mappings, and aliases that you specify inside the index template are applied last. PUT _index_template/daily_logs\n",
       "{\n",
       "  \"index_patterns\": [\n",
       "    \"logs-2020-01-*\"\n",
       "  ],\n",
       "  \"template\": {\n",
       "    \"aliases\": {\n",
       "      \"my_logs\": {}\n",
       "    },\n",
       "    \"settings\": {\n",
       "      \"number_of_shards\": 2,\n",
       "      \"number_of_replicas\": 1\n",
       "    },\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"timestamp\": {\n",
       "          \"type\": \"date\",\n",
       "          \"format\": \"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\"\n",
       "        },\n",
       "        \"value\": {\n",
       "          \"type\": \"double\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  },\n",
       "  \"priority\": 200,\n",
       "  \"composed_of\": [\n",
       "    \"component_template_1\",\n",
       "    \"component_template_2\"\n",
       "  ],\n",
       "  \"version\": 3,\n",
       "  \"_meta\": {\n",
       "    \"description\": \"using component templates\"\n",
       "  }\n",
       "}\n",
       " If you create an index named logs-2020-01-01, you can see that it derives its mappings and settings from both the component templates: PUT logs-2020-01-01\n",
       "GET logs-2020-01-01\n",
       " Example response {\n",
       "  \"logs-2020-01-01\": {\n",
       "    \"aliases\": {\n",
       "      \"my_logs\": {}\n",
       "    },\n",
       "    \"mappings\": {\n",
       "      \"properties\": {\n",
       "        \"@timestamp\": {\n",
       "          \"type\": \"date\"\n",
       "        },\n",
       "        \"ip_address\": {\n",
       "          \"type\": \"ip\"\n",
       "        },\n",
       "        \"timestamp\": {\n",
       "          \"type\": \"date\",\n",
       "          \"format\": \"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\"\n",
       "        },\n",
       "        \"value\": {\n",
       "          \"type\": \"double\"\n",
       "        }\n",
       "      }\n",
       "    },\n",
       "    \"settings\": {\n",
       "      \"index\": {\n",
       "        \"creation_date\": \"1625382479459\",\n",
       "        \"number_of_shards\": \"2\",\n",
       "        \"number_of_replicas\": \"1\",\n",
       "        \"uuid\": \"rYUlpOXDSUSuZifQLPfa5A\",\n",
       "        \"version\": {\n",
       "          \"created\": \"7100299\"\n",
       "        },\n",
       "        \"provided_name\": \"logs-2020-01-01\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       " Index template options You can specify the following template options: Option Type Description Required template Object Specify index settings, mappings, and aliases. No priority Integer The priority of the index template. No composed_of String array The names of component templates applied on a new index together with the current template. No version Integer Specify a version number to simplify template management. Default is null. No _meta Object Specify meta information about the template. No Create a template Retrieve a template Configure multiple templates Delete a template Create a component template Use component templates to create an index template WAS THIS PAGE HELPFUL? ‚úî Yes ‚úñ No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright ¬© OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\n",
       "                </div>\n",
       "        \n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "    </div>\n",
       "</div>\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parse and display all content blocks in HTML format\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Extract all items from the response\n",
    "all_items = json.loads(response['inference_results'][0]['output'][0]['result'])['items']\n",
    "\n",
    "# Prepare query text\n",
    "query_text = parameters.get('question', 'N/A')\n",
    "query_display = query_text[:50] + '...' if len(query_text) > 50 else query_text\n",
    "\n",
    "# Create comprehensive HTML output with better styling\n",
    "html_output = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "    * {\n",
    "        box-sizing: border-box;\n",
    "    }\n",
    "    \n",
    "    .html-container {\n",
    "        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;\n",
    "        max-width: 1000px;\n",
    "        margin: 0 auto;\n",
    "        color: #333;\n",
    "        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);\n",
    "        padding: 30px 20px;\n",
    "    }\n",
    "    \n",
    "    .header {\n",
    "        text-align: center;\n",
    "        margin-bottom: 40px;\n",
    "        color: #2c3e50;\n",
    "    }\n",
    "    \n",
    "    .header h1 {\n",
    "        font-size: 32px;\n",
    "        margin: 0 0 10px 0;\n",
    "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "        -webkit-background-clip: text;\n",
    "        -webkit-text-fill-color: transparent;\n",
    "    }\n",
    "    \n",
    "    .stats {\n",
    "        background: white;\n",
    "        padding: 20px;\n",
    "        border-radius: 8px;\n",
    "        margin-bottom: 30px;\n",
    "        box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n",
    "        display: flex;\n",
    "        gap: 20px;\n",
    "        flex-wrap: wrap;\n",
    "    }\n",
    "    \n",
    "    .stat-item {\n",
    "        flex: 1;\n",
    "        min-width: 200px;\n",
    "    }\n",
    "    \n",
    "    .stat-label {\n",
    "        font-size: 12px;\n",
    "        color: #7f8c8d;\n",
    "        text-transform: uppercase;\n",
    "        font-weight: bold;\n",
    "        margin-bottom: 5px;\n",
    "    }\n",
    "    \n",
    "    .stat-value {\n",
    "        font-size: 20px;\n",
    "        color: #2c3e50;\n",
    "        font-weight: bold;\n",
    "    }\n",
    "    \n",
    "    .results-container {\n",
    "        display: grid;\n",
    "        gap: 25px;\n",
    "    }\n",
    "    \n",
    "    .result-card {\n",
    "        background: white;\n",
    "        border-radius: 12px;\n",
    "        overflow: hidden;\n",
    "        box-shadow: 0 4px 15px rgba(0,0,0,0.1);\n",
    "        transition: transform 0.3s ease, box-shadow 0.3s ease;\n",
    "    }\n",
    "    \n",
    "    .result-card:hover {\n",
    "        transform: translateY(-5px);\n",
    "        box-shadow: 0 8px 25px rgba(0,0,0,0.15);\n",
    "    }\n",
    "    \n",
    "    .result-header {\n",
    "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "        color: white;\n",
    "        padding: 20px;\n",
    "        display: flex;\n",
    "        align-items: center;\n",
    "        gap: 15px;\n",
    "    }\n",
    "    \n",
    "    .result-number {\n",
    "        background: rgba(255,255,255,0.2);\n",
    "        width: 40px;\n",
    "        height: 40px;\n",
    "        border-radius: 50%;\n",
    "        display: flex;\n",
    "        align-items: center;\n",
    "        justify-content: center;\n",
    "        font-weight: bold;\n",
    "        font-size: 16px;\n",
    "        flex-shrink: 0;\n",
    "    }\n",
    "    \n",
    "    .result-title {\n",
    "        flex: 1;\n",
    "        font-size: 18px;\n",
    "        font-weight: bold;\n",
    "    }\n",
    "    \n",
    "    .result-url {\n",
    "        background: white;\n",
    "        padding: 15px 20px;\n",
    "        border-bottom: 1px solid #ecf0f1;\n",
    "        color: #3498db;\n",
    "        text-decoration: none;\n",
    "        font-size: 12px;\n",
    "        word-break: break-all;\n",
    "        font-family: 'Courier New', monospace;\n",
    "    }\n",
    "    \n",
    "    .result-url a {\n",
    "        color: #3498db;\n",
    "        text-decoration: none;\n",
    "    }\n",
    "    \n",
    "    .result-url a:hover {\n",
    "        text-decoration: underline;\n",
    "    }\n",
    "    \n",
    "    .result-body {\n",
    "        padding: 25px;\n",
    "    }\n",
    "    \n",
    "    .overview {\n",
    "        background: #f8f9fa;\n",
    "        padding: 15px;\n",
    "        border-radius: 6px;\n",
    "        margin-bottom: 20px;\n",
    "        border-left: 4px solid #667eea;\n",
    "        font-size: 14px;\n",
    "        line-height: 1.7;\n",
    "        color: #555;\n",
    "    }\n",
    "    \n",
    "    .steps-container {\n",
    "        display: grid;\n",
    "        gap: 15px;\n",
    "    }\n",
    "    \n",
    "    .step {\n",
    "        border-left: 4px solid #764ba2;\n",
    "        padding-left: 15px;\n",
    "        padding-top: 10px;\n",
    "        padding-bottom: 10px;\n",
    "    }\n",
    "    \n",
    "    .step-title {\n",
    "        font-weight: bold;\n",
    "        color: #764ba2;\n",
    "        font-size: 15px;\n",
    "        margin-bottom: 8px;\n",
    "        display: flex;\n",
    "        align-items: center;\n",
    "        gap: 8px;\n",
    "    }\n",
    "    \n",
    "    .step-number {\n",
    "        display: inline-block;\n",
    "        background: #764ba2;\n",
    "        color: white;\n",
    "        width: 24px;\n",
    "        height: 24px;\n",
    "        border-radius: 50%;\n",
    "        display: flex;\n",
    "        align-items: center;\n",
    "        justify-content: center;\n",
    "        font-size: 12px;\n",
    "        font-weight: bold;\n",
    "    }\n",
    "    \n",
    "    .step-content {\n",
    "        color: #555;\n",
    "        font-size: 13px;\n",
    "        line-height: 1.8;\n",
    "    }\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "<div class=\"html-container\">\n",
    "    <div class=\"header\">\n",
    "        <h1>üåê Web Search Results</h1>\n",
    "        <p>Comprehensive detailed view of all search results</p>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"stats\">\n",
    "        <div class=\"stat-item\">\n",
    "            <div class=\"stat-label\">üìä Total Results</div>\n",
    "            <div class=\"stat-value\">\"\"\" + str(len(all_items)) + \"\"\"</div>\n",
    "        </div>\n",
    "        <div class=\"stat-item\">\n",
    "            <div class=\"stat-label\">‚ùì Query</div>\n",
    "            <div class=\"stat-value\">\"\"\" + query_display + \"\"\"</div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"results-container\">\n",
    "\"\"\"\n",
    "\n",
    "# Parse and display each result\n",
    "for idx, item in enumerate(all_items, 1):\n",
    "    title = item.get('title', 'No Title')\n",
    "    url = item.get('url', 'No URL')\n",
    "    content = item.get('content', 'No Content')\n",
    "    \n",
    "    html_output += f\"\"\"\n",
    "        <div class=\"result-card\">\n",
    "            <div class=\"result-header\">\n",
    "                <div class=\"result-number\">{idx}</div>\n",
    "                <div class=\"result-title\">{title}</div>\n",
    "            </div>\n",
    "            <div class=\"result-url\">\n",
    "                <strong>üîó Source:</strong> <a href=\"{url}\" target=\"_blank\">{url}</a>\n",
    "            </div>\n",
    "            <div class=\"result-body\">\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parse content by steps\n",
    "    sections = content.split('Step ')\n",
    "    \n",
    "    # Add first section as overview if it exists\n",
    "    if sections[0].strip():\n",
    "        html_output += f\"\"\"\n",
    "                <div class=\"overview\">\n",
    "                    <strong>Overview:</strong><br>\n",
    "                    {sections[0].strip()}\n",
    "                </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    # Parse and format remaining steps\n",
    "    if len(sections) > 1:\n",
    "        html_output += \"\"\"\n",
    "                <div class=\"steps-container\">\n",
    "        \"\"\"\n",
    "        \n",
    "        for step_num, section in enumerate(sections[1:], 1):\n",
    "            lines = section.split('. ', 1)\n",
    "            if len(lines) > 1:\n",
    "                step_title = lines[0]\n",
    "                step_content = lines[1]\n",
    "                html_output += f\"\"\"\n",
    "                    <div class=\"step\">\n",
    "                        <div class=\"step-title\">\n",
    "                            <span class=\"step-number\">{step_num}</span>\n",
    "                            {step_title}\n",
    "                        </div>\n",
    "                        <div class=\"step-content\">{step_content}</div>\n",
    "                    </div>\n",
    "                \"\"\"\n",
    "            elif section.strip():\n",
    "                html_output += f\"\"\"\n",
    "                    <div class=\"step\">\n",
    "                        <div class=\"step-content\">{section.strip()}</div>\n",
    "                    </div>\n",
    "                \"\"\"\n",
    "        \n",
    "        html_output += \"\"\"\n",
    "                </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    html_output += \"\"\"\n",
    "            </div>\n",
    "        </div>\n",
    "    \"\"\"\n",
    "\n",
    "html_output += \"\"\"\n",
    "    </div>\n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdb82b2",
   "metadata": {},
   "source": [
    "## How do actual browsers show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ea77f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë DeepSeek API Key loaded: ‚úÖ Yes\n",
      "   Key preview: sk-40088b7...\n",
      "Result 1: Link Search Menu Expand Document Documentation Men\n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 2: \n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 3: \n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 4: \n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 5: \n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 6: Link Search Menu Expand Document Documentation Men\n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 7: Link Search Menu Expand Document Documentation Men\n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 8: \n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 9: \n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n",
      "Result 10: Link Search Menu Expand Document Documentation Men\n",
      "  üì§ Calling DeepSeek API...\n",
      "  üì• Response status: 200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "<meta charset=\"UTF-8\">\n",
       "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "<style>\n",
       "    * {\n",
       "        margin: 0;\n",
       "        padding: 0;\n",
       "        box-sizing: border-box;\n",
       "    }\n",
       "\n",
       "    body {\n",
       "        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;\n",
       "        background: #fff;\n",
       "        color: #202124;\n",
       "    }\n",
       "\n",
       "    .search-engine-container {\n",
       "        max-width: 600px;\n",
       "        margin: 40px auto;\n",
       "        padding: 20px;\n",
       "    }\n",
       "\n",
       "    .search-header {\n",
       "        margin-bottom: 30px;\n",
       "        padding-bottom: 20px;\n",
       "        border-bottom: 1px solid #dadce0;\n",
       "    }\n",
       "\n",
       "    .search-title {\n",
       "        font-size: 28px;\n",
       "        font-weight: 400;\n",
       "        color: #1f2937;\n",
       "        margin-bottom: 5px;\n",
       "    }\n",
       "\n",
       "    .search-query {\n",
       "        font-size: 14px;\n",
       "        color: #5f6368;\n",
       "    }\n",
       "\n",
       "    .search-stats {\n",
       "        font-size: 13px;\n",
       "        color: #70757a;\n",
       "        margin-top: 10px;\n",
       "    }\n",
       "\n",
       "    .search-results {\n",
       "        display: flex;\n",
       "        flex-direction: column;\n",
       "        gap: 30px;\n",
       "    }\n",
       "\n",
       "    .result-item {\n",
       "        display: flex;\n",
       "        flex-direction: column;\n",
       "        padding: 0;\n",
       "    }\n",
       "\n",
       "    .result-url {\n",
       "        font-size: 13px;\n",
       "        color: #006621;\n",
       "        margin-bottom: 5px;\n",
       "        word-break: break-all;\n",
       "        font-family: Arial, sans-serif;\n",
       "    }\n",
       "\n",
       "    .result-url a {\n",
       "        color: #006621;\n",
       "        text-decoration: none;\n",
       "    }\n",
       "\n",
       "    .result-url a:hover {\n",
       "        text-decoration: underline;\n",
       "    }\n",
       "\n",
       "    .result-title {\n",
       "        font-size: 20px;\n",
       "        color: #1f2937;\n",
       "        font-weight: 500;\n",
       "        margin-bottom: 8px;\n",
       "        line-height: 1.3;\n",
       "        cursor: pointer;\n",
       "        transition: color 0.2s;\n",
       "    }\n",
       "\n",
       "    .result-title:hover {\n",
       "        color: #1a73e8;\n",
       "        text-decoration: underline;\n",
       "    }\n",
       "\n",
       "    .result-title a {\n",
       "        color: inherit;\n",
       "        text-decoration: none;\n",
       "    }\n",
       "\n",
       "    .result-snippet {\n",
       "        font-size: 14px;\n",
       "        color: #545454;\n",
       "        line-height: 1.6;\n",
       "        margin-bottom: 5px;\n",
       "    }\n",
       "\n",
       "    .result-number {\n",
       "        font-size: 12px;\n",
       "        color: #9aa0a6;\n",
       "        margin-top: 5px;\n",
       "    }\n",
       "</style>\n",
       "</head>\n",
       "<body>\n",
       "<div class=\"search-engine-container\">\n",
       "    <div class=\"search-header\">\n",
       "        <div class=\"search-title\">üîç Search Results</div>\n",
       "        <div class=\"search-query\"><strong>Query:</strong> How to create an index pattern in OpenSearch?</div>\n",
       "        <div class=\"search-stats\">About 10 results</div>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"search-results\">\n",
       "\n",
       "        <div class=\"result-item\">\n",
       "            <div class=\"result-url\">\n",
       "                <a href=\"https://docs.opensearch.org/latest/dashboards/management/index-patterns/\" target=\"_blank\">https://docs.opensearch.org/latest/dashboards/management/index-patterns/</a>\n",
       "            </div>\n",
       "            <div class=\"result-title\">\n",
       "                <a href=\"https://docs.opensearch.org/latest/dashboards/management/index-patterns/\" target=\"_blank\">Link Search Menu Expand Document Documentation Menu</a>\n",
       "            </div>\n",
       "            <div class=\"result-snippet\">OpenSearch documentation for index patterns.</div>\n",
       "            <div class=\"result-number\">Result 1</div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-item\">\n",
       "            <div class=\"result-url\">\n",
       "                <a href=\"https://github.com/opensearch-project/opensearch-py/blob/main/guides/index_template.md\" target=\"_blank\">https://github.com/opensearch-project/opensearch-py/blob/main/guides/index_template.md</a>\n",
       "            </div>\n",
       "            <div class=\"result-title\">\n",
       "                <a href=\"https://github.com/opensearch-project/opensearch-py/blob/main/guides/index_template.md\" target=\"_blank\"></a>\n",
       "            </div>\n",
       "            <div class=\"result-snippet\">GitHub's OpenSearch Python client repository.</div>\n",
       "            <div class=\"result-number\">Result 2</div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-item\">\n",
       "            <div class=\"result-url\">\n",
       "                <a href=\"https://www.youtube.com/watch?v=pbABIerUYQI\" target=\"_blank\">https://www.youtube.com/watch?v=pbABIerUYQI</a>\n",
       "            </div>\n",
       "            <div class=\"result-title\">\n",
       "                <a href=\"https://www.youtube.com/watch?v=pbABIerUYQI\" target=\"_blank\"></a>\n",
       "            </div>\n",
       "            <div class=\"result-snippet\">YouTube's legal and policy information.</div>\n",
       "            <div class=\"result-number\">Result 3</div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-item\">\n",
       "            <div class=\"result-url\">\n",
       "                <a href=\"https://www.bookstack.cn/read/opensearch-2.19-en/4ce9edd150bec500.md\" target=\"_blank\">https://www.bookstack.cn/read/opensearch-2.19-en/4ce9edd150bec500.md</a>\n",
       "            </div>\n",
       "            <div class=\"result-title\">\n",
       "                <a href=\"https://www.bookstack.cn/read/opensearch-2.19-en/4ce9edd150bec500.md\" target=\"_blank\"></a>\n",
       "            </div>\n",
       "            <div class=\"result-snippet\">Guide to creating OpenSearch index patterns.</div>\n",
       "            <div class=\"result-number\">Result 4</div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-item\">\n",
       "            <div class=\"result-url\">\n",
       "                <a href=\"https://deepwiki.com/johnny-chivers/amazon-opensearch-service/3.1-index-patterns\" target=\"_blank\">https://deepwiki.com/johnny-chivers/amazon-opensearch-service/3.1-index-patterns</a>\n",
       "            </div>\n",
       "            <div class=\"result-title\">\n",
       "                <a href=\"https://deepwiki.com/johnny-chivers/amazon-opensearch-service/3.1-index-patterns\" target=\"_blank\"></a>\n",
       "            </div>\n",
       "            <div class=\"result-snippet\">Guide to OpenSearch index patterns.</div>\n",
       "            <div class=\"result-number\">Result 5</div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-item\">\n",
       "            <div class=\"result-url\">\n",
       "                <a href=\"https://docs.opensearch.org/latest/api-reference/index-apis/create-index-template/\" target=\"_blank\">https://docs.opensearch.org/latest/api-reference/index-apis/create-index-template/</a>\n",
       "            </div>\n",
       "            <div class=\"result-title\">\n",
       "                <a href=\"https://docs.opensearch.org/latest/api-reference/index-apis/create-index-template/\" target=\"_blank\">Link Search Menu Expand Document Documentation Menu</a>\n",
       "            </div>\n",
       "            <div class=\"result-snippet\">OpenSearch documentation for index templates.</div>\n",
       "            <div class=\"result-number\">Result 6</div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-item\">\n",
       "            <div class=\"result-url\">\n",
       "                <a href=\"https://opensearch.isharkfly.com/dashboards/management/index-patterns/\" target=\"_blank\">https://opensearch.isharkfly.com/dashboards/management/index-patterns/</a>\n",
       "            </div>\n",
       "            <div class=\"result-title\">\n",
       "                <a href=\"https://opensearch.isharkfly.com/dashboards/management/index-patterns/\" target=\"_blank\">Link Search Menu Expand Document Documentation Menu</a>\n",
       "            </div>\n",
       "            <div class=\"result-snippet\">Guide to creating OpenSearch index patterns.</div>\n",
       "            <div class=\"result-number\">Result 7</div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-item\">\n",
       "            <div class=\"result-url\">\n",
       "                <a href=\"https://repost.aws/knowledge-center/opensearch-index-pattern\" target=\"_blank\">https://repost.aws/knowledge-center/opensearch-index-pattern</a>\n",
       "            </div>\n",
       "            <div class=\"result-title\">\n",
       "                <a href=\"https://repost.aws/knowledge-center/opensearch-index-pattern\" target=\"_blank\"></a>\n",
       "            </div>\n",
       "            <div class=\"result-snippet\">Creating index patterns in OpenSearch Service.</div>\n",
       "            <div class=\"result-number\">Result 8</div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-item\">\n",
       "            <div class=\"result-url\">\n",
       "                <a href=\"https://stackoverflow.com/questions/71816340/how-to-create-an-index-pattern-in-opensearch-using-api\" target=\"_blank\">https://stackoverflow.com/questions/71816340/how-to-create-an-index-pattern-in-opensearch-using-api</a>\n",
       "            </div>\n",
       "            <div class=\"result-title\">\n",
       "                <a href=\"https://stackoverflow.com/questions/71816340/how-to-create-an-index-pattern-in-opensearch-using-api\" target=\"_blank\"></a>\n",
       "            </div>\n",
       "            <div class=\"result-snippet\">Creating OpenSearch index pattern via API.</div>\n",
       "            <div class=\"result-number\">Result 9</div>\n",
       "        </div>\n",
       "    \n",
       "        <div class=\"result-item\">\n",
       "            <div class=\"result-url\">\n",
       "                <a href=\"https://docs.opensearch.org/latest/im-plugin/index-templates/\" target=\"_blank\">https://docs.opensearch.org/latest/im-plugin/index-templates/</a>\n",
       "            </div>\n",
       "            <div class=\"result-title\">\n",
       "                <a href=\"https://docs.opensearch.org/latest/im-plugin/index-templates/\" target=\"_blank\">Link Search Menu Expand Document Documentation Menu</a>\n",
       "            </div>\n",
       "            <div class=\"result-snippet\">OpenSearch documentation for index templates.</div>\n",
       "            <div class=\"result-number\">Result 10</div>\n",
       "        </div>\n",
       "    \n",
       "    </div>\n",
       "</div>\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Displayed 10 search results in search engine format\n"
     ]
    }
   ],
   "source": [
    "# Display results as a search engine with AI-powered summaries\n",
    "import requests\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "\n",
    "# Try to load from environment\n",
    "DEEPSEEK_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "\n",
    "# If not found, try loading from .env file\n",
    "if not DEEPSEEK_API_KEY:\n",
    "    try:\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv(\"../../.env\")\n",
    "        DEEPSEEK_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Debug: Check if API key is available\n",
    "print(f\"üîë DeepSeek API Key loaded: {'‚úÖ Yes' if DEEPSEEK_API_KEY else '‚ùå No'}\")\n",
    "if DEEPSEEK_API_KEY:\n",
    "    print(f\"   Key preview: {DEEPSEEK_API_KEY[:10]}...\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  WARNING: DeepSeek API key not found. Set DEEPSEEK_API_KEY environment variable.\")\n",
    "\n",
    "DEEPSEEK_API_URL = \"https://api.deepseek.com/chat/completions\"\n",
    "\n",
    "# Extract all items from the response\n",
    "all_items = json.loads(response['inference_results'][0]['output'][0]['result'])['items']\n",
    "\n",
    "def parse_content_for_summary(content):\n",
    "    \"\"\"Parse content by steps to get better structured text for summarization\"\"\"\n",
    "    sections = content.split('Step ')\n",
    "    parsed_text = []\n",
    "    \n",
    "    # Add first section as overview if it exists\n",
    "    if sections[0].strip():\n",
    "        parsed_text.append(sections[0].strip())\n",
    "    \n",
    "    # Parse and format remaining steps\n",
    "    for step_num, section in enumerate(sections[1:], 1):\n",
    "        lines = section.split('. ', 1)\n",
    "        if len(lines) > 1:\n",
    "            step_title = lines[0]\n",
    "            step_content = lines[1]\n",
    "            parsed_text.append(f\"Step {step_num}: {step_title}. {step_content}\")\n",
    "        elif section.strip():\n",
    "            parsed_text.append(section.strip())\n",
    "    \n",
    "    return ' '.join(parsed_text)\n",
    "\n",
    "def get_summary_from_deepseek(content, max_words=10):\n",
    "    \"\"\"Get a brief summary of content using DeepSeek API\"\"\"\n",
    "    if not DEEPSEEK_API_KEY:\n",
    "        print(\"  ‚ö†Ô∏è  API key missing, returning fallback summary\")\n",
    "        # Return a basic fallback summary from content\n",
    "        parsed_content = parse_content_for_summary(content)\n",
    "        words = parsed_content.split()\n",
    "        fallback = ' '.join(words[:max_words]) + '...' if len(words) > max_words else parsed_content\n",
    "        return fallback\n",
    "    \n",
    "    try:\n",
    "        # Parse content by steps first\n",
    "        parsed_content = parse_content_for_summary(content)\n",
    "        \n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {DEEPSEEK_API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": \"deepseek-chat\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Summarize this text in less than {max_words} words, focusing on the main point:\\n\\n{parsed_content}\"\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 2000,\n",
    "            \"temperature\": 0.5\n",
    "        }\n",
    "        \n",
    "        print(f\"  üì§ Calling DeepSeek API...\")\n",
    "        response = requests.post(DEEPSEEK_API_URL, json=payload, headers=headers, timeout=10)\n",
    "        \n",
    "        print(f\"  üì• Response status: {response.status_code}\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            summary = result.get('choices', [{}])[0].get('message', {}).get('content', 'No summary available').strip()\n",
    "            # Truncate if needed\n",
    "            words = summary.split()\n",
    "            if len(words) > max_words:\n",
    "                summary = ' '.join(words[:max_words]) + '...'\n",
    "            return summary\n",
    "        else:\n",
    "            print(f\"  ‚ùå API Error: {response.status_code}\")\n",
    "            print(f\"  Response: {response.text[:200]}\")\n",
    "            # Return fallback\n",
    "            parsed_content = parse_content_for_summary(content)\n",
    "            words = parsed_content.split()\n",
    "            fallback = ' '.join(words[:max_words]) + '...' if len(words) > max_words else parsed_content\n",
    "            return fallback\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error calling DeepSeek API: {str(e)}\")\n",
    "        # Return fallback\n",
    "        try:\n",
    "            parsed_content = parse_content_for_summary(content)\n",
    "            words = parsed_content.split()\n",
    "            fallback = ' '.join(words[:max_words]) + '...' if len(words) > max_words else parsed_content\n",
    "            return fallback\n",
    "        except:\n",
    "            return \"Summary unavailable\"\n",
    "\n",
    "# Create HTML output styled like Google Search Results\n",
    "html_output = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<meta charset=\"UTF-8\">\n",
    "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "<style>\n",
    "    * {\n",
    "        margin: 0;\n",
    "        padding: 0;\n",
    "        box-sizing: border-box;\n",
    "    }\n",
    "    \n",
    "    body {\n",
    "        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;\n",
    "        background: #fff;\n",
    "        color: #202124;\n",
    "    }\n",
    "    \n",
    "    .search-engine-container {\n",
    "        max-width: 600px;\n",
    "        margin: 40px auto;\n",
    "        padding: 20px;\n",
    "    }\n",
    "    \n",
    "    .search-header {\n",
    "        margin-bottom: 30px;\n",
    "        padding-bottom: 20px;\n",
    "        border-bottom: 1px solid #dadce0;\n",
    "    }\n",
    "    \n",
    "    .search-title {\n",
    "        font-size: 28px;\n",
    "        font-weight: 400;\n",
    "        color: #1f2937;\n",
    "        margin-bottom: 5px;\n",
    "    }\n",
    "    \n",
    "    .search-query {\n",
    "        font-size: 14px;\n",
    "        color: #5f6368;\n",
    "    }\n",
    "    \n",
    "    .search-stats {\n",
    "        font-size: 13px;\n",
    "        color: #70757a;\n",
    "        margin-top: 10px;\n",
    "    }\n",
    "    \n",
    "    .search-results {\n",
    "        display: flex;\n",
    "        flex-direction: column;\n",
    "        gap: 30px;\n",
    "    }\n",
    "    \n",
    "    .result-item {\n",
    "        display: flex;\n",
    "        flex-direction: column;\n",
    "        padding: 0;\n",
    "    }\n",
    "    \n",
    "    .result-url {\n",
    "        font-size: 13px;\n",
    "        color: #006621;\n",
    "        margin-bottom: 5px;\n",
    "        word-break: break-all;\n",
    "        font-family: Arial, sans-serif;\n",
    "    }\n",
    "    \n",
    "    .result-url a {\n",
    "        color: #006621;\n",
    "        text-decoration: none;\n",
    "    }\n",
    "    \n",
    "    .result-url a:hover {\n",
    "        text-decoration: underline;\n",
    "    }\n",
    "    \n",
    "    .result-title {\n",
    "        font-size: 20px;\n",
    "        color: #1f2937;\n",
    "        font-weight: 500;\n",
    "        margin-bottom: 8px;\n",
    "        line-height: 1.3;\n",
    "        cursor: pointer;\n",
    "        transition: color 0.2s;\n",
    "    }\n",
    "    \n",
    "    .result-title:hover {\n",
    "        color: #1a73e8;\n",
    "        text-decoration: underline;\n",
    "    }\n",
    "    \n",
    "    .result-title a {\n",
    "        color: inherit;\n",
    "        text-decoration: none;\n",
    "    }\n",
    "    \n",
    "    .result-snippet {\n",
    "        font-size: 14px;\n",
    "        color: #545454;\n",
    "        line-height: 1.6;\n",
    "        margin-bottom: 5px;\n",
    "    }\n",
    "    \n",
    "    .result-number {\n",
    "        font-size: 12px;\n",
    "        color: #9aa0a6;\n",
    "        margin-top: 5px;\n",
    "    }\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "<div class=\"search-engine-container\">\n",
    "    <div class=\"search-header\">\n",
    "        <div class=\"search-title\">üîç Search Results</div>\n",
    "        <div class=\"search-query\"><strong>Query:</strong> \"\"\" + parameters.get('question', 'N/A') + \"\"\"</div>\n",
    "        <div class=\"search-stats\">About \"\"\" + str(len(all_items)) + \"\"\" results</div>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"search-results\">\n",
    "\"\"\"\n",
    "\n",
    "# Process each result\n",
    "for idx, item in enumerate(all_items, 1):\n",
    "    title = item.get('title', 'No Title')\n",
    "    url = item.get('url', 'No URL')\n",
    "    content = item.get('content', 'No Content')\n",
    "    \n",
    "    # Get summary from DeepSeek with parsed content\n",
    "    print(f\"Result {idx}: {title[:50]}\")\n",
    "    summary = get_summary_from_deepseek(content, max_words=10)\n",
    "    \n",
    "    html_output += f\"\"\"\n",
    "        <div class=\"result-item\">\n",
    "            <div class=\"result-url\">\n",
    "                <a href=\"{url}\" target=\"_blank\">{url}</a>\n",
    "            </div>\n",
    "            <div class=\"result-title\">\n",
    "                <a href=\"{url}\" target=\"_blank\">{title}</a>\n",
    "            </div>\n",
    "            <div class=\"result-snippet\">{summary}</div>\n",
    "            <div class=\"result-number\">Result {idx}</div>\n",
    "        </div>\n",
    "    \"\"\"\n",
    "\n",
    "html_output += \"\"\"\n",
    "    </div>\n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html_output))\n",
    "print(f\"\\n‚úÖ Displayed {len(all_items)} search results in search engine format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d31fc5d",
   "metadata": {},
   "source": [
    "## Step 5: Test Case 2 - Search for Technical Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ea20684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì Question: What is k-NN vector search and how does it work?\n",
      "============================================================\n",
      "\n",
      "üìö Technical Information:\n",
      "{\n",
      "  \"inference_results\": [\n",
      "    {\n",
      "      \"output\": [\n",
      "        {\n",
      "          \"name\": \"response\",\n",
      "          \"result\": \"{\\\"next_page\\\":\\\"https://duckduckgo.com/html?q=What+is+k-NN+vector+search+and+how+does+it+work?&s=10&nextParams=&v=l&o=json&dc=11&api=d.js&vqd=4-323378328593773489733371760493531760187&kl=wt-wt\\\",\\\"items\\\":[{\\\"url\\\":\\\"https://docs.opensearch.org/latest/vector-search/vector-search-techniques/index/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Discovery and cluster formation Node discovery and seed hosts Voting and quorum Voting configuration management Cluster bootstrapping Discovery and cluster formation settings Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Remote segment warmer Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Similarity Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Resource access management Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates OpenSearch FIPS configuration Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control Defining users and roles Permissions Default action groups REST layer authorization Document-level security Field-level security Field masking User impersonation Resource sharing and access control Resource sharing APIs API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Version Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Mapping explosion Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Rescore Regular expression syntax SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic queries Complex queries Functions JSON support Metadata queries Aggregate functions Delete JDBC driver ODBC driver PPL Subsearch Commands PPL syntax ad addcoltotals addtotals append appendcol appendpipe bin chart dedup describe eval eventstats expand explain fields fillnull flatten grok head join kmeans lookup ml multisearch parse patterns rare regex rename replace reverse rex search show datasources sort spath stats streamstats subquery table timechart top trendline where Identifiers Data types Functions Full-text search Settings Troubleshooting Monitoring Limitations Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Collecting UBI-formatted data in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Model access control through resource sharing Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller ML Tasks APIs Get ML task Search ML tasks Delete ML task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow access control Workflow settings Workflow state access control Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detector access control Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecaster access control Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Vector search Vector search techniques Vector search techniques OpenSearch implements vector search as k-nearest neighbors, or k-NN, search. k-NN search finds the k neighbors closest to a query point across an index of vectors. To determine the neighbors, you can specify the space (the distance function) you want to use to measure the distance between points. OpenSearch supports three different methods for obtaining the k-nearest neighbors from an index of vectors: Approximate search (approximate k-NN, or ANN): Returns approximate nearest neighbors to the query vector. Usually, approximate search algorithms sacrifice indexing speed and search accuracy in exchange for performance benefits such as lower latency, smaller memory footprints, and more scalable search. For most use cases, approximate search is the best option. Exact search: A brute-force, exact k-NN search of vector fields. OpenSearch supports the following types of exact search: Exact search with a scoring script: Using a scoring script, you can apply a filter to an index before executing the nearest neighbor search. Painless extensions: Adds the distance functions as Painless extensions that you can use in more complex combinations. You can use this method to perform a brute-force, exact vector search of an index, which also supports pre-filtering. In general, you should choose the ANN method for larger datasets because it scales significantly better. For smaller datasets, where you may want to apply a filter, you should choose the custom scoring approach. If you have a more complex use case in which you need to use a distance function as part of the scoring method, you should use the Painless scripting approach. Approximate search OpenSearch supports multiple backend algorithms (methods) and libraries for implementing these algorithms (engines). It automatically selects the optimal configuration based on the chosen mode and available memory. For more information, see Methods and engines. Using sparse vectors Neural sparse search offers an efficient alternative to dense vector search by using sparse embedding models and inverted indexes, providing performance similar to BM25. Unlike dense vector methods that require significant memory and CPU resources, sparse search creates a list of token-weight pairs and stores them in a rank features index. This approach combines the efficiency of traditional search with the semantic understanding of neural networks. OpenSearch supports both automatic embedding generation through ingest pipelines and direct sparse vector ingestion. For more information, see Neural sparse search. Combining multiple search techniques Hybrid search enhances search relevance by combining multiple search techniques in OpenSearch. It integrates traditional keyword search with vector-based semantic search. Through a configurable search pipeline, hybrid search normalizes and combines scores from different search methods to provide unified, relevant results. This approach is particularly effective for complex queries where both semantic understanding and exact matching are important. The search pipeline can be further customized with post-filtering operations and aggregations to meet specific search requirements. For more information, see Hybrid search. Approximate search Using sparse vectors Combining multiple search techniques WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright \\u00a9 OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\\\"},{\\\"url\\\":\\\"https://www.digitalocean.com/blog/enhancing-search-capabilities-with-k-nn-vector-search-in-opensearch\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Blog Docs Get Support Contact Sales DigitalOcean Products Featured Products Droplets Scalable virtual machines Kubernetes Scale more effectively Gradient\\u2122 AI Agentic Cloud Build and scale with AI Cloudways Managed cloud hosting App Platform Get apps to market faster Managed Databases Fully-managed database hosting Compute Droplets Kubernetes CPU-Optimized Droplets Functions App Platform Gradient\\u2122 AI Agentic Cloud GPU Droplets 1-Click Models Platform Bare Metal GPUs Backups & Snapshots Backups Snapshots SnapShooter Networking Virtual Private Cloud (VPC) Partner Network Connect Cloud Firewalls Load Balancers DNS DDoS Protection Managed Databases MongoDB Kafka MySQL PostgreSQL Valkey OpenSearch Storage Spaces Object Storage Volume Block Storage Network File Storage Developer Tools API CLI Support Plans Monitoring Uptime Identity and Access Management Marketplace Droplet 1-Click Kubernetes 1-Click AI 1-Click Models Add-Ons Cloud Website Hosting Cloudways See all products Solutions AI and Machine Learning Develop, train, and deploy AI apps GPUs Platform 1-Click Models HR Knowledge Assistant Code Copilot Support Ticket Triage Recommendation Engine Blockchain Infrastructure for decentralized apps Blogs, Forums and Content Websites Lightning-fast, reliable CMS hosting Wordpress Ghost Mastodon Data Analytics Real-time data processing at scale Data Streaming AdTech & Martech Kafka Developer Tools DevOps and CI/CD solutions CI/CD Prototyping Digital Marketing Agencies Power your clients\\u2019 websites and campaigns Freelancer IT Consulting Ecommerce Build beautiful online storefronts Dropshipping WooCommerce Magento Game Development Low-latency multiplayer servers Minecraft Hosting IoT Connect to the power of the cloud Kafka ISVs Streamlined ISV application development Secure Web Hosting Powerful protection from DDoS and more Private VPN Startup Cloud Hosting Scalable, cost-effective infrastructure Small Business Video Streaming High-bandwidth, low-latency delivery Kafka Web and Mobile Apps Simple cross-platform app hosting cPanel Docker Next.js Node.js Website Hosting Fast page loads and reliable site uptime VPS Hosting Virtual Machines Get help Migration Assistance Talk to an expert See all solutions Developers Our Community Community Home DevOps and development guides CSS-Tricks All things web design The Wave Content to level up your business. Resources Tutorials Questions and Answers Marketplace Tools Write for DOnations Cloud Chats Customer Stories DigitalOcean Blog Pricing Calculator Get Involved DigitalOcean Startups Open Source Sponsorships Hacktoberfest Deploy 2025 Wavemakers Program Documentation Quickstart Compute Gradient\\u2122 AI Platform Storage Managed Databases Containers Billing API Reference Partners DigitalOcean Partner Programs Become a Partner Partner Services Program DigitalOcean AI Partner Program Marketplace DigitalOcean Startups Connect with a Partner Partner Programs Resources Customer Stories DigitalOcean Onboarding Series Training for Agencies and Freelancers Price Estimate Calculator Featured Partner Articles Cloud cost optimization best practices Read more How to choose a cloud provider Read more DigitalOcean vs. AWS Lightsail: Which Cloud Platform is Right for You? Read more Questions? Talk to an expert Pricing Log in Sign up Blog Docs Get Support Contact Sales Log in Sign up Engineering Enhancing Search Capabilities with K-NN Vector Search in OpenSearch By Dustin Wilson and Govind Srinivasaraghavan Published: July 31, 2024 5 min read <- Back to blog home Many applications depend on the ability to deliver precise and relevant search results. Although the full-text search capabilities of traditional relational databases are sufficient in some situations, these databases can fall short in extracting semantic meaning from text or searching through less-structured data. In this blog post, we\\u2019ll explore how you can address these limitations using DigitalOcean-managed OpenSearch and a collection of techniques called K-Nearest Neighbor vector search (K-NN). K-NN makes OpenSearch a powerful and flexible solution for various search and analytics applications. Understanding K-NN Vector Search What is K-NN Vector Search? Unlike traditional search methods that rely on keyword matching, K-NN vector search involves representing each record in a dataset as a vector that encapsulates the attributes of the record. Machine learning models are often used to embed data into a vector representation. When a query is made, the search engine computes the distance between the query vector and the data vectors and returns the nearest neighbors based on a predefined distance metric, such as Euclidean distance or cosine similarity. Why Use OpenSearch for K-NN Vector Search? Introduction to OpenSearch OpenSearch is a highly scalable open-source search and analytics engine. It builds upon the strengths of Elasticsearch, providing robust features for full-text search, log analytics, and more. With the introduction of vector search capabilities, OpenSearch extends its utility to more advanced use cases such as natural language processing, recommendation systems, and image retrieval. Benefits of Using OpenSearch for Vector Search Scalability: OpenSearch can handle large volumes of data and queries efficiently. Using approximate nearest neighbor algorithms, OpenSearch can provide relevant search results much faster and with a lower memory footprint. Flexibility: It supports various types of data and search functionalities, making it suitable for diverse applications. Community and Support: Being open-source, it benefits from a vibrant community and regular updates. Setting Up OpenSearch for K-NN Vector Search Installing OpenSearch To get started, you need to install OpenSearch. Here\\u2019s a basic command to pull and run the latest version of the OpenSearch Docker image: docker pull opensearchproject/opensearch:latest\\\\n\\\\n\\\\ndocker run -d --name opensearch -p 9200:9200 -e \\\\\\\"discovery.type=single-node\\\\\\\" -e \\\\\\\"OPENSEARCH_INITIAL_ADMIN_PASSWORD=<your-strong-password>\\u201d opensearchproject/opensearch:latest\\\\n Note: You need to set an initial admin password when you try to run the opensearch docker container. It should be a minimum of 8 characters and must contain at least one uppercase letter, one lowercase letter, one digit, and one special character that is strong. Alternatively, DigitalOcean supports Managed OpenSearch, which makes configuring and managing OpenSearch clusters a breeze. Configuring OpenSearch for Vector Search After installing OpenSearch, the next step is to enable the K-NN plugin. On self-managed clusters, this involves modifying the cluster\\u2019s configuration file. On DigitalOcean Managed Opensearch The K-NN plugin is enabled by default and no additional configuration is required. Implementing K-NN Vector Search To use K-NN vector search, you must first create an index with vector fields. You can do so by navigating to the Opensearch development console at https://${CLUSTER_HOST}/app/dev_tools#/console and submitting the following request. Alternatively, you can send these commands as HTTP requests to https://${CLUSTER_HOST}:9200. PUT /my_vector_index\\\\n\\\\n{\\\\n\\\\n  \\\\\\\"mappings\\\\\\\": {\\\\n\\\\n    \\\\\\\"properties\\\\\\\": {\\\\n\\\\n      \\\\\\\"my_vector\\\\\\\": {\\\\n\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"K-NN_vector\\\\\\\",\\\\n\\\\n        \\\\\\\"dimension\\\\\\\": 128\\\\n\\\\n      }\\\\n\\\\n    }\\\\n\\\\n  }\\\\n\\\\n}\\\\n With this request you\\u2019ve created an index, my_vector_index, which you can use to store and query data using 128-dimension embeddings. You can now begin adding documents along with their vector representations to the index with the following request. PUT /my_vector_index/_doc/1\\\\n\\\\n{\\\\n\\\\n  \\\\\\\"my_vector\\\\\\\": [0.1, 0.2, ... , 0.128],\\\\n\\\\n  \\\\\\\"description\\\\\\\": \\\\\\\"Sample document\\\\\\\"\\\\n\\\\n}\\\\n Finally, to perform a K-NN search over these documents, you can use the following query. POST /my_vector_index/_search\\\\n\\\\n{\\\\n\\\\n  \\\\\\\"size\\\\\\\": 5,\\\\n\\\\n  \\\\\\\"query\\\\\\\": {\\\\n\\\\n    \\\\\\\"K-NN\\\\\\\": {\\\\n\\\\n      \\\\\\\"my_vector\\\\\\\": {\\\\n\\\\n        \\\\\\\"vector\\\\\\\": [0.1, 0.2, ... , 0.128],\\\\n\\\\n        \\\\\\\"k\\\\\\\": 5\\\\n\\\\n      }\\\\n\\\\n    }\\\\n\\\\n  }\\\\n\\\\n}\\\\n Use Cases and Applications Let\\u2019s cover a few end-to-end applications that could make use of Opensearch\\u2019s K-NN capabilities. Customer Support Chatbot: Vector search is often used to find semantically similar texts. A chatbot service might use a machine-learning model to embed an incoming query (e.g. \\u201cHow can I reset my password?\\u201d) into a vector and then use K-NN vector search to find similar queries in the knowledge base, such as \\u201cI forgot my password, how do I reset it?\\u201d. The chatbot can use this information to provide the user a more helpful response based on these similar queries. E-commerce Platform: K-NN vector search can enhance recommendation systems by finding items similar to a user\\u2019s preferences based on vector representations. For example, a user who buys a book from an online store might be recommended other books by the same author, books from the same genre, or even books that other users with similar preferences have bought. In this example, the vector representation of a book may include attributes like author, genre, ratings, and keywords from reviews. Fashion Retailer: By converting images into vectors using deep learning models, K-NN vector search can be used to retrieve visually similar images from a database. A user may upload a photo of a red dress. The system processes the image to create a vector representing the dress\\u2019s visual features. Using K-NN vector search, the platform retrieves and displays similar dresses in various shades of red, with similar cuts and designs, helping the user find exactly what they\\u2019re looking for. Challenges and Considerations using K-NN with OpenSearch 1. Vector Dimensionality High-dimensional vectors can lead to increased computational complexity. It\\u2019s important to balance vector dimensions with performance requirements. Luckily, OpenSearch has multiple K-NN methods with their own performance characteristics. While each method aims to return vectors with the minimal distance to an incoming vector, some can be tuned to prioritize memory use, response time or accuracy. 2. Data Normalization Ensuring that data is normalized and consistent is crucial for the accuracy of K-NN search results. 3. Performance Tuning Optimizing OpenSearch settings and hardware resources is essential for handling large-scale vector searches efficiently. See this article for more details on performance tuning. Conclusion K-NN vector search opens up new possibilities for delivering highly relevant search results across various domains. By leveraging OpenSearch\\u2019s powerful capabilities, developers can implement advanced search functionalities with relative ease. Whether it\\u2019s for recommendation systems, image retrieval, or NLP applications, K-NN vector search with OpenSearch is a valuable tool in the search technology landscape. About the author(s) Dustin Wilson Author See author profile See author profile Govind Srinivasaraghavan Author See author profile See author profile Share Engineering Try DigitalOcean for free Click below to sign up and get $200 of credit to try our products over 60 days! Sign up Related Articles Engineering DoTs SDK Development: Automating TypeScript Client Generation mchittupolu December 5, 2025 7 min read Read more Engineering How startups scale on DigitalOcean Kubernetes: Best Practices Part VI - Security Kunju Perath October 8, 2024 12 min read Read more Engineering Introducing new GitHub Actions for App Platform Markus Th\\u00f6mmes September 26, 2024 8 min read Read more Company About Leadership Blog Careers Customers Partners Referral Program Affiliate Program Press Legal Privacy Policy Security Investor Relations Products Overview Droplets Kubernetes Functions App Platform Gradient\\u2122 AI GPU Droplets Gradient\\u2122 AI Bare Metal GPUs Gradient\\u2122 AI 1-Click Models Gradient\\u2122 AI Platform Load Balancers Managed Databases Spaces Block Storage Network File Storage API Uptime Identity and Access Management Cloudways Resources Community Tutorials Community Q&A CSS-Tricks Write for DOnations Currents Research DigitalOcean Startups Wavemakers Program Compass Council Open Source Newsletter Signup Marketplace Pricing Pricing Calculator Documentation Release Notes Code of Conduct Shop Swag Solutions Website Hosting VPS Hosting Web & Mobile Apps Game Development Streaming VPN SaaS Platforms Cloud Hosting for Blockchain Startup Resources Migration Assistance Contact Support Sales Report Abuse System Status Share your ideas Company About Leadership Blog Careers Customers Partners Referral Program Affiliate Program Press Legal Privacy Policy Security Investor Relations Products Overview Droplets Kubernetes Functions App Platform Gradient\\u2122 AI GPU Droplets Gradient\\u2122 AI Bare Metal GPUs Gradient\\u2122 AI 1-Click Models Gradient\\u2122 AI Platform Load Balancers Managed Databases Spaces Block Storage Network File Storage API Uptime Identity and Access Management Cloudways Resources Community Tutorials Community Q&A CSS-Tricks Write for DOnations Currents Research DigitalOcean Startups Wavemakers Program Compass Council Open Source Newsletter Signup Marketplace Pricing Pricing Calculator Documentation Release Notes Code of Conduct Shop Swag Solutions Website Hosting VPS Hosting Web & Mobile Apps Game Development Streaming VPN SaaS Platforms Cloud Hosting for Blockchain Startup Resources Migration Assistance Contact Support Sales Report Abuse System Status Share your ideas \\u00a9 2026 DigitalOcean, LLC.Sitemap.\\\"},null,{\\\"url\\\":\\\"https://docs.aws.amazon.com/opensearch-service/latest/developerguide/knn.html\\\",\\\"title\\\":\\\"k-Nearest Neighbor (k-NN) search in Amazon OpenSearch Service - Amazon OpenSearch Service\\\",\\\"content\\\":\\\"k-Nearest Neighbor (k-NN) search in Amazon OpenSearch Service - Amazon OpenSearch Service DocumentationAmazon OpenSearch ServiceDeveloper Guide Getting started with k-NNk-NN differences, tuning, and limitations k-Nearest Neighbor (k-NN) search in Amazon OpenSearch Service Short for its associated k-nearest neighbors algorithm, k-NN for Amazon OpenSearch Service lets you search for points in a vector space and find the \\\\\\\"nearest neighbors\\\\\\\" for those points by Euclidean distance or cosine similarity. Use cases include recommendations (for example, an \\\\\\\"other songs you might like\\\\\\\" feature in a music application), image recognition, and fraud detection. Note This documentation provides a brief overview of the k-NN plugin, as well as limitations when using the plugin with managed OpenSearch Service. For comprehensive documentation of the k-NN plugin, including simple and complex examples, parameter references, and the complete API reference, see the open source OpenSearch documentation. The open source documentation also covers performance tuning and k-NN-specific cluster settings. Getting started with k-NN To use k-NN, you must create an index with the index.knn setting and add one or more fields of the knn_vector data type. PUT my-index\\\\n\\\\n{\\\\n  \\\\\\\"settings\\\\\\\": {\\\\n    \\\\\\\"index.knn\\\\\\\": true\\\\n  },\\\\n  \\\\\\\"mappings\\\\\\\": {\\\\n    \\\\\\\"properties\\\\\\\": {\\\\n      \\\\\\\"my_vector1\\\\\\\": {\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"knn_vector\\\\\\\",\\\\n        \\\\\\\"dimension\\\\\\\": 2\\\\n      },\\\\n      \\\\\\\"my_vector2\\\\\\\": {\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"knn_vector\\\\\\\",\\\\n        \\\\\\\"dimension\\\\\\\": 4\\\\n      }\\\\n    }\\\\n  }\\\\n} The knn_vector data type supports a single list of up to 10,000 floats, with the number of floats defined by the required dimension parameter. After you create the index, add some data to it. POST _bulk\\\\n\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"1\\\\\\\" } }\\\\n{ \\\\\\\"my_vector1\\\\\\\": [1.5, 2.5], \\\\\\\"price\\\\\\\": 12.2 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"2\\\\\\\" } }\\\\n{ \\\\\\\"my_vector1\\\\\\\": [2.5, 3.5], \\\\\\\"price\\\\\\\": 7.1 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"3\\\\\\\" } }\\\\n{ \\\\\\\"my_vector1\\\\\\\": [3.5, 4.5], \\\\\\\"price\\\\\\\": 12.9 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"4\\\\\\\" } }\\\\n{ \\\\\\\"my_vector1\\\\\\\": [5.5, 6.5], \\\\\\\"price\\\\\\\": 1.2 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"5\\\\\\\" } }\\\\n{ \\\\\\\"my_vector1\\\\\\\": [4.5, 5.5], \\\\\\\"price\\\\\\\": 3.7 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"6\\\\\\\" } }\\\\n{ \\\\\\\"my_vector2\\\\\\\": [1.5, 5.5, 4.5, 6.4], \\\\\\\"price\\\\\\\": 10.3 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"7\\\\\\\" } }\\\\n{ \\\\\\\"my_vector2\\\\\\\": [2.5, 3.5, 5.6, 6.7], \\\\\\\"price\\\\\\\": 5.5 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"8\\\\\\\" } }\\\\n{ \\\\\\\"my_vector2\\\\\\\": [4.5, 5.5, 6.7, 3.7], \\\\\\\"price\\\\\\\": 4.4 }\\\\n{ \\\\\\\"index\\\\\\\": { \\\\\\\"_index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"_id\\\\\\\": \\\\\\\"9\\\\\\\" } }\\\\n{ \\\\\\\"my_vector2\\\\\\\": [1.5, 5.5, 4.5, 6.4], \\\\\\\"price\\\\\\\": 8.9 }\\\\n Then you can search the data using the knn query type. GET my-index/_search\\\\n{\\\\n  \\\\\\\"size\\\\\\\": 2,\\\\n  \\\\\\\"query\\\\\\\": {\\\\n    \\\\\\\"knn\\\\\\\": {\\\\n      \\\\\\\"my_vector2\\\\\\\": {\\\\n        \\\\\\\"vector\\\\\\\": [2, 3, 5, 6],\\\\n        \\\\\\\"k\\\\\\\": 2\\\\n      }\\\\n    }\\\\n  }\\\\n} In this case, k is the number of neighbors you want the query to return, but you must also include the size option. Otherwise, you get k results for each shard (and each segment) rather than k results for the entire query. k-NN supports a maximum k value of 10,000. If you mix the knn query with other clauses, you might receive fewer than k results. In this example, the post_filter clause reduces the number of results from 2 to 1. GET my-index/_search\\\\n\\\\n{\\\\n  \\\\\\\"size\\\\\\\": 2,\\\\n  \\\\\\\"query\\\\\\\": {\\\\n    \\\\\\\"knn\\\\\\\": {\\\\n      \\\\\\\"my_vector2\\\\\\\": {\\\\n        \\\\\\\"vector\\\\\\\": [2, 3, 5, 6],\\\\n        \\\\\\\"k\\\\\\\": 2\\\\n      }\\\\n    }\\\\n  },\\\\n  \\\\\\\"post_filter\\\\\\\": {\\\\n    \\\\\\\"range\\\\\\\": {\\\\n      \\\\\\\"price\\\\\\\": {\\\\n        \\\\\\\"gte\\\\\\\": 6,\\\\n        \\\\\\\"lte\\\\\\\": 10\\\\n      }\\\\n    }\\\\n  }\\\\n} If you need to handle a large volume of queries while maintaining optimal performance, you can use the _msearch API to construct a bulk search with JSON and send a single request to perform multiple searches: GET _msearch\\\\n\\\\n{ \\\\\\\"index\\\\\\\": \\\\\\\"my-index\\\\\\\"}\\\\n{ \\\\\\\"query\\\\\\\": { \\\\\\\"knn\\\\\\\": {\\\\\\\"my_vector2\\\\\\\":{\\\\\\\"vector\\\\\\\": [2, 3, 5, 6],\\\\\\\"k\\\\\\\":2 }} } }\\\\n{ \\\\\\\"index\\\\\\\": \\\\\\\"my-index\\\\\\\", \\\\\\\"search_type\\\\\\\": \\\\\\\"dfs_query_then_fetch\\\\\\\"}\\\\n{ \\\\\\\"query\\\\\\\": { \\\\\\\"knn\\\\\\\": {\\\\\\\"my_vector1\\\\\\\":{\\\\\\\"vector\\\\\\\": [2, 3],\\\\\\\"k\\\\\\\":2 }} } } The following video demonstrates how to set up bulk vector searches for K-NN queries. k-NN differences, tuning, and limitations OpenSearch lets you modify all k-NN settings using the _cluster/settings API. On OpenSearch Service, you can change all settings except knn.memory.circuit_breaker.enabled and knn.circuit_breaker.triggered. k-NN statistics are included as Amazon CloudWatch metrics. In particular, check the KNNGraphMemoryUsage metric on each data node against the knn.memory.circuit_breaker.limit statistic and the available RAM for the instance type. OpenSearch Service uses half of an instance's RAM for the Java heap (up to a heap size of 32 GiB). By default, k-NN uses up to 50% of the remaining half, so an instance type with 32 GiB of RAM can accommodate 8 GiB of graphs (32 * 0.5 * 0.5). Performance can suffer if graph memory usage exceeds this value. You can migrate a k-NN index created on version 2.x or later to UltraWarm or cold storage on a domain with version 2.17 or later. Clear cache api and warmup apis for k-NN indices are blocked for warm indices. When the first query is initiated for the index, it downloads the graph files from Amazon S3 and loads the graph to memory. Similarly, when TTL is expired for the graphs, the files are automatically evicted from memory. Javascript is disabled or is unavailable in your browser. To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions. Document Conventions Advanced search capabilities with an Amazon S3 vector engine Vector ingestion Did this page help you? - Yes Thanks for letting us know we're doing a good job! If you've got a moment, please tell us what we did right so we can do more of it. Did this page help you? - No Thanks for letting us know this page needs work. We're sorry we let you down. If you've got a moment, please tell us how we can make the documentation better.\\\"},{\\\"url\\\":\\\"https://deepwiki.com/opensearch-project/k-NN/2-core-concepts\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Loading... Index your code with Devin DeepWiki DeepWiki opensearch-project/k-NN Index your code with Devin Edit Wiki Share Loading... Last indexed: 30 April 2025 (3a48c4) Overview Core Concepts Architecture Query Processing Vector Storage and Indexing Model Management Memory Management JNI Integration FAISS Integration NMSLIB and Lucene Engines Advanced Features Derived Source Compression & Performance Optimization Monitoring and Statistics Developer Guide Build System Testing Framework Continuous Integration Menu Core Concepts Relevant source files .github/draft-release-notes-config.yml .github/workflows/draft-release-notes-workflow.yml README.md qa/restart-upgrade/src/test/java/org/opensearch/knn/bwc/IndexingIT.java qa/rolling-upgrade/src/test/java/org/opensearch/knn/bwc/IndexingIT.java release-notes/opensearch-knn.release-notes-3.0.0.0-beta1.md src/main/java/org/opensearch/knn/index/SpaceType.java src/main/java/org/opensearch/knn/index/query/common/DocAndScoreQuery.java src/main/java/org/opensearch/knn/index/query/common/QueryUtils.java src/main/java/org/opensearch/knn/index/query/explain/KnnExplanation.java src/test/java/org/opensearch/knn/index/ExplainIT.java src/test/java/org/opensearch/knn/index/NmslibIT.java src/test/java/org/opensearch/knn/index/OpenSearchIT.java src/test/java/org/opensearch/knn/index/VectorDataTypeIT.java src/test/java/org/opensearch/knn/index/query/ExplainTests.java src/test/java/org/opensearch/knn/index/query/common/DocAndScoreQueryTests.java src/test/java/org/opensearch/knn/integ/ExpandNestedDocsIT.java src/test/java/org/opensearch/knn/recall/RecallTestsIT.java This page explains the fundamental concepts of the OpenSearch k-NN (k-Nearest Neighbors) plugin, which enables similarity search across vector data. Understanding these core concepts is essential for effectively implementing and using vector search capabilities in OpenSearch. For detailed architectural information, see the Architecture page. Vector Search Basics k-NN (k-Nearest Neighbors) is an algorithm that finds the k most similar items to a query point in a vector space. In OpenSearch, the k-NN plugin allows you to: Search for similar vectors across billions of documents Perform efficient approximate nearest neighbor (ANN) search Balance between search accuracy and performance Combine vector search with traditional filters Vector search works by: Converting data into numerical vectors (embeddings) Indexing these vectors using specialized data structures Computing similarity between vectors using distance metrics Retrieving the k closest vectors to a query vector Sources: README.md15-17 Vector Spaces and Distance Metrics Vector spaces define how similarity between vectors is measured. The choice of distance metric significantly impacts search results and should match your use case. Space Type Description Ideal For Supported By L2 (Euclidean) Straight-line distance General-purpose similarity, images All engines COSINESIMIL Angle between vectors Text embeddings, semantic search All engines L1 (Manhattan) Sum of absolute differences Grid-based data, robust to outliers All engines LINF (Chebyshev) Maximum difference Worst-case distance applications All engines INNER_PRODUCT Dot product Relevance measurement All engines HAMMING Binary difference count Binary vectors, hash codes FAISS Each space type implements a scoreTranslation method to convert raw distances to OpenSearch scores (higher = more similar). Sources: src/main/java/org/opensearch/knn/index/SpaceType.java29-278 Vector Data Types The k-NN plugin supports different vector data types to accommodate various use cases and memory constraints: When choosing a vector data type, consider: Precision requirements: FLOAT offers highest precision Memory constraints: BINARY uses least memory, BYTE is in between Compatible spaces: BINARY works only with HAMMING space Engine support: Different engines support different combinations Sources: src/test/java/org/opensearch/knn/index/VectorDataTypeIT.java58-61 Search Methods OpenSearch k-NN supports different search methods, each with its own trade-offs between accuracy, speed, and memory usage: HNSW (Hierarchical Navigable Small World) HNSW builds a navigable graph where each vector connects to its nearest neighbors across multiple layers. This creates \\\\\\\"small world\\\\\\\" navigation paths that enable efficient search. Key parameters: M: Maximum connections per node (default: 16) efConstruction: Build-time accuracy control (default: 512) efSearch: Query-time accuracy control (default: equal to k) IVF (Inverted File) IVF partitions vectors into clusters and searches only the most promising clusters during query time. Key parameters: nlist: Number of clusters (default: 4) nprobes: Number of clusters to search (default: equal to nlist) Product Quantization (PQ) An encoding technique often used with IVF that compresses vectors to reduce memory usage: Divides vectors into subvectors Uses a codebook to encode each subvector Significantly reduces memory usage with some accuracy loss Sources: src/test/java/org/opensearch/knn/recall/RecallTestsIT.java63-417 Backend Engines OpenSearch k-NN uses multiple backend engines to perform vector operations, each with different capabilities: FAISS Engine FAISS (Facebook AI Similarity Search) is a specialized library for efficient vector search with: Advanced algorithm implementations (HNSW, IVF) Support for vector compression (PQ, SQ) High performance for large datasets Optimized for high-dimensional vectors Lucene Engine The Lucene engine uses Apache Lucene's vector capabilities: Seamless integration with OpenSearch Efficient filtering during vector search Support for on-disk storage modes Optimized for general-purpose vector search NMSLIB Engine (Deprecated) The NMSLIB engine is deprecated in OpenSearch 3.0+: Existing indices continue to work New indices should use FAISS or Lucene Will be removed in a future release Sources: qa/rolling-upgrade/src/test/java/org/opensearch/knn/bwc/IndexingIT.java224-252 Storage Modes Vector data can be stored in different ways to balance memory usage and performance: IN_MEMORY Mode The default mode where vector indices are loaded entirely into memory: Best performance for search operations Highest memory requirements Suitable for performance-critical applications ON_DISK Mode Vectors are stored on disk and loaded only when needed: Significantly reduced memory footprint Performance impact compared to in-memory Optional rescoring for improved accuracy Ideal for large indices with memory constraints MEMORY_OPTIMIZED Mode A hybrid approach that balances memory usage and performance: More memory-efficient than IN_MEMORY Better performance than ON_DISK Available for the FAISS engine Sources: src/test/java/org/opensearch/knn/integ/ExpandNestedDocsIT.java68-98 Query Types and Execution Flow OpenSearch k-NN supports several query types to meet different search needs: Query Execution Flow The following diagram shows how k-NN queries are processed: Client submits a k-NN query Query is parsed by KNNQueryBuilder KNNWeight handles execution logic Circuit breaker checks memory availability Vector index is retrieved from cache or loaded Query is executed against the index Results are returned to the client Sources: src/main/java/org/opensearch/knn/index/query/common/DocAndScoreQuery.java27-212 src/main/java/org/opensearch/knn/index/query/common/QueryUtils.java38-178 Memory Management The k-NN plugin includes robust memory management to prevent out-of-memory errors: Circuit Breaker The circuit breaker protects against out-of-memory errors: Monitors native memory usage for vector indices Triggers when memory thresholds are exceeded Blocks new indexing operations when active Configurable via knn.memory.circuit_breaker.limit Native Memory Cache Manages vector indices in memory: Implements a least-recently-used (LRU) eviction policy Handles thread-safety for concurrent access Manages different allocation types (index, model, training) Optimizes memory usage across searches Build Thresholds Controls when vector indices are built: index.knn.algo_param.index_thread_qty: Thread count for building index.knn.build_vector_data_structure_threshold: When to build -1: Never build (use exact search) 0: Always build n: Build when document count exceeds n Sources: src/test/java/org/opensearch/knn/index/OpenSearchIT.java578-631 Model Management The k-NN plugin includes a model management system for training and using vector models: Model Training Models can be trained on sample data to optimize for specific vector distributions: Client submits a training request with parameters System routes the training job to an appropriate node Training occurs asynchronously Trained model is stored in the .opensearch-knn-models index Model Storage and Retrieval Models are stored in a dedicated index: Metadata stored as JSON Binary model data stored efficiently API endpoints for management Cached for efficient reuse Model Usage Trained models are used during indexing and search: Referenced by model_id in the index mapping Loaded from cache when needed Applied during indexing to create optimized structures Used during search to find nearest neighbors Sources: src/test/java/org/opensearch/knn/recall/RecallTestsIT.java292-417 Advanced Features Remote Vector Index Building For large-scale deployments, remote index building offloads computation: Remote building is useful for: Very large vector collections Resource-constrained clusters Computationally expensive index types Specialized hardware requirements Vector Field Compression Techniques to reduce memory requirements: Product Quantization (PQ): Encodes vectors as compact codes Scalar Quantization (SQ): Reduces precision of components Binary vectors: Most memory-efficient for certain applications Sources: release-notes/opensearch-knn.release-notes-3.0.0.0-beta1.md1-28 Summary The OpenSearch k-NN plugin provides a comprehensive vector search solution with: Multiple distance metrics for different similarity definitions Various vector data types to balance precision and memory High-performance search algorithms (HNSW, IVF) Multiple backend engines (FAISS, Lucene) Flexible storage modes for memory/performance tradeoffs Sophisticated memory management Model training and management capabilities Advanced features for large-scale deployments Understanding these core concepts is essential for effectively implementing vector search in OpenSearch. For more detailed information on the architecture and implementation, see the Architecture page. Dismiss Refresh this wiki Enter email to refresh On this page Core Concepts Vector Search Basics Vector Spaces and Distance Metrics Vector Data Types Search Methods HNSW (Hierarchical Navigable Small World) IVF (Inverted File) Product Quantization (PQ) Backend Engines FAISS Engine Lucene Engine NMSLIB Engine (Deprecated) Storage Modes IN_MEMORY Mode ON_DISK Mode MEMORY_OPTIMIZED Mode Query Types and Execution Flow Query Execution Flow Memory Management Circuit Breaker Native Memory Cache Build Thresholds Model Management Model Training Model Storage and Retrieval Model Usage Advanced Features Remote Vector Index Building Vector Field Compression Summary\\\"},null,{\\\"url\\\":\\\"https://learncodecamp.net/vector-databases-knn-hnsw/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to content Learn Code Camp Menu Menu Home Java AI System Design JavaScript Dev Tools Kafka Exploring the Power of Vector Databases: Leveraging KNN and HNSW for Efficient Data Retrieval 6 March 2024 by Nitin What are vector databases? Key techniques employed in vector databases Approximate Nearest Neighbors Search (K-ANNS) Examples of ANN algorithms HNSW Summary What are vector databases? A Vector Database is a type of database that stores information in a structured way using vectors. Now, what are vectors? Think of them as mathematical representations of data that capture its meaning and context. Let\\u2019s say you have a photo of a cat. Instead of just storing the image file, a Vector Database will convert this photo into a vector, which is essentially a set of numbers that represent various features of the cat, like its color, shape, and size. This vector will contain information about the cat in a way that a computer can understand. Now, the cool thing about vector databases is that they allow you to search for similar items easily. For instance, if you upload a photo of a dog, the database can quickly find other photos with similar features to that dog by comparing their vectors. This is like when you search for similar images on your smartphone\\u2014except it\\u2019s done using mathematical calculations rather than just looking for file names or tags. So, in simple terms, a Vector Database helps organize and search for different types of data by converting them into mathematical representations called vectors, making it easier to find similar items or information. Check Understanding Embeddings: https://learncodecamp.net/embeddings/ Vector databases are specialized databases tailored for high-dimensional data points represented as vectors, offering efficient storage and retrieval capabilities. They excel at performing nearest-neighbor searches, swiftly retrieving data points closest to a given point in multi-dimensional space. Key techniques employed in vector databases k-Nearest Neighbor (k-NN) Index: This technique enables rapid identification of the k nearest neighbors of a given vector. It aids in efficiently narrowing down the search space, improving retrieval speed. Hierarchical Navigable Small World (HNSW): HNSW algorithm efficiently organizes data points to facilitate faster nearest-neighbor searches. It constructs a hierarchical graph structure that optimizes the search process. In summary, vector databases leverage advanced methods such as k-NN indexes and algorithms like HNSW to ensure efficient storage and retrieval of high-dimensional vectors, enabling rapid lookup of nearest neighbors in multi-dimensional spaces. # Function to find K Nearest Neighbors\\\\ndef find_k_nearest_neighbors(query_vector, vectors, k=5, threshold=0.8):\\\\n    nearest_neighbors = []\\\\n    for vector in vectors:\\\\n        similarity = cosine_similarity(query_vector, vector)\\\\n        if similarity >= threshold:\\\\n            nearest_neighbors.append((vector, similarity))\\\\n    nearest_neighbors.sort(key=lambda x: x[1], reverse=True)\\\\n    return nearest_neighbors[:k]\\\\n Simple pseudocode for finding k nearest neighbors, query_vector is the embedding vector of the search term, and k is the number of the items to retrieve, threshold is minimum match % The brute force of a kNN search is computationally very expensive \\u2013 and depending on the size of your database, a single query could take anything from several seconds to even mins. Number of computations = Number of dimensions \\u00d7 Vector size Given: Number of dimensions (d) = 1536 Vector size (n) = 1 million = 1\\u00d710^6 Number of computations=1536\\u00d71\\u00d710^6 = 1.536\\u00d710^9 approximately 1.536 billion it would take approximately 1.536 seconds to perform all the computations needed for your kNN search on a system capable of performing 1 billion computations per second. Let\\u2019s explore Approximate Nearest Neighbors Algorithms. Approximate Nearest Neighbors Search (K-ANNS) This is used to efficiently find approximate nearest neighbors for a given query point in a large dataset. It\\u2019s particularly useful when dealing with high-dimensional data where traditional exact nearest neighbor search methods become computationally expensive. The quality of an inexact search (the recall) is defined as the ratio between the number of found true nearest neighbors and K To elaborate: True Nearest Neighbors: These are the actual nearest neighbors of the query point in the dataset, determined by some distance metric. For example, if we\\u2019re searching for the 5 nearest neighbors (K=5) of a given point, the true nearest neighbors are those 5 points in the dataset that are closest to the query point. Found Nearest Neighbors: These are the points that the approximate search algorithm returns as the nearest neighbors of the query point. Due to the approximate nature of the search, they may not be exactly the same as the true nearest neighbors. Recall: The recall of the search is then defined as the ratio of the number of found true nearest neighbors to the total number of nearest neighbors desired (K). It\\u2019s calculated using the formula: Recall = (Number of Found True Nearest Neighbors) / K For example, if a search algorithm returns 3 out of the 5 true nearest neighbors for a query with K=5, the recall would be 3/5, or 0.6. This means that the algorithm successfully retrieved 60% of the true nearest neighbors. High recall is desirable in many applications because it indicates that the algorithm is effectively capturing the most relevant points in the dataset. Examples of ANN algorithms Examples of ANN methods are: trees \\u2013 e.g. ANNOY (Figure 1), proximity graphs \\u2013 e.g. HNSW (Figure 2), clustering \\u2013 e.g. FAISS, hashing \\u2013 e.g. LSH, vector compression \\u2013 e.g. PQ or SCANN. Figure 1 Annoy is used at Spotify for music recommendations. Redis Search supports\\u2002FLAT \\u2013 Brute-force index and HNSW HNSW Probabilistic Skip List: A skip list is a data structure that allows for fast search, insertion, and deletion operations in a sorted list. It achieves this by adding multiple layers of pointers, allowing for \\u201cskipping\\u201d over some elements during traversal. In HNSW, the probabilistic skip list is used to organize the data points within each layer of the hierarchical structure. Probabilistic skip list The \\u201cNavigable Small World\\u201d (NSW) part of Hierarchical Navigable Small World (HNSW) refers to a graph structure designed to maintain both local connectivity and global exploration capabilities. Let\\u2019s break down the NSW component: Navigability: NSW aims to create a graph structure where each data point (or node) is connected to its neighbors in a way that facilitates efficient navigation through the dataset. This means that similar points are likely to be connected, allowing for quick traversal between them. Small World Property: The small-world property refers to the idea that even though the graph may be large and sparsely connected, it\\u2019s still possible to navigate from one point to another through a relatively small number of connections. This property is essential for efficient search and exploration in large datasets. Connection Strategy: In NSW, connections between points are established based on their proximity in the data space. Typically, points that are closer together in the data space are more likely to be connected. However, NSW also incorporates randomness into the connection strategy to balance local connectivity with global exploration. Efficient Search: By creating a graph structure with the small-world property, NSW enables efficient search for nearest neighbors. During the search process, the algorithm can navigate through the graph using a combination of local connections to quickly find nearby points and occasional long-range connections to explore distant regions of the dataset. Summary Vector databases rely on Machine Learning models to generate vector embeddings for all data objects. Vector embeddings represent the meaning and context of data, enabling efficient analysis and retrieval. Vector databases provide rapid query capabilities due to Approximate Nearest Neighbors (ANN) algorithms. ANN algorithms sacrifice some accuracy in exchange for significant performance improvements. Categories AI Building a RESTful API with Node.js, Express, and MongoDB Revolutionizing AI: LLMs Without GPUs? The Promise of BitNet B1.58 Leave a comment Cancel reply Comment Name Email Save my name, email, and website in this browser for the next time I comment. \\u0394 Search for: Recent Posts Understanding LLM Inference Basics: Prefill and Decode, TTFT, and ITL Analysis of open ai home directory Managing Multiple Python and Java Versions: A Developer\\u2019s Guide to pyenv and SDKMAN Search for: Categories AI Blog Dev Tools Java JavaScript Kafka Spring Boot System Design Recent Posts Understanding LLM Inference Basics: Prefill and Decode, TTFT, and ITL Analysis of open ai home directory Managing Multiple Python and Java Versions: A Developer\\u2019s Guide to pyenv and SDKMAN Debugging HTTP Traffic Like a Pro: HTTP Toolkit and Terminal Interception How to Stop Hallucinations in RAG Chatbots: A Complete Guide Tags AI aop beans command line embeddings eol java java8 javascript kafka maven microservices mvn spring boot system design Quick Links Home Contact Us Privacy Policy About Us \\u00a9 2026 Learn Code Camp \\u2022 Built with GeneratePress\\\"},{\\\"url\\\":\\\"https://www.geeksforgeeks.org/machine-learning/k-nearest-neighbours/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Interview Prep Tutorials Tracks Python for Machine Learning Machine Learning with R Machine Learning Algorithms EDA Math for Machine Learning Machine Learning Interview Questions ML Projects Deep Learning NLP Computer vision Data Science Artificial Intelligence K-Nearest Neighbor(KNN) Algorithm Last Updated : 23 Dec, 2025 K-Nearest Neighbors (KNN) is a supervised machine learning algorithm generally used for classification but can also be used for regression tasks. It works by finding the \\\\\\\"k\\\\\\\" closest data points (neighbors) to a given input and makes a predictions based on the majority class (for classification) or the average value (for regression). Since KNN makes no assumptions about the underlying data distribution it makes it a non-parametric and instance-based learning method. K-Nearest Neighbors is also called as a lazy learner algorithm because it does not learn from the training set immediately instead it stores the entire dataset and performs computations only at the time of classification. For example, consider the following table of data points containing two features: The new point is classified as Category 2 because most of its closest neighbors are blue squares. KNN assigns the category based on the majority of nearby points. The image shows how KNN predicts the category of a new data point based on its closest neighbours. The red diamonds represent Category 1 and the blue squares represent Category 2. The new data point checks its closest neighbors (circled points). Since the majority of its closest neighbors are blue squares (Category 2) KNN predicts the new data point belongs to Category 2. KNN Algorithm working visualization KNN works by using proximity and majority voting to make predictions. What is 'K' in K Nearest Neighbour? In the k-Nearest Neighbours algorithm k is just a number that tells the algorithm how many nearby points or neighbors to look at when it makes a decision. Example: Imagine you're deciding which fruit it is based on its shape and size. You compare it to fruits you already know. If k = 3, the algorithm looks at the 3 closest fruits to the new one. If 2 of those 3 fruits are apples and 1 is a banana, the algorithm says the new fruit is an apple because most of its neighbors are apples. How to choose the value of k for KNN Algorithm? The value of k in KNN decides how many neighbors the algorithm looks at when making a prediction. Choosing the right k is important for good results. If the data has lots of noise or outliers, using a larger k can make the predictions more stable. But if k is too large the model may become too simple and miss important patterns and this is called underfitting. So k should be picked carefully based on the data. Statistical Methods for Selecting k Cross-Validation: Cross-Validation is a good way to find the best value of k is by using k-fold cross-validation. This means dividing the dataset into k parts. The model is trained on some of these parts and tested on the remaining ones. This process is repeated for each part. The k value that gives the highest average accuracy during these tests is usually the best one to use. Elbow Method: In Elbow Method we draw a graph showing the error rate or accuracy for different k values. As k increases the error usually drops at first. But after a certain point error stops decreasing quickly. The point where the curve changes direction and looks like an \\\\\\\"elbow\\\\\\\" is usually the best choice for k. Odd Values for k: It\\u2019s a good idea to use an odd number for k especially in classification problems. This helps avoid ties when deciding which class is the most common among the neighbors. Distance Metrics Used in KNN Algorithm KNN uses distance metrics to identify nearest neighbor, these neighbors are used for classification and regression task. To identify nearest neighbor we use below distance metrics: 1. Euclidean Distance Euclidean distance is defined as the straight-line distance between two points in a plane or space. You can think of it like the shortest path you would walk if you were to go directly from one point to another. \\\\\\\\text{distance}(x, X_i) = \\\\\\\\sqrt{\\\\\\\\sum_{j=1}^{d} (x_j - X_{i_j})^2} ] 2. Manhattan Distance This is the total distance you would travel if you could only move along horizontal and vertical lines like a grid or city streets. It\\u2019s also called \\\\\\\"taxicab distance\\\\\\\" because a taxi can only drive along the grid-like streets of a city. d\\\\\\\\left ( x,y \\\\\\\\right )={\\\\\\\\sum_{i=1}^{n}\\\\\\\\left | x_i-y_i \\\\\\\\right |} 3. Minkowski Distance Minkowski distance is like a family of distances, which includes both Euclidean and Manhattan distances as special cases. d\\\\\\\\left ( x,y \\\\\\\\right )=\\\\\\\\left ( {\\\\\\\\sum_{i=1}^{n}\\\\\\\\left ( x_i-y_i \\\\\\\\right )^p} \\\\\\\\right )^{\\\\\\\\frac{1}{p}} From the formula above, when p=2, it becomes the same as the Euclidean distance formula and when p=1, it turns into the Manhattan distance formula. Minkowski distance is essentially a flexible formula that can represent either Euclidean or Manhattan distance depending on the value of p. Working of KNN algorithm Th\\u0435 K-Nearest Neighbors (KNN) algorithm operates on the principle of similarity where it predicts the label or value of a new data point by considering the labels or values of its K nearest neighbors in the training dataset. Step 1: Selecting the optimal value of K K represents the number of nearest neighbors that needs to be considered while making prediction. Step 2: Calculating distance To measure the similarity between target and training data points Euclidean distance is widely used. Distance is calculated between data points in the dataset and target point. Step 3: Finding Nearest Neighbors The k data points with the smallest distances to the target point are nearest neighbors. Step 4: Voting for Classification or Taking Average for Regression When you want to classify a data point into a category like spam or not spam, the KNN algorithm looks at the K closest points in the dataset. These closest points are called neighbors. The algorithm then looks at which category the neighbors belong to and picks the one that appears the most. This is called majority voting. In regression, the algorithm still looks for the K closest points. But instead of voting for a class in classification, it takes the average of the values of those K neighbors. This average is the predicted value for the new point for the algorithm. It shows how a test point is classified based on its nearest neighbors. As the test point moves the algorithm identifies the closest 'k' data points i.e. 5 in this case and assigns test point the majority class label that is grey label class here. Implementing KNN from Scratch in Python 1. Importing Libraries Counter is used to count the occurrences of elements in a list or iterable. In KNN after finding the k nearest neighbor labels Counter helps count how many times each label appears. Python import numpy as np\\\\nfrom collections import Counter\\\\n 2. Defining the Euclidean Distance Function euclidean_distance is to calculate euclidean distance between points. Python def euclidean_distance(point1, point2):\\\\n    return np.sqrt(np.sum((np.array(point1) - np.array(point2))**2))\\\\n 3. KNN Prediction Function distances.append saves how far each training point is from the test point, along with its label. distances.sort is used to sorts the list so the nearest points come first. k_nearest_labels picks the labels of the k closest points. Uses Counter to find which label appears most among those k labels that becomes the prediction. Python def knn_predict(training_data, training_labels, test_point, k):\\\\n    distances = []\\\\n    for i in range(len(training_data)):\\\\n        dist = euclidean_distance(test_point, training_data[i])\\\\n        distances.append((dist, training_labels[i]))\\\\n    distances.sort(key=lambda x: x[0])\\\\n    k_nearest_labels = [label for _, label in distances[:k]]\\\\n    return Counter(k_nearest_labels).most_common(1)[0][0]\\\\n 4. Training Data, Labels and Test Point Python training_data = [[1, 2], [2, 3], [3, 4], [6, 7], [7, 8]]\\\\ntraining_labels = ['A', 'A', 'A', 'B', 'B']\\\\ntest_point = [4, 5]\\\\nk = 3\\\\n 5. Prediction Python prediction = knn_predict(training_data, training_labels, test_point, k)\\\\nprint(prediction)\\\\n Output: A The algorithm calculates the distances of the test point [4, 5] to all training points selects the 3 closest points as k = 3 and determines their labels. Since the majority of the closest points are labelled 'A' the test point is classified as 'A'. In machine learning we can also use Scikit Learn python library which has in built functions to perform KNN machine learning model and for that you refer to Implementation of KNN classifier using Sklearn. Applications of KNN Recommendation Systems: Suggests items like movies or products by finding users with similar preferences. Spam Detection: Identifies spam emails by comparing new emails to known spam and non-spam examples. Customer Segmentation: Groups customers by comparing their shopping behavior to others. Speech Recognition: Matches spoken words to known patterns to convert them into text. Advantages of KNN Simple to use: Easy to understand and implement. No training step: No need to train as it just stores the data and uses it during prediction. Few parameters: Only needs to set the number of neighbors (k) and a distance method. Versatile: Works for both classification and regression problems. Disadvantages of KNN Slow with large data: Needs to compare every point during prediction. Struggles with many features: Accuracy drops when data has too many features. Can Overfit: It can overfit especially when the data is high-dimensional or not clean. Also Check for more understanding: K Nearest Neighbors with Python | ML Implementation of K-Nearest Neighbors from Scratch using Python Mathematical explanation of K-Nearest Neighbour Weighted K-NN Suggested Quiz 0 Questions Quiz Completed Successfully Your Score : 0/0 Accuracy : 0% Comment Article Tags: Article Tags: Machine Learning AI-ML-DS Directi ML-Classification Machine Learning AI-ML-DS With Python +2 More Explore Machine Learning Basics Introduction to Machine Learning8 min read Types of Machine Learning7 min read What is Machine Learning Pipeline?6 min read Applications of Machine Learning3 min read Python for Machine Learning Machine Learning with Python Tutorial5 min read NumPy Tutorial - Python Library3 min read Pandas Tutorial4 min read Data Preprocessing in Python4 min read EDA - Exploratory Data Analysis in Python6 min read Feature Engineering What is Feature Engineering?5 min read Introduction to Dimensionality Reduction4 min read Feature Selection Techniques in Machine Learning4 min read Supervised Learning Supervised Machine Learning7 min read Linear Regression in Machine learning14 min read Logistic Regression in Machine Learning10 min read Decision Tree in Machine Learning8 min read Random Forest Algorithm in Machine Learning5 min read K-Nearest Neighbor(KNN) Algorithm8 min read Support Vector Machine (SVM) Algorithm9 min read Naive Bayes Classifiers6 min read Unsupervised Learning What is Unsupervised Learning5 min read K means Clustering \\u2013 Introduction6 min read Hierarchical Clustering in Machine Learning6 min read DBSCAN Clustering in ML - Density based clustering6 min read Apriori Algorithm6 min read Frequent Pattern Growth Algorithm5 min read ECLAT Algorithm - ML5 min read Principal Component Analysis (PCA)7 min read Model Evaluation and Tuning Evaluation Metrics in Machine Learning9 min read Regularization in Machine Learning5 min read Cross Validation in Machine Learning5 min read Hyperparameter Tuning5 min read Underfitting and Overfitting in ML3 min read Bias and Variance in Machine Learning6 min read Advanced Techniques Reinforcement Learning9 min read Semi-Supervised Learning in ML5 min read Self-Supervised Learning (SSL)6 min read Ensemble Learning7 min read Machine Learning Practice Machine Learning Interview Questions and Answers15+ min read 100+ Machine Learning Projects with Source Code5 min read Corporate & Communications Address: A-143, 7th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305) Registered Address: K 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305 Company About Us Legal Privacy Policy Contact Us Advertise with us GFG Corporate Solution Campus Training Program Explore POTD Job-A-Thon Blogs Nation Skill Up Tutorials Programming Languages DSA Web Technology AI, ML & Data Science DevOps CS Core Subjects Interview Preparation Software and Tools Courses ML and Data Science DSA and Placements Web Development Programming Languages DevOps & Cloud GATE Trending Technologies Videos DSA Python Java C++ Web Development Data Science CS Subjects Preparation Corner Interview Corner Aptitude Puzzles GfG 160 System Design @GeeksforGeeks, Sanchhaya Education Private Limited, All rights reserved\\\"},{\\\"url\\\":\\\"https://www.mongodb.com/resources/basics/knn-search\\\",\\\"title\\\":\\\"arrow-right arrow-right arrow-right arrow-right arrow-right arrow-right arrow-right arrow-right arrow-right menu-vertical\\\",\\\"content\\\":\\\"MongoDB Event MongoDB.local SF, Jan 15: See the speaker lineup & ship your AI vision faster. Use WEB50 to save 50% > AnnouncementLearn why MongoDB was named a Leader in the 2025 Gartner\\u00ae Magic Quadrant\\u2122 Learn more > General Information General Information Documentation Developer Articles & Topics Community Forums Blog University Products Platform Atlas Build and scale with an AI-ready platform Platform Services DatabaseDeploy a multi-cloud databaseSearchDeliver engaging search experiencesVector SearchDesign intelligent apps with gen AIStream ProcessingIntegrate MongoDB and Kafka Self Managed Enterprise AdvancedRun and manage MongoDB yourselfCommunity EditionDevelop locally with MongoDB Tools CompassWork with MongoDB data in a GUIIntegrationsIntegrations with third-party servicesRelational MigratorMigrate to MongoDB with confidence View All ProductsExplore our full developer suite arrow-right MongoDB 8.0Our fastest version ever arrow-right Build with MongoDB Atlas Get started for free in minutes Sign Up Test Enterprise Advanced Develop with MongoDB on-premises Download Try Community Edition Explore the latest version of MongoDB Download Resources DocumentationLearn how to build with MongoDB and get started todaySkills and CertificationsDevelop in-demand skills and earn MongoDB certificationsBooksRead books and e-books about MongoDB MongoDB for EducatorsTake advantage of educator resourcesMongoDB for StudentsTake advantage of student benefitsCommunityJoin a community of developersEvents and WebinarsFind an event or webinar near you Resources HubGet help building the next big thing with MongoDB arrow-right Solutions Use cases Artificial IntelligenceModernizationPaymentsServerless DevelopmentGamingIntelligent SearchEdge and Mobile Industries Financial ServicesTelecommunicationsHealthcareRetailPublic SectorManufacturing Solutions LibraryOrganized and tailored solutions to kick-start projects arrow-right MongoDB AMP Modernize applications up to 3x faster Learn more arrow-right Startups and AI Innovators For world-changing ideas and AI pioneers Learn more arrow-right Customer Case Studies Hear directly from our users See stories arrow-right Company CareersStart your next adventureBlogRead articles and announcementsNewsroomRead press releases and news stories PartnersLearn about our partner ecosystemLeadershipMeet our executive teamCompanyLearn more about who we are Contact Us Reach out to MongoDB Connect with an expert arrow-right Investors Visit our investor portal Learn more arrow-right Pricing Eng Support Sign In menu-vertical Get Started What is K-Nearest Neighbors (KNN) Search? Build intelligent applications powered by semantic search and generative AI using native, full-featured vector database capabilities. Get Started Get Started With MongoDB Atlas Try Free English English Portugu\\u00eas Espa\\u00f1ol \\ud55c\\uad6d\\uc5b4 \\u65e5\\u672c\\u8a9e Italiano Deutsch Fran\\u00e7ais \\u7b80\\u4f53\\u4e2d\\u6587 \\u00a9 2026 MongoDB, Inc. About Careers Investor Relations Legal Privacy Policy GitHub Security Information Trust Center Follow Us Support Contact Us Customer Portal Atlas Status Product Updates Customer Support Manage Cookies Your Privacy Choices Deployment Options MongoDB Atlas Enterprise Advanced Community Edition Data Basics Vector Databases NoSQL Databases Document Databases RAG Database ACID Transactions MERN Stack MEAN Stack \\u00a9 2026 MongoDB, Inc.\\\"},{\\\"url\\\":\\\"https://www.elastic.co/search-labs/tutorials/search-tutorial/vector-search/nearest-neighbor-search\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Explore Elastic: elastic.co Security Labs Observability Labs Tutorials Examples Integrations Blogs Start free trial Tutorials/Search Tutorial k-Nearest Neighbor (kNN) Search In this series Welcome Requirements Project Setup Full-Text Search Python Client Setup Create an Index Search Basics Pagination Filters Faceted Search Vector Search Embeddings Intro Generating Embeddings Storing Embeddings k-Nearest Neighbor Search Hybrid Search Semantic Search ELSER Model Semantic Queries Hybrid Search Conclusion Copy Share The k-nearest neighbor (kNN) algorithm performs a similarity search on fields of dense_vector type. This type of search, which is more appropriately called \\\\\\\"approximate kNN\\\\\\\", accepts a vector or embedding as a search term, and finds entries in the index that are close. In this section you are going to learn how to run a kNN search using the document embeddings created in the previous section. The In the full-text search section of the tutorial you learned about the query option passed to the search() method of the Elasticsearch client. When searching vectors, the knn option is used instead. Below you can see a new version of the handle_search() function in app.py that runs a kNN search for the query entered by the user in the search form. In this version of the function, the query option was replaced with knn. The size and from_ options for pagination remain the same, and everything else in the function and the index.html template are also the same as before. The knn search option accepts a number of parameters that configure the search: field: the field in the index to search. The field must have a dense_vector type. query_vector: the embedding to search for. This should be an embedding generated from the search text. num_candidates: the number of candidate documents to consider from each shard. Elasticsearch retrieves this many candidates from each shard, combines them into a single list and then finds the closest \\\\\\\"k\\\\\\\" to return as results. k: the number of results to return. This number has a direct effect on performance, so it should be kept as small as possible. The value passed in this option must be less than num_candidates. With the settings used in the code above, the 10 best matching results will be returned. You are welcome to experiment with this new version of the application. Here are a pair of good examples to appreciate how useful this type of search: Searching for \\\\\\\"holiday\\\\\\\", which is the British English equivalent to \\\\\\\"vacation\\\\\\\" in American English, kNN search returns the document \\\\\\\"Vacation Policy\\\\\\\" as top result, even though the word holiday itself does not appear in the document. Searching for \\\\\\\"cats and dogs\\\\\\\" or any other term related to pets brings the \\\\\\\"Office Pet Policy\\\\\\\" document as top result, even though the document summary does not mention any specific pets. Using Filters in kNN Queries The search query, as defined in the full-text section of this tutorial, allowed the user to request a specific category to be used, using the syntax category:<category-name> in any place of the search text. The extract_filters() function in app.py is in charge of finding and separating these filter expressions from the search query. In the version of the handle_search() function from the previous section the filters variable is not used, so the category filters are ignored. Luckily, the knn option also supports filtering. The filter option actually accepts the same type of filters, so the filters can be inserted directly into the knn query, exactly as they are returned by the extract_filters() function: Aggregations also work well in kNN queries, so they can also be added back: This version of the handle_search() function has the same functionality as the full-text search version, implemented using vector search instead of keyword-based search. In the next section, you'll learn how to combine results from these two different search methods. Previously Storing Embeddings Next Hybrid Search Report an issue Ready to build state of the art search experiences? Sufficiently advanced search isn\\u2019t achieved with the efforts of one. Elasticsearch is powered by data scientists, ML ops, engineers, and many more who are just as passionate about search as you are. Let\\u2019s connect and work together to build the magical search experience that will get you the results you want. Try it yourself Subscribe to newsletter Elasticsearch Labs is the one-stop destination for developers to learn how to easily utilize Elasticsearch to build advanced search experiences including generative AI, embedding models, reranking capabilities and more. Let's Connect Menu Tutorials Examples Integrations Blogs Search Additional Resources Elasticsearch API Reference Elastic.co en Sitemap RSS 2026. Elasticsearch B.V. All Rights Reserved.\\\"}]}\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Search for ML and vector search concepts\n",
    "parameters = {\n",
    "    \"question\": \"What is k-NN vector search and how does it work?\"\n",
    "}\n",
    "\n",
    "print(\"‚ùì Question: What is k-NN vector search and how does it work?\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "response = execute_agent(client, agent_id, parameters)\n",
    "\n",
    "print(\"\\nüìö Technical Information:\")\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade91ea6",
   "metadata": {},
   "source": [
    "## Step 6: Test Case 3 - Search for Current News/Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b05fd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì Question: Latest features in OpenSearch 2.11\n",
      "============================================================\n",
      "\n",
      "üì∞ Current Information:\n",
      "{\n",
      "  \"inference_results\": [\n",
      "    {\n",
      "      \"output\": [\n",
      "        {\n",
      "          \"name\": \"response\",\n",
      "          \"result\": \"{\\\"next_page\\\":\\\"https://duckduckgo.com/html?q=Latest+features+in+OpenSearch+2.11&s=10&nextParams=&v=l&o=json&dc=11&api=d.js&vqd=4-231324411429662890603570163260423810443&kl=wt-wt\\\",\\\"items\\\":[{\\\"url\\\":\\\"https://github.com/opensearch-project/opensearch-build/blob/main/release-notes/opensearch-release-notes-2.11.0.md\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to content Navigation Menu Toggle navigation Sign in Appearance settings Platform AI CODE CREATION GitHub CopilotWrite better code with AI GitHub SparkBuild and deploy intelligent apps GitHub ModelsManage and compare prompts MCP RegistryNewIntegrate external tools DEVELOPER WORKFLOWS ActionsAutomate any workflow CodespacesInstant dev environments IssuesPlan and track work Code ReviewManage code changes APPLICATION SECURITY GitHub Advanced SecurityFind and fix vulnerabilities Code securitySecure your code as you build Secret protectionStop leaks before they start EXPLORE Why GitHub Documentation Blog Changelog Marketplace View all features Solutions BY COMPANY SIZE Enterprises Small and medium teams Startups Nonprofits BY USE CASE App Modernization DevSecOps DevOps CI/CD View all use cases BY INDUSTRY Healthcare Financial services Manufacturing Government View all industries View all solutions Resources EXPLORE BY TOPIC AI Software Development DevOps Security View all topics EXPLORE BY TYPE Customer stories Events & webinars Ebooks & reports Business insights GitHub Skills SUPPORT & SERVICES Documentation Customer support Community forum Trust center Partners Open Source COMMUNITY GitHub SponsorsFund open source developers PROGRAMS Security Lab Maintainer Community Accelerator Archive Program REPOSITORIES Topics Trending Collections Enterprise ENTERPRISE SOLUTIONS Enterprise platformAI-powered developer platform AVAILABLE ADD-ONS GitHub Advanced SecurityEnterprise-grade security features Copilot for BusinessEnterprise-grade AI features Premium SupportEnterprise-grade 24/7 support Pricing Search or jump to... Search code, repositories, users, issues, pull requests... Search Clear Search syntax tips Provide feedback We read every piece of feedback, and take your input very seriously. Include my email address so I can be contacted Cancel Submit feedback Saved searches Use saved searches to filter your results more quickly Name Query To see all available qualifiers, see our documentation. Cancel Create saved search Sign in Sign up Appearance settings Resetting focus You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert {{ message }} opensearch-project / opensearch-build Public generated from amazon-archives/__template_Apache-2.0 Notifications You must be signed in to change notification settings Fork 316 Star 185 Code Issues 177 Pull requests 20 Discussions Actions Projects 3 Wiki Security Uh oh! There was an error while loading. Please reload this page. Insights Additional navigation options Code Issues Pull requests Discussions Actions Projects Wiki Security Insights Footer \\u00a9 2026 GitHub, Inc. Footer navigation Terms Privacy Security Status Community Docs Contact Manage cookies Do not share my personal information You can\\u2019t perform that action at this time.\\\"},{\\\"url\\\":\\\"https://opensearch.org/blog/get-started-opensearch-2-11/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to main content Search Close Search search Menu About Foundation Governing Board Charter Meeting Calendar Platform Platform OpenSearch CoreOpenSearch is a powerful search and analytics engine built on Apache Lucene. OpenSearch DashboardsOur data visualization toolset is a flexible, fully integrated solution for visually exploring and querying your data. OpenSearch Data PrepperA server-side data collector designed to enrich, transform, and aggregate data for downstream analytics with Opensearch. OpenSearch Vector EnginePower machine learning and generative AI applications with a high-performance database designed for the way AI understands data. Capabilities Machine learning and AI Vector Search Anomaly Detection Search E-Commerce Document Search Search Relevance Observability Performance Monitoring Log Analytics Security Analytics Threat Intelligence Event Correlation Performance Benchmarks View key performance metrics across different workloads View Data Roadmap Image OpenSearch Project RoadmapExplore our official project roadmap on GitHub Community OpenSearch Community ForumFind answers to your questions, help others in the community, and join the conversation. EventsCommunity Meetings, Development Backlog & Triage, in-person, and virtual events. AmbassadorsAmbassadors Community leaders who share knowledge and grow OpenSearch. Solutions ProvidersFind open-source providers offering solutions and services. ProjectsHighlights of projects built by the community. User GroupsJoin the OpenSearch Project Meetup Network Community Resources SlackSpeak with other developers. GitHub Project OrganizationJoin us for in-person and virtual events to learn the latest about the project. OpenSearchCon Image OpenSearchCon China17-18 March 2026 | Shanghai, China OpenSearchCon Europe16-17 April 2026 | Prague, Czechia OpenSearchCon India15-16 June 2026 | Mumbai, India Documentation Documentation Library OpenSearch and DashboardsBuild your OpenSearch solution using core tooling and visualizations. OpenSearch Data PrepperFilter, mutate, and sample your data for ingestion into OpenSearch. Migration AssistantBegin your transition to OpenSearch with our migration toolkit Documentation Library II OpenSearch BenchmarkMeasure performance metrics for your OpenSearch cluster. ClientsInteract with OpenSearch from your application using language APIs. Blog & News Blog Announcements Case Studies News Authors Downloads search Blog Get started with OpenSearch 2.11 By James McIntyreOctober 16, 2023June 18th, 2025No Comments OpenSearch 2.11 is now available, with exciting new capabilities for observability applications, an expanded selection of search tools, enhancements to data durability, and more, along with new experimental functionality to explore. For a complete view of what\\u2019s new in this release, see the release notes, and you can give OpenSearch Dashboards a try on OpenSearch Playground. An easier way to infuse multimodal search into your applications This release introduces text and image multimodal search using neural search. This functionality allows users to search image and text pairs, like product catalog items (product image and description), based on visual and semantic similarity. This enables new search experiences that can deliver more relevant results. For instance, users can search for \\u201cwhite blouse\\u201d to retrieve product images\\u2014the machine learning (ML) model that powers this experience is able to associate semantics and visual characteristics. Users can also search by image to retrieve visually similar products or search by both text and image to find the products most similar to a particular product catalog item. You can now build these capabilities into your application to connect directly to multimodal models and run multimodal search queries without having to build custom middleware. See the multimodal search documentation for guidance on how to get started with multimodal semantic search, and look out for more input types to be added to this functionality in future releases. Choose the best retrieval method for semantic search applications Previously, OpenSearch offered only a dense retrieval approach for text-based vector search. With this release, search practitioners can now choose between sparse retrieval or dense retrieval methods for semantic search applications. Each method presents tradeoffs for users, depending on their application; for example, dense retrieval typically delivers high search relevance while consuming more memory and compute resources and has higher latencies. In comparison, the new sparse retrieval functionality offers two modes with different advantages: a document-only mode can deliver low-latency performance more comparable to BM25 search, with limitations for advanced syntax as compared to dense methods, and a bi-encoder mode can maximize search relevance while performing at higher latencies. With this update, users can now choose the method that works best for their performance, accuracy, and cost requirements. For an in-depth exploration of each method and their advantages for different workloads, stay tuned for an upcoming blog post. Compare and tune your search results Introduced in OpenSearch 2.4 as experimental functionality, this release makes the search comparison tool generally available for production workloads. This tool lets you compare the results of two different search queries side by side in OpenSearch Dashboards, as shown in the following example UI. As an example, you can compare the results of a lexical search against the results from a semantic search query so that you can view both rankings and tune your results accordingly. Protect data efficiently with interoperability between snapshots and remote-backed storage Today, OpenSearch offers two built-in ways to enhance data durability: remote-backed storage, which gives you the option to automatically store all transactions on a per-index basis using your choice of cloud storage services, and snapshots, which let you create an on-demand snapshot of a cluster\\u2019s indexes and metadata in a configured repository. With this feature, you have the option to use snapshots more efficiently, with less demand on compute resources, by taking snapshots that refer to data in your remote-backed repository rather than duplicating the data in full. Usability improvements for Security Analytics Following from the results of a recent usability study, this release brings updates to the user experience designed to make it easier to get started with Security Analytics. A new workflow simplifies the process of creating threat detectors and setting up alerts within OpenSearch Dashboards, reducing the number of steps and clarifying certain form fields. Another change adds categories to log types, organizing prepackaged and custom logs into predefined categories for easier filtering and sorting. Improving the security posture of OpenSearch Dashboards OpenSearch 2.11 marks the culmination of a long-term project with the goal of removing dependencies on AngularJS from OpenSearch Dashboards. With AngularJS having reached end-of-life, this step will help to modernize and improve the security posture of OpenSearch Dashboards. For a detailed view of what has changed and how it may affect users, please review this recently published notice in GitHub. Bringing authorization to the REST layer for plugin development REST layer authorization empowers plugin developers to establish secure access controls for REST endpoints in addition to transport layer authorization. Previously, OpenSearch exclusively enforced authorization checks at the transport layer. Given that extensions solely interact with the OpenSearch cluster through the REST layer, the introduction of extensions necessitated the implementation of authorization checks at that layer. Now offered as an independent feature, this enables plugin developers to incorporate routes with an additional layer of security. Integration of this functionality with the extension framework is currently under development. Experimental features OpenSearch 2.11 includes experimental features designed to allow users to preview new tools before they are generally available. Experimental features should not be used in a production environment. Track OpenSearch requests with traces OpenSearch 2.11 introduces the ability to trace OpenSearch requests and tasks as an experimental functionality. With this release, OpenSearch introduces a new framework that allows developers to follow OpenSearch requests and tasks as they traverse components and services across the distributed architecture. Users can also enable this functionality in order to trace their requests and monitor their paths through the system, measure request latencies, and more. This release enables this functionality at the network layer, REST layer, and transport layer. As development of the feature continues, additional capabilities will address collecting trace and span data at different levels of granularity and with different code paths. Refer to the documentation to learn more and see how you can explore these capabilities. To share feedback, please see our request for comments. Customize pipelines for retrieval augmented generation Enhancing the conversational search functionality introduced in OpenSearch 2.10 as an experimental toolkit, this release introduces several new parameters that can be used to customize retrieval augmented generation (RAG) pipelines. These optional parameters provide core logic that allows you to adapt the way OpenSearch interacts with large language models (LLMs) as part of generative artificial intelligence (GenAI) applications. See the documentation for this feature to explore the available parameters. The latest version of OpenSearch is ready for download! You can find out more about these features and many others in the release notes and the documentation release notes as well as the documentation. OpenSearch Playground offers a turnkey option for exploring the visualization toolkit before downloading it. Look for upcoming blog posts that dive deeper into the new functionality delivered in OpenSearch 2.11. Share or Summarize with AI ClaudeChatGPTGoogle AIGeminiGrokPerplexityTwitter (X)LinkedInWhatsAppEmail Author James McIntyre James McIntyre is a senior product marketing manager with AWS serving the OpenSearch Project and chair of the OpenSearch Software Foundation Marketing Outreach Committee. View all posts Share Subscribe for updates, event info, and the latest community news OpenSearch is a community-driven, Apache 2.0-licensed open source search and analytics suite that makes it easy to ingest, search, visualize, and analyze data. [social-icons-display order=\\u201dlinkedin,github,slack,youtube,mastodon,bluesky,twitter\\u201d] Participate Code of Conduct Forum Project Repo Community Repo Meetup Connect Providers Become a Provider Find a Provider Resources About FAQ Release Schedule Maintenance Policy Documentation Getting Started Testimonials Trademark & Brand Privacy \\u00a9 Copyright The Linux Foundation. The OpenSearch Project is a project of The Linux Foundation. For web site terms of use, trademark policy and other policies applicable to The OpenSearch Project please see Linux Foundation Policies. The OpenSearch Project supports the OpenSearch open source project, which has been established as OpenSearch Project a Series of LF Projects, LLC. For policies applicable to the OpenSearch Project a Series of LF Projects, LLC, please see LF Projects, LLC Policies, Privacy Policy, Terms of Use and the OpenSearch Trademark Policy. Close Menu About Foundation Governing Board Charter Meeting Calendar Platform Platform OpenSearch CoreOpenSearch is a powerful search and analytics engine built on Apache Lucene. OpenSearch DashboardsOur data visualization toolset is a flexible, fully integrated solution for visually exploring and querying your data. OpenSearch Data PrepperA server-side data collector designed to enrich, transform, and aggregate data for downstream analytics with Opensearch. OpenSearch Vector EnginePower machine learning and generative AI applications with a high-performance database designed for the way AI understands data. Capabilities Machine learning and AI Vector Search Anomaly Detection Search E-Commerce Document Search Search Relevance Observability Performance Monitoring Log Analytics Security Analytics Threat Intelligence Event Correlation Performance Benchmarks View key performance metrics across different workloads View Data Roadmap Image OpenSearch Project RoadmapExplore our official project roadmap on GitHub Community OpenSearch Community ForumFind answers to your questions, help others in the community, and join the conversation. EventsCommunity Meetings, Development Backlog & Triage, in-person, and virtual events. AmbassadorsAmbassadors Community leaders who share knowledge and grow OpenSearch. Solutions ProvidersFind open-source providers offering solutions and services. ProjectsHighlights of projects built by the community. User GroupsJoin the OpenSearch Project Meetup Network Community Resources SlackSpeak with other developers. GitHub Project OrganizationJoin us for in-person and virtual events to learn the latest about the project. OpenSearchCon Image OpenSearchCon China17-18 March 2026 | Shanghai, China OpenSearchCon Europe16-17 April 2026 | Prague, Czechia OpenSearchCon India15-16 June 2026 | Mumbai, India Documentation Documentation Library OpenSearch and DashboardsBuild your OpenSearch solution using core tooling and visualizations. OpenSearch Data PrepperFilter, mutate, and sample your data for ingestion into OpenSearch. Migration AssistantBegin your transition to OpenSearch with our migration toolkit Documentation Library II OpenSearch BenchmarkMeasure performance metrics for your OpenSearch cluster. ClientsInteract with OpenSearch from your application using language APIs. Blog & News Blog Announcements Case Studies News Authors Downloads\\\"},{\\\"url\\\":\\\"https://aws.amazon.com/about-aws/whats-new/2023/11/amazon-opensearch-supports-version-2-11/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to main content Click here to return to Amazon Web Services homepage About AWS Contact Us Support English My Account Sign In Create an AWS Account Close Profile Your profile helps improve your interactions with select AWS experiences. Login Close Profile Your profile helps improve your interactions with select AWS experiences. View profile Log out Amazon Q Products Solutions Pricing Documentation Learn Partner Network AWS Marketplace Customer Enablement Events Explore More Close \\u0639\\u0631\\u0628\\u064a Bahasa Indonesia Deutsch English Espa\\u00f1ol Fran\\u00e7ais Italiano Portugu\\u00eas Ti\\u1ebfng Vi\\u1ec7t T\\u00fcrk\\u00e7e \\u03a1\\u0443\\u0441\\u0441\\u043a\\u0438\\u0439 \\u0e44\\u0e17\\u0e22 \\u65e5\\u672c\\u8a9e \\ud55c\\uad6d\\uc5b4 \\u4e2d\\u6587 (\\u7b80\\u4f53) \\u4e2d\\u6587 (\\u7e41\\u9ad4) Close My Profile Sign out of AWS Builder ID AWS Management Console Account Settings Billing & Cost Management Security Credentials AWS Personal Health Dashboard Close Support Center Expert Help Knowledge Center AWS Support Overview AWS re:Post Click here to return to Amazon Web Services homepage Get Started for Free Contact Us Products Solutions Pricing Introduction to AWS Getting Started Documentation Training and Certification Developer Center Customer Success Partner Network AWS Marketplace Support AWS re:Post Log into Console Download the Mobile App Amazon OpenSearch Service now supports OpenSearch version 2.11 Posted On: Nov 20, 2023 You can now run OpenSearch version 2.11 in Amazon OpenSearch Service. With OpenSearch 2.11, we have made several improvements to search, observability, security analytics, and OpenSearch Dashboards. This version includes features that were launched as part of open source OpenSearch versions 2.10 and 2.11. This launch includes the introduction of hybrid search queries, which uses normalization processors to improve search relevance, by combining relevance scores of lexical queries with natural language-based k-NN vector search queries. It also includes multimodal search, which allows users to search image and text pairs like product catalog items, and the introduction of neural sparse retrieval in addition to existing dense retrieval for semantic search applications. Search practitioners can test out these new search methods with the new search comparison tool which lets you compare the results of two different search queries side by side in OpenSearch Dashboards. Security Analytics now provides threat detection capabilities to detect malicious activity and adds custom log categories for easier filtering and sorting. Other improvements include a new visual theme and a discover tool for a more user-friendly Dashboards environment, and a new IP2Geo processor that allows users to retrieve the geographical location of an IPv4 or IPv6 address, and add that information to incoming data during ingest or at a later time, as required. For information on upgrading to OpenSearch 2.11, please see this documentation. OpenSearch 2.11 is now available in all AWS Regions where Amazon OpenSearch Service is available. \\u00bb Sign In to the Console Learn About AWS What Is AWS? What Is Cloud Computing? AWS Accessibility What Is DevOps? What Is a Container? What Is a Data Lake? What is Artificial Intelligence (AI)? What is Generative AI? What is Machine Learning (ML)? AWS Cloud Security What's New Blogs Press Releases Resources for AWS Getting Started Training and Certification AWS Trust Center AWS Solutions Library Architecture Center Product and Technical FAQs Analyst Reports AWS Partners Developers on AWS Developer Center SDKs & Tools .NET on AWS Python on AWS Java on AWS PHP on AWS JavaScript on AWS Help Contact Us Get Expert Help File a Support Ticket AWS re:Post Knowledge Center AWS Support Overview Legal AWS Careers Create an AWS Account Amazon is an Equal Opportunity Employer: Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age. Language \\u0639\\u0631\\u0628\\u064a Bahasa Indonesia Deutsch English Espa\\u00f1ol Fran\\u00e7ais Italiano Portugu\\u00eas Ti\\u1ebfng Vi\\u1ec7t T\\u00fcrk\\u00e7e \\u03a1\\u0443\\u0441\\u0441\\u043a\\u0438\\u0439 \\u0e44\\u0e17\\u0e22 \\u65e5\\u672c\\u8a9e \\ud55c\\uad6d\\uc5b4 \\u4e2d\\u6587 (\\u7b80\\u4f53) \\u4e2d\\u6587 (\\u7e41\\u9ad4) Privacy | Accessibility | Site Terms | Cookie Preferences | \\u00a9 2025, Amazon Web Services, Inc. or its affiliates. All rights reserved. Ending Support for Internet Explorer Got it AWS support for Internet Explorer ends on 07/31/2022. Supported browsers are Chrome, Firefox, Edge, and Safari. Learn more \\u00bb Got it\\\"},{\\\"url\\\":\\\"https://opensearch.isharkfly.com/release-notes/opensearch-documentation-release-notes-2.11.0/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu OpenSearchCon 2024 - Stay Informed Sessions Speakers Exhibitors Workshops Unconference CFP is closed Download About Releases Roadmap FAQ Community Blog Forum Slack Events Partners Projects Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home API Style Guide Formatting Guide OpenSearch Documentation Website 2.10.0 Release Notes OpenSearch Documentation Website 2.11.0 Release Notes OpenSearch Documentation Website 2.12.0 Release Notes OpenSearch Documentation Website 2.4.0 Release Notes OpenSearch Documentation Website 2.5.0 Release Notes OpenSearch Documentation Website 2.6.0 Release Notes OpenSearch Documentation Website 2.7.0 Release Notes OpenSearch Documentation Website 2.8.0 Release Notes OpenSearch Documentation Website 2.9.0 Release Notes OpenSearch Project Style Guidelines OpenSearch terms Overview About OpenSearch Intro to OpenSearch Quickstart Version history Breaking changes Install and upgrade Installing OpenSearch Docker Helm Tarball RPM Debian Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Circuit breaker settings Cluster settings Index settings Search settings Availability and recovery settings Plugin settings Experimental feature flags Logs Configuring OpenSearch Dashboards Upgrading OpenSearch Rolling Upgrade Upgrades appendix Rolling upgrade lab Installing plugins Managing OpenSearch Dashboards plugins Migrate to OpenSearch Using snapshots to migrate data Migrating from Elasticsearch OSS to OpenSearch Migrating Docker clusters to OpenSearch Migrating from Kibana OSS to OpenSearch Dashboards Managing Indexes Index templates Index aliases Data streams Reindex data Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings Index management security Refresh search analyzer ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Ingest Pipelines Create pipeline Simulate pipeline Get pipeline Delete pipeline Handling pipeline failures Ingest processors Append Bytes Convert Copy CSV Date Date index name Dissect Dot expander Drop IP2Geo Grok KV Lowercase Remove_by_pattern Remove Sparse encoding Text embedding Text/image embedding Uppercase OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Analyzing data Time filter Creating dashboards Building data visualizations Using area charts Using coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using the self-host maps server Using Gantt charts Using VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimize query performance using OpenSearch indexing Dev Tools Running queries in the Dev Tools console Query Workbench Custom branding Dashboards Query Language (DQL) Search telemetry OpenSearch Integrations Creating and tuning your cluster Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Remote cluster state Remote segment backpressure Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Tuning for indexing speed Security in OpenSearch Configuration Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates Generating self-signed certificates Applying changes to configuration files API rate limiting Configuring sign-in options Disabling security OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Access control REST layer authorization Document-level security Users and roles Field-level security Field masking User impersonation Cross-cluster search Permissions Default action groups API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Creating detectors Supported log types Creating correlation rules Creating custom log types Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Security Analytics settings Mappings and field types Supported field types Alias Binary Numeric field types Unsigned long Boolean Date field types Date Date nanoseconds IP address Range field types Object field types Object Nested Flat object Join String field types Keyword Text Match-only text Token count Autocomplete field types Completion Search as you type Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape k-NN vector Rank field types Percolator Text analysis Language analyzers Index analyzers Search analyzers Tokenizers Token filters Delimited term frequency Normalizers Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Exists Fuzzy IDs Prefix Range Regexp Term Terms Terms set Wildcard Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box xy Span queries Match all queries Specialized queries Neural Neural sparse Script score Minimum should match Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Matrix stats Maximum Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Bucket aggregations Adjacency matrix Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Range Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Search Searching data Paginate results Point in Time Point in Time API Sort results Highlight query matches Autocomplete Did-you-mean Keyword search k-NN search k-NN index Exact k-NN with scoring script Approximate k-NN search k-NN search with filters k-NN search with nested fields k-NN Painless extensions API JNI libraries Settings Performance tuning Neural search Neural search tutorial Semantic search Multimodal search Neural sparse search Hybrid search Conversational search Search relevance Comparing search results Reranking search results Querqy Search pipelines Creating a search pipeline Using a search pipeline Retrieving search pipelines Search processors Collapse Filter query Neural query enricher Normalization Oversample Personalize search ranking Retrieval-augmented generation Rename field Rerank Script Truncate hits Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic Queries Complex Queries Functions JSON Support Metadata Queries Aggregate Functions Delete JDBC Driver ODBC Driver PPL Syntax Commands Identifiers Data Types Functions Full-Text Search Settings Troubleshooting Monitoring Limitations Machine learning ML Commons cluster settings Integrating ML models Model access control Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Connector blueprints Agents and tools Agents and tools tutorial Tools Agent tool CAT Index tool Index Mapping tool ML Model tool Neural Sparse Search tool PPL tool RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool OpenSearch Assistant Toolkit Managing ML models in OpenSearch Dashboards Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Model group APIs Register model group Update model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Execute agent Get agent Search agent Delete agent Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller Execute algorithm Tasks APIs Get task Search task Delete task Train and Predict APIs Train and predict Train Predict Profile Stats Automating configurations Workflow steps Workflow tutorial Workflow settings Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Monitoring your cluster Job Scheduler Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metrics analytics Query insights Top N queries Trace Analytics Getting Started OpenSearch Dashboards plugin Analyzing Jaeger trace data Distrbuted tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detection visualizations and dashboards Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI OpenSearch Kubernetes Operator Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana API reference Analyze API Analysis API Terminology CAT API CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices operation CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster routing and awareness Cluster decommission Cluster health Cluster settings Cluster stats Count Document APIs Index document Get document Update document Delete document Bulk Multi-get document Delete by query Update by query Reindex document Explain Index APIs Alias Clear cache Clone index Close index Create index Create or update mappings Dangling indexes Delete index Force merge Get index Get settings Index exists Open index Shrink index Split index Stats Update settings Ingest APIs Multi-search Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Profile Ranking evaluation Remote cluster information Script APIs Create or Update Stored Script Execute Painless stored script Get Stored Script Delete Script Get Stored Script Contexts Get Script Language Execute Painless script Scroll Search Search templates Snapshot APIs Register Snapshot Repository Get Snapshot Repository Delete Snapshot Repository Verify Snaphot Repository Create Snapshot Get Snapshot Delete Snapshot Get Snapshot Status Restore Snapshot Tasks Supported units Common REST Parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Extensions OpenSearch Documentation Website 2.11.0 Release Notes The OpenSearch 2.11.0 documentation includes the following additions and updates. New documentation for 2.11.0 Add Conversational Search changes for 2.11 #5195 Remove warning about alerting and segment replication compatibility #5191 Add documentation for log type categories #5181 Add updates to creating a detector UX #5176 Add multimodal search/sparse search/pre- and post-processing function documentation #5168 Add documentation for new recovery setting #5162 Add terminate after behavior to concurrent segment search #5143 Add documentation for configurable merge policy #5137 Remove experimental header from search comparison tool #5124 Add documentation about setting a default model for neural search #5121 Add total wait time to thread pool in nodes stats #5120 Add new documentation for distributed tracing #4964 Add documentation for authorization on the REST layer #4544 New documentation for 2.11.0 WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links \\u53c2\\u4e0e\\u9879\\u76ee\\uff08Get Involved\\uff09 Code of Conduct OpenSearch \\u4e2d\\u6587\\u8bba\\u575b \\u5b98\\u65b9\\u8bba\\u575b \\u4e2d\\u6587\\u6587\\u6863\\u4ee3\\u7801\\u4ed3\\u5e93 \\u5b98\\u65b9 Github Slack \\u793e\\u533a\\u9879\\u76ee \\u8d44\\u6e90\\uff08Resources\\uff09 About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy \\u8054\\u7cfb\\u6211\\u4eec\\uff08Contact Us\\uff09 \\u8054\\u7cfb\\uff08Connect\\uff09 Twitter LinkedIn YouTube Meetup Facebook \\u00a9 OpenSearch contributors, 2024. OpenSearch is a registered trademark of Amazon Web Services. \\u00a9 2005-2021 Django Software Foundation and individual contributors. Django is a registered trademark of the Django Software Foundation. This website was forked from the BSD-licensed djangoproject.com originally designed by Threespot & andrevv.\\\"},null,{\\\"url\\\":\\\"https://docs.opensearch.org/latest/version-history/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Discovery and cluster formation Node discovery and seed hosts Voting and quorum Voting configuration management Cluster bootstrapping Discovery and cluster formation settings Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Remote segment warmer Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Similarity Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Resource access management Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates OpenSearch FIPS configuration Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control Defining users and roles Permissions Default action groups REST layer authorization Document-level security Field-level security Field masking User impersonation Resource sharing and access control Resource sharing APIs API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Version Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Mapping explosion Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Rescore Regular expression syntax SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic queries Complex queries Functions JSON support Metadata queries Aggregate functions Delete JDBC driver ODBC driver PPL Subsearch Commands PPL syntax ad addcoltotals addtotals append appendcol appendpipe bin chart dedup describe eval eventstats expand explain fields fillnull flatten grok head join kmeans lookup ml multisearch parse patterns rare regex rename replace reverse rex search show datasources sort spath stats streamstats subquery table timechart top trendline where Identifiers Data types Functions Full-text search Settings Troubleshooting Monitoring Limitations Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Collecting UBI-formatted data in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Model access control through resource sharing Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller ML Tasks APIs Get ML task Search ML tasks Delete ML task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow access control Workflow settings Workflow state access control Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detector access control Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecaster access control Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions About OpenSearch Version history Version history OpenSearch version Release highlights Release date 3.4.0 Introduces PPL alerting capabilities with monitor execution and stats management. Adds Anomaly Detection Daily Insights Page and Flow Framework enhancements including agent summary and MCP server support. Includes k-NN memory-optimized search warmup, native FP16 vector scoring, and enhanced resource sharing frameworks. Features infrastructure upgrades including JDK 25 and improved access control. For a full list of release highlights, see the Release Notes. 16 December 2025 3.3.2 Includes maintenance changes and bug fixes for the OpenSearch core engine and ML Commons, Neural Search, Skills, k-NN and Security plugins. For a full list of release highlights, see the Release Notes. 30 October 2025 3.3.1 Fixes backward compatibility handling of date fields while maintaining performance optimizations. The skip_list parameter is now automatically set to true for new @timestamp fields created since 3.3.0, while preserving skip_list=false for existing indexes with @timestamp or index sort date fields. This approach ensures date histogram aggregation performance benefits for new indexes while maintaining compatibility with existing workloads. For a full list of release highlights, see the Release Notes. 22 October 2025 3.3.0 Introduces redesigned Discover interface with log analytics and distributed tracing capabilities, and Apache Calcite as default PPL query engine with expanded functions. Makes agentic search and agentic memory APIs generally available for AI applications. Implements Seismic algorithm for neural sparse search performance improvements and processor chains for data transformation pipelines. Expands gRPC support for additional query types and adds experimental streaming with Apache Arrow Flight. Includes workload management enhancements with rule-based auto-tagging and query monitoring capabilities. For a full list of release highlights, see the Release Notes. 14 October 2025 3.2.0 Updates Search Relevance Workbench. Makes gRPC APIs generally available. Introduces derived source, updates workload management, semantic field, and star tree functionality. Adds experimental Agentic Memory APIs and Job Scheduler APIs. For a full list of release highlights, see the Release Notes. 19 August 2025 3.1.0 Makes GPU acceleration for vector index builds generally available. Introduces memory-optimized search for Faiss indexes using Lucene HNSW, semantic field type for streamlined semantic search, and Search Relevance Workbench for search quality optimization. Makes star-tree indexes generally available with support for comprehensive query types. Enhances observability with ML Commons metrics integration, custom index support for OpenTelemetry data, and new PPL commands for JSON manipulation. Improves agent management with Update Agent API and persistent MCP tools. Includes security enhancements with immutable user objects and new resource sharing framework. For a full list of release highlights, see the Release Notes. 24 June 2025 3.0.0 Upgrades to Lucene 10 for improved indexing and vector search. Adds experimental gRPC support and pull-based ingestion from Kafka and Kinesis. Introduces GPU acceleration for vector operations and semantic sentence highlighting. Improves range query performance and hybrid search with z-score normalization. Adds plan-execute-reflect agents and native MCP protocol support for agentic workflows. Enhances security with a new Java agent replacing the Security Manager. Includes PPL query improvements with lookup, join, and subsearch commands. For a full list of release highlights, see the Release Notes. 06 May 2025 2.19.4 Fixes critical security vulnerabilities across multiple components including ML Commons, Query Insights Dashboards, and SQL. Resolves bugs in Flow Framework multi-tenancy, Security wildcard matching, and Query Insights time validation. Includes extensive CVE fixes and dependency updates across dashboards plugins. For a full list of release highlights, see the Release Notes. 06 November 2025 2.19.3 Improves Flow Framework with enhanced memory handling and workflow step processing. Fixes several Query Insights and Query Insights Dashboards issues. Implements security updates across multiple components. Updates infrastructure components and documentation across multiple plugins. For a full list of release highlights, see the Release Notes. 22 July 2025 2.19.2 Improves query insights with better index handling, a new verbose API parameter, and a default index template. Fixes bugs across Query Insights, Observability, Flow Framework, and Dashboards. Includes multiple CVE fixes, test enhancements, and a new PGP key for artifact verification. For a full list of release highlights, see the Release Notes. 29 April 2025 2.19.1 Adds execution hint for cardinality aggregator. Includes bug fixes for ML Commons, Query Insights Dashboards, and Remote Metadata SDK. Contains maintenance updates for several components. For a full list of release highlights, see the Release Notes. 27 February 2025 2.19.0 Adds workload management, additional query insights, and template queries. Introduces a query insights page to OpenSearch Dashboards. Includes improvements and bug fixes to snapshots, search statistics, star-tree search, and index management. For a full list of release highlights, see the Release Notes. 11 February 2025 2.18.0 Adds a redesigned home page, updated Discover interface, and collaborative workspaces to OpenSearch Dashboards. Includes improvements to ML inference processor and query grouping. Introduces reranking by field and paginated CAT APIs. Includes experimental OpenSearch Dashboards Assistant capabilities. For a full list of release highlights, see the Release Notes. 05 November 2024 2.17.1 Includes bug fixes for ML Commons, anomaly detection, k-NN, and security analytics. Adds various infrastructure and maintenance updates. For a full list of release highlights, see the Release Notes. 1 October 2024 2.17.0 Includes disk-optimized vector search, binary quantization, and byte vector encoding in k-NN. Adds asynchronous batch ingestion for ML tasks. Provides search and query performance enhancements and a new custom trace source in trace analytics. Includes application-based configuration templates. For a full list of release highlights, see the Release Notes. 17 September 2024 2.16.0 Includes built-in byte vector quantization and binary vector support in k-NN. Adds new sort, split, and ML inference search processors for search pipelines. Provides application-based configuration templates and additional plugins to integrate multiple data sources in OpenSearch Dashboards. Includes an experimental Batch Predict ML Commons API. For a full list of release highlights, see the Release Notes. 06 August 2024 2.15.0 Includes parallel ingestion processing, SIMD support for exact search, and the ability to disable doc values for the k-NN field. Adds wildcard and derived field types. Improves performance for single-cardinality aggregations, rolling upgrades to remote-backed clusters, and more metrics for top N queries. For a full list of release highlights, see the Release Notes. 25 June 2024 2.14.0 Includes performance improvements to hybrid search and date histogram queries with multi-range traversal, ML model integration within the Ingest API, semantic cache for LangChain applications, low-level vector query interface for neural sparse queries, and improved k-NN search filtering. Provides an experimental tiered cache feature. For a full list of release highlights, see the Release Notes. 14 May 2024 2.13.0 Makes agents and tools and the OpenSearch Assistant Toolkit generally available. Introduces vector quantization within OpenSearch. Adds LLM guardrails and hybrid search with aggregations. Adds the Bloom filter skipping index for Apache Spark data sources, I/O-based admission control, and the ability to add an alerting cluster that manages all alerting tasks. For a full list of release highlights, see the Release Notes. 2 April 2024 2.12.0 Makes concurrent segment search and conversational search generally available. Provides an experimental OpenSearch Assistant Toolkit, including agents and tools, workflow automation, and OpenSearch Assistant for OpenSearch Dashboards UI. Adds a new match-only text field, query insights to monitor top N queries, and k-NN search on nested fields. For a full list of release highlights, see the Release Notes. 20 February 2024 2.11.1 Includes maintenance changes and bug fixes for cross-cluster replication, alerting, observability, OpenSearch Dashboards, index management, machine learning, security, and security analytics. For a full list of release highlights, see the Release Notes. 30 November 2023 2.11.0 Adds multimodal and sparse neural search capability and the ability to take shallow snapshots that refer to data stored in remote-backed storage. Makes the search comparison tool generally available. Includes a simplified workflow to create threat detectors in Security Analytics and improved security in OpenSearch Dashboards. Experimental features include a new framework and toolset for distributed tracing and updates to conversational search. For a full list of release highlights, see the Release Notes. 16 October 2023 2.10.0 Makes remote-backed storage generally available. Adds hybrid search capability, custom log types for Security Analytics, IP2Geo ingest processor, and delimited term frequency token filter. Includes a new look and feel for OpenSearch Dashboards and updates the Discover tool. Adds Microsoft Teams webhook support for notifications. Experimental features include concurrent segment search and conversational search. For a full list of release highlights, see the Release Notes. 25 September 2023 2.9.0 Makes search pipelines and the Neural Search plugin generally available. Adds ML model access control and integration with external ML tools. Implements k-NN byte vectors and efficient filtering with the Faiss engine. Integrates alerting and anomaly detection with OpenSearch Dashboards and adds composite monitors. Adds two new index codec algorithm options. Includes a new ingestion schema for Security Analytics, geoshape aggregations, and extensions\\u2014a new mechanism for extending OpenSearch functionality. For a full list of release highlights, see the Release Notes. 24 July 2023 2.8.0 Adds cross-cluster query with PPL, search pipelines, an option to turn on segment replication as the default replication type, improved searchable snapshot performance, and Amazon OpenSearch Serverless support with SigV4 authentication for multiple data sources. Includes the UI for the flush, refresh, and clear cache operations in OpenSearch Dashboards. For a full list of release highlights, see the Release Notes. 06 June 2023 2.7.0 Includes searchable snapshots and segment replication, which are now generally available. Adds multiple data sources, observability features, dynamic tenant management, component templates, and shape-based map filters in OpenSearch Dashboards. Includes the flat object field type, hot shard identification, and a new automatic reloading mechanism for ML models. For a full list of release highlights, see the Release Notes. 02 May 2023 2.6.0 Includes simple schema for observability, index management UI enhancements, Security Analytics enhancements, search backpressure at the coordinator node level, and the ability to add maps to dashboards. Experimental features include a new ML model health dashboard, new text embedding models in ML, and SigV4 authentication in Dashboards. For a full list of release highlights, see the Release Notes. 28 February 2023 2.5.0 Includes index management UI enhancements, multi-layer maps, Jaeger support for observability, Debian distributions, returning cluster health by awareness attribute, cluster manager task throttling, weighted zonal search request routing policy, and query string support in index rollups. Experimental features include request-level durability in remote-backed storage and GPU acceleration for ML nodes. For a full list of release highlights, see the Release Notes. 24 January 2023 2.4.1 Includes maintenance changes and bug fixes for gradle check and indexing pressure tests. Adds support for skipping changelog. For a full list of release highlights, see the Release Notes. 13 December 2022 2.4.0 Includes Windows support, Point-in-time search, custom k-NN filtering, xy_point and xy_shape field types for Cartesian coordinates, GeoHex grid aggregation, and resilience enhancements, including search backpressure. In OpenSearch Dashboards, this release adds snapshot restore functionality, multiple authentication, and aggregate view of saved objects. This release includes the following experimental features: searchable snapshots, Compare Search Results, multiple data sources in OpenSearch Dashboards, a new Model Serving Framework in ML Commons, a new Neural Search plugin that supports semantic search, and a new Security Analytics plugin to analyze security logs. For a full list of release highlights, see the Release Notes. 15 November 2022 2.3.0 This release includes the following experimental features: segment replication, remote-backed storage, and drag and drop for OpenSearch Dashboards. Experimental features allow you to test new functionality in OpenSearch. Because these features are still being developed, your testing and feedback can help shape the development of the feature before it\\u2019s official released. We do not recommend use of experimental features in production. Additionally, this release adds maketime and makedate datetime functions for the SQL plugin. Creates a new OpenSearch Playground demo site for OpenSearch Dashboards. For a full list of release highlights, see the Release Notes. 14 September 2022 2.2.1 Includes gradle updates and bug fixes for gradle check. For a full list of release highlights, see the Release Notes. 01 September 2022 2.2.0 Includes support for Logistic Regression and RCF Summarize machine learning algorithms in ML Commons, Lucene or C-based Nmslib and Faiss libraries for approximate k-NN search, search by relevance using SQL and PPL queries, custom region maps for visualizations, and rollup enhancements. For a full list of release highlights, see the Release Notes. 11 August 2022 2.1.0 Includes support for dedicated ML node in the ML Commons plugin, relevance search and other features in SQL, multi-terms aggregation, and Snapshot Management. For a full list of release highlights, see the Release Notes. 07 July 2022 2.0.1 Includes bug fixes and maintenance updates for Alerting and Anomaly Detection. For a full list of release highlights, see the Release Notes. 16 June 2022 2.0.0 Includes document-level monitors for alerting, OpenSearch Notifications plugins, and Geo Map Tiles in OpenSearch Dashboards. Also adds support for Lucene 9 and bug fixes for all OpenSearch plugins. For a full list of release highlights, see the Release Notes. 26 May 2022 2.0.0-rc1 The Release Candidate for 2.0.0. This version allows you to preview the upcoming 2.0.0 release before the GA release. The preview release adds document-level alerting, support for Lucene 9, and the ability to use term lookup queries in document level security. For a full list of release highlights, see the Release Notes. 03 May 2022 1.3.20 Includes enhancements to Anomaly Detection Dashboards, bug fixes for Alerting and Dashboards Reports, and maintenance updates for several OpenSearch components. For a full list of release highlights, see the Release Notes. 11 December 2024 1.3.19 Includes bug fixes and maintenance updates for OpenSearch security, OpenSearch security Dashboards, and anomaly detection. For a full list of release highlights, see the Release Notes. 27 August 2024 1.3.18 Includes maintenance updates for OpenSearch security. For a full list of release highlights, see the Release Notes. 16 July 2024 1.3.17 Includes maintenance updates for OpenSearch security and OpenSearch Dashboards security. For a full list of release highlights, see the Release Notes. 06 June 2024 1.3.16 Includes bug fixes and maintenance updates for OpenSearch security, index management, performance analyzer, and reporting. For a full list of release highlights, see the Release Notes. 23 April 2024 1.3.15 Includes bug fixes and maintenance updates for cross-cluster replication, SQL, OpenSearch Dashboards reporting, and alerting. For a full list of release highlights, see the Release Notes. 05 March 2024 1.3.14 Includes bug fixes and maintenance updates for OpenSearch security and OpenSearch Dashboards security. For a full list of release highlights, see the Release Notes. 12 December 2023 1.3.13 Includes bug fixes for Anomaly Detection, adds maintenance updates and infrastructure enhancements. For a full list of release highlights, see the Release Notes. 21 September 2023 1.3.12 Adds maintenance updates for OpenSearch security and OpenSearch Dashboards observability. Includes bug fixes for observability, OpenSearch Dashboards visualizations, and OpenSearch security. For a full list of release highlights, see the Release Notes. 10 August 2023 1.3.11 Adds maintenance updates for OpenSearch security, OpenSearch Dashboards security, and ML Commons. For a full list of release highlights, see the Release Notes. 29 June 2023 1.3.10 Adds infrastructure enhancements and maintenance updates for anomaly detection, observability, and security. Includes bug fixes for index management and OpenSearch security. For a full list of release highlights, see the Release Notes. 18 May 2023 1.3.9 Adds Debian support. Includes upgrades, enhancements, and maintenance updates for OpenSearch core, k-NN, and OpenSearch security. For a full list of release highlights, see the Release Notes. 16 March 2023 1.3.8 Adds OpenSearch security enhancements. Updates tool scripts to run on Windows. Includes maintenance updates and bug fixes for Anomaly Detection and OpenSearch security. For a full list of release highlights, see the Release Notes. 02 February 2023 1.3.7 Adds Windows support. Includes maintenance updates and bug fixes for error handling. For a full list of release highlights, see the Release Notes. 13 December 2022 1.3.6 Includes maintenance updates and bug fixes for tenancy in the OpenSearch Security Dashboards plugin. For a full list of release highlights, see the Release Notes. 06 October 2022 1.3.5 Includes maintenance updates and bug fixes for gradle check and OpenSearch security. For a full list of release highlights, see the Release Notes. 01 September 2022 1.3.4 Includes maintenance updates and bug fixes for OpenSearch and OpenSearch Dashboards. For a full list of release highlights, see the Release Notes. 14 July 2022 1.3.3 Adds enhancements to Anomaly Detection and ML Commons. Bug fixes for Anomaly Detection, Observability, and k-NN. For a full list of release highlights, see the Release Notes. 09 June 2022 1.3.2 Bug fixes for Anomaly Detection and the Security Dashboards Plugin, adds the option to install OpenSearch using RPM, as well as enhancements to the ML Commons execute task, and the removal of the job-scheduler zip in Anomaly Detection. For a full list of release highlights, see the Release Notes. 05 May 2022 1.3.1 Bug fixes when using document-level security, and adjusted ML Commons to use the latest RCF jar and protostuff to RCF model serialization. For a full list of release highlights, see the Release Notes. 30 March 2022 1.3.0 Adds Model Type Validation to Validate Detector API, continuous transforms, custom actions, applied policy parameter to Explain API, default action retries, and new rollover and transition conditions to Index Management, new ML Commons plugin, parse command to SQL, Application Analytics, Live Tail, Correlation, and Events Flyout to Observability, and auto backport and support for OPENSEARCH_JAVA_HOME to Performance Analyzer. Bug fixes. For a full list of release highlights, see the Release Notes. 17 March 2022 1.2.4 Updates Performance Analyzer, SQL, and Security plugins to Log4j 2.17.1, Alerting and Job Scheduler to cron-utils 9.1.6, and gson in Anomaly Detection and SQL. For a full list of release highlights, see the Release Notes. 18 January 2022 1.2.3 Updates the version of Log4j used in OpenSearch to Log4j 2.17.0 as recommended by the advisory in CVE-2021-45105. For a full list of release highlights, see the Release Notes. 22 December 2021 1.2.0 Adds observability, new validation API for Anomaly Detection, shard-level indexing back-pressure, new \\u201cmatch\\u201d query type for SQL and PPL, support for Faiss libraries in k-NN, and custom Dashboards branding. For a full list of release highlights, see the Release Notes. 23 November 2021 1.1.0 Adds cross-cluster replication, security for Index Management, bucket-level alerting, a CLI to help with upgrading from Elasticsearch OSS to OpenSearch, and enhancements to high cardinality data in the anomaly detection plugin. For a full list of release highlights, see the Release Notes. 05 October 2021 1.0.1 Bug fixes. For a full list of release highlights, see the Release Notes. 01 September 2021 1.0.0 General availability release. Adds compatibility setting for clients that require a version check before connecting. For a full list of release highlights, see the Release Notes. 12 July 2021 1.0.0-rc1 First release candidate. For a full list of release highlights, see the Release Notes. 07 June 2021 1.0.0-beta1 Initial beta release. Refactors plugins to work with OpenSearch. For a full list of release highlights, see the Release Notes. 13 May 2021 WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright \\u00a9 OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\\\"},{\\\"url\\\":\\\"https://www.instaclustr.com/blog/opensearch-2-11-is-now-available-on-the-instaclustr-managed-platform/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Search Search Search Contact us Support Sign in Platform + Left Column PlatformIntelligent, open source application data infrastructure Explore our platform Security and trustEnterprise-grade security Learn more HostingData infrastructure management in the cloud and on-prem Learn more AIPower RAG with open source data infrastructure Read more Right Column Store PostgreSQL\\u00ae Apache Cassandra\\u00ae Stream Apache Kafka\\u00ae Kafka\\u00ae Connect Orchestrate Cadence Analyze ClickHouse\\u00ae Search OpenSearch Pricing Services + Support Training Professional services About + About us Customers Our commitment to open source Resources + Getting started Sign up Documentation Quick start videos Integrations Support portal Discover Blog Events Content library Glossary Education hub Stream + Apache Kafka\\u00ae Real-time streaming Search + OpenSearch Store + PostgreSQL\\u00ae Apache Cassandra\\u00ae Analyze + ClickHouse\\u00ae Orchestrate + Cadence Workflow Open source + Open source AI Data infrastructure + Vector search Data streaming Data architecture Managed databases + Best practices NoSQL databases Vector databases Agentic AI Get a demo Try for free Free trial Sign in Platform + Left Column PlatformIntelligent, open source application data infrastructure Explore our platform Security and trustEnterprise-grade security Learn more HostingData infrastructure management in the cloud and on-prem Learn more AIPower RAG with open source data infrastructure Read more Right Column Store PostgreSQL\\u00ae Apache Cassandra\\u00ae Stream Apache Kafka\\u00ae Kafka\\u00ae Connect Orchestrate Cadence Analyze ClickHouse\\u00ae Search OpenSearch Pricing Services + Support Training Professional services About + About us Customers Our commitment to open source Resources + Getting started Sign up Documentation Quick start videos Integrations Support portal Discover Blog Events Content library Glossary Education hub Stream + Apache Kafka\\u00ae Real-time streaming Search + OpenSearch Store + PostgreSQL\\u00ae Apache Cassandra\\u00ae Analyze + ClickHouse\\u00ae Orchestrate + Cadence Workflow Open source + Open source AI Data infrastructure + Vector search Data streaming Data architecture Managed databases + Best practices NoSQL databases Vector databases Agentic AI Search Search Search Support Contact us Blog>Technology>OpenSearch\\u00ae 2.11 Is Now Available on the Instaclustr Managed Platform\\u202f OpenSearch\\u00ae 2.11 Is Now Available on the Instaclustr Managed Platform\\u202f January 12, 2024 | By Alex Bunday OpenSearch\\u00ae version 2.11 has now been released to the Instaclustr Managed Platform! This release brings a number of enhancements and improvements to OpenSearch. OpenSearch 2.11 resolves two vulnerabilities, CVE-2023-45807 and GHSA-8wx3-324g-w4qq. CVE-2023-45807 relates to a vulnerability found in multi-tenanted OpenSearch Dashboard deployments. GHSA-8wx3-324g-w4qq relates to an issue with how OpenSearch handled requests on the HTTP layer. You can find out more about these vulnerabilities, how we assessed them, and mitigation approaches on our security advisory blog post. One of the key highlights of this new release is the update to OpenSearch Dashboards. An entirely new user interface has been implemented, providing the same functionality but with improved usability and an updated look and feel. You can find out more about what has been changed here. Looking under the hood, this new release brings some solid enhancements. The OpenSearch Index Management Plugin now provides a unique ID to each rollup job to help with debugging, and users of the k-NN tool can flush k-NN indices out of the cache via the API. The OpenSearch Security Plugin has also been improved with added authorization in the REST layer, making queries more secure. And lastly, customers can now send OpenSearch notifications to Microsoft Teams. This latest version of OpenSearch also comes with new and experimental features that we are actively testing for future use on the Instaclustr Managed Platform. These features include the Neural Search Plugin (which turns text into vectors that can be stored and searched), and remote backed indices (which automatically creates backups of all index transactions and sends them to remote storage, providing a cost-effective solution for reducing the risk of data loss). We will have more news for you on these features in future updates. Customers of the Instaclustr Managed Platform can now begin deploying OpenSearch 2.11 on new clusters through the Console, API, or Terraform. For existing clusters, customers can contact our Support team to upgrade at [email protected]. For new customers, you can spin up an OpenSearch cluster for free through our customer console now. If you have any questions about this update or OpenSearch in general, please contact our friendly team at any time. About the author Alex Bunday | Product Manager Alex Bunday is a Product Manager with a strong focus on security and search within the Instaclustr Managed Platform, driving value through innovative solutions in the open source community. With expertise in managing product lifecycles and engaging stakeholders, Alex leverages data-driven insights to continuously improve and deliver impactful results. His collaborative approach empowers teams to develop and ship enhancements that meet customer needs and strengthen product offerings. Get the latest articles for open source In your inbox Sign up now Related content Zero Downtime Migration to Instaclustr Yes, we can migrate existing Cassandra clusters to Instaclustr without any downtime. Here's what to expect from the process... Workflow Comparison: Uber Cadence vs Netflix Conductor When choosing what\\u2019s right for your company\\u2019s opensource workflow needs it is important to know the difference and similarities ... Will Your Cassandra Database Project Succeed?: The New Stack Open source Apache Cassandra\\u00ae continues to stand out as an enterprise-proven solution for organizations seeking high availability... \\u00d7 Sign up to our Newsletter Platform + Explore our platform Security and trust Hosting AI Stream Apache Kafka\\u00ae Kafka\\u00ae Connect Store PostgreSQL\\u00ae Apache Cassandra\\u00ae Analyze ClickHouse\\u00ae Search OpenSearch Orchestrate Cadence Column 2 Pricing + Explore our pricing Services + Support Professional services Training About + About us Customers Careers Our commitment to open source Resources + Sign up Documentation Quick start videos Integrations Support portal Blog Events Content library Glossary Stream Apache Kafka\\u00ae Store PostgreSQL\\u00ae Apache Cassandra\\u00ae Valkey\\u2122 Analyze ClickHouse\\u00ae Apache Spark\\u2122 Search OpenSearch Data infrastructure Vector search Data streaming Policies + Terms of service Security and trust Security policy Support inclusions Subscription specifications Service-level agreements Cookie settings Privacy policy Platform + Explore our platform Security and trust Hosting AI Stream Apache Kafka\\u00ae Kafka\\u00ae Connect Store PostgreSQL\\u00ae Apache Cassandra\\u00ae Analyze ClickHouse\\u00ae Search OpenSearch Orchestrate Cadence Pricing Explore our pricing Services + Support Professional services Training About + About us Customers Careers Our commitment to open source Resources + Sign up Documentation Quick start videos Integrations Support portal Blog Events Content library Glossary Stream Apache Kafka\\u00ae Store PostgreSQL\\u00ae Apache Cassandra\\u00ae Valkey\\u2122 Analyze ClickHouse\\u00ae Apache Spark\\u2122 Search OpenSearch Data infrastructure Vector search Data streaming Policies + Terms of service Security and trust Security policy Support inclusions Subscription specifications Service-level agreements Cookie settings Privacy policy \\u00a92025 NetApp Copyright. NETAPP, the NETAPP logo, Instaclustr and the marks listed at https://www.netapp.com/TM are trademarks of NetApp, Inc. Other company and product names may be trademarks of their respective owners. Apache\\u00ae, Apache Cassandra\\u00ae, Apache Kafka\\u00ae, Apache Spark\\u2122, and Apache ZooKeeper\\u2122 are trademarks of The Apache Software Foundation.\\\"},{\\\"url\\\":\\\"https://docs.oracle.com/en-us/iaas/releasenotes/changes/69cff0e5-0db2-4f97-83d9-809559f0f141/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Oracle Cloud Infrastructure Documentation / Release Notes All Pages Skip to main content Search with OpenSearch now supports OpenSearch version 2.11 Services: Oracle Cloud Infrastructure Government Cloud, Search with OpenSearch Release Date: March 13, 2024 OCI Search with OpenSearch now supports OpenSearch version 2.11. The upgrade to OpenSearch version 2.11 comes with several improvements, including: Semantic search with custom models. Conversational search with external connectors to OCI Generative AI-hosted LLM models. Inline upgrade for minor version upgrades. Support for additional plugins, including reporting, query workbench, enhanced table. New clusters are created by default as OpenSearch 2.11 clusters. Existing clusters will still use previous version of OpenSearch, however you can upgrade them to version 2.11 using one of the following approaches: For OpenSearch 2.3 clusters, see Performing a Minor Build Version Upgrade for an OpenSearch Cluster For OpenSearch 1.2.4 clusters, see Upgrading an OpenSearch Cluster For more information: Search Service with OpenSearch OpenSearch Search with OpenSearch documentation Copyright \\u00a9 2025, Oracle and/or its affiliates. About Oracle Contact Us Legal Notices Terms of Use & Privacy Document Conventions\\\"},{\\\"url\\\":\\\"https://github.com/opensearch-project/opensearch-build/blob/main/release-notes/opensearch-release-notes-2.11.0.md?trk=public_post_comment-text\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to content Navigation Menu Toggle navigation Sign in Appearance settings Platform AI CODE CREATION GitHub CopilotWrite better code with AI GitHub SparkBuild and deploy intelligent apps GitHub ModelsManage and compare prompts MCP RegistryNewIntegrate external tools DEVELOPER WORKFLOWS ActionsAutomate any workflow CodespacesInstant dev environments IssuesPlan and track work Code ReviewManage code changes APPLICATION SECURITY GitHub Advanced SecurityFind and fix vulnerabilities Code securitySecure your code as you build Secret protectionStop leaks before they start EXPLORE Why GitHub Documentation Blog Changelog Marketplace View all features Solutions BY COMPANY SIZE Enterprises Small and medium teams Startups Nonprofits BY USE CASE App Modernization DevSecOps DevOps CI/CD View all use cases BY INDUSTRY Healthcare Financial services Manufacturing Government View all industries View all solutions Resources EXPLORE BY TOPIC AI Software Development DevOps Security View all topics EXPLORE BY TYPE Customer stories Events & webinars Ebooks & reports Business insights GitHub Skills SUPPORT & SERVICES Documentation Customer support Community forum Trust center Partners Open Source COMMUNITY GitHub SponsorsFund open source developers PROGRAMS Security Lab Maintainer Community Accelerator Archive Program REPOSITORIES Topics Trending Collections Enterprise ENTERPRISE SOLUTIONS Enterprise platformAI-powered developer platform AVAILABLE ADD-ONS GitHub Advanced SecurityEnterprise-grade security features Copilot for BusinessEnterprise-grade AI features Premium SupportEnterprise-grade 24/7 support Pricing Search or jump to... Search code, repositories, users, issues, pull requests... Search Clear Search syntax tips Provide feedback We read every piece of feedback, and take your input very seriously. Include my email address so I can be contacted Cancel Submit feedback Saved searches Use saved searches to filter your results more quickly Name Query To see all available qualifiers, see our documentation. Cancel Create saved search Sign in Sign up Appearance settings Resetting focus You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert {{ message }} opensearch-project / opensearch-build Public generated from amazon-archives/__template_Apache-2.0 Notifications You must be signed in to change notification settings Fork 316 Star 185 Code Issues 177 Pull requests 20 Discussions Actions Projects 3 Wiki Security Uh oh! There was an error while loading. Please reload this page. Insights Additional navigation options Code Issues Pull requests Discussions Actions Projects Wiki Security Insights Footer \\u00a9 2026 GitHub, Inc. Footer navigation Terms Privacy Security Status Community Docs Contact Manage cookies Do not share my personal information You can\\u2019t perform that action at this time.\\\"},{\\\"url\\\":\\\"https://docs.public.oneportal.content.oci.oraclecloud.com/iaas/releasenotes/changes/69cff0e5-0db2-4f97-83d9-809559f0f141/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Oracle Cloud Infrastructure Documentation / Release Notes All Pages Skip to main content Search with OpenSearch now supports OpenSearch version 2.11 Services: Oracle Cloud Infrastructure Government Cloud, Search with OpenSearch Release Date: March 13, 2024 OCI Search with OpenSearch now supports OpenSearch version 2.11. The upgrade to OpenSearch version 2.11 comes with several improvements, including: Semantic search with custom models. Conversational search with external connectors to OCI Generative AI-hosted LLM models. Inline upgrade for minor version upgrades. Support for additional plugins, including reporting, query workbench, enhanced table. New clusters are created by default as OpenSearch 2.11 clusters. Existing clusters will still use previous version of OpenSearch, however you can upgrade them to version 2.11 using one of the following approaches: For OpenSearch 2.3 clusters, see Performing a Minor Build Version Upgrade for an OpenSearch Cluster For OpenSearch 1.2.4 clusters, see Upgrading an OpenSearch Cluster For more information: Search Service with OpenSearch OpenSearch Search with OpenSearch documentation Copyright \\u00a9 2025, Oracle and/or its affiliates. About Oracle Contact Us Legal Notices Terms of Use & Privacy Document Conventions\\\"}]}\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Search for current information\n",
    "parameters = {\n",
    "    \"question\": \"Latest features in OpenSearch 2.11\"\n",
    "}\n",
    "\n",
    "print(\"‚ùì Question: Latest features in OpenSearch 2.11\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "response = execute_agent(client, agent_id, parameters)\n",
    "\n",
    "print(\"\\nüì∞ Current Information:\")\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47efc600",
   "metadata": {},
   "source": [
    "## Step 7: Test Case 4 - Search for Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "207e77cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì Question: OpenSearch cluster sizing best practices\n",
      "============================================================\n",
      "\n",
      "üí° Best Practices:\n",
      "{\n",
      "  \"inference_results\": [\n",
      "    {\n",
      "      \"output\": [\n",
      "        {\n",
      "          \"name\": \"response\",\n",
      "          \"result\": \"{\\\"next_page\\\":\\\"https://duckduckgo.com/html?q=OpenSearch+cluster+sizing+best+practices&s=10&nextParams=&v=l&o=json&dc=11&api=d.js&vqd=4-326276642320892287721390097967891377785&kl=wt-wt\\\",\\\"items\\\":[{\\\"url\\\":\\\"https://docs.aws.amazon.com/opensearch-service/latest/developerguide/bp.html\\\",\\\"title\\\":\\\"Operational best practices for Amazon OpenSearch Service - Amazon OpenSearch Service\\\",\\\"content\\\":\\\"Operational best practices for Amazon OpenSearch Service - Amazon OpenSearch Service DocumentationAmazon OpenSearch ServiceDeveloper Guide Monitoring and alertingShard strategyStabilityPerformanceSecurityCost optimization Operational best practices for Amazon OpenSearch Service This chapter provides best practices for operating Amazon OpenSearch Service domains and includes general guidelines that apply to many use cases. Each workload is unique, with unique characteristics, so no generic recommendation is exactly right for every use case. The most important best practice is to deploy, test, and tune your domains in a continuous cycle to find the optimal configuration, stability, and cost for your workload. Topics Monitoring and alerting Shard strategy Stability Performance Security Cost optimization Sizing Amazon OpenSearch Service domains Petabyte scale in Amazon OpenSearch Service Dedicated coordinator nodes in Amazon OpenSearch Service Dedicated master nodes in Amazon OpenSearch Service Monitoring and alerting The following best practices apply to monitoring your OpenSearch Service domains. Configure CloudWatch alarms OpenSearch Service emits performance metrics to Amazon CloudWatch. Regularly review your cluster and instance metrics and configure recommended CloudWatch alarms based on your workload performance. Enable log publishing OpenSearch Service exposes OpenSearch error logs, search slow logs, indexing slow logs, and audit logs in Amazon CloudWatch Logs. Search slow logs, indexing slow logs, and error logs are useful for troubleshooting performance and stability issues. Audit logs, which are only available if you enable fine-grained access control to track user activity. For more information, see Logs in the OpenSearch documentation. Search slow logs and indexing slow logs are an important tool for understanding and troubleshooting the performance of your search and indexing operations. Enable search and index slow log delivery for all production domains. You must also configure logging thresholds\\u2014otherwise, CloudWatch won't capture the logs. Shard strategy Shards distribute your workload across the data nodes in your OpenSearch Service domain. Properly configured indexes can help boost overall domain performance. When you send data to OpenSearch Service, you send that data to an index. An index is analogous to a database table, with documents as the rows, and fields as the columns. When you create the index, you tell OpenSearch how many primary shards you want to create. The primary shards are independent partitions of the full dataset. OpenSearch Service automatically distributes your data across the primary shards in an index. You can also configure replicas of the index. Each replica shard comprises a full set of copies of the primary shards for that index. OpenSearch Service maps the shards for each index across the data nodes in your cluster. It ensures that the primary and replica shards for the index reside on different data nodes. The first replica ensures that you have two copies of the data in the index. You should always use at least one replica. Additional replicas provide additional redundancy and read capacity. OpenSearch sends indexing requests to all of the data nodes that contain shards that belong to the index. It sends indexing requests first to data nodes that contain primary shards, and then to data nodes that contain replica shards. Search requests are routed by the coordinator node to either a primary or replica shard for all shards belonging to the index. For example, for an index with five primary shards and one replica, each indexing request touches 10 shards. In contrast, search requests are sent to n shards, where n is the number of primary shards. For an index with five primary shards and one replica, each search query touches five shards (primary or replica) from that index. Determine shard and data node counts Use the following best practices to determine shard and data node counts for your domain. Shard size \\u2013 The size of data on disk is a direct result of the size of your source data, and it changes as you index more data. The source-to-index ratio can vary wildly, from 1:10 to 10:1 or more, but usually it's around 1:1.10. You can use that ratio to predict the index size on disk. You can also index some data and retrieve the actual index sizes to determine the ratio for your workload. After you have a predicted index size, set a shard count so that each shard will be between 10\\u201330 GiB (for search workloads), or between 30\\u201350 GiB (for logs workloads). 50 GiB should be the maximum\\u2014be sure to plan for growth. Shard count \\u2013 The distribution of shards to data nodes has a large impact on a domain\\u2019s performance. When you have indexes with multiple shards, try to make the shard count a multiple of the data node count. This helps to ensure that shards are evenly distributed across data nodes, and prevents hot nodes. For example, if you have 12 primary shards, your data node count should be 2, 3, 4, 6, or 12. However, shard count is secondary to shard size\\u2014if you have 5 GiB of data, you should still use a single shard. Shards per data node \\u2013 The total number of shards that a node can hold is proportional to the node\\u2019s Java virtual machine (JVM) heap memory. Aim for 25 shards or fewer per GiB of heap memory. For example, a node with 32 GiB of heap memory should hold no more than 800 shards. Although shard distribution can vary based on your workload patterns, there's a limit of 1,000 shards per node for Elasticsearch and OpenSearch 1.1 to 2.15 and 4,000 for OpenSearch 2.17 and above. The cat/allocation API provides a quick view of the number of shards and total shard storage across data nodes. Shard to CPU ratio \\u2013 When a shard is involved in an indexing or search request, it uses a vCPU to process the request. As a best practice, use an initial scale point of 1.5 vCPU per shard. If your instance type has 8 vCPUs, set your data node count so that each node has no more than six shards. Note that this is an approximation. Be sure to test your workload and scale your cluster accordingly. For storage volume, shard size, and instance type recommendations, see the following resources: Sizing Amazon OpenSearch Service domains Petabyte scale in Amazon OpenSearch Service Avoid storage skew Storage skew occurs when one or more nodes within a cluster holds a higher proportion of storage for one or more indexes than the others. Indications of storage skew include uneven CPU utilization, intermittent and uneven latency, and uneven queueing across data nodes. To determine whether you have skew issues, see the following troubleshooting sections: Node shard and storage skew Index shard and storage skew Stability The following best practices apply to maintaining a stable and healthy OpenSearch Service domain. Keep current with OpenSearch Service software updates OpenSearch Service regularly releases software updates that add features or otherwise improve your domains. Updates don't change the OpenSearch or Elasticsearch engine version. We recommend that you schedule a recurring time to run the DescribeDomain API operation, and initiate a service software update if the UpdateStatus is ELIGIBLE. If you don't update your domain within a certain time frame (typically two weeks), OpenSearch Service automatically performs the update. OpenSearch version upgrades OpenSearch Service regularly adds support for community-maintained versions of OpenSearch. Always upgrade to the latest OpenSearch versions when they're available. OpenSearch Service simultaneously upgrades both OpenSearch and OpenSearch Dashboards (or Elasticsearch and Kibana if your domain is running a legacy engine). If the cluster has dedicated master nodes, upgrades complete without downtime. Otherwise, the cluster might be unresponsive for several seconds post-upgrade while it elects a master node. OpenSearch Dashboards might be unavailable during some or all of the upgrade. There are two ways to upgrade a domain: In-place upgrade \\u2013 This option is easier because you keep the same cluster. Snapshot/restore upgrade \\u2013 This option is good for testing new versions on a new cluster or migrating between clusters. Regardless of which upgrade process you use, we recommend that you maintain a domain that is solely for development and testing, and upgrade it to the new version before you upgrade your production domain. Choose Development and testing for the deployment type when you're creating the test domain. Make sure to upgrade all clients to compatible versions immediately following the domain upgrade. Improve snapshot performance To prevent your snapshot from getting stuck in processing, the instance type for the dedicated master node should match the shard count. For more information, see Choosing instance types for dedicated master nodes. Additionally, each node should have no more than the recommended 25 shards per GiB of Java heap memory. For more information, see Choosing the number of shards. Enable dedicated master nodes Dedicated master nodes improve cluster stability. A dedicated master node performs cluster management tasks, but doesn't hold index data or respond to client requests. This offloading of cluster management tasks increases the stability of your domain and makes it possible for some configuration changes to happen without downtime. Enable and use three dedicated master nodes for optimal domain stability across three Availability Zones. Deploying with Multi-AZ with Standby configures three dedicated master nodes for you. For instance type recommendations, see Choosing instance types for dedicated master nodes. Deploy across multiple Availability Zones To prevent data loss and minimize cluster downtime in the event of a service disruption, you can distribute nodes across two or three Availability Zones in the same AWS Region. Best practice is to deploy using Multi-AZ with Standby, which configures three Availability Zones, with two zones active and one acting as a standby, and with and two replica shards per index. This configuration lets OpenSearch Service distribute replica shards to different AZs than their corresponding primary shards. There are no cross-AZ data transfer charges for cluster communications between Availability Zones. Availability Zones are isolated locations within each Region. With a two-AZ configuration, losing one Availability Zone means that you lose half of all domain capacity. Moving to three Availability Zones further reduces the impact of losing a single Availability Zone. Control ingest flow and buffering We recommend that you limit the overall request count using the _bulk API operation. It's more efficient to send one _bulk request that contains 5,000 documents than it is to send 5,000 requests that contain a single document. For optimal operational stability, it's sometimes necessary to limit or even pause the upstream flow of indexing requests. Limiting the rate of index requests is an important mechanism for dealing with unexpected or occasional spikes in requests that might otherwise overwhelm the cluster. Consider building a flow control mechanism into your upstream architecture. The following diagram shows multiple component options for a log ingest architecture. Configure the aggregation layer to allow sufficient space to buffer incoming data for sudden traffic spikes and brief domain maintenance. Create mappings for search workloads For search workloads, create mappings that define how OpenSearch stores and indexes documents and their fields. Set dynamic to strict in order to prevent new fields from being added accidentally. PUT my-index\\\\n{\\\\n  \\\\\\\"mappings\\\\\\\": {\\\\n    \\\\\\\"dynamic\\\\\\\": \\\\\\\"strict\\\\\\\",\\\\n    \\\\\\\"properties\\\\\\\": {\\\\n      \\\\\\\"title\\\\\\\": { \\\\\\\"type\\\\\\\" : \\\\\\\"text\\\\\\\" },\\\\n      \\\\\\\"author\\\\\\\": { \\\\\\\"type\\\\\\\" : \\\\\\\"integer\\\\\\\" },\\\\n      \\\\\\\"year\\\\\\\": { \\\\\\\"type\\\\\\\" : \\\\\\\"text\\\\\\\" }\\\\n    }\\\\n  }\\\\n} Use index templates You can use an index template as a way to tell OpenSearch how to configure an index when it's created. Configure index templates before creating indexes. Then, when you create an index, it inherits the settings and mappings from the template. You can apply more than one template to a single index, so you can specify settings in one template and mappings in another. This strategy allows one template for common settings across multiple indexes, and separate templates for more specific settings and mappings. The following settings are helpful to configure in templates: Number of primary and replica shards Refresh interval (how often to refresh and make recent changes to the index available to search) Dynamic mapping control Explicit field mappings The following example template contains each of these settings: {\\\\n   \\\\\\\"index_patterns\\\\\\\":[\\\\n      \\\\\\\"index-*\\\\\\\"\\\\n   ],\\\\n   \\\\\\\"order\\\\\\\": 0,\\\\n   \\\\\\\"settings\\\\\\\": {\\\\n      \\\\\\\"index\\\\\\\": {\\\\n         \\\\\\\"number_of_shards\\\\\\\": 3,\\\\n         \\\\\\\"number_of_replicas\\\\\\\": 1,\\\\n         \\\\\\\"refresh_interval\\\\\\\": \\\\\\\"60s\\\\\\\"\\\\n      }\\\\n   },\\\\n   \\\\\\\"mappings\\\\\\\": {\\\\n      \\\\\\\"dynamic\\\\\\\": false,\\\\n      \\\\\\\"properties\\\\\\\": {\\\\n         \\\\\\\"field_name1\\\\\\\": {\\\\n            \\\\\\\"type\\\\\\\": \\\\\\\"keyword\\\\\\\"\\\\n         }\\\\n      }\\\\n   }\\\\n} Even if they rarely change, having settings and mappings defined centrally in OpenSearch is simpler to manage than updating multiple upstream clients. Manage indexes with Index State Management If you're managing logs or time-series data, we recommend using Index State Management (ISM). ISM lets you automate regular index lifecycle management tasks. With ISM, you can create policies that invoke index alias rollovers, take index snapshots, move indexes between storage tiers, and delete old indexes. You can even use the ISM rollover operation as an alternative data lifecycle management strategy to avoid shard skew. First, set up an ISM policy. For example, see Sample policies. Then, attach the policy to one or more indexes. If you include an ISM template field in the policy, OpenSearch Service automatically applies the policy to any index that matches the specified pattern. Remove unused indexes Regularly review the indexes in your cluster and identify any that aren't in use. Take a snapshot of those indexes so that they're stored in S3, and then delete them. When you remove unused indexes, you reduce the shard count, and make it possible to have more balanced storage distribution and resource utilization across nodes. Even when they're idle, indexes consume some resources during internal index maintenance activities. Rather than manually deleting unused indexes, you can use ISM to automatically take a snapshot and delete indexes after a certain period of time. Use multiple domains for high availability To achieve high availability beyond 99.9% uptime across multiple Regions, consider using two domains. For small or slowly changing datasets, you can set up cross-cluster replication to maintain an active-passive model. In this model, only the leader domain is written to, but either domain can be read from. For larger data sets and quickly changing data, configure dual delivery in your ingest pipeline so that all data is written independently to both domains in an active-active model. Architect your upstream and downstream applications with failover in mind. Make sure to test the failover process along with other disaster recovery processes. Performance The following best practices apply to tuning your domains for optimal performance. Optimize bulk request size and compression Bulk sizing depends on your data, analysis, and cluster configuration, but a good starting point is 3\\u20135 MiB per bulk request. Send requests and receive responses from your OpenSearch domains by using gzip compression to reduce the payload size of requests and responses. You can use gzip compression with the OpenSearch Python client, or by including the following headers from the client side: 'Accept-Encoding': 'gzip' 'Content-Encoding': 'gzip' To optimize your bulk request sizes, start with a bulk request size of 3 MiB. Then, slowly increase the request size until indexing performance stops improving. Note To enable gzip compression on domains running Elasticsearch version 6.x, you must set http_compression.enabled at the cluster level. This setting is true by default in Elasticsearch versions 7.x and all versions of OpenSearch. Reduce the size of bulk request responses To reduce the size of OpenSearch responses, exclude unnecessary fields with the filter_path parameter. Make sure that you don't filter out any fields that are required to identify or retry failed requests. For more information and examples, see Reducing response size. Tune refresh intervals OpenSearch indexes have eventual read consistency. A refresh operation makes all the updates that are performed on an index available for search. The default refresh interval is one second, which means that OpenSearch performs a refresh every second while an index is being written to. The less frequently that you refresh an index (higher refresh interval), the better the overall indexing performance is. The trade-off of increasing the refresh interval is that there\\u2019s a longer delay between an index update and when the new data is available for search. Set your refresh interval as high as you can tolerate to improve overall performance. We recommend setting the refresh_interval parameter for all of your indexes to 30 seconds or more. Enable Auto-Tune Auto-Tune uses performance and usage metrics from your OpenSearch cluster to suggest changes to queue sizes, cache sizes, and Java virtual machine (JVM) settings on your nodes. These optional changes improve cluster speed and stability. You can revert to the default OpenSearch Service settings at any time. Auto-Tune is enabled by default on new domains unless you explicitly disable it. We recommend that you enable Auto-Tune on all domains, and either set a recurring maintenance window or periodically review its recommendations. Security The following best practices apply to securing your domains. Enable fine-grained access control Fine-grained access control lets you control who can access certain data within an OpenSearch Service domain. Compared to generalized access control, fine-grained access control gives each cluster, index, document, and field its own specified policy for access. Access criteria can be based on a number of factors, including the role of the person who is requesting access and the action that they intend to perform on the data. For example, you might give one user access to write to an index, and another user access only to read the data on the index without making any changes. Fine-grained access control allows data with different access requirements to exist in the same storage space without running into security or compliance issues. We recommend enabling fine-grained access control on your domains. Deploy domains within a VPC Placing your OpenSearch Service domain within a virtual private cloud (VPC) helps enable secure communication between OpenSearch Service and other services within the VPC\\u2014without the need for an internet gateway, NAT device, or VPN connection. All traffic remains securely within the AWS Cloud. Because of their logical isolation, domains that reside within a VPC have an extra layer of security compared to domains that use public endpoints. We recommend that you create your domains within a VPC. Apply a restrictive access policy Even if your domain is deployed within a VPC, it's a best practice to implement security in layers. Make sure to check the configuration of your current access policies. Apply a restrictive resource-based access policy to your domains and follow the principle of least privilege when granting access to the configuration API and the OpenSearch API operations. As a general rule, avoid using the anonymous user principal \\\\\\\"Principal\\\\\\\": {\\\\\\\"AWS\\\\\\\": \\\\\\\"*\\\\\\\" } in your access policies. There are some situations, however, where it's acceptable to use an open access policy, such as when you enable fine-grained access control. An open access policy can enable you to access the domain in cases where request signing is difficult or impossible, such as from certain clients and tools. Enable encryption at rest OpenSearch Service domains offer encryption of data at rest to help prevent unauthorized access to your data. Encryption at rest uses AWS Key Management Service (AWS KMS) to store and manage your encryption keys, and the Advanced Encryption Standard algorithm with 256-bit keys (AES-256) to perform the encryption. If your domain stores sensitive data, enable encryption of data at rest. Enable node-to-node encryption Node-to-node encryption provides an additional layer of security on top of the default security features within OpenSearch Service. It implements Transport Layer Security (TLS) for all communications between the nodes that are provisioned within OpenSearch. Node-to-node encryption, any data sent to your OpenSearch Service domain over HTTPS remains encrypted in transit while it's being distributed and replicated between nodes. If your domain stores sensitive data, enable node-to-node encryption. Monitor with AWS Security Hub CSPM Monitor your usage of OpenSearch Service as it relates to security best practices by using AWS Security Hub CSPM. Security Hub CSPM uses security controls to evaluate resource configurations and security standards to help you comply with various compliance frameworks. For more information about using Security Hub CSPM to evaluate OpenSearch Service resources, see Amazon OpenSearch Service controls in the AWS Security Hub User Guide. Cost optimization The following best practices apply to optimizing and saving on your OpenSearch Service costs. Use the latest generation instance types OpenSearch Service is always adopting new Amazon EC2 instances types that deliver better performance at a lower cost. We recommend always using the latest generation instances. Avoid using T2 or t3.small instances for production domains because they can become unstable under sustained heavy load. r6g.large instances are an option for small production workloads (both as data nodes and as dedicated master nodes). Use the latest Amazon EBS gp3 volumes OpenSearch data nodes require low latency and high throughput storage to provide fast indexing and query. By using Amazon EBS gp3 volumes, you get higher baseline performance (IOPS and throughput) at a 9.6% lower cost than with the previously-offered Amazon EBS gp2 volume type. You can provision additional IOPS and throughput independent of volume size using gp3. These volumes are also more stable than previous generation volumes as they do not use burst credits. The gp3 volume type also doubles the per-data-node volume size limits of the gp2 volume type. With these larger volumes, you can reduce the cost of passive data by increasing the amount of storage per data node. Use UltraWarm and cold storage for time-series log data If you're using OpenSearch for log analytics, move your data to UltraWarm or cold storage to reduce costs. Use Index State Management (ISM) to migrate data between storage tiers and manage data retention. UltraWarm provides a cost-effective way to store large amounts of read-only data in OpenSearch Service. UltraWarm uses Amazon S3 for storage, which means that the data is immutable and only one copy is needed. You only pay for storage that's equivalent to the size of the primary shards in your indexes. Latencies for UltraWarm queries grow with the amount of S3 data that's needed to service the query. After the data has been cached on the nodes, queries to UltraWarm indexes perform similar to queries to hot indexes. Cold storage is also backed by S3. When you need to query cold data, you can selectively attach it to existing UltraWarm nodes. Cold data incurs the same managed storage cost as UltraWarm, but objects in cold storage don't consume UltraWarm node resources. Therefore, cold storage provides a significant amount of storage capacity without impacting UltraWarm node size or count. UltraWarm becomes cost-effective when you have roughly 2.5 TiB of data to migrate from hot storage. Monitor your fill rate and plan to move indexes to UltraWarm before you reach that volume of data. Review recommendations for Reserved Instances Consider purchasing Reserved Instances (RIs) after you have a good baseline on your performance and compute consumption. Discounts start at around 30% for no-upfront, 1-year reservations and can increase up to 50% for all-upfront, 3-year commitments. After you observe stable operation for at least 14 days, review Accessing reservation recommendations in the AWS Cost Management User Guide. The Amazon OpenSearch Service heading displays specific RI purchase recommendations and projected savings. Javascript is disabled or is unavailable in your browser. To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions. Document Conventions Traces Sizing domains Did this page help you? - Yes Thanks for letting us know we're doing a good job! If you've got a moment, please tell us what we did right so we can do more of it. Did this page help you? - No Thanks for letting us know this page needs work. We're sorry we let you down. If you've got a moment, please tell us how we can make the documentation better.\\\"},{\\\"url\\\":\\\"https://docs.opensearch.org/latest/tuning-your-cluster/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Discovery and cluster formation Node discovery and seed hosts Voting and quorum Voting configuration management Cluster bootstrapping Discovery and cluster formation settings Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Remote segment warmer Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Similarity Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Resource access management Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates OpenSearch FIPS configuration Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control Defining users and roles Permissions Default action groups REST layer authorization Document-level security Field-level security Field masking User impersonation Resource sharing and access control Resource sharing APIs API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Version Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Mapping explosion Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Rescore Regular expression syntax SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic queries Complex queries Functions JSON support Metadata queries Aggregate functions Delete JDBC driver ODBC driver PPL Subsearch Commands PPL syntax ad addcoltotals addtotals append appendcol appendpipe bin chart dedup describe eval eventstats expand explain fields fillnull flatten grok head join kmeans lookup ml multisearch parse patterns rare regex rename replace reverse rex search show datasources sort spath stats streamstats subquery table timechart top trendline where Identifiers Data types Functions Full-text search Settings Troubleshooting Monitoring Limitations Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Collecting UBI-formatted data in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Model access control through resource sharing Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller ML Tasks APIs Get ML task Search ML tasks Delete ML task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow access control Workflow settings Workflow state access control Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detector access control Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecaster access control Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Creating a cluster Before diving into OpenSearch and searching and aggregating data, you first need to create an OpenSearch cluster. OpenSearch can operate as a single-node or multi-node cluster. The steps to configure both are, in general, quite similar. This page demonstrates how to create and configure a multi-node cluster, but with only a few minor adjustments, you can follow the same steps to create a single-node cluster. To create and deploy an OpenSearch cluster according to your requirements, it\\u2019s important to understand how node discovery and cluster formation work and what settings govern them. There are many ways to design a cluster. The following illustration shows a basic architecture that includes a four-node cluster that has one dedicated cluster manager node, one dedicated coordinating node, and two data nodes that are cluster manager eligible and also used for ingesting data. The master node is now referred to as the cluster manager node. Nodes The following table provides brief descriptions of the node types: Node type Description Best practices for production Cluster manager Manages the overall operation of a cluster and keeps track of the cluster state. This includes creating and deleting indexes, keeping track of the nodes that join and leave the cluster, checking the health of each node in the cluster (by running ping requests), and allocating shards to nodes. Three dedicated cluster manager nodes in three different zones is the right approach for almost all production use cases. This configuration ensures your cluster never loses quorum. Two nodes will be idle for most of the time except when one node goes down or needs some maintenance. Cluster manager eligible Elects one node among them as the cluster manager node through a voting process. For production clusters, make sure you have dedicated cluster manager nodes. The way to achieve a dedicated node type is to mark all other node types as false. In this case, you have to mark all the other nodes as not cluster manager eligible. Data Stores and searches data. Performs all data-related operations (indexing, searching, aggregating) on local shards. These are the worker nodes of your cluster and need more disk space than any other node type. As you add data nodes, keep them balanced between zones. For example, if you have three zones, add data nodes in multiples of three, one for each zone. We recommend using storage and RAM-heavy nodes. Ingest Pre-processes data before storing it in the cluster. Runs an ingest pipeline that transforms your data before adding it to an index. If you plan to ingest a lot of data and run complex ingest pipelines, we recommend you use dedicated ingest nodes. You can also optionally offload your indexing from the data nodes so that your data nodes are used exclusively for searching and aggregating. Coordinating Delegates client requests to the shards on the data nodes, collects and aggregates the results into one final result, and sends this result back to the client. A couple of dedicated coordinating-only nodes is appropriate to prevent bottlenecks for search-heavy workloads. We recommend using CPUs with as many cores as you can. Dynamic Delegates a specific node for custom work, such as machine learning (ML) tasks, preventing the consumption of resources from data nodes and therefore not affecting any OpenSearch functionality. Warm Provides access to searchable snapshots. Incorporates techniques like frequently caching used segments and removing the least used data segments in order to access the searchable snapshot index (stored in a remote long-term storage source, for example, Amazon Simple Storage Service [Amazon S3] or Google Cloud Storage). Search nodes contain an index allocated as a snapshot cache. Thus, we recommend using dedicated nodes with more compute (CPU and memory) than storage capacity (hard disk). Search Search nodes are dedicated nodes that host only search replica shards, helping separate search workloads from indexing workloads. Because search nodes host search replicas and handle search traffic, we recommend using them for dedicated memory-optimized instances. By default, each node is a cluster-manager-eligible, data, ingest, and coordinating node. Deciding on the number of nodes, assigning node types, and choosing the hardware for each node type depends on your use case. You must take into account factors like the amount of time you want to hold on to your data, the average size of your documents, your typical workload (indexing, searches, aggregations), your expected price-performance ratio, your risk tolerance, and so on. After you assess all these requirements, we recommend you use a benchmark testing tool like OpenSearch Benchmark to provision a small sample cluster and run tests with varying workloads and configurations. Compare and analyze the system and query metrics for these tests to design an optimum architecture. This page demonstrates how to work with the different node types. It assumes that you have a four-node cluster similar to the preceding illustration. It is a best practice to direct traffic from external sources, such as OpenSearch Dashboards, OpenSearch Data Prepper, and others, to the nodes in the following order of availability: ingest node, coordinating node, data node. We do not recommended sending traffic directly to the cluster manager node. Prerequisites Before you get started, you must install and configure OpenSearch on all of your nodes. For information about the available options, see Install and configure OpenSearch. After you\\u2019re done, use SSH to connect to each node, then open the config/opensearch.yml file. You can set all configurations for your cluster in this file. Step 1: Name a cluster Specify a unique name for the cluster. If you don\\u2019t specify a cluster name, it\\u2019s set to opensearch by default. Setting a descriptive cluster name is important, especially if you want to run multiple clusters inside a single network. To specify the cluster name, change the following line: #cluster.name: my-application\\\\n to cluster.name: opensearch-cluster\\\\n Make the same change on all the nodes to make sure that they\\u2019ll join to form a cluster. Step 2: Set node attributes for each node in a cluster After you name the cluster, set node attributes for each node in your cluster. Cluster manager node Give your cluster manager node a name. If you don\\u2019t specify a name, OpenSearch assigns a machine-generated name that makes the node difficult to monitor and troubleshoot. node.name: opensearch-cluster_manager\\\\n You can also explicitly specify that this node is a cluster manager node, even though it is already set to true by default. Set the node role to cluster_manager to make it easier to identify the cluster manager node. node.roles: [ cluster_manager ]\\\\n Data nodes Change the name of two nodes to opensearch-d1 and opensearch-d2, respectively: node.name: opensearch-d1\\\\n node.name: opensearch-d2\\\\n You can make them cluster-manager-eligible data nodes that will also be used for ingesting data: node.roles: [ data, ingest ]\\\\n You can also specify any other attributes that you\\u2019d like to set for the data nodes. Coordinating node Change the name of the coordinating node to opensearch-c1: node.name: opensearch-c1\\\\n Every node is a coordinating node by default, so to make this node a dedicated coordinating node, set node.roles to an empty list: node.roles: []\\\\n Step 3: Bind a cluster to specific IP addresses network.bind_host defines the IP address used to bind the node. By default, OpenSearch listens on a local host, which limits the cluster to a single node. You can also use _local_ and _site_ to bind to any loopback or site-local address, whether IPv4 or IPv6: network.bind_host: [_local_, _site_]\\\\n To form a multi-node cluster, specify the IP address of the node: network.bind_host: <IP address of the node>\\\\n Make sure to configure these settings on all of your nodes. Step 4: Configure discovery hosts and initial cluster manager nodes for a cluster Now that you\\u2019ve configured the network hosts, you need to configure the discovery hosts and specify the cluster manager nodes for the initial cluster election. Note that this is the node name and not the IP Address, hostname, or fully-qualified hostname. For example, the setting looks like the following: cluster.initial_cluster_manager_nodes: [\\\\\\\"opensearch-cluster_manager\\\\\\\"]\\\\n Zen Discovery is the built-in, default mechanism that uses unicast to find other nodes in the cluster. You can generally add all of your cluster-manager-eligible nodes to the discovery.seed_hosts array. When a node starts up, it finds the other cluster-manager-eligible nodes, determines which one is the cluster manager, and asks to join the cluster. For example, for opensearch-cluster_manager the line looks something like this: discovery.seed_hosts: [\\\\\\\"<private IP of opensearch-d1>\\\\\\\", \\\\\\\"<private IP of opensearch-d2>\\\\\\\", \\\\\\\"<private IP of opensearch-c1>\\\\\\\"]\\\\n Step 5: Start the cluster After you set the configurations, start OpenSearch on all nodes: sudo systemctl start opensearch.service\\\\n Installing OpenSearch from a tar archive will not automatically create a service with systemd. See Run OpenSearch as a service with systemd for instructions on how to create and start the service if you receive an error like Failed to start opensearch.service: Unit not found. Then go to the logs file to see the formation of the cluster: less /var/log/opensearch/opensearch-cluster.log\\\\n Perform the following _cat query on any node to see all the nodes formed as a cluster: curl -XGET https://<private-ip>:9200/_cat/nodes?v -u 'admin:<custom-admin-password>' --insecure\\\\n ip             heap.percent ram.percent cpu load_1m load_5m load_15m node.role cluster_manager name\\\\nx.x.x.x           13          61   0    0.02    0.04     0.05 mi        *      opensearch-cluster_manager\\\\nx.x.x.x           16          60   0    0.06    0.05     0.05 md        -      opensearch-d1\\\\nx.x.x.x           34          38   0    0.12    0.07     0.06 md        -      opensearch-d2\\\\nx.x.x.x           23          38   0    0.12    0.07     0.06 md        -      opensearch-c1\\\\n To better understand and monitor your cluster, use the CAT API. (Advanced) Step 6: Configure shard allocation awareness or forced awareness To further fine-tune your shard allocation, you can set custom node attributes for shard allocation awareness or forced awareness. Shard allocation awareness You can set custom node attributes on OpenSearch nodes to be used for shard allocation awareness. For example, you can set the zone attribute on each node to represent the zone in which the node is located. You can also use the zone attribute to ensure that the primary shard and its replica shards are allocated in a balanced manner across available, distinct zones. In this scenario, maximum shard copies per zone would equal ceil (number_of_shard_copies/number_of_distinct_zones). OpenSearch, by default, allocates shard copies of a single shard across different nodes. When only 1 zone is available, such as after a zone failure, OpenSearch allocates replica shards to the only remaining zone\\u2014it considers only available zones (attribute values) when calculating the maximum number of allowed shard copies per zone. For example, if your index has a total of 5 shard copies (1 primary and 4 replicas) and nodes in 3 distinct zones, then OpenSearch will perform the following to allocate all 5 shard copies: Allocate no more than 2 shards per zone, which will require at least 2 nodes in 2 zones. Allocate the last shard in the third zone, with at least 1 node needed in the third zone. Alternatively, if you have 3 nodes in the first zone and 1 node in each remaining zone, then OpenSearch will allocate: 2 shard copies in the first zone. 1 shard copy in the remaining 2 zones. The final shard copy will remain unallocated due to the lack of nodes. With shard allocation awareness, if the nodes in one of your zones fail, you can be assured that your replica shards are spread across your other zones, adding a layer of fault tolerance to ensure that your data survives zone failures. To configure shard allocation awareness, add zone attributes to opensearch-d1 and opensearch-d2, respectively: node.attr.zone: zoneA\\\\n node.attr.zone: zoneB\\\\n Update the cluster settings: PUT _cluster/settings\\\\n{\\\\n  \\\\\\\"persistent\\\\\\\": {\\\\n    \\\\\\\"cluster.routing.allocation.awareness.attributes\\\\\\\": \\\\\\\"zone\\\\\\\"\\\\n  }\\\\n}\\\\n You can also use multiple attributes for shard allocation awareness by providing the attributes as a comma-separated string, for example, zone,rack. You can either use persistent or transient settings. We recommend the persistent setting because it persists through a cluster reboot. Transient settings don\\u2019t persist through a cluster reboot. Shard allocation awareness attempts to separate primary and replica shards across multiple zones. However, if only one zone is available (such as after a zone failure), OpenSearch allocates replica shards to the only remaining zone. Forced awareness Another option is to require that primary and replica shards are never allocated to the same zone. This is called forced awareness. To configure forced awareness, specify all the possible values for your zone attributes: PUT _cluster/settings\\\\n{\\\\n  \\\\\\\"persistent\\\\\\\": {\\\\n    \\\\\\\"cluster.routing.allocation.awareness.attributes\\\\\\\": \\\\\\\"zone\\\\\\\",\\\\n    \\\\\\\"cluster.routing.allocation.awareness.force.zone.values\\\\\\\":[\\\\\\\"zoneA\\\\\\\", \\\\\\\"zoneB\\\\\\\"]\\\\n  }\\\\n}\\\\n Now, if a data node fails, forced awareness doesn\\u2019t allocate the replicas to a node in the same zone. Instead, the cluster enters a yellow state and only allocates the replicas when nodes in another zone come online. In our two-zone architecture, we can use allocation awareness if opensearch-d1 and opensearch-d2 are less than 50% utilized, so that each of them have the storage capacity to allocate replicas in the same zone. If that is not the case, and opensearch-d1 and opensearch-d2 do not have the capacity to contain all primary and replica shards, we can use forced awareness. This approach helps to make sure that, in the event of a failure, OpenSearch doesn\\u2019t overload your last remaining zone and lock up your cluster due to lack of storage. Choosing allocation awareness or forced awareness depends on how much space you might need in each zone to balance your primary and replica shards. Replica count enforcement To enforce an even distribution of shards across all zones and avoid hotspots, you can set the routing.allocation.awareness.balance attribute to true. This setting can be configured in the opensearch.yml file and dynamically updated using the cluster update settings API: PUT _cluster/settings\\\\n{\\\\n  \\\\\\\"persistent\\\\\\\": {\\\\n    \\\\\\\"cluster\\\\\\\": {\\\\n      \\\\\\\"routing.allocation.awareness.balance\\\\\\\": \\\\\\\"true\\\\\\\"\\\\n    }\\\\n  }\\\\n}\\\\n The routing.allocation.awareness.balance setting is false by default. When it is set to true, the total number of shards for the index must be a multiple of the highest count for any awareness attribute. For example, consider a configuration with two awareness attributes\\u2014zones and rack IDs. Let\\u2019s say there are two zones and three rack IDs. The highest count of either the number of zones or the number of rack IDs is three. Therefore, the number of shards must be a multiple of three. If it is not, OpenSearch throws a validation exception. routing.allocation.awareness.balance takes effect only if cluster.routing.allocation.awareness.attributes and cluster.routing.allocation.awareness.force.zone.values are set. routing.allocation.awareness.balance applies to all operations that create or update indexes. For example, let\\u2019s say you\\u2019re running a cluster with three nodes and three zones in a zone-aware setting. If you try to create an index with one replica or update an index\\u2019s settings to one replica, the attempt will fail with a validation exception because the number of shards must be a multiple of three. Similarly, if you try to create an index template with one shard and no replicas, the attempt will fail for the same reason. However, in all of those operations, if you set the number of shards to one and the number of replicas to two, the total number of shards is three and the attempt will succeed. (Advanced) Step 7: Set up a hot-warm architecture You can design a hot-warm architecture where you first index your data to hot nodes\\u2014fast and expensive\\u2014and after a certain period of time move them to warm nodes\\u2014slow and cheap. If you analyze time-series data that you rarely update and want the older data to go onto cheaper storage, this architecture can be a good fit. This architecture helps save money on storage costs. Rather than increasing the number of hot nodes and using fast, expensive storage, you can add warm nodes for data that you don\\u2019t access as frequently. To configure a hot-warm storage architecture, add temp attributes to opensearch-d1 and opensearch-d2, respectively: node.attr.temp: hot\\\\n node.attr.temp: warm\\\\n You can set the attribute name and value to whatever you want as long as it\\u2019s consistent for all your hot and warm nodes. To add an index newindex to the hot node: PUT newindex\\\\n{\\\\n  \\\\\\\"settings\\\\\\\": {\\\\n    \\\\\\\"index.routing.allocation.require.temp\\\\\\\": \\\\\\\"hot\\\\\\\"\\\\n  }\\\\n}\\\\n Take a look at the following shard allocation for newindex: GET _cat/shards/newindex?v\\\\nindex     shard prirep state      docs store ip         node\\\\nnew_index 2     p      STARTED       0  230b 10.0.0.225 opensearch-d1\\\\nnew_index 2     r      UNASSIGNED\\\\nnew_index 3     p      STARTED       0  230b 10.0.0.225 opensearch-d1\\\\nnew_index 3     r      UNASSIGNED\\\\nnew_index 4     p      STARTED       0  230b 10.0.0.225 opensearch-d1\\\\nnew_index 4     r      UNASSIGNED\\\\nnew_index 1     p      STARTED       0  230b 10.0.0.225 opensearch-d1\\\\nnew_index 1     r      UNASSIGNED\\\\nnew_index 0     p      STARTED       0  230b 10.0.0.225 opensearch-d1\\\\nnew_index 0     r      UNASSIGNED\\\\n In this example, all primary shards are allocated to opensearch-d1, which is our hot node. All replica shards are unassigned, because we\\u2019re forcing this index to allocate only to hot nodes. To add an index oldindex to the warm node: PUT oldindex\\\\n{\\\\n  \\\\\\\"settings\\\\\\\": {\\\\n    \\\\\\\"index.routing.allocation.require.temp\\\\\\\": \\\\\\\"warm\\\\\\\"\\\\n  }\\\\n}\\\\n The shard allocation for oldindex: GET _cat/shards/oldindex?v\\\\nindex     shard prirep state      docs store ip        node\\\\nold_index 2     p      STARTED       0  230b 10.0.0.74 opensearch-d2\\\\nold_index 2     r      UNASSIGNED\\\\nold_index 3     p      STARTED       0  230b 10.0.0.74 opensearch-d2\\\\nold_index 3     r      UNASSIGNED\\\\nold_index 4     p      STARTED       0  230b 10.0.0.74 opensearch-d2\\\\nold_index 4     r      UNASSIGNED\\\\nold_index 1     p      STARTED       0  230b 10.0.0.74 opensearch-d2\\\\nold_index 1     r      UNASSIGNED\\\\nold_index 0     p      STARTED       0  230b 10.0.0.74 opensearch-d2\\\\nold_index 0     r      UNASSIGNED\\\\n In this case, all primary shards are allocated to opensearch-d2. Again, all replica shards are unassigned because we only have one warm node. A popular approach is to configure your index templates to set the index.routing.allocation.require.temp value to hot. This way, OpenSearch stores your most recent data on your hot nodes. You can then use the Index State Management (ISM) plugin to periodically check the age of an index and specify actions to take on it. For example, when the index reaches a specific age, change the index.routing.allocation.require.temp setting to warm to automatically move your data from hot nodes to warm nodes. Next steps If you are using the Security plugin, the previous request to _cat/nodes?v might have failed with an initialization error. For full guidance around using the Security plugin, see Security configuration. Nodes Shard allocation awareness Forced awareness Replica count enforcement WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright \\u00a9 OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\\\"},null,null,{\\\"url\\\":\\\"https://www.devcentrehouse.eu/blogs/opensearch-strategies-for-backends/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Dev Centre House Ireland Knowledge Hub Technology Industries Retail Finance E-commerce Education Manufacturing Government Real Estate Healthcare Telecommunications Services Custom Software Development Cybersercurity Data Engineering Data Management DevOp Digital Transformation Forward Deployed Software Engineers Internet of Things IT Staff Augmentation LLM Development Machine Learning Mobile App Development Network Prompt Engineering Vibe Coding Dev Centre House Scaling OpenSearch: 8 Powerful Strategies for High-Performance Backends When it comes to powering high-performance search solutions, OpenSearch is a popular choice for many organisations. However, ensuring optimal performance at scale is essential for delivering fast and reliable results. Whether you\\u2019re dealing with large datasets or high query volumes, scaling OpenSearch effectively is key to maintaining a responsive and robust backend. In this article, we explore 8 powerful strategies that can help you scale OpenSearch to meet the demands of high-performance backends. 1. Cluster Sizing and Sharding for Optimal Distribution One of the first steps in scaling OpenSearch is properly sizing your cluster. The size of your OpenSearch cluster should match the volume of data and the query load you expect. The distribution of data is handled through shards, which break your data into smaller pieces, allowing them to be distributed across multiple nodes in the cluster. To ensure high availability and performance, it\\u2019s essential to have an adequate number of primary and replica shards. The primary shards store the original data, while replica shards provide redundancy and help balance the query load. Tip: For high traffic applications, aim for a minimum of three nodes to ensure fault tolerance and balanced distribution. 2. Use Node Types to Optimise Resource Allocation Different types of nodes serve different purposes in an OpenSearch cluster. For example, you can designate certain nodes as data nodes, which are responsible for storing and processing data, while others can be designated as master nodes or client nodes. By distributing the roles across multiple nodes, you can ensure that each node is optimised for specific tasks, such as query processing, indexing, or cluster management. This segmentation helps prevent any one node from becoming overwhelmed, improving the overall performance and scalability of the system. Example: Designate dedicated master nodes to handle cluster management tasks, and separate data nodes for indexing and querying large datasets. 3. Horizontal Scaling for Increased Throughput Horizontal scaling involves adding more nodes to your OpenSearch cluster to distribute the load across more machines. By expanding the number of nodes, you can increase throughput and ensure that your system can handle higher volumes of search queries and indexing operations. Adding more nodes increases the available resources (CPU, RAM, storage), which enhances the overall performance and reliability of your OpenSearch backend. As a result, you can support a growing number of users without sacrificing speed or accuracy. Tip: Monitor the health of your cluster and add new nodes when you notice resource saturation, such as high CPU or memory usage. 4. Efficient Index Management for Faster Search Performance As your data grows, the number of indices in your OpenSearch cluster may also increase. Efficient index management is crucial to maintaining optimal search performance. To improve performance, consider implementing the following strategies: Index Lifecycle Management (ILM): Automate the management of indices based on their age or size, such as archiving old data and deleting unnecessary indices. Index Templates: Use templates to define index settings and mappings for consistency across similar types of data. Rolling Indices: Instead of adding more data to existing indices, create new indices periodically to distribute the load. Example: Use ILM to automatically roll over indices when they exceed a certain size, keeping your system clean and efficient. 5. Caching for Faster Query Responses Caching is a powerful strategy for improving the speed of repeated search queries. By storing previously executed queries and their results in mem ory, OpenSearch can return results almost instantaneously without needing to reprocess the query. You can use query result caching and filter caching to store the results of common queries and filters, reducing the strain on your system. Additionally, setting up HTTP caching for your OpenSearch endpoints can also improve response times for repeated requests. Tip: Keep in mind that caching is most effective for queries that are frequently repeated and do not change frequently. 6. Optimise Search Queries for Efficiency Optimising search queries is another essential part of scaling OpenSearch. Complex queries with multiple filters, aggregations, or sorting operations can slow down performance. Here are a few tips to ensure your queries are efficient: Avoid wildcard queries: Wildcard queries can be slow because they require OpenSearch to scan many documents. Use prefix queries or edge n-grams when possible. Use filters instead of queries: Filters are faster than queries because they do not score documents. Limit the number of returned results: Returning a large number of results can be resource-intensive. Consider using pagination or limiting the number of results returned. Example: For a high-traffic search engine, limit the results to a smaller subset (e.g., 10 to 20 results per query) to improve response times. 7. Monitor and Automate Cluster Health Checks Regular monitoring of your OpenSearch cluster is essential for ensuring that it\\u2019s performing optimally. Automated health checks can help identify issues such as node failures, slow queries, or resource bottlenecks before they impact performance. Use tools like OpenSearch Dashboards or Elasticsearch\\u2019s monitoring features to visualise key metrics such as CPU usage, disk I/O, and query response times. Setting up alerting systems based on certain thresholds (e.g., high memory usage or slow queries) can help you take proactive actions to maintain optimal performance. Tip: Automate the scaling process by integrating with orchestration tools like Kubernetes to automatically add or remove nodes based on the cluster\\u2019s performance. 8. Leverage Cross-Cluster Search for Global Scalability If you have multiple data centres or geographically dispersed systems, cross-cluster search can help scale your OpenSearch deployment across multiple clusters. This allows you to query data from multiple OpenSearch clusters in different regions or locations, without having to move the data itself. By using cross-cluster search, you can distribute your search load across multiple clusters, improving search response times and enabling global scalability. This is particularly useful for organisations with large-scale, geographically distributed datasets. Example: A global e-commerce platform can query multiple clusters in different regions to provide localised search results without compromising speed. Final Thoughts Scaling OpenSearch for high-performance backends requires a combination of strategies that optimise resource allocation, query efficiency, and cluster management. By following these 8 powerful strategies, you can ensure that your OpenSearch deployment remains fast, reliable, and scalable, no matter how large your dataset or how many users you support. Integrating techniques such as horizontal scaling, query optimisation, caching, and cross-cluster search will allow you to handle more traffic and provide a seamless search experience for users. Moreover, by leveraging the power of automated monitoring and index management, you can future-proof your OpenSearch solution for years to come. If you\\u2019re looking to take your OpenSearch implementation to the next level, Dev Centre House Ireland offers expert services in optimising OpenSearch for large-scale, high-performance backends. Their team can help you design and implement a robust, scalable search infrastructure tailored to your business needs. Ready to scale your OpenSearch solution? Implement these strategies and watch your backend performance soar! Post Views: 1,784 Get Expert Advice \\u2013 Book Your Session A quick strategy session to unlock clarity and discover your next growth steps. Search Search Search Latest Post Cloud Migration Pitfalls for Kilkenny Businesses \\u2014 and How to Avoid ThemDecember 11, 2025 Mobile App Development in Kerry: When Native Beats Cross PlatformDecember 11, 2025 Why Galway Companies Choose Custom Software Over TemplatesDecember 11, 2025 From Concept to Launch: MVP Development Tips for Cork EntrepreneursDecember 11, 2025 Five Questions Dublin SMEs Should Ask Before Hiring Web DevelopersDecember 11, 2025 Published Date: 5/2/2025 Reading Time: 4 minutes Author: Anthony Mc Cann Post Views: 1,784 Ask for Expert Advice LinkedIn Facebook Mail Instagram\\\"},{\\\"url\\\":\\\"https://dev.to/aws-builders/the-scoop-on-opensearch-sizing-1c9e\\\",\\\"title\\\":\\\"Dropdown menu Dropdown menu Navigation menu Search Search Close More... Copy link Enter fullscreen mode Exit fullscreen mode Enter fullscreen mode Exit fullscreen mode\\\",\\\"content\\\":\\\"Forem Feed Follow new Subforems to improve your feed DEV Community Follow A space to discuss and keep up software development and manage your software career Future Follow News and discussion of science and technology such as AI, VR, cryptocurrency, quantum computing, and more. Open Forem Follow A general discussion space for the Forem community. If it doesn't have a home elsewhere, it belongs here Gamers Forem Follow An inclusive community for gaming enthusiasts Music Forem Follow From composing and gigging to gear, hot music takes, and everything in between. Vibe Coding Forem Follow Discussing AI software development, and showing off what we're building. Popcorn Movies and TV Follow Movie and TV enthusiasm, criticism and everything in-between. DUMB DEV Community Follow Memes and software development shitposting Design Community Follow Web design, graphic design and everything in-between Security Forem Follow Your central hub for all things security. From ethical hacking and CTFs to GRC and career development, for beginners and pros alike Golf Forem Follow A community of golfers and golfing enthusiasts Crypto Forem Follow A collaborative community for all things Crypto\\u2014from Bitcoin to protocol development and DeFi to NFTs and market analysis. Parenting Follow A place for parents to the share the joys, challenges, and wisdom that come from raising kids. We're here for them and for each other. Forem Core Follow Discussing the core forem open source software project \\u2014 features, bugs, performance, self-hosting. Maker Forem Follow A community for makers, hobbyists, and professionals to discuss Arduino, Raspberry Pi, 3D printing, and much more. HMPL.js Forem Follow For developers using HMPL.js to build fast, lightweight web apps. A space to share projects, ask questions, and discuss server-driven templating Dropdown menu Dropdown menu Skip to content Navigation menu Search Powered by Algolia Search Log in Create account DEV Community Close Add reaction Like Unicorn Exploding Head Raised Hands Fire Jump to Comments Save Boost More... Copy link Copy link Copied to Clipboard Share to X Share to LinkedIn Share to Facebook Share to Mastodon Share Post via... Report Abuse dejanualex for AWS Community Builders Posted on Sep 2, 2024 \\u2022 Edited on Mar 7, 2025 The Scoop On OpenSearch sizing #aws #opensearch #tutorial #elasticsearch Search and analytics means you can search and analyze your data once it has been ingested into OpenSearch. Getting acquainted with the terminology is mandatory when working with OpenSearch, therefore you should check OpenSearch for Humans\\u200a-\\u200aa friendly guide. Additionally, a simple yet concrete OpenSearch Calculator implementation. Index size? Number of shards per index? OpenSearch splits indices into shards. Each shard stores a subset of all documents in an index. A shard can be either primary (used for WRITE operations e.g. index, re-index, delete) or replica (used for HA and READ operations e.g. searches). OpenSearch defaults to one primary and one replica shard, for a total of two shards per index. \\u26a0\\ufe0f Primary shards cannot be on the same node as the replica. A shard is a piece of an OpenSearch index, each shard is a full Lucene Index, and each instance of Lucene is a running process that consumes CPU and Memory. Avoid Oversharding and Node hot spotting When a shard is involved in an indexing or search request, it uses the CPU to process the request. Each shard you add to an index distributes the processing of requests for that index across an additional CPU. The number of active shards that your domain can support depends on the number of CPUs in the cluster. Node hot spotting occurs when resource utilizations are unevenly distributed across nodes, e.g. uneven JVM heap size usage. To quickly detect node hot spotting use OpenSearch API: GET _cat/nodes?v=true&h=name,heap.current,heap.percent\\\\n Enter fullscreen mode Exit fullscreen mode As a rule of thumb, the allocated heap size should be based on the available RAM: set Xms and Xmx to the same value, and no more than 50% of your total memory. A larger Java heap size is useful for indexing, but as memory usage increases, garbage collection becomes more frequent and takes longer. Shard Count Shard count is secondary to shard size. Shard size matters because it impacts both search latency and write performance. A small set of large shards uses fewer resources than many small shards (too many small shards will exhaust the memory\\u200a-\\u200aJVM Heap), however, on the other side, too few large shards prevent OpenSearch from properly distributing requests. For fast indexing (ingestion), you need as many shards as possible; for fast searching, it is better to have as few shards as possible When an index is created, the number of shards must be specified and cannot be changed later without reindexing the data. The number of shards you set for an index should correspond to the size of an index, e.g. looking at the two indices store.sizes (one which has replicas set to 0 and the other has replicas set to 1) we can observe that each replica is a full copy of a primary shard. store.size is the store size taken by primary and replica shards. pri.store.size is the store size taken only by primary shards. Total number of shards First, try to estimate the total size of the data you plan to store in the index and the retention period, and then you can calculate the total number of shards using the formula: \\u26a0\\ufe0f Ideally, shard sizes should be between 10GB and 50GB per shard, 10\\u201330 GB for workloads that prioritize low latency (e.g., search workloads), or 30\\u201350 GB (e.g. logging workloads). Number of shards per index To prevent hot nodes, OpenSearch distributes shards to instances based on count, where each instance receives as nearly as possible the same number of shards. Use shard counts that are multiples of the data node count to ensure that each index is distributed evenly across data nodes. To ensure an even distribution of shards across the data nodes follow the formula: i.e. If your cluster has 4 nodes and you want to distribute the shards across all nodes evenly, your index should have 8 shards. In other words, you should have at least one shard per data node. Tunning cluster performance: Search (read) or Ingest (write)? Search Intensive Try to reduce the number of shards as much as possible. Replicas improve search performance, so you might want more if you have a read-heavy workload. Ingest Intensive Try to have as many shards, as possible. Each replica duplicates the indexing process (new documents are first indexed on the primary and then on any replicas) if you anticipate heavy indexing you can temporarily set the replica count value index.number_of_replicas to 0. Increase Index refresh frequency: Indexing documents initially place them into a memory buffer. At this stage, the documents are not yet searchable. To make these documents searchable, a refresh operation is required. OpenSearch refreshes indexes that have received at least one search request in the last 30 seconds, every 1 second. # GET /_cluster/settings?include_defaults=true\\\\ndefault\\\\\\\": {\\\\n        \\\\\\\"index\\\\\\\": {\\\\n          \\\\\\\"refresh_interval\\\\\\\": \\\\\\\"1s\\\\\\\"\\\\n        }\\\\n      },\\\\n Enter fullscreen mode Exit fullscreen mode This means that documents written to an active index should typically become searchable within 1 second of being written to OpenSearch. This setting can be adjusted on a per-index basis. Keep in mind a shorter refresh interval allows documents to become searchable more rapidly post-indexing, but it does so at the expense of increased resource utilisation. Last but not least, some key takeaways: Seven rules for OpenSearch sizing Links: OpenSearch for Humans OpenSearch: Do Some Stats on Your Indices Tooling for benchmarking: OpenSearch BenchMark for gathering performance metrics and rally a framework for ElasticSearch OpenSearch calculator AWS OpenSearch service Top comments (0) Subscribe \\\\n Personal Trusted User Create template Templates let you quickly answer FAQs or store snippets for re-use. Submit Preview Dismiss Code of Conduct \\u2022 Report abuse Are you sure you want to hide this comment? It will become hidden in your post, but will still be visible via the comment's permalink. Hide child comments as well Confirm For further actions, you may consider blocking this person and/or reporting abuse AWS Community Builders Follow Build On! Would you like to become an AWS Community Builder? Learn more about the program and apply to join when applications are open next. Learn more More from AWS Community Builders Lightweight ETL with AWS Lambda, chDB, and PyIceberg (Compared with DuckDB) #aws #iceberg #chdb #duckdb Dockerize a Snake and Ladder Game Application in EC2 #webdev #programming #aws #docker Building Serverless Microservices on AWS with ECS Fargate, ECR, and Terraform #serverless #microservices #terraform #aws \\ud83d\\udc8e DEV Diamond Sponsors Thank you to our Diamond Sponsors for supporting the DEV Community Google AI is the official AI Model and Platform Partner of DEV Neon is the official database partner of DEV Algolia is the official search partner of DEV DEV Community \\u2014 A space to discuss and keep up software development and manage your software career Home DEV++ Reading List Podcasts Videos DEV Education Tracks DEV Challenges DEV Help Advertise on DEV DEV Showcase About Contact Free Postgres Database Software comparisons Forem Shop Code of Conduct Privacy Policy Terms of Use Built on Forem \\u2014 the open source software that powers DEV and other inclusive communities. Made with love and Ruby on Rails. DEV Community \\u00a9 2016 - 2026. We're a place where coders share, stay up-to-date and grow their careers. Log in Create account\\\"},null,{\\\"url\\\":\\\"https://www.prosperops.com/blog/aws-opensearch-best-practices/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Products Rate Optimization Autonomous Discount Management Automate commitment management to maximize savings and reduce lock-in risk Amazon Web Services Google Cloud Microsoft Azure WORKLOAD Optimization Autonomous Resource Management Synchronize resource schedules with commitment actions to minimize waste ProsperOps Scheduler REPORTING CAPABILITIES Intelligent Showback Effective Savings Rate Commitment Lock-In Risk Data Export Resources Learn & Meet Library In-depth research and strategies to guide your FinOps strategy. Blog Get best practices, tips, and strategies for maximum cloud cost savings for now and in the future. Events Join ProsperOps for an upcoming event, including conferences, trade shows, and local happy hours. Podcast Candid conversations with practitioners, influencers, and thought leaders in cloud financial management. Webinars Register to join us live, or watch recordings of our webcasts about cloud cost optimization and FinOps. Success Stories Learn how our automated cost optimization software helps customers, resellers, and partners conquer cloud economics. Using ProsperOps Help Center Get help with frequently asked questions and get started quickly. Legal Learn more about our service terms, privacy policy, and more. FinOps Automation Video Series. Learn how to implement automated FinOps tools within your cloud financial management practice, measure your success, and achieve better outcomes. Learn More Pricing Company About ProsperOps Learn more about about our company, timeline, and leadership. News Read press releases and see ProsperOps in the news. Contact Reach out to our team to learn more. Careers We're hiring! See open positions and learn more about joining our team. Partners Learn more about Partnering with ProsperOps. Private Equity Learn more about benefits to Private Equity portfolio companies. 2025 AWS Compute Rate Optimization Insights Report is now available. Discover your Effective Savings Rate benchmarking and trends. Learn More FinOps Automation Video Series. Learn how to implement automated FinOps tools within your cloud financial management practice, measure your success, and achieve better outcomes. Learn More Log In Get a Demo All blog posts AWS Maximizing AWS OpenSearch: 15 Best Practices for Optimal Performance Originally Published February, 2024 \\u00b7 Last Updated September, 2024 By: Ross Clurman Marketing Amazon Web Services (AWS) OpenSearch is a scalable and open-source search and analytics suite derived from Amazon Elasticsearch Service. It offers enhanced features and compatibility with Elasticsearch APIs. However, navigating AWS OpenSearch can often feel daunting, even for experienced AWS customers. To get the most out of the platform, it\\u2019s not enough to optimize your searches; you need to ensure you\\u2019re leveraging your data\\u2019s full potential while managing your OpenSearch clusters. This article outlines 15 AWS OpenSearch best practices that give you practical, actionable tips to elevate your OpenSearch experience. From optimizing cluster performance to ensuring high-level security, we\\u2019ll cover key practices that can significantly impact your operations. These 15 practices are divided into four categories: data management, performance and scalability, cost optimization, and security. Data management In managing your Amazon OpenSearch Service, specific strategies for cluster configuration, sharding, replication, and operation restrictions are essential for optimal performance and reliability. 1. Changing default cluster name By default, your OpenSearch Service domain is assigned a generic cluster name that isn\\u2019t easily distinguishable. You should immediately change the default cluster name to a clear, meaningful identifier. This change not only aids in better organization but also prevents confusion when managing multiple clusters within your infrastructure. 2. Sharding and replication Understanding and configuring shards and replicas is critical to how your data is distributed and made resilient across the OpenSearch Service. When creating an index, aim for an optimal shard count that suits your data volume and query demands. Each index contains primary shards holding your data and replica shards, providing redundancy and increasing search operations\\u2019 availability. Be strategic; while more shards provide higher parallel processing, they also consume more resources. A balanced approach maximizes both performance and fault tolerance. 3. Restrict wildcards in destructive operations To ensure the integrity of your indices, it\\u2019s wise to restrict wildcards (* or ?) in destructive operations, such as deleting indices. Accidental deletion is a real risk that can result in significant data loss. By limiting wildcard usage, you enforce more granular control over such operations. You\\u2019ll safeguard your data within the Amazon OpenSearch Service domain against unintended bulk deletions. Performance and scalability You need to understand the complex dynamics of performance and scalability to maintain an efficient Amazon OpenSearch Service environment. By leveraging best practices, you can ensure your deployment is fine-tuned for optimal performance and the ability to scale effectively as demand grows. 4. Limit script usage Scripts, particularly those in Painless, can be resource-intensive. You should minimize script usage and optimize your deploy scripts to conserve RAM and boost overall performance. Heavily scripted operations can increase latency, so judicious use is key for high availability. 5. Careful use of regex in scripts Be careful when using regular expressions (regex) in scripts, as these can quickly become performance bottlenecks. Poorly constructed regex can lead to significant resource drain, so it\\u2019s imperative to employ efficient patterns that don\\u2019t overburden the CPU. 6. Dedicated master and coordinating nodes Deploying dedicated master nodes is recommended for clusters that are critical or have heavy loads. This ensures better throughput and stability during volatility, for instance, in count or data-intensive operations. Similarly, dedicated coordinating nodes can manage request routing, reducing the load on data nodes. 7. Correct configuration of minimum master nodes To prevent split-brain scenarios and potential data loss, you should correctly configure the minimum number of master-eligible nodes. Typically, this is (number of dedicated master nodes / 2) + 1, ensuring high availability and mitigating failure risks. 8. Autotune for Amazon OpenSearch Service Autotune is an Amazon OpenSearch Service feature that automatically adjusts resources for improved performance. It can modify Java Virtual Machine (JVM) settings and other performance-related parameters, influencing RAM usage and accelerating operations based on your workload patterns. 9. Use CloudWatch for monitoring and alerting Consistent, real-time monitoring is pivotal for performance and scaling. Leverage Amazon CloudWatch to track crucial metrics like CPU utilization, RAM usage, and disk I/O, which will inform you about the health of your cluster. Set CloudWatch alarms and use Cloudwatch Logs to avoid potential issues and maintain availability. You\\u2019ll also better understand query latency and throughput, which are crucial for scaling decisions such as adjusting the number of replicas, shards, and shard sizes across availability zones. Cost optimization Achieving cost efficiency in AWS OpenSearch is pivotal as your data grows and your infrastructure scales. Careful consideration of instance types and the use of cost optimization tools can lead to significant savings. 10. Latest generation instance types Selecting the latest generation instance types can improve resource utilization and cost efficiency when using AWS OpenSearch. Your choice should align with your workload\\u2019s specific requirements: m5 and r5 instances: Ideal for balanced memory and compute-optimized tasks, offering a mix of CPU power and memory suitable for general-purpose workloads. i3 instances: Best for high I/O-intensive applications, which demand low-latency, high-throughput workloads. c5 instances: Favored for compute-intensive applications, delivering high CPU performance for processes that require heavy calculations. Be aware that, often, newer instances can deliver higher performance at a lower cost than older generation instances at comparable pricing models. Scaling your instance counts to match your demand will optimize costs without compromising service delivery. 11. Using a cost optimization tool Incorporate a cost optimization tool designed for AWS services to automate saving processes and manage costs effectively. For example, you can leverage ProsperOps\\u2019 Automated Discount Management for OpenSearch to streamline your cost optimization efforts. Through this offering, ProsperOps will automatically manage Reserved Instances (RIs) for OpenSearch by building an RI ladder over time to balance savings and risk. A cost optimization tool simplifies the process of: Analyzing spending trends: Understand where the costs come from and identify underutilized resources. Implementing pricing models: Opt for pricing models that work best for your infrastructure costs, like Reserved Instances or Savings Plans, which offer savings over on-demand pricing. Remember that these tools help customers use their resources more effectively, ensuring you only pay for the throughput and instance types you need. Regularly review your strategy to ensure it adapts to your business\\u2019s data growth and operational changes. By prioritizing the latest generation instance types and employing cost optimization tools, you can maintain cost efficiency while managing a robust AWS OpenSearch service. Security Security is paramount when managing your AWS OpenSearch Service to protect your data and ensure access is controlled and monitored. Implementing the following best practices helps to maintain high availability and prevent data loss or exposure. 12. Enabling fine-grained access control To safeguard your OpenSearch clusters, fine-grained access control is essential. You\\u2019re able to establish precise user permissions for your OpenSearch data. Use AWS Identity and Access Management (IAM) to define roles and responsibilities, ensuring that users only have access to the resources relevant to their duties. 13. Restrictive access policy Employ a restrictive access policy to limit access to your OpenSearch environment. By default, deny all incoming traffic and explicitly allow only necessary communication. This minimizes the risk of unauthorized access or accidental exposure of sensitive information. 14. Schedule time for updates Regularly schedule updates and upgrades to your OpenSearch Service to patch any vulnerabilities and ensure your systems are up to date. Expect minimal downtime by using dedicated master nodes, which also help maintain cluster stability during updates. 15. Enable encryption at rest and node-to-node encryption Protect your data by enabling encryption at rest for your EBS volume size to secure disk space against unauthorized access. Also, activating node-to-node encryption ensures that data in transit between nodes in your cluster is not intercepted, thus maintaining the integrity and privacy of your search engine\\u2019s traffic. Optimize your AWS costs easily with ProsperOps Get the most from AWS OpenSearch features, including visualization capabilities with OpenSearch Dashboards and Kibana. Optimize your costs with ProsperOps and craft a cost-effective AWS environment by selecting the right instance types and scaling appropriately. ProsperOps makes AWS cost optimization simpler with hands-off: Pricing optimization: Reduce your AWS costs through automated tools that ensure you use the most cost-effective solutions. Resource allocation & budget management: Align your spending with company goals, ensuring every dollar spent drives value. Long-term savings: Commit to smarter resource use for sustained reductions in cloud expenses. Ready to learn more about how ProsperOps can help your business optimize AWS costs? Book a demo today to see what our solutions can do firsthand. Share Facebook Twitter Linkedin Reddit Get Started for Free Sign Up Data management 1. Changing default cluster name 2. Sharding and replication 3. Restrict wildcards in destructive operations Performance and scalability 4. Limit script usage 5. Careful use of regex in scripts 6. Dedicated master and coordinating nodes 7. Correct configuration of minimum master nodes 8. Autotune for Amazon OpenSearch Service 9. Use CloudWatch for monitoring and alerting Cost optimization 10. Latest generation instance types 11. Using a cost optimization tool Security 12. Enabling fine-grained access control 13. Restrictive access policy 14. Schedule time for updates 15. Enable encryption at rest and node-to-node encryption Optimize your AWS costs easily with ProsperOps Get Started for Free Sign Up Latest from our blog Product 2025 Wrapped: Key Product Updates Read More AWS AWS re:Invent 2025 Recap: Unlocking Cost Efficiency in the Cloud Read More Azure Microsoft Ignite 2025 Recap: What You Missed Read More Request a Free Savings Analysis 3 out of 4 customers see at least a 50% increase in savings. Get a deeper understanding of your current cloud spend and savings, and find out how much more you can save with ProsperOps! Visualize your savings potential Benchmark performance vs. peers 10-minute setup, no strings attached Submit the form to request your free cloud savings analysis. Home Pricing Partners About Us News FinOps Podcast \\ud83c\\udf99\\ufe0f Get a Demo Start for Free Cloud Savings Analysis Become a Partner Resource Center Effective Savings Rate Contact Us Careers Legal Status Log In Help Center Trust Center \\u00a9 2026 ProsperOps, Inc. All rights reserved. Website Terms Privacy Policy Submit the form to request your free cloud savings analysis.\\\"},{\\\"url\\\":\\\"https://logit.io/blog/post/opensearch-best-practises/\\\",\\\"title\\\":\\\"back back\\\",\\\"content\\\":\\\"Logit.io requires JavaScript to be enabled Platform Logging Log Management Logging as a Service Metrics Metrics as a Service Metrics Management Observability Cloud Application Performance Monitoring Application Performance Monitoring Application Performance Analyser SIEM as a Service Logit.io For OpenTelemetry Trace Analytics Features Hosted OpenSearch Hosted ELK Hosted Jaeger Hosted Prometheus Hosted Kibana Hosted Grafana Hosted Logstash Grafana Demo Using a managed solution like the one provided by Logit.io, enables you to get started with Grafana within minutes. Prometheus as a Service Identify the root cause behind container failures faster by using Prometheus as a Service ELK as a Service ELK as a Service provides busy DevOps, SysAdmins, and IT leaders with an affordable and scalable alternative to building their own Elastic Stacks. Solutions Monitoring Log Monitoring Container Monitoring Data Monitoring Production Monitoring Infrastructure Monitoring Hybrid Cloud & Multi-Cloud Monitoring Kubernetes Monitoring Logging Observability Security Logging Logging Made Easy (LME) Compliance and Auditing Compliance and Auditing Analysis Analysis Solutions Log Analysis Business Analytics DevOps Analytics Event Log Analyser Security Analytics Platform-Specific Logging Amazon Web Services (AWS) Azure Google Cloud Platform (GCP) Django CMMC Solution CMMC Audit Logging Datadog Alternative Learn more on how Logit.io can easily be leveraged as an affordable alternative to Datadog. Splunk Alternative See how metrics, traces & logs can be measured affordably for security and alerting with Logit.io. Logz.io Alternative Switch today & save when you use Logit.io as your highly affordable observability platform. New Relic Alternative Empower your team to observe key insights while saving on costs when using Logit.io. Pricing Docs Get a DemoStart Free TrialSign In back Back to Blog Top OpenSearch Best Practises for Success By David Benson May 27th, 2024 Resources 4 min read While OpenSearch provides a rich set of features and capabilities out of the box, optimizing its performance, reliability, and security requires adherence to best practices. To assist you in navigating OpenSearch we have put together an extensive guide of the best practices for OpenSearch to ensure that you get the most out of the solution. These best practices cover multiple aspects of cluster architecture, indexing, querying, monitoring, security, and more, guaranteeing that your OpenSearch deployment operates smoothly and delivers actionable insights to your organization. What is OpenSearch? OpenSearch is an open-source distributed search and analytics engine created for scalability, simplicity, and performance. It serves as a powerful tool for indexing, searching, and examining large volumes of data in real-time. OpenSearch is built on Apache Lucene, a commonly used full-text search library, and it offers a robust platform for a broad range of use cases such as log analytics, monitoring, search engines, and business intelligence. Originally, OpenSearch was a community-driven fork of Elasticsearch, an open-source search and analytics engine developed by Elastic. However, it has since evolved into a separate project with its own governance and roadmap. OpenSearch intends to supply users with a fully open-source alternative to proprietary search and analytics solutions, providing transparency, flexibility, and control over their data and infrastructure. Contents OpenSearch Best Practices Cluster Sizing and Configuration Index Management Data Ingestion and Pipeline Query Optimization Monitoring and Alerting Security, Backup, and Disaster Recovery Documentation and Training Hosted OpenSearch OpenSearch Best Practices Optimizing the utilization of OpenSearch entails adhering to a set of best practices aimed at improving performance, reliability, and security. We have listed a range of OpenSearch best practices that cover all aspects of the solution below. Cluster Sizing and Configuration Firstly, cluster sizing and configuration are crucial. You need to properly outline node types and hardware specifications to match your workload demands. Dedicate nodes for certain roles such as master, data, and coordinating nodes to streamline responsibilities and enhance performance. Additionally, you should determine the amount of shards and replicas for each index to stop resource overutilization and facilitate efficient cluster operation. Fine-tune network settings to ensure seamless communication between nodes to avoid latency issues and bottlenecks. Index Management Another vital aspect when using OpenSearch in index management. You should utilize Index Lifecycle Management (ILM) policies to automate index lifecycle operations such as rollover, retention, and deletion. Implement index shrink and split operations to manage index size and distribution effectively, to improve query performance and storage efficiency. Data Ingestion and Pipeline Efficient data ingestion and processing are vital for maintaining optimal cluster performance in OpenSearch. You and your team should employ bulk indexing techniques to ingest large volumes of data swiftly while minimizing overhead. Make sure to utilize ingest node pipelines to preprocess and enrich data before indexing, guaranteeing data quality and optimizing search capabilities. Query Optimization Query optimization is a vital practice to ensure maximum search performance. You should focus on carefully designing indices and mappings to support efficient querying. Utilize the Query DSL to construct enhanced queries, leveraging filters, aggregations, and scoring mechanisms. Regularly track query performance and use profiling tools to highlight and address performance bottlenecks. Monitoring and Alerting Maintaining cluster health and proactively addressing issues is made simpler by utilizing monitoring and alerting mechanisms. Track critical cluster metrics such as CPU usage, memory utilization, disk I/O, and JVM heap usage to identify anomalies and performance degradation. It\\u2019s vital to configure alerts to fire when critical events occur and thresholds are breached to notify administrators promptly to sped up time to resolution. Security, Backup, and Disaster Recovery Enhance the security of your OpenSearch cluster by enabling authentication and authorization mechanisms. Employ role-based access control (RBAC) to manage access to indices, documents, and cluster APIs based on user roles and permissions. Also, you should encrypt network traffic using Transport Layer Security (TLS) to protect data in transit. Ensure you enable encryption at rest to encrypt data stored on disk to prevent unauthorized access. Also, backup and disaster recovery strategies are crucial for guaranteeing data resilience and business continuity. Employ snapshot and restore functionality to create frequent backups of indices and restore them in case of data loss or corruption. Documentation and Training To continue the effective operation of Opensearch, comprehensive documentation and ongoing training are vital for fostering knowledge sharing and empowering administrators and users to leverage OpenSearch effectively. You should maintain detailed documentation covering cluster configuration, best practices, troubleshooting procedures, and recovery processes. As well as this, offer frequent training sessions and resources to guarantee administrators and users have the skills and knowledge to manage OpenSearch clusters effectively. Hosted OpenSearch Opting for a Hosted OpenSearch solution could be the perfect choice for your organization. With a Hosted OpenSearch solution, like the one provided by Logit.io, you can benefit from a streamlined deployment process, removing the need for manual setup and configuration. This lessens the complexity and time required to get started with OpenSearch. As well as this, Logit.io Hosted OpenSearch the infrastructure is managed by us, including provisioning, scaling, monitoring, and maintenance tasks. This reduces the burden of managing infrastructure from your team, enabling you to focus on your organisation's key business objectives. In addition to this, Logit.io's service employs stringent security features, including encryption at rest and in transit, role-based access control (RBAC), and integration with identity providers for authentication. This aids in enhancing the security posture of your OpenSearch deployment without requiring additional configuration. Our hosted OpenSearch offers a convenient and cost-effective way to leverage the power of OpenSearch without the overhead of managing infrastructure and operations. If you\\u2019re interested in finding out more about Logit.io\\u2019s hosted OpenSearch solution, don\\u2019t hesitate to arrange an OpenSearch demo, or begin exploring the platform for yourself with a 14-day free trial. If you've enjoyed this article why not read OpenSearch vs Elasticsearch or The Best OpenSearch Dashboard Examples next? Previous Post: The Critical Role of Log Management in SaaS Environments Next Post: The Top 50 OpenSearch Interview Questions Get the latest elastic Stack & logging resources when you subscribe back Back to Blog The Latest News from Logit.io OpenTelemetry Distributed Tracing Implementation Guide Manufacturing IoT Monitoring: Complete Enterprise Guide Media Streaming Performance: Complete Enterprise Guide Gaming Infrastructure Monitoring: Complete Enterprise Guide Financial Services Security Monitoring: Enterprise Guide Leading Tools Alternatives Dashboards Guides Kubernetes Management Tools Distributed Tracing Tools Data Visualisation Tools Log Management Tools Log Monitoring Tools Metrics Tools SIEM Tools Platform Logging Metrics Observability Features Pricing Solutions Monitoring Security Log Application Logging Logging Made Easy Django Logging Compliance and Auditing Analysis CMMC Solution Azure Logging Log Viewer Resources Integrations Documentation Platform Status Logit.io Blog Compare Compare alternatives Datadog alternative Dynatrace alternative Sumo Logic alternative Logz.io alternative LogicMonitor alternative Loggly alternative Stackify alternative Splunk alternative Papertrail alternative New Relic alternative Mezmo alternative About Us About Us Legal Why Logit? Security and Compliance Consultancy Contact Us Partner \\u00a9 2025 Logit.io Ltd, All rights reserved.\\\"},{\\\"url\\\":\\\"https://docs.aws.amazon.com/prescriptive-guidance/latest/opensearch-service-migration/sizing.html\\\",\\\"title\\\":\\\"Sizing - AWS Prescriptive Guidance\\\",\\\"content\\\":\\\"Sizing - AWS Prescriptive Guidance DocumentationAWS Prescriptive GuidanceMigrating to Amazon OpenSearch Service StorageNumber of nodes and instance typesDetermining the indexing strategy and shard countCPU utilizationInstance types Sizing Sizing helps you determine the right instance type, number of data nodes, and storage requirement for your target environment. We recommend that you size first by the storage and then by CPUs. If you're already using Elasticsearch or OpenSearch, the sizing will generally remain the same. However, you need to identify the instance type that is equivalent to your current environment. To help determine the right size, we recommend using the following guidelines. Storage Sizing your cluster starts with defining the storage requirements. Identify the raw storage that you need for your cluster. This is determined by assessing the data generated by your source system (for example, servers generating logs, or product catalog raw size). After you identify how much raw data you have, use the following formula to calculate storage requirements. You can then use the result as a starting point for your PoC. storage needed = (daily source data in bytes \\u00d7 1.45) (number_of_replicas + 1) \\u00d7 number of days retained The formula takes into consideration the following: The on-disk size of an index varies, but it's often 10 percent larger than the source data. Operating system overhead of 5 percent is reserved by Linux for system recovery and to safeguard against disk defragmentation problems. OpenSearch reserves 20 percent of the storage space of each instance for segment merges, logs, and other internal operations. We recommend keeping 10 percent additional storage to help minimize the impact of node failure and Availability Zone outages. Combined, these overheads and reservations require 45 percent additional space based on the actual raw data in the source. That's why you multiply the source data by 1.45. Next, multiply this by number of copies of data (for example, one primary plus the number of replicas you will use). The replica count depends on your resiliency and throughput requirement. For an average use case, you start with one primary and one replica. Finally, multiply by the number of days that you want to retain data in a hot-storage tier. Amazon OpenSearch Service offers hot, warm, and cold storage tiers. The warm storage tier uses UltraWarm storage. UltraWarm provides a cost-effective way to store large amounts of read-only data on Amazon OpenSearch Service. Standard data nodes use hot storage, which takes the form of instance stores or Amazon Elastic Block Store (Amazon EBS) volumes attached to each node. Hot storage provides the fastest possible performance for indexing and searching new data. UltraWarm nodes use Amazon Simple Storage Service (Amazon S3) as storage and a sophisticated caching solution to improve performance. For indexes that you are not actively writing to, or query less frequently, and do not have the same performance requirements, UltraWarm offers significantly lower costs per GiB of data. For more information about UltraWarm, see the AWS documentation. When you create an OpenSearch Service domain and use hot storage, you might need to define the EBS volume size. It depends on your choice of instance type for the data nodes. You can use the same storage-requirement formula to determine the volume size for Amazon EBS backed instances. We recommend using gp3 volumes for latest-generation T3, R5, R6G, M5, M5g, C5, and C6g instance families. Using Amazon EBS gp3 volumes, you can provision performance independent of storage capacity. Amazon EBS gp3 volumes also provide better baseline performance, at a 9.6 percent lower cost per GB than existing gp2 volumes on OpenSearch Service. With gp3, you also get denser storage on R5, R6g, M5, and M6g instance families, which can help you to further optimize your costs. You can create EBS volumes up to the supported quota. For more information on quotas, see Amazon OpenSearch Service quotas. For data nodes that have NVM Express (NVMe) drives, such as i3 and r6gd instances, the volume size is fixed, so EBS volumes are not an option. Number of nodes and instance types The number of nodes is based on the number of CPUs required to operate your workload. The number of CPUs is based on the shard count. An index in OpenSearch is made up of multiple shards. When you create an index, you specify the number of shards for the index. Therefore, you need to do the following: Calculate the total shard count that you intend to store in the domain. Determine the CPU. Find the most cost-effective node type and count that gives you the required number of CPUs and storage. This is usually a starting point. Run tests to determine that the estimate size is meeting your functional and nonfunctional requirements. Determining the indexing strategy and shard count After you know the storage requirements, you can decide how many indexes you need and identify the shard count for each. Generally, search use cases have one or a few indexes, each representing a searchable entity or a catalog. For log analytics use cases, an index can represent a daily or weekly log file. After you decide how many indexes, begin with the following scale guidance, and determine appropriate shard count: Search use cases \\u2013 10\\u201330 GB/shard Log analytics use cases \\u2013 50 GB/shard You can divide the total volume of data in a single index by the shard size you are aiming for in your use case. This will give you the number of shards for the index. Identifying the total number of shards will help you find the right instance types that suit your workload. The shards shouldn't be too large or too numerous. Large shards can make it difficult for OpenSearch to recover from failure, but because each shard uses some amount of CPU and memory, having too many small shards can cause performance issues and out-of-memory errors. Moreover, imbalance in shard allocation to data nodes can lead to skewing. When you have indexes with multiple shards, try to make the shard count an even multiple of the data node count. This helps to ensure that shards are evenly distributed across data nodes, and prevents hot nodes. For example, if you have 12 primary shards, your data node count should be 2, 3, 4, 6, or 12. However, shard count is secondary to shard size\\u2014if you have 5 GiB of data, you should still use a single shard. Balancing replica shard count evenly across the Availability Zone also helps improve resilience. CPU utilization The next step is to identify how many CPUs you need for your workload. We recommend starting with a CPU count 1.5 times that of your active shards. An active shard is any shard for an index that is receiving substantial writes. Use the primary shard count to determine active shards for indexes that are receiving substantial read or write requests. For log analytics, only the current index is generally active. For search use cases, all primary shards will be considered as active shards. Although we recommend 1.5 CPU per active shard, this is highly workload-dependent. Be sure to test and monitor CPU utilization and scale accordingly. A best practice for maintaining your CPU utilization is to make sure that the OpenSearch service domain has enough resources to perform its tasks. A cluster that has consistently high CPU utilization can degrade cluster stability. When your cluster is overloaded, OpenSearch Service will block incoming requests, which results in request rejections. This is to protect the domain from failing. General guidelines on the CPU usage will be about 60 percent average, 80 percent max CPU utilization. Occasional spikes of 100 percent are still acceptable and might not require scaling or reconfiguration. Instance types Amazon OpenSearch Service provides you with a choice of several instance types. You can choose the instance types that best fit your use case. Amazon OpenSearch Service supports the R, C, M, T, and I instance families. You choose an instance family based on the workload: memory optimized, compute optimized, or mixed. After you identify an instance family, choose the latest-generation instance type. Generally, we recommend Graviton and later generations because they are built to provide improved performance with lower costs compared with previous-generation instances. Based on various testing that was performed for log analytics and search use cases, we recommend the following: For log analytics use cases , a general guideline is to begin with the R family of Graviton instances for data nodes. We recommend that you run tests, establish benchmarks for your requirements, and identify the appropriate instance size for your workload. For search use cases, we recommend using R and C family Graviton instances for data nodes, because search use cases require more CPU compared with log analytics use cases. For smaller workloads, you can use M family Graviton instances for both search and logs. I family instances offer NVMe drives and are used by customers with fast-indexing and low-latency search requirements. The cluster is composed of data nodes and cluster manager nodes. Although dedicated master nodes don't process search and query requests, their size is highly correlated with the instance size and number of instances, indexes, and shards that they can manage. AWS documentation provides a matrix that recommends minimum dedicated cluster manager instance type. AWS offers general purpose (M6g), compute optimized (C6g), and memory optimized (R6g and R6gd) for Amazon OpenSearch Service version 7.9 or later powered by AWS Graviton2 processors. These instances are built using custom silicon designed by Amazon. They are Amazon-designed hardware and software innovations that enable the delivery of efficient, flexible, and secure cloud services with isolated multi-tenancy, private networking, and fast local storage. The Graviton2 instance family reduces indexing latency by up to 50 percent and improves query performance by up to 30 percent when compared with the previous generation Intel-based instances available in OpenSearch Service (M5, C5, R5). Javascript is disabled or is unavailable in your browser. To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions. Document Conventions Planning Functionality Did this page help you? - Yes Thanks for letting us know we're doing a good job! If you've got a moment, please tell us what we did right so we can do more of it. Did this page help you? - No Thanks for letting us know this page needs work. We're sorry we let you down. If you've got a moment, please tell us how we can make the documentation better.\\\"}]}\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Search for operational best practices\n",
    "parameters = {\n",
    "    \"question\": \"OpenSearch cluster sizing best practices\"\n",
    "}\n",
    "\n",
    "print(\"‚ùì Question: OpenSearch cluster sizing best practices\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "response = execute_agent(client, agent_id, parameters)\n",
    "\n",
    "print(\"\\nüí° Best Practices:\")\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4b9e8f",
   "metadata": {},
   "source": [
    "## Step 8: Test Case 5 - Search for Troubleshooting Help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb6e28d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì Question: How to fix circuit breaker errors in OpenSearch\n",
      "============================================================\n",
      "\n",
      "üîß Troubleshooting Information:\n",
      "{\n",
      "  \"inference_results\": [\n",
      "    {\n",
      "      \"output\": [\n",
      "        {\n",
      "          \"name\": \"response\",\n",
      "          \"result\": \"{\\\"next_page\\\":\\\"https://duckduckgo.com/html?q=How+to+fix+circuit+breaker+errors+in+OpenSearch&s=10&nextParams=&v=l&o=json&dc=11&api=d.js&vqd=4-81718980996992644004850907040242820933&kl=wt-wt\\\",\\\"items\\\":[{\\\"url\\\":\\\"https://opster.com/guides/opensearch/opensearch-basics/opensearch-circuit-breaker-exceptions-how-to-handle-circuit-breakers/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Product BUILT FOR ELASTICSEARCH AutoOps Prevent & resolve issues, cut down administration time & hardware costs. Community Tools Tools For The Community Check-Up, Search Log Analyzer & OpsGPT Resources Guides Technical guides on Elasticsearch & Opensearch Blog Insights, Opster news, blogs and more Documentation Opster product documentation Error Messages Error Repository About About Our story & vision Login AutoOps Login Contact Login Contact Running self-managed Elasticsearch just got easier. Announcing AutoOps for your clusters. Read the announcement \\ud83c\\udf89\\ud83c\\udf89 Opensearch Guides > OpenSearch Basics Elasticsearch OpenSearch Circuit Breaker Exceptions: How to Handle Circuit Breakers By Opster Team Updated: Jun 19, 2024 | 4 min read Quick links What are circuit breakers? Finding out your current circuit breaker status Fielddata circuit breaker Request circuit breaker Inflight requests circuit breaker Script compilation circuit breaker Parent circuit breakers Accounting circuit breakers Adjusting circuit breakers What are circuit breakers? 50% of memory on an OpenSearch node is generally used for the JVM (Java Virtual Machine) heap, while the other half of the memory is used for other requirements such as cache. In order to prevent \\u201cOut of Memory\\u201d (OOM) errors, OpenSearch implements circuit breakers. If a certain request could cause errors in the node because of memory issues, OpenSearch will throw a \\u201cCircuitBreakerException\\u201d and reject the request rather than risk crashing the entire node. A circuit breaker exception is usually an exception that is thrown to alert us of something else that needs to be fixed to reduce memory usage. Circuit breakers generally come with sensible defaults. Simply increasing the circuit breaking limit is likely to increase the risk that your node crashes due to an OutOfMemoryError. If you get a circuit breaking exception, you should check what type of circuit breaker it is, and then look at your monitoring data and OpenSearch logs to diagnose what caused it. Remember that the event or query that appears in the log may just be the \\u201cstraw that broke the camel\\u2019s back\\u201d. There may be other causes of high memory usage, and the event in the log is just the very last one which pushed OpenSearch over the limit. Possible causes are discussed in each section below. Finding out your current circuit breaker status Get your current settings GET /_cluster/settings?include_defaults=true Find out your current memory usage and breakers GET _nodes/stats/breaker This will return useful information like this \\\\\\\"breakers\\\\\\\" : {\\\\n    \\\\t\\\\\\\"request\\\\\\\" : {\\\\n      \\\\t\\\\\\\"limit_size_in_bytes\\\\\\\" : 20574004838,\\\\n      \\\\t\\\\\\\"limit_size\\\\\\\" : \\\\\\\"19.1gb\\\\\\\",\\\\n      \\\\t\\\\\\\"estimated_size_in_bytes\\\\\\\" : 0,\\\\n      \\\\t\\\\\\\"estimated_size\\\\\\\" : \\\\\\\"0b\\\\\\\",\\\\n      \\\\t\\\\\\\"overhead\\\\\\\" : 1.0,\\\\n      \\\\t\\\\\\\"tripped\\\\\\\" : 0\\\\n    \\\\t},\\\\n    \\\\t\\\\\\\"fielddata\\\\\\\" : {\\\\n      \\\\t\\\\\\\"limit_size_in_bytes\\\\\\\" : 13716003225,\\\\n      \\\\t\\\\\\\"limit_size\\\\\\\" : \\\\\\\"12.7gb\\\\\\\",\\\\n      \\\\t\\\\\\\"estimated_size_in_bytes\\\\\\\" : 0,\\\\n      \\\\t\\\\\\\"estimated_size\\\\\\\" : \\\\\\\"0b\\\\\\\",\\\\n      \\\\t\\\\\\\"overhead\\\\\\\" : 1.03,\\\\n      \\\\t\\\\\\\"tripped\\\\\\\" : 0\\\\n    \\\\t},\\\\n    \\\\t\\\\\\\"in_flight_requests\\\\\\\" : {\\\\n      \\\\t\\\\\\\"limit_size_in_bytes\\\\\\\" : 34290008064,\\\\n      \\\\t\\\\\\\"limit_size\\\\\\\" : \\\\\\\"31.9gb\\\\\\\",\\\\n      \\\\t\\\\\\\"estimated_size_in_bytes\\\\\\\" : 6254164,\\\\n      \\\\t\\\\\\\"estimated_size\\\\\\\" : \\\\\\\"5.9mb\\\\\\\",\\\\n      \\\\t\\\\\\\"overhead\\\\\\\" : 2.0,\\\\n      \\\\t\\\\\\\"tripped\\\\\\\" : 0\\\\n    \\\\t},\\\\n    \\\\t\\\\\\\"accounting\\\\\\\" : {\\\\n      \\\\t\\\\\\\"limit_size_in_bytes\\\\\\\" : 34290008064,\\\\n      \\\\t\\\\\\\"limit_size\\\\\\\" : \\\\\\\"31.9gb\\\\\\\",\\\\n      \\\\t\\\\\\\"estimated_size_in_bytes\\\\\\\" : 282771278,\\\\n      \\\\t\\\\\\\"estimated_size\\\\\\\" : \\\\\\\"269.6mb\\\\\\\",\\\\n      \\\\t\\\\\\\"overhead\\\\\\\" : 1.0,\\\\n      \\\\t\\\\\\\"tripped\\\\\\\" : 0\\\\n    \\\\t},\\\\n    \\\\t\\\\\\\"parent\\\\\\\" : {\\\\n      \\\\t\\\\\\\"limit_size_in_bytes\\\\\\\" : 32575507660,\\\\n      \\\\t\\\\\\\"limit_size\\\\\\\" : \\\\\\\"30.3gb\\\\\\\",\\\\n      \\\\t\\\\\\\"estimated_size_in_bytes\\\\\\\" : 13431618584,\\\\n      \\\\t\\\\\\\"estimated_size\\\\\\\" : \\\\\\\"12.5gb\\\\\\\",\\\\n      \\\\t\\\\\\\"overhead\\\\\\\" : 1.0,\\\\n      \\\\t\\\\\\\"tripped\\\\\\\" : 0\\\\n    \\\\t}\\\\n  \\\\t} Fielddata circuit breaker indices.breaker.fielddata.limit (default=40% JVM heap) indices.breaker.fielddata.overhead (default=1.03) The limit is set as a proportion of the JVM heap set in jvm.options, while the \\u201coverhead\\u201d setting is a fixed ratio which OpenSearch uses to multiply the theoretical calculations to estimate the circuit breaker memory requirement. Fielddata circuit breaker is a limit on the total amount of memory used by fielddata in your indices. Fielddata is by default set to false on a text field, but may be used where you have defined it in one of your mappings: \\\\\\\"fielddata\\\\\\\": true In general it is recommended to avoid this setting because of the large amount of memory required in putting individual text values into memory. If possible you should change your mappings to set it to false, and use keyword type mappings rather than text type for aggregations and sorting. However, if this is not possible and you need to aggregate based on individual terms in a text rather than keywords, then you could also consider setting a fielddata frequency filter on the mapping to limit the amount of fielddata put into memory. PUT my-index-000001\\\\n{\\\\n  \\\\\\\"mappings\\\\\\\": {\\\\n    \\\\\\\"properties\\\\\\\": {\\\\n      \\\\\\\"need_to_aggregate_individual_terms_on_this_field\\\\\\\": {\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"text\\\\\\\",\\\\n        \\\\\\\"fielddata\\\\\\\": true,\\\\n        \\\\\\\"fielddata_frequency_filter\\\\\\\": {\\\\n          \\\\\\\"min\\\\\\\": 0.001,\\\\n          \\\\\\\"max\\\\\\\": 0.1,\\\\n          \\\\\\\"min_segment_size\\\\\\\": 500\\\\n        }\\\\n      }\\\\n    }\\\\n  }\\\\n} Request circuit breaker indices.breaker.request.limit(default=60% JVM heap) indices.breaker.request.overhead(default=1) The limit is set as a proportion of the JVM heap set in jvm.options, while the \\u201coverhead\\u201d setting is a fixed ratio which OpenSearch uses to multiply the theoretical calculations to estimate the circuit breaker memory requirement. The request circuit breaker takes into account the memory required based on the request structures, in particular aggregations. The most common cause of exceeding this circuit breaker is through the use of aggregations with a large size value. Try reducing the value of \\u201csize\\u201d in your aggregations. Inflight requests circuit breaker network.breaker.inflight_requests.limit (default=100% JVM heap) network.breaker.inflight_requests.overhead (default=2) The limit is set as a proportion of the JVM heap set in jvm.options, while the \\u201coverhead\\u201d setting is a fixed ratio which OpenSearch uses to multiply the theoretical calculations to estimate the circuit breaker memory requirement. The in-flight requests circuit breaker considers the size of active transport and http requests for the node based on the byte size of those requests. Generally this circuit breaker is activated when batch sizes for bulk requests are too large. Try reducing the size of bulk requests, particularly if those requests contain large documents. Script compilation circuit breaker script.context.$CONTEXT.max_compilations_rate (default=75/5m) The script compilation circuit breaker is slightly different from the others. Rather than applying a memory limit, it limits the number of times a script can be compiled in a given period. If you get this warning, you should use stored scripts with parameters instead of inline ones, as the former are compiled only once, while the latter are compiled on each execution. Parent circuit breakers indices.breaker.total.use_real_memory default=true indices.breaker.total.limit default=95% JVM heap Parent circuit breaker exceptions are caused by the sum of all memory being used across the different types of circuit breakers. If the use_real_memory is left as the default, then the parent circuit breaker will take into account real memory usage and will be based upon 95% of the JVM heap size. In general it is better to base this circuit upon real memory usage since it gives you a more accurate picture of what is going on in the instance. On the other hand if you choose to set \\u201cuse_real_memory\\u201d to false, then the limit will be based on the sum of the estimates of other circuit breakers in which case the default limit will be reduced to 70% of the JVM heap size to take into account the margin or error with using a sum of estimates. Accounting circuit breakers indices.breaker.accounting.limit default= 100% of JVM heap indices.breaker.accounting.overhead default=1 This circuit breaker is to protect the node from over usage of memory due to things that persist in memory after a request has completed, such as lucene segments before they are flushed to disk. The default limit is however set at 100% of JVM heap so the parent circuit breaker will trip before this limit becomes effective. The accounting overhead setting is a coefficient which is used to multiply all estimates before applying the limit. Adjusting circuit breakers In general, and as warned above, it is usually not advisable to modify circuit breakers from their defaults, since it is far worse to lose a node from an OutOfMemoryError than to drop a few requests. Instead you should try to understand why you are exceeding them and prevent this from happening. Also bear in mind that the default calculations are based on your JVM heap size which is generally assumed to be 50% of the total available size. If this is not the case, then you may want to re-consider setting the JVM settings in jvm.options before reconfiguring everything else. However if you still think you need to modify the circuit breakers (or restore the defaults), you can adjust circuit breaker settings just like any other cluster settings PUT _cluster/settings\\\\n{\\\\n  \\\\\\\"transient\\\\\\\": {\\\\\\\"indices.breaker.total.limit\\\\\\\":\\\\\\\"5GB\\\\\\\" }\\\\n} Or to restore the setting to it\\u2019s default PUT _cluster/settings\\\\n{\\\\n  \\\\\\\"transient\\\\\\\": {\\\\\\\"indices.breaker.total.limit\\\\\\\":null }\\\\n} Additional notes Elasticsearch and OpenSearch are both powerful search and analytics engines, but Elasticsearch has several key advantages. Elasticsearch boasts a more mature and feature-rich development history, translating to a better user experience, more features, and continuous optimizations. Our testing has consistently shown that Elasticsearch delivers faster performance while using fewer compute resources than OpenSearch. Additionally, Elasticsearch\\u2019s comprehensive documentation and active community forums provide invaluable resources for troubleshooting and further optimization. Elastic, the company behind Elasticsearch, offers dedicated support, ensuring enterprise-grade reliability and performance. These factors collectively make Elasticsearch a more versatile, efficient, and dependable choice for organizations requiring sophisticated search and analytics capabilities. Related Articles Choose the Correct Number of Shards How to Solve Indexing Downtime How OzTam Improved Search Performance Back to all articles Product AutoOps for Elasticsearch Community Tools Tools for the Community Company About Our Customers info@opster.com Resources Documentation Blog Guides Elasticsearch Error Messages Elasticsearch Log Errors Taking Care of Your Entire Search Operation. Opster\\u2019s solutions reduce the time and cost of running Elasticsearch. Get Improved performance & stability with less hardware. Contact Us \\u00a9 2026 Opster Privacy Policy Terms of Use We use cookies to ensure that we give you the best experience on our website. By continuing to browse this site, you agree to our Privacy Policy and Terms of Use. Agree Close GDPR Cookie Settings Privacy Overview Strictly Necessary Cookies Powered by GDPR Cookie Compliance Privacy Overview This website uses cookies so that we can provide you with the best user experience possible. Cookie information is stored in your browser and performs functions such as recognising you when you return to our website and helping our team to understand which sections of the website you find most interesting and useful. Strictly Necessary Cookies Strictly Necessary Cookie should be enabled at all times so that we can save your preferences for cookie settings. Enable or Disable Cookies Enabled Disabled Enable All Save Settings\\\"},{\\\"url\\\":\\\"https://docs.opensearch.org/latest/install-and-configure/configuring-opensearch/circuit-breaker/\\\",\\\"title\\\":\\\"Link Search Menu Expand Document Documentation Menu\\\",\\\"content\\\":\\\"Link Search Menu Expand Document Documentation Menu OpenSearch Menu About Releases Roadmap FAQ Platform Search Observability Security Analytics Vector Database Playground Demo Performance Benchmarks Community Forum Slack Events Solutions Providers Projects Members Documentation OpenSearch and Dashboards Data Prepper Clients Benchmark Migration Assistant Blog Download Documentation OpenSearch and OpenSearch Dashboards \\u2190 Back to docs home About OpenSearch Version history Breaking changes Getting started Intro to OpenSearch Installation quickstart Communicate with OpenSearch Ingest data Search your data Concepts Tutorials Vector search Getting started with semantic and hybrid search Vector operations Generating embeddings Semantic search using byte vectors Optimizing vector search using Cohere compressed embeddings Semantic search Semantic search using OpenAI Semantic search using Cohere Embed Semantic search using Cohere Embed on Amazon Bedrock Semantic search using Amazon Bedrock Titan Semantic search using Amazon Bedrock Titan in another account Semantic search in Amazon SageMaker Semantic search using AWS CloudFormation and Amazon SageMaker Semantic search using AWS CloudFormation and Amazon Bedrock Semantic search using an asymmetric embedding model Semantic search using text chunking Using semantic highlighting Reranking search results Reranking using Cohere Rerank Reranking search results using Cohere Rerank on Amazon Bedrock Reranking search results using Amazon Bedrock models Reranking search results using a cross-encoder in Amazon SageMaker Reranking search results using a reranker in Amazon SageMaker Reranking search results by a field Generative AI RAG RAG using the DeepSeek Chat API RAG using DeepSeek-R1 on Amazon Bedrock RAG using DeepSeek-R1 in Amazon SageMaker Conversational search using Cohere Command Conversational search using Anthropic Claude on Amazon Bedrock Conversational search using OpenAI Agentic AI Building a plan-execute-reflect agent Chatbots RAG chatbot RAG chatbot with a conversational flow agent Build your own chatbot AI search workflows Model guardrails Amazon Bedrock model guardrails Faceted search Install and configure Installing OpenSearch Docker Helm Tarball RPM Debian OpenSearch Kubernetes Operator Ansible playbook Windows Installing OpenSearch Dashboards Docker Tarball RPM Debian Helm Windows Configure TLS Configuring OpenSearch Configuration and system settings Network settings Discovery and gateway settings Security settings Cluster settings Index settings Search settings Availability and recovery settings Thread pool settings Circuit breaker settings Plugin settings Experimental feature flags Logs Compatible operating systems Configuring OpenSearch Dashboards Installing plugins Additional plugins Ingest-attachment plugin Mapper-size plugin Managing OpenSearch Dashboards plugins Migrate or upgrade Snapshot and restore Rolling upgrade Migration Assistant Creating and tuning your cluster Discovery and cluster formation Node discovery and seed hosts Voting and quorum Voting configuration management Cluster bootstrapping Discovery and cluster formation settings Cluster manager task throttling Cross-cluster replication Getting started Auto-follow Replication security Replication settings API Availability and recovery Snapshots Take and restore snapshots Snapshot management Snapshot management API Searchable snapshots Remote-backed storage Migrating to remote-backed storage Remote cluster state Remote segment backpressure Remote segment warmer Shallow snapshots Remote Store Stats API Search backpressure Shard indexing backpressure Stats API Settings Segment replication Segment replication backpressure Rule-based auto-tagging Rules API Workload management Workload groups Workload group rules Managing workloads in OpenSearch Dashboards Tuning for indexing speed Separate index and search workloads Managing Indexes Index templates Index aliases Data streams Append-only index Index context Index sorting Reindex data Refresh search analyzer Similarity Index State Management Policies Managed indexes Settings ISM API Index transforms Transforms APIs Index rollups Index rollups API Settings ISM Error Prevention ISM Error Prevention resolutions ISM Error Prevention API Notification settings Index management security Ingest Pipelines Create or update pipeline Simulate pipeline Get pipeline Delete pipeline Access data in a pipeline Handling pipeline failures Conditional execution Complex conditionals Conditionals with the pipeline processor Regex conditionals Ingest processors Append Bytes Convert Copy CSV Date Community ID Date index name Dissect Dot expander Drop Fail Fingerprint Foreach gsub IP2Geo Grok HTML strip Join JSON KV Lowercase ML inference Pipeline Remove Remove by pattern Rename Script Set Sparse encoding Sort Text chunking Text embedding Split Text/image embedding Trim Uppercase URL decode User agent OpenSearch Dashboards OpenSearch Dashboards quickstart guide OpenSearch Assistant for OpenSearch Dashboards Alert insights Data summary Anomaly detector suggestions Text to visualization Analyzing data with Discover Creating dashboards Building data visualizations Area charts Coordinate and region maps Using maps Maps Stats API Configuring a Web Map Service (WMS) Using self-hosted map servers TSVB Vega VisBuilder Index Management Indexes Data streams Force merge Rollover Component templates Notification settings Snapshot Management Dashboards Management Index patterns Advanced settings Access control lists for saved objects Resource access management Data sources Configuring and using multiple data sources Connecting Amazon S3 to OpenSearch Query and visualize Amazon S3 data Optimizing query performance using OpenSearch indexing Scheduled Query Acceleration Connecting Prometheus to OpenSearch Dev Tools Workspace for OpenSearch Dashboards Getting started with workspaces Create a workspace Manage workspaces Workspace access control lists Workspaces APIs Dashboards Query Language (DQL) Query Workbench Custom branding Integrations in OpenSearch Dashboards Configuring CSP rules for frame ancestors Search telemetry Security Getting started with OpenSearch security Configuration Best practices Setting up a demo configuration System indexes Configuring the Security backend Modifying the YAML files Configuring TLS certificates OpenSearch FIPS configuration Generating self-signed certificates Applying changes to configuration files Security configuration versioning API rate limiting Configuring sign-in options Disabling and enabling the Security plugin OpenSearch keystore Authentication backends HTTP basic authentication JSON Web Token OpenID Connect SAML Active Directory and LDAP Proxy-based authentication Client certificate authentication Kerberos Access control Defining users and roles Permissions Default action groups REST layer authorization Document-level security Field-level security Field masking User impersonation Resource sharing and access control Resource sharing APIs API Authorization tokens Anonymous authentication Audit logs Audit log field reference Audit log storage types OpenSearch Dashboards multi-tenancy Multi-tenancy configuration Dynamic configuration in OpenSearch Dashboards Multi-tenancy aggregate view for saved objects Security analytics OpenSearch Security for Security Analytics Setting up Security Analytics Working with log types Creating detectors Creating correlation rules Supported log types AD LDAP Amazon S3 Apache Access AWS CloudTrail Azure DNS GitHub Google Workspace Linux Microsoft 365 NetFlow Network Okta VPC Flow WAF Windows Other log type mappings Using Security Analytics The Overview page Working with detectors Working with findings Working with detection rules Working with the correlation graph Working with alerts API tools Detector APIs Rule APIs Mappings APIs Alerts and findings APIs Correlation engine APIs Log type APIs Threat intelligence Getting started Threat intelligence APIs Monitor API Alerts and Findings API Source API Security Analytics settings Mappings Supported field types Alias Boolean Binary String field types Text Keyword Match-only text Wildcard Token count Constant keyword Numeric field types Unsigned long Date field types Date Date nanoseconds IP address Geographic field types Geopoint Geoshape Cartesian field types xy point xy shape Range field types Object field types Object Nested Flat object Join Version Autocomplete field types Completion Search as you type k-NN vector Spaces Methods and engines Memory-optimized vectors Sparse vector Specialized search field types Semantic Rank field types Percolator Star-tree Derived Metadata fields Field names ID Ignored Index Meta Routing Source Mapping parameters Analyzer Boost Coerce Copy to Doc values Dynamic Eager global ordinals Enabled Fields Format Ignore above Ignore malformed Index options Index Index phrases Index prefixes Meta Normalizer Norms Null value Position increment gap Properties Search analyzer Similarity Store Term vector Mapping explosion Text analysis Analyzers Index analyzers Search analyzers Creating a custom analyzer Standard analyzer Fingerprint analyzer Keyword analyzer Pattern analyzer Simple analyzer Stop analyzer Whitespace analyzer DL model analyzers Language analyzers Arabic Armenian Basque Bengali Brazilian Bulgarian Catalan CJK Czech Danish Dutch English Estonian Finnish French Galician German Greek Hindi Hungarian Indonesian Irish Italian Latvian Lithuanian Norwegian Persian Polish Portuguese Romanian Russian Sorani Spanish Swedish Thai Turkish Ukrainian Phone number analyzers Tokenizers Character group Classic Edge n-gram Keyword Letter Lowercase N-gram Path hierarchy Pattern Simple pattern Simple pattern split Standard Thai UAX URL email Whitespace Token filters Apostrophe ASCII folding CJK bigram CJK width Classic Common grams Condition Decimal digit Delimited payload Delimited term frequency Dictionary decompounder Edge n-gram Elision Fingerprint Flatten graph Hunspell Hyphenation decompounder Keep types Keep words Keyword marker Keyword repeat KStem Kuromoji completion Length Limit Lowercase Min hash Multiplexer N-gram Normalization Pattern capture Pattern replace Phonetic Porter stem Predicate token filter Remove duplicates Reverse Shingle Snowball Stemmer Stemmer override Stop Synonym Synonym graph Trim Truncate Unique Uppercase Word delimiter Word delimiter graph Character filters HTML strip Mapping Pattern replace Normalizers Stemming Token graphs Query DSL Query and filter context Term-level and full-text queries compared Term-level queries Term Terms Terms set IDs Range Prefix Exists Fuzzy Wildcard Regexp Full-text queries Match Match Boolean prefix Match phrase Match phrase prefix Multi-match Query string Simple query string Intervals Compound queries Boolean Boosting Constant score Disjunction max Function score Hybrid Geographic and xy queries Geo-bounding box Geodistance Geopolygon Geoshape xy Joining queries Has child Has parent Nested Parent ID Span queries Span containing Span field masking Span first Span multi-term Span near Span not Span or Span term Span within Match all queries Specialized queries Agentic Distance feature k-NN k-NN query explain More like this Neural Neural sparse Percolate Script query Script score Template Rank feature Wrapper Minimum should match Rewrite Rescore Regular expression syntax SQL and PPL SQL and PPL API Response formats SQL and PPL CLI SQL Basic queries Complex queries Functions JSON support Metadata queries Aggregate functions Delete JDBC driver ODBC driver PPL Subsearch Commands PPL syntax ad addcoltotals addtotals append appendcol appendpipe bin chart dedup describe eval eventstats expand explain fields fillnull flatten grok head join kmeans lookup ml multisearch parse patterns rare regex rename replace reverse rex search show datasources sort spath stats streamstats subquery table timechart top trendline where Identifiers Data types Functions Full-text search Settings Troubleshooting Monitoring Limitations Aggregations Metric aggregations Average Cardinality Extended stats Geobounds Geocentroid Matrix stats Maximum Median absolute deviation Minimum Percentile ranks Percentile Scripted metric Stats Sum Top hits Value count Weighted average Bucket aggregations Adjacency matrix Auto-interval date histogram Children Composite Date histogram Date range Diversified sampler Filter Filters Geodistance Geohash grid Geohex grid Geotile grid Global Histogram IP range Missing Multi-terms Nested Parent Range Rare terms Reverse nested Sampler Significant terms Significant text Terms Pipeline aggregations Average bucket Bucket script Bucket selector Bucket sort Cumulative sum Derivative Extended stats bucket Maximum bucket Minimum bucket Moving average Moving function Percentiles bucket Serial differencing Stats bucket Sum bucket Search features Search options Paginate results Point in Time Sort results Filter results Collapse search results Highlight query matches Autocomplete Did-you-mean Retrieve inner hits Retrieve specific fields Search shard routing Keyword search Learning to Rank ML ranking core concepts Scope of the plugin Working with features Feature engineering Logging feature scores Uploading trained models Optimizing search with LTR Advanced functionality Common issues Cross-cluster search Search relevance Search Relevance Workbench Query sets Search configurations Judgments Comparing single queries Comparing search results Comparing query sets Evaluating search quality Optimizing hybrid search Exploring search evaluation results Reranking search results Reranking using a cross-encoder model Reranking by a field Reranking by a field using a cross-encoder Reranking by a field using a late interaction model Query rewriting Template queries Querqy User Behavior Insights UBI index schemas UBI JavaScript Collector Example UBI query DSL queries Sample UBI SQL queries UBI dashboard tutorial Collecting UBI-formatted data in Amazon OpenSearch Service Search pipelines Creating a search pipeline Using a search pipeline Debugging a search pipeline Retrieving search pipelines Deleting search pipelines User-defined search processors Collapse Hybrid score explanation Filter query ML inference (request) ML inference (response) Neural query enricher Neural sparse query two-phase Normalization Oversample Personalize search ranking Rename field Rerank Retrieval-augmented generation Score ranker Script Sort Split Truncate hits System-generated search processors Search pipeline metrics Improving search performance Asynchronous search Asynchronous search security Settings Concurrent segment search Star-tree index Caching Index request cache Tiered cache Field data cache Vector search Getting started Vector search basics Preparing vectors Generating embeddings automatically Concepts Vector search techniques Approximate k-NN search Exact k-NN search with a scoring script Painless extensions Creating a vector index Ingesting data Text chunking Searching data AI search Semantic search Hybrid search Using sorting with a hybrid query Paginating hybrid query results Hybrid search with search_after Collapsing hybrid query results Hybrid search with post-filtering Combining hybrid search and aggregations Using inner hits in hybrid queries Hybrid search explain Multimodal search Neural sparse search Generating sparse vector embeddings automatically Using custom configurations for neural sparse search Neural sparse search using raw vectors Neural sparse ANN search Conversational search with RAG Agentic search Configuring agents Using flow agents Using conversational agents Configuring agents for semantic search Adding search templates Using external MCP servers Building AI search workflows in OpenSearch Dashboards Configuring AI search types Configuring agentic search Filtering data Efficient k-NN filtering Post-filtering Scoring script filter Filtering in neural sparse ANN search Specialized vector search Nested field search Radial search Vector search with MMR reranking Optimizing vector storage Vector quantization Lucene scalar quantization Faiss 16-bit scalar quantization Faiss product quantization Binary quantization Disk-based vector search Memory-optimized search Performance tuning Indexing performance tuning Search performance tuning Remote index build LLM framework integration Vector search API k-NN API Neural Search API Settings Machine learning Integrating ML models Model access control Model access control through resource sharing Using ML models within OpenSearch Custom models Pretrained models GPU acceleration Connecting to externally hosted models Connectors Supported connectors Connector blueprints Guardrails Batch ingestion Asynchronous batch ingestion Managing ML models in OpenSearch Dashboards Agents and tools Agents and tools tutorial Agents Flow agents Conversational flow agents Conversational agents Plan-execute-reflect agents Tools Agent tool Connector tool Create Anomaly Detector tool Data Distribution tool Index Mapping tool List Index tool Log Pattern tool Log Pattern Analysis tool ML Model tool Neural Sparse Search tool Query Planning tool PPL tool Scratchpad tools RAG tool Search Alerts tool Search Anomaly Detectors tool Search Anomaly Results tool Search Index tool Search Monitors tool Vector DB tool Visualization tool Web Search tool Using MCP tools Connecting to an external MCP server Processor chains Agentic memory OpenSearch Assistant Toolkit Supported algorithms ML Commons APIs Model APIs Register model Deploy model Get model Search model Update model Undeploy model Delete model Train Predict Predict stream Batch predict Train and predict Model group APIs Register model group Update model group Get model group Search model group Delete model group Connector APIs Create connector Get connector Search connector Update connector Delete connector Agent APIs Register agent Update agent Execute agent Execute stream agent Get agent Search agent Delete agent Agentic memory APIs Create memory container Update memory container Get memory container Search memory containers Delete memory container Create session Add agentic memory Get memory Update memory Delete memory Search memory MCP server APIs Register MCP tools Update MCP tools List MCP tools Remove MCP tools MCP Streamable HTTP Server Memory APIs Create or update memory Get memory Search memory Delete memory Create or update message Get message Search message Get message traces Controller APIs Create controller Get controller Delete controller ML Tasks APIs Get ML task Search ML tasks Delete ML task Asynchronous batch ingestion Execute algorithm Execute tool Profile Stats ML Commons cluster settings Automating configurations Workflow steps Workflow tutorial Workflow templates Workflow access control Workflow settings Workflow state access control Workflow APIs Create or update a workflow Get a workflow Provision a workflow Get a workflow status Get workflow steps Search for a workflow Search for a workflow state Deprovision a workflow Delete a workflow Workflow template security Monitoring your cluster Job Scheduler Jobs API Locks API Metrics framework Performance Analyzer API Create PerfTop Dashboards Metrics Reference Root Cause Analysis API RCA Reference Hot shard identification Observability Observability security Application analytics Event analytics Log ingestion Metric analytics Query insights Top N queries Grouping top N queries Live queries Query metrics Query Insights plugin health Query insights dashboards Trace Analytics Getting Started Trace Analytics plugin for OpenSearch Dashboards Analyzing Jaeger trace data Distributed tracing Notebooks Operational panels Alerting Monitors Per query and per bucket monitors Per cluster metrics monitors Per document monitors Composite monitors Triggers Actions Management Alerting security API Cron Adding comments Alerting dashboards and visualizations Anomaly detection Anomaly detection API Settings Anomaly result mapping Anomaly detection security Anomaly detector access control Anomaly detection visualizations and dashboards Configuring anomaly alerting Forecasting Getting started with forecasting Managing forecasters Forecasting security Forecaster access control Forecasting API Notifications API Simple Schema for Observability Cross-cluster search Reporting Reporting using OpenSearch Dashboards Reporting using the CLI Download and install the Reporting CLI tool Create and request visualization reports Schedule reports with the cron utility Schedule reports with AWS Lambda Reporting CLI options Use environment variables with the Reporting CLI Tools OpenSearch CLI Logstash Logstash execution model Common filter plugins Read from OpenSearch Ship events to OpenSearch Advanced configurations Terraform Grafana Sycamore API reference Analyze API CAT APIs CAT aliases CAT allocation CAT count CAT field data CAT health CAT indices CAT cluster manager CAT nodeattrs CAT nodes CAT pending tasks CAT PIT segments CAT plugins CAT recovery CAT repositories CAT segment replication CAT segments CAT shards CAT snapshots CAT tasks CAT templates CAT thread pool Cluster APIs Cluster allocation explain Cluster decommission Cluster health Cluster pending tasks Cluster reroute Cluster routing and awareness Cluster settings Cluster state Cluster stats Cluster information Remote cluster information Voting configuration exclusions Document APIs Index document Get document Update document Delete document Bulk Streaming bulk Multi-get documents Update by query Delete by query Reindex documents Term vectors Multi term vectors Pull-based ingestion Pull-based ingestion management gRPC APIs Bulk (gRPC) Search (gRPC) k-NN (gRPC) Index APIs Core index APIs Create index Delete index Get index Index exists Open index Close index Resolve index Index operations Clear cache Clone index Flush Force merge Index recovery Refresh index Roll over index Scale Index segments Index shard stores Shrink index Split index Index stats Index settings and mappings Get settings Update settings Create or update mappings Alias APIs Create or update alias Get alias Delete alias Alias exists Manage aliases Index templates Create or update index template Delete index template Get index template Index template exists Simulate index templates Component template APIs Post template (deprecated) Put template (deprecated) Get template (deprecated) Template exists (deprecated) Delete template (deprecated) Index blocks and allocation Blocks Shard allocation Data stream stats Dangling indexes Ingest APIs List APIs List shards List indices Nodes APIs Nodes info Nodes stats Nodes hot threads Nodes usage Nodes reload secure settings Script APIs Execute inline script Create or update stored script Execute stored script Get stored script Delete stored script Get script languages Get script contexts Search APIs Search Multi-search Point in Time Scroll Count Explain Field capabilities Profile Ranking evaluation Search shards Validate query Search templates Render template Multi-search template Security APIs Authentication APIs Authentication Information API Change Password API Configuration APIs Upgrade Check API Upgrade Perform API Update Security Configuration API Get Configuration API Patch Configuration API Snapshot APIs Register snapshot repository Get snapshot repository Delete snapshot repository Verify snaphot repository Create Snapshot Get snapshot Delete snapshot Get snapshot status Restore Snapshot Clone snapshot Cleanup snapshot repository Tasks APIs List tasks Get task Cancel tasks Rethrottle Supported units Common REST parameters Popular APIs Troubleshooting Troubleshoot securityadmin.sh Troubleshoot TLS Troubleshoot SAML Troubleshoot OpenID Connect Developer documentation Plugin as a service Extensions Install and configure Configuring OpenSearch Circuit breaker settings Circuit breaker settings Circuit breakers prevent OpenSearch from causing a Java OutOfMemoryError. The parent circuit breaker specifies the total available amount of memory for all child circuit breakers. The child circuit breakers specify the total available amount of memory for themselves. To learn more about static and dynamic settings, see Configuring OpenSearch. Parent circuit breaker settings OpenSearch supports the following parent circuit breaker settings: indices.breaker.total.use_real_memory (Static, Boolean): If true, the parent circuit breaker considers the actual memory usage. Otherwise, the parent circuit breaker considers the amount of memory reserved by the child circuit breakers. Default is true. indices.breaker.total.limit (Dynamic, percentage): Specifies the initial memory limit for the parent circuit breaker. If indices.breaker.total.use_real_memory is true, defaults to 95% of the JVM heap. If indices.breaker.total.use_real_memory is false, defaults to 70% of the JVM heap. Field data circuit breaker settings The field data circuit breaker limits the heap memory required to load a field into the field data cache. OpenSearch supports the following field data circuit breaker settings: indices.breaker.fielddata.limit (Dynamic, percentage): Specifies the memory limit for the field data circuit breaker. Default is 40% of the JVM heap. indices.breaker.fielddata.overhead (Dynamic, double): A constant by which the field data estimations are multiplied to determine the final estimation. Default is 1.03. Request circuit breaker settings The request circuit breaker limits the memory required to build data structures that are needed for a request (for example, when calculating aggregations). OpenSearch supports the following request circuit breaker settings: indices.breaker.request.limit (Dynamic, percentage): Specifies the memory limit for the request circuit breaker. Default is 60% of the JVM heap. indices.breaker.request.overhead (Dynamic, double): A constant by which the request estimations are multiplied to determine the final estimation. Default is 1. In-flight request circuit breaker settings The in-flight request circuit breaker limits the memory usage for all currently running incoming requests on transport and HTTP level. The memory usage for a request is based on the content length of the request and includes memory needed for the raw request and a structured object representing the request. OpenSearch supports the following in-flight request circuit breaker settings: network.breaker.inflight_requests.limit (Dynamic, percentage): Specifies the memory limit for the in-flight request circuit breaker. Default is 100% of JVM heap (thus, the memory usage limit for an in-flight request is determined by the memory limit of the parent circuit breaker). network.breaker.inflight_requests.overhead (Dynamic, double): A constant by which the in-flight request estimations are multiplied to determine the final estimation. Default is 2. Script compilation circuit breaker settings The script compilation circuit breaker limits the number of inline script compilations within a time interval. OpenSearch supports the following script compilation circuit breaker setting: script.max_compilations_rate (Dynamic, rate): The maximum number of unique dynamic scripts compiled within a time interval for a given context. Default is 150 every 5 minutes (150/5m). Regular expression circuit breaker settings The regular expression circuit breaker enables or disables regular expressions and limits their complexity. OpenSearch supports the following regular expression circuit breaker settings: script.painless.regex.enabled (Static, string): Enables regular expressions in Painless scripts. Valid values are: limited: Enables regular expressions and limits their complexity using the script.painless.regex.limit-factor setting. true: Enables regular expressions. Turns off the regular expression circuit breaker and does not limit regular expression complexity. false: Disables regular expressions. If a Painless script contains a regular expression, it returns an error. Default is limited. script.painless.regex.limit-factor (Static, integer): Applied only if script.painless.regex.enabled is set to limited. Limits the number of characters a regular expression in a Painless script. The character limit is calculated by multiplying the number of characters in the script input by script.painless.regex.limit-factor. Default is 6 (thus, if the input has 5 characters, the maximum number of characters in a regular expression is 5 \\u00b7 6 = 30). Parent circuit breaker settings Field data circuit breaker settings Request circuit breaker settings In-flight request circuit breaker settings Script compilation circuit breaker settings Regular expression circuit breaker settings WAS THIS PAGE HELPFUL? \\u2714 Yes \\u2716 No Tell us why 350 characters left Send Thank you for your feedback! Have a question? Ask us on the OpenSearch forum. Want to contribute? Edit this page or create an issue. OpenSearch Links Get Involved Code of Conduct Forum GitHub Slack Resources About Release Schedule Maintenance Policy FAQ Testimonials Trademark and Brand Policy Privacy Contact Us Connect Twitter LinkedIn YouTube Meetup Facebook Copyright \\u00a9 OpenSearch Project a Series of LF Projects, LLC For web site terms of use, trademark policy and other project policies please see https://lfprojects.org.\\\"},null,{\\\"url\\\":\\\"https://repost.aws/knowledge-center/opensearch-circuit-breaker-exception\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to content By using AWS re:Post, you agree to the AWS re:Post Terms of Use re:Post Search About re:Post English EnglishDeutschEspa\\u00f1olFran\\u00e7aisItaliano\\u65e5\\u672c\\u8a9e\\ud55c\\uad6d\\uc5b4Portugu\\u00eas\\u4e2d\\u6587 (\\u7b80\\u4f53)\\u4e2d\\u6587 (\\u7e41\\u9ad4) Resources Sign in Home Questions Knowledge Center Articles Selections Tags Topics Community Groups AWS Support Official AWS Trust & Safety Center Ask question AWS re:Post Knowledge Center Feedback Survey Help us improve the AWS re:Post Knowledge Center by sharing your feedback in a brief survey. Your input can influence how we create and update our content to better support your AWS journey. / How do I troubleshoot a circuit breaker exception in OpenSearch Service?lg.../ How do I troubleshoot a circuit breaker exception in OpenSearch Service? 6 minute read 1 I want to send data to my Amazon OpenSearch Service cluster. However, I receive a circuit breaking exception error that states that my data is too large. Short description When a request reaches OpenSearch Service nodes, circuit breakers estimate the amount of memory required to load the data. OpenSearch Service then compares the estimated size with the configured heap size quota. If the estimated size of the data is greater than the available heap size, then OpenSearch Service terminates the query. To prevent overloading the node, OpenSearch Service shows a CircuitBreakerException error. To resolve circuit breaking exception errors, first identify the circuit breaking exemption. Then, to reduce the load on your data nodes in the future, reduce high Java virtual machine (JVM) pressure. Resolution Identify the circuit breaking exemption OpenSearch Service uses the following circuit breakers to prevent JVM OutofMemoryError exceptions: Request Field data In flight requests Accounting Parent Important: Identify each of the five circuit breakers that raises the exception. Each circuit breaker has its own tuning needs. For more information about circuit breaker types, see Circuit breaker settings on the Elasticsearch website. To get the current memory usage per node and per breaker, run the following command: GET _nodes/stats/breaker Note that circuit breakers are a best-effort mechanism. Circuit breakers provide limited resiliency against overloading nodes. However, you might still receive an OutOfMemoryError. Circuit breakers can track memory only if it's explicitly reserved. It's not always possible to estimate the exact memory usage in advance. For example, if you have a small amount of memory heap, then the relative overhead of untracked memory is larger. For more information about circuit breakers and node resiliency, see Improving node resiliency with the real memory circuit breaker on the Elasticsearch website. If you reach the circuit breaker quota and use Elasticsearch version 7.x or higher with 16 GB of heap, then you receive the following error: {\\\\n    \\\\\\\"error\\\\\\\": {\\\\n\\\\n        \\\\\\\"root_cause\\\\\\\": [{\\\\n\\\\n            \\\\\\\"type\\\\\\\": \\\\\\\"circuit_breaking_exception\\\\\\\",\\\\n\\\\n            \\\\\\\"reason\\\\\\\": \\\\\\\"[parent] Data too large, data for [<http_request>] would be [16355096754/15.2gb], which is larger than the limit of [16213167308/15gb]\\\\\\\",\\\\n\\\\n            \\\\\\\"bytes_wanted\\\\\\\": 16355096754,\\\\n\\\\n            \\\\\\\"bytes_limit\\\\\\\": 16213167308\\\\n\\\\n        }],\\\\n\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"circuit_breaking_exception\\\\\\\",\\\\n\\\\n        \\\\\\\"reason\\\\\\\": \\\\\\\"[parent] Data too large, data for [<http_request>] would be [16355096754/15.2gb], which is larger than the limit of [16213167308/15gb]\\\\\\\",\\\\n\\\\n        \\\\\\\"bytes_wanted\\\\\\\": 16355096754,\\\\n\\\\n        \\\\\\\"bytes_limit\\\\\\\": 16213167308\\\\n\\\\n    },\\\\n\\\\n    \\\\\\\"status\\\\\\\": 503\\\\n\\\\n} The preceding example output shows that the data is too large for the parent circuit breaker to process. The parent circuit breaker manages the overall memory usage of your cluster. When a parent circuit breaker exception occurs, the total memory used across all circuit breakers exceeds the set limit. A parent breaker throws an exception when the cluster exceeds 95% of 16 GB (15.2 GB of heap). To verify the logic, calculate the difference between memory usage and set circuit breaker limit. That is, with this example output, subtract the real usage of [15283269136/14.2gb] from the limit of [16213167308/15gb]. The example request needs 1.02 GB of new bytes reserved memory to process the request. However, the cluster has less than 0.8 GB of available free memory heap when the data request is received. As a result, the circuit breaker trips. To interpret the circuit breaker exception message, use the following guidelines: data for [<http_request>]: The client sends an HTTP request to a node in your cluster. OpenSearch Service either processes the request locally or passes it to another node for additional processing. would be [#]: The heap size when the request is processed. limit of [#]: The current circuit breaker limit. real usage: The actual use of the JVM heap. new bytes reserved: The actual memory needed to process the request. Reduce high JVM memory pressure High JVM pressure often causes circuit breaking exemptions. JVM memory pressure is the percentage of Java heap that all data nodes in your cluster use. Check the JVMMemoryPressure metric in Amazon CloudWatch to determine your current usage. Note: The JVM heap size of a data node is set to half the size of physical memory (RAM) per node, up to 32 GB. For example, if the physical memory is 30 GB per node, then the heap size is 15 GB. If the physical memory is 128 GB per node, then the heap size is 32 GB. To resolve high JVM memory pressure, take one or more of the following actions: Reduce incoming traffic to your cluster, especially if you have a heavy workload. An increase in the number of requests to the cluster can cause high JVM pressure. Check the IndexRate and SearchRate metrics in CloudWatch to determine your current load. Scale the cluster to get more JVM memory to support your workload. If you can't scale the cluster, then delete old or unused indices to reduce the number of shards. Shard metadata is stored in memory. When you reduce the number of shards, you reduce the overall memory usage. To identify faulty requests, turn on slow logs. Note: Before you make configuration changes, to avoid additional overhead to existing resources, verify that JVM memory pressure is below 85%. Optimize search and indexing requests, and choose the correct number of shards for your use case. Unbalanced shard allocation across nodes or too many shards in a cluster can cause high JVM pressure. For more information about indexing and shard count, see Get started with Amazon OpenSearch Service: How many shards do I need? Turn off and don't use the fielddata data structure to query data. By default, fielddata is set to false on a text field unless explicitly defined otherwise in index mappings. Fielddata can consume a large amount of heap space, and remains in the heap for the lifetime of a segment. As a result, when you use fielddata, JVM memory pressure remains high on the cluster. For more information, see fielddata on the Elasticsearch website. Change your index type to a keyword. For more information, see Reindex API or Create or update index template API on the Elasticsearch website. You can use the keyword type as an alternative to aggregations and sorting on text fields. To prevent increases in field data, avoid aggregating on text fields. When you use more field data, you consume more heap space. Use the cluster stats API operation on the Elasticsearch website to check your field data. Remove aggregation, wildcards, and wide time ranges from your queries. Clear the fielddata cache. Run the following API call: POST /index_name/_cache/clear?fielddata=true (index-level cache)POST */_cache/clear?fielddata=true (cluster-level cache) Important: If you clear the fielddata cache, then you might disrupt in-progress queries. For more information, see How do I troubleshoot high JVM memory pressure on my OpenSearch Service cluster? Related information Operational best practices for Amazon OpenSearch Service How can I improve the indexing performance on my Amazon OpenSearch Service cluster? Follow Share Topics Analytics Tags Amazon OpenSearch Service Language English AWS OFFICIALUpdated a year ago No comments Comment on this article Clear Post comment Relevant content resetting knn circuit breaker triggered Accepted Answer iamlmt asked 2 years ago ECS Circuit Breaker is not preventing deployment loop Sam asked a year ago Error occurred during operation 'ECS Deployment Circuit Breaker was triggered rePost-User-3108449 asked 2 years ago Error deploying service: ECS Deployment Circuit Breaker was triggered Accepted Answer mertt asked 2 years ago Always this errorECS Deployment Circuit Breaker was triggered Accepted Answer Orlando Parra asked 2 years ago Why did the Amazon ECS deployment circuit breaker set my deployment state to FAILED? AWS OFFICIALUpdated 10 months ago Why is OpenSearch Dashboards in red status on my Amazon OpenSearch Service domain? AWS OFFICIALUpdated 3 years ago How do I configure and monitor the Amazon ECS deployment circuit breaker? AWS OFFICIALUpdated a year ago How do I troubleshoot high JVM memory pressure on my OpenSearch Service cluster? AWS OFFICIALUpdated 4 months ago ECS Deployment Circuit Breaker was triggered. EXPERT Chethangowda B C published 9 months ago FEEDBACK Privacy| Site Terms| Cookie Preferences | Sitemap| Legal| \\u00a9 2026, Amazon Web Services, Inc. or its affiliates. All rights reserved. Community Guidelines\\\"},null,{\\\"url\\\":\\\"https://socprime.com/blog/opensearch-circuit-breakers/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Platform Threat Detection Marketplace Your Home for Threat Detection Attack Detective Industry-First SaaS for Advanced Threat Hunting Uncoder AI Single IDE for Detection Engineering Shift-Left Detection Run Sigma rules on Kafka Ecosystem Use Cases Fortify SIEM Posture Audit your SIEM posture to maximize threat visibility & address detection coverage gaps. Obtain Rules for Alerting Get prioritized SIEM use cases ready-to-deploy as low-noise and high-value alerts. Advance Threat Detection Access the world\\u2019s largest rule feed for emerging threats, manage & deploy detections at scale. Elevate Detection Engineering Save time and costs, obtain CTI-enriched use cases, adapt CI/CD workflows. Accelerate MDR Services Reduce customer churn, address technical debt in threat detection, and save on SIEM costs. Hyperscale SIEM Migration Accelerate time-to-value and maximize the ROI of your SIEM migration project. Enable Bear Fence For Your MDE Maximize your Microsoft Defender for Endpoint with automated hunting for APT28 (Fancy Bear) and other Russian APTs. Services Professional Services Overview Explore our on-demand services and training. MITRE ATT&CK Audit Minimize blind spots and ensure comprehensive data visibility. Custom Content Engineering Adopt out-of-the-box detection engineering capability to identify threats challenging your business. SIEM Migration Services Accelerate time-to-value and maximize the ROI of your SIEM migration project. Resources Blog Research, guides, interviews News Headlines in cyberspace Events Stay tuned to our cybersecurity events Data Sheets Explore our data sheets for detailed insights Active Threats Get detection code and simulations Customer Success Stories Learn how global organizations trust SOC Prime Detection as Code Explore our latest innovation reports Roota Open-Source Language for Collective Cyber Defence Sigma History of Sigma Evolution Industry Expertise Center of Excellence for Microsoft Sentinel Center of Excellence for Amazon Web Services Splunk Migration & Support Tools Uncoder.IO The Prime Hunt browser extension: Chrome Firefox Edge Company Why SOC Prime? Collective cyber defense for a secure tomorrow About Us Our story and mission Industry Recognition Verified value for cybersecurity Leadership Biography and DNA Careers Job opportunities at SOC Prime Privacy SOC Prime\\u2019s privacy-centric mindset SOC 2 Type II Compliance Benchmark for security compliance Partner Programs for Universities Sigma & MITRE ATT&CK\\u00ae Education Pricing Log In Request a Demo Request a Demo Request a Demo Blog/Knowledge Bits/This article OpenSearch Circuit Breakers WRITTEN BY Oleksii K. DevOps Engineer [post-views] December 04, 2024 \\u00b7 2 min read Table of contents: Types of Circuit Breakers in OpenSearch Handling Circuit Breaker Exceptions OpenSearch employs circuit breakers to prevent nodes from running out of Java Virtual Machine (JVM) heap memory, which could lead to crashes. These circuit breakers estimate the memory required for operations and compare it to the available heap size. If an operation exceeds the configured limit, OpenSearch throws a CircuitBreakerException to avoid potential OutOfMemoryErrors. Types of Circuit Breakers in OpenSearch Parent Circuit Breaker: This breaker sets the overall memory limit for all child circuit breakers. By default, it is configured to 95% of the JVM heap size. It\\u2019s crucial to ensure that the indices.breaker.request.limit is set lower than the parent breaker to prevent the parent breaker from being triggered prematurely. Fielddata Circuit Breaker: This breaker limits the memory used to load fields into the fielddata cache, which is essential for operations like aggregations and sorting. The default limit is 40% of the JVM heap. To adjust this limit, you can use the following command: PUT /_cluster/settings\\\\n{\\\\n  \\\\\\\"persistent\\\\\\\": {\\\\n    \\\\\\\"indices.breaker.fielddata.limit\\\\\\\": \\\\\\\"60%\\\\\\\"\\\\n  }\\\\n} Request Circuit Breaker: This breaker estimates the memory required to process a request, including memory for aggregations. The default limit is 60% of the JVM heap. If a request exceeds this limit, it is terminated to prevent memory overload. In-Flight Requests Circuit Breaker: This breaker monitors the memory usage of active incoming requests. The default limit is set to 100% of the JVM heap, which is effectively controlled by the parent circuit breaker. Script Compilation Circuit Breaker: This breaker limits the number of inline script compilations within a specified time interval. The default setting allows 150 compilations every 5 minutes. To adjust this limit, you can modify the script.max_compilations_rate setting. Handling Circuit Breaker Exceptions When a circuit breaker is triggered, OpenSearch throws a CircuitBreakerException, often accompanied by a 429 status code indicating \\u201cdata too large.\\u201d To handle these exceptions effectively: Review Query and Mapping: Examine your queries and index mappings to identify operations that consume excessive memory. For instance, using large size values in aggregations can lead to high memory usage. Optimize Fielddata Usage: Avoid enabling fielddata on text fields unless absolutely necessary, as it can consume significant memory. Instead, use keyword fields for aggregations and sorting. Adjust Circuit Breaker Settings: While it\\u2019s generally advisable to keep default settings to prevent OutOfMemoryErrors, you can adjust circuit breaker limits if you have a clear understanding of your workload and memory requirements. For example, to increase the fielddata limit to 60%, use the command mentioned earlier. Scale Your Cluster: If your workload consistently exceeds memory limits, consider scaling your cluster by adding more nodes or increasing the JVM heap size to accommodate the increased memory demands. Table of Contents Types of Circuit Breakers in OpenSearch Handling Circuit Breaker Exceptions Was this article helpful? Like and share it with your peers. Join SOC Prime's Detection as Code platform to improve visibility into threats most relevant to your business. To help you get started and drive immediate value, book a meeting now with SOC Prime experts. Join for Free Book a Meeting Call with SOC Prime \\u00d7 Related Posts Apr 25/2025 2 min read SOC Prime Platform Rule Deployment into a Data Plane by Steven Edwards Apr 25/2025 2 min read SOC Prime Platform Translate from Sigma into 48 Languages by Steven Edwards Dec 4/2024 2 min read Knowledge Bits Splunk: How to Write a Query to Monitor Multiple Sources and Send Alert if they Stop Coming by Oleh P. All News Boost Your Cyber Defense with Threat Detection Marketplace The leading platform for Detection as Code and Continuous Security Intelligence Join Now Platform Threat Detection Marketplace Attack Detective Uncoder AI Shift-Left Detection Ecosystem Use Cases Fortify SIEM Posture Obtain Rules for Alerting Advance Threat Detection Elevate Detection Engineering Accelerate MDR Services Hyperscale SIEM Migration Enable Bear Fence For Your MDE Services Professional Services Overview MITRE ATT&CK Audit Custom Content Engineering SIEM Migration Services Industry Expertise Center of Excellence for Microsoft Sentinel Center of Excellence for Amazon Web Services Splunk Migration & Support Tools Uncoder.IO The Prime Hunt for: Chrome Firefox Edge Resources Blog News Events Data Sheets Active Threats Customer Success Stories Detection as Code Roota Sigma Company Why SOC Prime? About Us Industry Recognition Leadership Careers Privacy SOC 2 Type II Compliance Partner Programs for Universities PRICING Cookie Policy Privacy Policy LEGAL NOTICE (IMPRESSUM) SOC PRIME PLATFORM TERMS OF SERVICE Privacy FAQ Engage WIth Us SOC Prime, SOC Prime Logo and Threat Detection Marketplace are registered trademarks of SOC Prime, Inc. All other trademarks are the property of their respective owners. This website uses cookies (small text files that are stored by the web browser on the user's device) to improve the user experience while you navigate through the website for the statistical analysis of traffic and to adapt the content of the website to your individual needs. It also lets us improve your overall experience of the website. These cookies will only be stored in your browser with your consent. However, if you would like to, you can opt-out of these cookies in your browser settings at any time. But opting out of some of these cookies may have a negative impact on your viewing experience. More information can be found in our Cookie Policy, and for a detailed list of the cookies we use, see our Cookie Settings. Accept and Close Cookie Settings Cookie Settings Below is a detailed list of the cookies we use on our Site. We classify cookies in the following categories: Strictly Necessary Cookies Performance Cookies Functional Cookies Targeting Cookies Strictly Necessary Cookies Cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information. Name Descripiton PHPSESSID Preserves user session state across page requests. Cookie generated by applications based on the PHP language. This is a general purpose identifier used to maintain user session variables. It is normally a random generated number, how it is used can be specific to the site, but a good example is maintaining a logged-in status for a user between pages. sp_i Used to store information about authenticated User. sp_r Used to store information about authenticated User. sp_a Used to store information about authenticated User. Performance Cookies These cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site. All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site, and will not be able to monitor its performance. Name Descripiton tuuid Collects anonymous data related to the user's visits to the website, such as the number of visits, average time spent on the website and what pages have been loaded. tuuid_last_update Collects anonymous data related to the user's visits to the website, such as the number of visits, average time spent on the website and what pages have been loaded. um Collects anonymous data related to the user's visits to the website, such as the number of visits, average time spent on the website and what pages have been loaded. umeh Collects anonymous data related to the user's visits to the website, such as the number of visits, average time spent on the website and what pages have been loaded. na_sc_x Used by the social sharing platform AddThis to keep a record of parts of the site that has been visited in order to recommend other parts of the site. APID Collects anonymous data related to the user's visits to the website. IDSYNC Collects anonymous data related to the user's visits to the website. _cc_aud Collects anonymous statistical data related to the user's website visits, such as the number of visits, average time spent on the website and what pages have been loaded. The purpose is to segment the website's users according to factors such as demographics and geographical location, in order to enable media and marketing agencies to structure and understand their target groups to enable customised online advertising. _cc_cc Collects anonymous statistical data related to the user's website visits, such as the number of visits, average time spent on the website and what pages have been loaded. The purpose is to segment the website's users according to factors such as demographics and geographical location, in order to enable media and marketing agencies to structure and understand their target groups to enable customised online advertising. _cc_dc Collects anonymous statistical data related to the user's website visits, such as the number of visits, average time spent on the website and what pages have been loaded. The purpose is to segment the website's users according to factors such as demographics and geographical location, in order to enable media and marketing agencies to structure and understand their target groups to enable customised online advertising. _cc_id Collects anonymous statistical data related to the user's website visits, such as the number of visits, average time spent on the website and what pages have been loaded. The purpose is to segment the website's users according to factors such as demographics and geographical location, in order to enable media and marketing agencies to structure and understand their target groups to enable customised online advertising. dpm Via a unique ID that is used for semantic content analysis, the user's navigation on the website is registered and linked to offline data from surveys and similar registrations to display targeted ads. acs Collects anonymous data related to the user's visits to the website, such as the number of visits, average time spent on the website and what pages have been loaded, with the purpose of displaying targeted ads. clid Collects anonymous data related to the user's visits to the website, such as the number of visits, average time spent on the website and what pages have been loaded, with the purpose of displaying targeted ads. KRTBCOOKIE_# Registers a unique ID that identifies the user's device during return visits across websites that use the same ad network. The ID is used to allow targeted ads. PUBMDCID Registers a unique ID that identifies the user's device during return visits across websites that use the same ad network. The ID is used to allow targeted ads. PugT Registers a unique ID that identifies the user's device during return visits across websites that use the same ad network. The ID is used to allow targeted ads. ssi Registers a unique ID that identifies a returning user's device. The ID is used for targeted ads. _tmid Registers a unique ID that identifies the user's device upon return visits. The ID is used to target ads in video clips. wam-sync Used by the advertising platform Weborama to determine the visitor's interests based on pages visits, content clicked and other actions on the website. wui Used by the advertising platform Weborama to determine the visitor's interests based on pages visits, content clicked and other actions on the website. AFFICHE_W Used by the advertising platform Weborama to determine the visitor's interests based on pages visits, content clicked and other actions on the website. B Collects anonymous data related to the user's website visits, such as the number of visits, average time spent on the website and what pages have been loaded. The registered data is used to categorise the users' interest and demographical profiles with the purpose of customising the website content depending on the visitor. 1P_JAR These cookies are used to gather website statistics, and track conversion rates. APISID Google set a number of cookies on any page that includes a Google reCAPTCHA. While we have no control over the cookies set by Google, they appear to include a mixture of pieces of information to measure the number and behaviour of Google reCAPTCHA users. HSID Google set a number of cookies on any page that includes a Google reCAPTCHA. While we have no control over the cookies set by Google, they appear to include a mixture of pieces of information to measure the number and behaviour of Google reCAPTCHA users. NID Google set a number of cookies on any page that includes a Google reCAPTCHA. While we have no control over the cookies set by Google, they appear to include a mixture of pieces of information to measure the number and behaviour of Google reCAPTCHA users. SAPISID Google set a number of cookies on any page that includes a Google reCAPTCHA. While we have no control over the cookies set by Google, they appear to include a mixture of pieces of information to measure the number and behaviour of Google reCAPTCHA users. SID Google set a number of cookies on any page that includes a Google reCAPTCHA. While we have no control over the cookies set by Google, they appear to include a mixture of pieces of information to measure the number and behaviour of Google reCAPTCHA users. SIDCC Security cookie to protect users data from unauthorised access. SSID Google set a number of cookies on any page that includes a Google reCAPTCHA. While we have no control over the cookies set by Google, they appear to include a mixture of pieces of information to measure the number and behaviour of Google reCAPTCHA users. __utmx This cookie is associated with Google Website Optimizer, a tool designed to help site owners improve their wbesites. It is used to distinguish between two varaitions a webpage that might be shown to a visitor as part of an A/B split test. This helps site owners to detemine which version of a page performs better, and therefore helps to improve the website. __utmxx This cookie is associated with Google Website Optimizer, a tool designed to help site owners improve their wbesites. It is used to distinguish between two varaitions a webpage that might be shown to a visitor as part of an A/B split test. This helps site owners to detemine which version of a page performs better, and therefore helps to improve the website. Functional Cookies These cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages. If you do not allow these cookies then some or all of these services may not function properly. Name Descripiton _hjid Hotjar cookie. This cookie is set when the customer first lands on a page with the Hotjar script. It is used to persist the random user ID, unique to that site on the browser. This ensures that behavior in subsequent visits to the same site will be attributed to the same user ID. _hjIncludedInSample This cookie is associated with web analytics functionality and services from Hot Jar, a Malta based company. It uniquely identifies a visitor during a single browser session and indicates they are included in an audience sample. intercom-id-[xxx] This cookie is used by Intercom as a session so that users can continue a chat as they move through the site. intercom-session-[xxx] Used to keeping track of sessions and remember logins and conversations. demdex Via a unique ID that is used for semantic content analysis, the user's navigation on the website is registered and linked to offline data from surveys and similar registrations to display targeted ads. CookieConsent Stores the user's cookie consent state for the current domain. __cfduid Used by the content network, Cloudflare, to identify trusted web traffic. ss These cookies enable the website to provide enhanced functionality and personalisation . They may be set by us or by third party providers whose services we have added to our pages. These services may include the Live Chat facility, Contact Us form(s), the Product Quotation forms and submission process, and the Email Newsletter sign up functionality . Targeting Cookies These cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. They do not store directly personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising. Name Descripiton _ga This cookie name is asssociated with Google Universal Analytics - which is a significant update to Google's more commonly used analytics service. This cookie is used to distinguish unique users by assigning a randomly generated number as a client identifier. It is included in each page. Registers a unique ID that is used to generate statistical data on how the visitor uses the website. request in a site and used to calculate visitor, session and campaign data for the sites analytics reports. By default it is set to expire after 2 years, although this is customisable by website owners. _gat Used by Google Analytics to throttle request rate. This cookie name is associated with Google Universal Analytics, according to documentation it is used to throttle the request rate - limiting the collection of data on high traffic sites. It expires after 10 minutes. _gid This cookie name is asssociated with Google Universal Analytics. This appears to be a new cookie and as of Spring 2017 no information is available from Google. It appears to store and update a unique value for each page visited. Registers a unique ID that is used to generate statistical data on how the visitor uses the website. IDE Used by Google DoubleClick to register and report the website user's actions after viewing or clicking one of the advertiser's ads with the purpose of measuring the efficacy of an ad and to present targeted ads to the user. r/collect Used by Google DoubleClick to register and report the website user's actions after viewing or clicking one of the advertiser's ads with the purpose of measuring the efficacy of an ad and to present targeted ads to the user. test_cookie Used to check if the user's browser supports cookies. collect Used to send data to Google Analytics about the visitor's device and behaviour. Tracks the visitor across devices and marketing channels. ads/user-lists/# These cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. c Registers anonymised user data, such as IP address, geographical location, visited websites, and what ads the user has clicked, with the purpose of optimising ad display based on the user's movement on websites that use the same ad network. khaos Registers anonymised user data, such as IP address, geographical location, visited websites, and what ads the user has clicked, with the purpose of optimising ad display based on the user's movement on websites that use the same ad network. put_# Registers anonymised user data, such as IP address, geographical location, visited websites, and what ads the user has clicked, with the purpose of optimising ad display based on the user's movement on websites that use the same ad network. rpb Registers anonymised user data, such as IP address, geographical location, visited websites, and what ads the user has clicked, with the purpose of optimising ad display based on the user's movement on websites that use the same ad network. rpx Registers anonymised user data, such as IP address, geographical location, visited websites, and what ads the user has clicked, with the purpose of optimising ad display based on the user's movement on websites that use the same ad network. tap.php Registers anonymised user data, such as IP address, geographical location, visited websites, and what ads the user has clicked, with the purpose of optimising ad display based on the user's movement on websites that use the same ad network.\\\"},{\\\"url\\\":\\\"https://opensearch.org/blog/error-logs/error-log-circuit_breaking_exception-data-too-large/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to main content Search Close Search search Menu About Foundation Governing Board Charter Meeting Calendar Platform Platform OpenSearch CoreOpenSearch is a powerful search and analytics engine built on Apache Lucene. OpenSearch DashboardsOur data visualization toolset is a flexible, fully integrated solution for visually exploring and querying your data. OpenSearch Data PrepperA server-side data collector designed to enrich, transform, and aggregate data for downstream analytics with Opensearch. OpenSearch Vector EnginePower machine learning and generative AI applications with a high-performance database designed for the way AI understands data. Capabilities Machine learning and AI Vector Search Anomaly Detection Search E-Commerce Document Search Search Relevance Observability Performance Monitoring Log Analytics Security Analytics Threat Intelligence Event Correlation Performance Benchmarks View key performance metrics across different workloads View Data Roadmap Image OpenSearch Project RoadmapExplore our official project roadmap on GitHub Community OpenSearch Community ForumFind answers to your questions, help others in the community, and join the conversation. EventsCommunity Meetings, Development Backlog & Triage, in-person, and virtual events. AmbassadorsAmbassadors Community leaders who share knowledge and grow OpenSearch. Solutions ProvidersFind open-source providers offering solutions and services. ProjectsHighlights of projects built by the community. User GroupsJoin the OpenSearch Project Meetup Network Community Resources SlackSpeak with other developers. GitHub Project OrganizationJoin us for in-person and virtual events to learn the latest about the project. OpenSearchCon Image OpenSearchCon China17-18 March 2026 | Shanghai, China OpenSearchCon Europe16-17 April 2026 | Prague, Czechia OpenSearchCon India15-16 June 2026 | Mumbai, India Documentation Documentation Library OpenSearch and DashboardsBuild your OpenSearch solution using core tooling and visualizations. OpenSearch Data PrepperFilter, mutate, and sample your data for ingestion into OpenSearch. Migration AssistantBegin your transition to OpenSearch with our migration toolkit Documentation Library II OpenSearch BenchmarkMeasure performance metrics for your OpenSearch cluster. ClientsInteract with OpenSearch from your application using language APIs. Blog & News Blog Announcements Case Studies News Authors Downloads search Error Logs Error Log: Circuit_breaking_exception \\u2013 Data too large! By OpenSearchNovember 19, 2025No Comments Error Log: This error occurs when OpenSearch detects that an operation (often a search query with aggregations) would consume too much memory, potentially causing an OutOfMemoryError and crashing the node. JSON {\\\\r\\\\n  \\\\\\\"error\\\\\\\" : {\\\\r\\\\n    \\\\\\\"root_cause\\\\\\\" : [\\\\r\\\\n      {\\\\r\\\\n        \\\\\\\"type\\\\\\\" : \\\\\\\"circuit_breaking_exception\\\\\\\",\\\\r\\\\n        \\\\\\\"reason\\\\\\\" : \\\\\\\"[parent] Data too large, data for [] would be [123456789b] which is larger than the limit of [67108864b]\\\\\\\",\\\\r\\\\n        \\\\\\\"bytes_wanted\\\\\\\" : 123456789,\\\\r\\\\n        \\\\\\\"bytes_limit\\\\\\\" : 67108864\\\\r\\\\n      }\\\\r\\\\n    ],\\\\r\\\\n    \\\\\\\"type\\\\\\\" : \\\\\\\"circuit_breaking_exception\\\\\\\",\\\\r\\\\n    \\\\\\\"reason\\\\\\\" : \\\\\\\"[parent] Data too large, data for [] would be [123456789b] which is larger than the limit of [67108864b]\\\\\\\"\\\\r\\\\n  },\\\\r\\\\n  \\\\\\\"status\\\\\\\" : 429\\\\r\\\\n} Why\\u2026 is this happening? OpenSearch uses circuit breakers to prevent operations from consuming too much memory and crashing the Java Virtual Machine (JVM). When a query\\u2019s estimated memory usage exceeds a configured limit, the circuit breaker \\u201ctrips,\\u201d aborting the operation and returning this exception. The most common reasons are: [parent] Circuit Breaker: This is the most common. A query (often with complex aggregations, deeply nested documents, or large terms aggregations) tries to load too much data into the JVM heap. [fielddata] Circuit Breaker: This usually means you\\u2019re trying to sort or aggregate on a text field for which fielddata is enabled. fielddata loads all unique terms for a field into memory, which can be extremely expensive for high-cardinality text fields. [request] Circuit Breaker: An individual request (like a bulk request or a very large search request) is too big. Best Practice: Optimize Your Queries/Aggregations: Reduce size: For terms aggregations, reduce the size parameter if you don\\u2019t need all results. Filter Before Aggregating: Apply filters to your data before performing aggregations to reduce the dataset. Avoid High-Cardinality terms Aggregations on Text Fields: If you need to aggregate on a text-like field, ensure it has a keyword sub-field and aggregate on that. Pagination: Use search_after or scroll APIs for deep pagination instead of from/size on very large result sets. Do Not Enable fielddata on text Fields: This is almost always the wrong solution. Use .keyword sub-fields for aggregations and sorting. Increase JVM Heap (with caution): You can increase the JVM heap size (ES_JAVA_OPTS=\\\\\\\"-Xms...\\\\\\\" \\\\\\\"-Xmx...\\\\\\\") in jvm.options, but be aware that larger heaps can lead to longer garbage collection pauses. A general rule of thumb is to allocate no more than 50% of your total RAM to the heap, up to ~30-32GB. Scale Out: Add more data nodes to your cluster. This distributes the memory load across multiple JVMs. What else can I do? Are your CircuitBreakingException errors persistent? Share your problematic queries and mappings with the OpenSearch community to get specific optimization advice. For expert help with cluster sizing and query optimization, contact us in The OpenSearch Slack Channel in #General. Share or Summarize with AI ClaudeChatGPTGoogle AIGeminiGrokPerplexityTwitter (X)LinkedInWhatsAppEmail Author OpenSearch View all posts Share Subscribe for updates, event info, and the latest community news OpenSearch is a community-driven, Apache 2.0-licensed open source search and analytics suite that makes it easy to ingest, search, visualize, and analyze data. [social-icons-display order=\\u201dlinkedin,github,slack,youtube,mastodon,bluesky,twitter\\u201d] Participate Code of Conduct Forum Project Repo Community Repo Meetup Connect Providers Become a Provider Find a Provider Resources About FAQ Release Schedule Maintenance Policy Documentation Getting Started Testimonials Trademark & Brand Privacy \\u00a9 Copyright The Linux Foundation. The OpenSearch Project is a project of The Linux Foundation. For web site terms of use, trademark policy and other policies applicable to The OpenSearch Project please see Linux Foundation Policies. The OpenSearch Project supports the OpenSearch open source project, which has been established as OpenSearch Project a Series of LF Projects, LLC. For policies applicable to the OpenSearch Project a Series of LF Projects, LLC, please see LF Projects, LLC Policies, Privacy Policy, Terms of Use and the OpenSearch Trademark Policy. Close Menu About Foundation Governing Board Charter Meeting Calendar Platform Platform OpenSearch CoreOpenSearch is a powerful search and analytics engine built on Apache Lucene. OpenSearch DashboardsOur data visualization toolset is a flexible, fully integrated solution for visually exploring and querying your data. OpenSearch Data PrepperA server-side data collector designed to enrich, transform, and aggregate data for downstream analytics with Opensearch. OpenSearch Vector EnginePower machine learning and generative AI applications with a high-performance database designed for the way AI understands data. Capabilities Machine learning and AI Vector Search Anomaly Detection Search E-Commerce Document Search Search Relevance Observability Performance Monitoring Log Analytics Security Analytics Threat Intelligence Event Correlation Performance Benchmarks View key performance metrics across different workloads View Data Roadmap Image OpenSearch Project RoadmapExplore our official project roadmap on GitHub Community OpenSearch Community ForumFind answers to your questions, help others in the community, and join the conversation. EventsCommunity Meetings, Development Backlog & Triage, in-person, and virtual events. AmbassadorsAmbassadors Community leaders who share knowledge and grow OpenSearch. Solutions ProvidersFind open-source providers offering solutions and services. ProjectsHighlights of projects built by the community. User GroupsJoin the OpenSearch Project Meetup Network Community Resources SlackSpeak with other developers. GitHub Project OrganizationJoin us for in-person and virtual events to learn the latest about the project. OpenSearchCon Image OpenSearchCon China17-18 March 2026 | Shanghai, China OpenSearchCon Europe16-17 April 2026 | Prague, Czechia OpenSearchCon India15-16 June 2026 | Mumbai, India Documentation Documentation Library OpenSearch and DashboardsBuild your OpenSearch solution using core tooling and visualizations. OpenSearch Data PrepperFilter, mutate, and sample your data for ingestion into OpenSearch. Migration AssistantBegin your transition to OpenSearch with our migration toolkit Documentation Library II OpenSearch BenchmarkMeasure performance metrics for your OpenSearch cluster. ClientsInteract with OpenSearch from your application using language APIs. Blog & News Blog Announcements Case Studies News Authors Downloads\\\"},{\\\"url\\\":\\\"https://www.antstack.com/blog/how-to-handle-the-circuit-breaker-exception-in-open-search/\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Services UX & Design UI Engineering Application Development Application Modernization Data Engineering & Modernization AI Engineering Industries SME Healthcare QSR Media & Entertainment BFSI SaaS Logistics Case Studies Blogs About us Talk to us Somya Sharma 7 min read Dec 8, 2022 aws elasticsearch opensearch Subscribe to newsletter How to Handle the Circuit Breaker Exception in OpenSearch Summarize Chat GPT Perplexity Gemini Claude AI We had a search functionality requirement in one of the projects and that\\u2019s how I got to know about Amazon OpenSearch Service, It provides a quick, relevant search experience and makes it easier to add a search feature to your applications. The only hiccup is sizing the OpenSearch is a tricky and long-term process, and it often takes many iterations to make sure that you get the right specifications according to your workload. It also needs monitoring so as to be aware of future problems. You make an initial estimate of the resources, test them, and verify their performance. If the performance is not good, then you need to resize it and iterate. In this process, you often face many challenges. Some of them are listed below: Red / Yellow Cluster Status Exceeded maximum shard limit JVM OutOfMemoryError Failed cluster nodes While I was working with OpenSearch, I faced one such issue, which I will cover in this post. Our cluster was ready to go after going through the estimation process and performance testing, but after a while, we started seeing CircuitBreakerException in our logs. I find it difficult to understand, so I thought to write about it. I hope this blog helps you understand it better. Before we get into the topic, I would like to explain a little about clusters and nodes in OpenSearch. OpenSearch cluster is made up of one or more nodes, which are servers that handle search queries and store your data. As the cluster grows we can subdivide the responsibilities among different nodes(Master, Data, and more). Now, Let\\u2019s dive into the issue. What is a circuit breaker? In data nodes, 50 % of the available memory up to 32GB is used by the JVM heap and the rest is used for other operations. Circuit breakers are limitations put on a node to stop operations with the risk of resulting in JVM OutofMemoryError, which could cause the node to crash completely. The amount of memory each circuit breaker can utilize is specified. In response to requests, the breakers calculate how much memory the activity requires and compare the calculated size to the specified heap size limit. The query is aborted if the anticipated size exceeds the available heap size. In order to avoid overloading the node, a CircuitBreakerException is raised. Types of Circuit breakers There are many types of circuit breakers and a few of them are as follows: Parent circuit breaker - It specifies the maximum amount of memory that all breakers can utilize. If the combined memory utilization results in more than the specified limit the parent circuit exception will occur. It is configured using the below settings. indices.breaker.total.use_real_memory (default to true) - Determines whether the parent breaker should take real memory usage into account (true) or only consider the amount that is reserved by child circuit breakers (false). indices.breaker.total.limit (default - 95% of JVM heap) - Limit for overall parent breaker. If indices.breaker.total.use_real_memory is false then 70% JVM heap otherwise 95% of the JVM heap. Field Data circuit breaker - It is anticipated how much heap memory will be required to load a field into the field data cache. The circuit breaker terminates the operation and reports an error if loading the field will cause the cache to use more memory than was allowed. The field data cache contains field data (to allow text fields to be available for aggregations, sorting, and scripting) and global ordinals (It is an internal data structure used in elasticsearch for pre-computing and optimizing the performance of terms aggregations). indices.breaker.fielddata.limit - Limit for fielddata breaker. Defaults to 40% of the JVM heap. indices.breaker.fielddata.overhead - A constant (1.03) that all field data estimations are multiplied to determine a final estimation. Request circuit breaker - It is estimated how much heap memory will be required to process a request. It also includes the memory used for calculating aggregations during a request. If the memory usage is more than the limit, the request is terminated and an exception is raised. indices.breaker.request.limit - Defaults to 60% of the JVM heap. indices.breaker.request.overhead - A constant (1) that all request estimations are multiplied to determine a final estimation. In-flight requests circuit breaker - It is caused when the memory usage of all active incoming requests exceeds the configured threshold on a node. network.breaker.inflight_requests.limit - Defaults to 100% of JVM heap. This means that it is bound by the limit configured for the parent circuit breaker. network.breaker.inflight_requests.overhead - A constant (2) that is multiplied to determine a final estimation. Accounting circuit breaker - It is a limit to prevent items from using too much memory that isn't released when a request is finished, such as Lucene segment memory. A segment is an inverted index. indices.breaker.accounting.limit - Limit for accounting breaker, defaults to 100% of JVM heap. This means that it is bound by the limit configured for the parent circuit breaker. indices.breaker.accounting.overhead - A constant (1) that is multiplied to determine a final estimation. Useful Commands GET /_nodes/stats/breaker To retrieve the current memory use per node and per breaker. GET _cat/nodes?v=true&h=id,r,ram,heap* To obtain information about heap and memory details per node. GET /_cluster/settings?include_defaults=true It will return explicitly defined and default setting in the cluster including breaker settings. GET _nodes/stats?filter_path=nodes..jvm.mem.pools.old To calculate the JVM memory pressure of each node. Use the response to calculate memory pressure as JVM Memory Pressure = used_in_bytes / max_in_bytes. Circuit Breaker Exception Example Above is an example of a circuit breaker error message which I had encountered while working with AWS OpenSearch Service. The error will result in a 429 status code. Let\\u2019s look into the error more closely and try to understand what is happening here. type - It specifies the type of the exception raised. reason - More detailed information about the reason which led to the mentioned exception. [parent] - It specifies that the parent circuit breaker exception has resulted in the error. The default parent circuit breaker setting is 95%. real usage - It defines the current heap usage. new bytes reserved - It specifies the number of new bytes required. limit of - It is the maximum memory allocation for the parent circuit breaker. If the real usage + new bytes reserved exceeds the limit of, the parent circuit breaker will be triggered. durability - It specifies if the issue that triggered the circuit breaker eventually resolves itself (TRANSIENT) or calls for manual intervention (PERMANENT). Suggestions Reduce JVM memory pressure - High JVM memory pressure often causes circuit breaker errors. Check the JVM memory pressure and try to reduce it using the following suggestions. Reduce the shard numbers of each index- For search latency workloads use a shard size between 10\\u201330 GiB. For write-heavy workloads use a shard size between 30\\u201350 GiB. On a given node, have no more than 20 shards per GiB of Java heap. Avoid searches that might be very expensive (Using large size in pagination). Enable slow logs for identifying expensive search queries. Aggregation, wildcards, and wide time ranges in your queries might also result in high JVM pressure. A mapping explosion, which consumes a lot of memory, might result from defining too many fields or nesting fields too deeply. Avoid sending a large number of requests at the same time or tuning bulk size according to your workload. Increase the cluster's size to get an extra JVM heap to handle yours. Disable and avoid using fielddata as it can consume a large amount of heap space. Monitoring OpenSearch cluster metrics with Amazon CloudWatch and create alarms for various cluster metrics. Enable logs for better observability of the errors and issues. Innovate faster, and go farther with serverless-native application development. Explore limitless possibilities with AntStack's serverless solutions. Empowering your business to achieve your most audacious goals. Talk to us About Somya Sharma Backend Dev currently focusing on AWS Services, Algorithms, and Serverless Application Development. Tags aws elasticsearch opensearch Subscribe to newsletter Your Digital Journey deserves a great story. Build one with us. Talk to us Recommended Blogs Editorial Team 5 min read Nov 24, 2025 Strangler Fig, Serverless, and Agentic AI: It\\u2019s Not the Future, It\\u2019s the Present Krishna Muddi 6 min read Oct 20, 2025 Managing Roles and Permissions in Amazon OpenSearch with AWS SSO Krishna Muddi 5 min read Sep 15, 2025 Integrating Amazon OpenSearch with AWS SSO for Secure Authentication Jeevan Dongre 5 min read Jul 11, 2025 Why Your Menu API Is Slowing Down Your QSR Jeevan Dongre 6 min read Jun 12, 2025 The Hidden Cost of Status Quo: Why Healthcare CTOs Can't Afford to Delay Modernization Vishwasa Navada K 5 min read Jun 2, 2025 Comparison of LLM Prompt Caching: Cloudflare AI Gateway, Portkey, and Amazon Bedrock This website stores cookies on your computer. These cookies are used to collect information about how you interact with this website and allow us to remember you. We use this information to improve and customize your browsing experience, as well as for analytics. If you decline, your information won\\u2019t be tracked when you visit this website. A single cookie will be used in your browser to remember your preference. Decline Accept Services DesignUI EngineeringApplication DevelopmentApplication ModernizationData Engineering & ModernizationAI Engineering Industries Small and mid level enterprisesHealthcareQSRMedia & EntertainmentBFSISaaSLogistics Quick links BlogEventsCase StudiesGuidesTalksServerlessServerless ToolsServerless Architecture Company About usAntVerseCareersPrivacy PolicyBrand GuidelinesTrust Center Headquarters AntStack Inc. 8 The Green STE D, Dover, Kent, 19901, USA. +1 (650) 305-6238 Delivery Centre AntStack Technologies Private Limited #620, 3rd Floor, Dr Rajkumar Rd, 2nd Block, 1st Main, Rajajinagar, Bengaluru, Karnataka 560010 080-41330449 / +91-9353139419 Follow Subscribe to our newsletter Our bi-weekly newsletter delivers serverless, AI, tech trends, podcasts and blogs straight to your inbox. Subscribe \\u00a9 2019 - 2026 AntStack. All Rights Reserved.\\\"},{\\\"url\\\":\\\"https://drdroid.io/stack-diagnosis/opensearch-circuitbreakingexception\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Product Alerts Inbox Single pane of glass for all your alerts AI investigations Let AI debug the issue and identify remediation steps Context Engine Coming Soon Runbook Automation Automated Execution of Runbooks Alert Analytics Get insights on alerts that are creating fatigue and reduce noise Resources Docs Integrations Whitepapers Blog Pricing About Our Team Careers Get Started OpenSearch CircuitBreakingException The request exceeded the memory limits set by the circuit breaker. Thank you! Your submission has been received! Oops! Something went wrong while submitting the form. Stuck? Get Expert Help TensorFlow expert \\u2022 Under 10 minutes \\u2022 Starting at $20 Talk Now What is OpenSearch CircuitBreakingException ? Understanding OpenSearch OpenSearch is a powerful, open-source search and analytics suite that enables users to perform full-text searches, structured searches, and analytics on large volumes of data. It is designed to be highly scalable and is often used for log analytics, real-time application monitoring, and search backends. Identifying the Symptom: CircuitBreakingException When using OpenSearch, you might encounter an error message that reads CircuitBreakingException. This exception indicates that a request has exceeded the memory limits set by the circuit breaker, which is a safeguard to prevent the system from running out of memory. Exploring the Issue: What is CircuitBreakingException? The CircuitBreakingException is triggered when a query or operation in OpenSearch requires more memory than what is available or allocated by the circuit breaker settings. Circuit breakers are designed to protect the cluster from running out of memory by halting operations that exceed predefined memory limits. Why Circuit Breakers Matter Circuit breakers are crucial in maintaining the stability and performance of an OpenSearch cluster. They prevent memory overconsumption, which could lead to node failures or degraded performance. Steps to Resolve CircuitBreakingException To resolve this issue, you can either optimize your queries to use less memory or adjust the circuit breaker settings. Here\\u2019s how: 1. Optimize Your Queries Review your queries to ensure they are efficient. Avoid fetching unnecessary fields or large result sets. Use filters instead of queries where possible, as filters are cached and more efficient. Consider using aggregations wisely, as they can be memory-intensive. 2. Adjust Circuit Breaker Settings If optimizing queries is not sufficient, you may need to adjust the circuit breaker settings: { \\\\\\\"indices.breaker.total.limit\\\\\\\": \\\\\\\"70%\\\\\\\" } To apply this setting, use the following command: PUT /_cluster/settings { \\\\\\\"persistent\\\\\\\": { \\\\\\\"indices.breaker.total.limit\\\\\\\": \\\\\\\"70%\\\\\\\" } } For more details on configuring circuit breakers, refer to the OpenSearch Circuit Breakers Documentation. Conclusion By understanding and addressing the CircuitBreakingException, you can ensure that your OpenSearch cluster remains stable and performs optimally. Always monitor your cluster\\u2019s performance and adjust settings as necessary to accommodate your workload. For further reading on optimizing OpenSearch performance, check out the OpenSearch Performance Tuning Guide. Attached error: OpenSearch CircuitBreakingException Thank you! Your submission has been received! Oops! Something went wrong while submitting the form. Master OpenSearch debugging in Minutes \\u2014 Grab the Ultimate Cheatsheet (Perfect for DevOps & SREs) Most-used commands Real-world configs/examples Handy troubleshooting shortcuts Business Email Your email is safe with us. No spam, ever. Thank you for your submission We have sent the cheatsheet on your email! Oops! Something went wrong while submitting the form. OpenSearch Cheatsheet (Perfect for DevOps & SREs) Most-used commands Business Email Your email is safe with us. No spam, ever. Thank you for your submission We have sent the cheatsheet on your email! Oops! Something went wrong while submitting the form. MORE ISSUES OpenSearch IndexShardNotRelocatedException An operation was attempted on a shard that is not relocated. OpenSearch SnapshotRestoreInProgressException An operation was attempted while a snapshot restore is in progress. OpenSearch An operation was attempted on a shard that is not recovering. The shard is not in a recovering state when the operation was attempted. OpenSearch An operation was attempted on a shard that is not recovering. The shard is not in a recovering state when the operation is attempted. OpenSearch SnapshotRestoreInProgressException encountered during an operation. An operation was attempted while a snapshot restore is in progress. OpenSearch An operation was attempted on a shard that is not relocated. The shard is not yet relocated, causing the operation to fail. OpenSearch SnapshotRestoreInProgressException encountered during an operation. An operation was attempted while a snapshot restore is in progress. OpenSearch An operation was attempted on a shard that is not recovering. The shard is not in a recovering state when an operation is attempted. OpenSearch An operation was attempted on a shard that is not relocated. The shard has not been properly relocated before the operation was attempted. OpenSearch SnapshotInProgressException An operation was attempted while a snapshot is in progress. OpenSearch An operation was attempted on a shard that is not recovering. The shard is not in a recovering state, which is required for certain operations. OpenSearch SearchParseException An error occurred while parsing a search request. OpenSearch IndexShardNotStartedException An operation was attempted on a shard that has not started. OpenSearch InvalidTypeNameException encountered during index creation or update. The type name provided does not adhere to OpenSearch naming conventions. OpenSearch AliasMissingException The specified alias does not exist. OpenSearch IndexTemplateMissingException The specified index template does not exist. OpenSearch SnapshotMissingException The specified snapshot does not exist. OpenSearch NodeDisconnectedException A node was disconnected from the cluster. OpenSearch IndexShardRelocatedException An operation was attempted on a shard that has been relocated. OpenSearch An operation was attempted on a closed shard. The shard is closed, preventing any operations from being performed. OpenSearch QueryPhaseExecutionException An error occurred during the query phase, possibly due to a malformed query. OpenSearch SearchContextMissingException The search context was missing or expired. OpenSearch IndexShardRecoveryException An error occurred while recovering a shard. OpenSearch ClusterStateException An error occurred while updating the cluster state. OpenSearch IllegalStateException An operation was attempted in an invalid state. OpenSearch ElasticsearchParseException encountered during query execution or configuration. An error occurred while parsing a query or configuration. OpenSearch An error occurred while creating an index. Incorrect index settings or configurations. OpenSearch ResourceAlreadyExistsException An attempt was made to create a resource that already exists. OpenSearch IndexTemplateAlreadyExistsException An attempt was made to create an index template that already exists. OpenSearch InvalidAliasNameException The alias name provided is invalid. OpenSearch DocumentMissingException An operation was attempted on a document that does not exist. OpenSearch InvalidIndexNameException encountered when creating or accessing an index. The index name provided does not comply with OpenSearch naming conventions. OpenSearch PrimaryShardNotAllocatedException The primary shard is not allocated, possibly due to insufficient resources. OpenSearch An operation was attempted on a closed index. The index is closed, preventing any operations from being performed. OpenSearch TransportException An error occurred in the transport layer, possibly due to network issues. OpenSearch MapperParsingException An error occurred while parsing a document due to mapping issues. OpenSearch IllegalArgumentException encountered during an OpenSearch operation. An invalid argument was provided to an OpenSearch operation. OpenSearch IndexShardMissingException A shard is missing from the index. OpenSearch SnapshotRestoreException An error occurred while restoring a snapshot. OpenSearch An error occurred while creating a snapshot. Check the repository settings and ensure the storage location is accessible. OpenSearch IndexAlreadyExistsException An attempt was made to create an index that already exists. OpenSearch A request to OpenSearch timed out. The query execution time exceeded the configured timeout settings. OpenSearch NoNodeAvailableException No nodes are available to process the request. OpenSearch NodeNotConnectedException A node is not connected to the cluster. OpenSearch MasterNotDiscoveredException The node cannot connect to the master node. OpenSearch A document update failed due to a version conflict. The document being updated has been modified since it was last retrieved, leading to a version conflict. OpenSearch SearchPhaseExecutionException An error occurred during the search phase, possibly due to a malformed query. OpenSearch CircuitBreakingException The request exceeded the memory limits set by the circuit breaker. OpenSearch ClusterBlockException The cluster is read-only due to insufficient disk space. OpenSearch ShardFailure A shard has failed due to hardware issues or corrupted data. OpenSearch IndexNotFoundException The specified index does not exist in the cluster. Backed by Resources DocumentationFun For DevsBlog Contact Contact UsAbout UsCareersTerms and ConditionsPrivacy PolicyShipping & and Delivery PolicyCancellation & Refund Policy Platform AI OpsAlert Grouping & De-DuplicationPlayBooksKubernetes Bot Connect DiscordGithubLinkedInX (Twitter) SOC 2 Type II certifed ISO 27001 certified Deep Sea Tech Inc. \\u2014 Made with \\u2764\\ufe0f in Bangalore & San Francisco \\ud83c\\udfe2 Doctor Droid\\\"},{\\\"url\\\":\\\"https://github.com/opensearch-project/OpenSearch/issues/12475\\\",\\\"title\\\":\\\"\\\",\\\"content\\\":\\\"Skip to content Navigation Menu Toggle navigation Sign in Appearance settings Platform AI CODE CREATION GitHub CopilotWrite better code with AI GitHub SparkBuild and deploy intelligent apps GitHub ModelsManage and compare prompts MCP RegistryNewIntegrate external tools DEVELOPER WORKFLOWS ActionsAutomate any workflow CodespacesInstant dev environments IssuesPlan and track work Code ReviewManage code changes APPLICATION SECURITY GitHub Advanced SecurityFind and fix vulnerabilities Code securitySecure your code as you build Secret protectionStop leaks before they start EXPLORE Why GitHub Documentation Blog Changelog Marketplace View all features Solutions BY COMPANY SIZE Enterprises Small and medium teams Startups Nonprofits BY USE CASE App Modernization DevSecOps DevOps CI/CD View all use cases BY INDUSTRY Healthcare Financial services Manufacturing Government View all industries View all solutions Resources EXPLORE BY TOPIC AI Software Development DevOps Security View all topics EXPLORE BY TYPE Customer stories Events & webinars Ebooks & reports Business insights GitHub Skills SUPPORT & SERVICES Documentation Customer support Community forum Trust center Partners Open Source COMMUNITY GitHub SponsorsFund open source developers PROGRAMS Security Lab Maintainer Community Accelerator Archive Program REPOSITORIES Topics Trending Collections Enterprise ENTERPRISE SOLUTIONS Enterprise platformAI-powered developer platform AVAILABLE ADD-ONS GitHub Advanced SecurityEnterprise-grade security features Copilot for BusinessEnterprise-grade AI features Premium SupportEnterprise-grade 24/7 support Pricing Search or jump to... Search code, repositories, users, issues, pull requests... Search Clear Search syntax tips Provide feedback We read every piece of feedback, and take your input very seriously. Include my email address so I can be contacted Cancel Submit feedback Saved searches Use saved searches to filter your results more quickly Name Query To see all available qualifiers, see our documentation. Cancel Create saved search Sign in Sign up Appearance settings Resetting focus You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert {{ message }} opensearch-project / OpenSearch Public Notifications You must be signed in to change notification settings Fork 2.4k Star 12.1k Code Issues 2.2k Pull requests 313 Actions Projects 3 Wiki Security Uh oh! There was an error while loading. Please reload this page. Insights Additional navigation options Code Issues Pull requests Actions Projects Wiki Security Insights [BUG] Circuit breaker exceptions due to misconfigured fielddata cache size and circuit breaker for fieldcache #12475 New issue Copy link New issue Copy link Open Open [BUG] Circuit breaker exceptions due to misconfigured fielddata cache size and circuit breaker for fieldcache#12475 Copy link Labels SearchSearch query, autocomplete ...etcSearch query, autocomplete ...etcSearch:ResiliencybugSomething isn't workingSomething isn't workinglucene Description vikasvb90 opened on Feb 27, 2024 Issue body actions Describe the bug We allow users to configure setting indices.breaker.fielddata.limit lesser than indices.fielddata.cache.size. If this happens and if fielddata cache is enabled on one or more fields then it is possible for fielddata cache to grow beyond fielddata breaker limit. This can happen if there is a sudden burst of heavy search queries which can fill up the cache with more field data than CB limit before circuit breaker starts kicking in. Due to this, subsequent search queries or aggregations on fielddata cache enabled fields will start failing with circuit breaker exceptions. [2024-02-25T09:00:44,638][DEBUG][o.o.a.s.TransportSearchAction] [f92acfa0c58f3643980f1cada9df945d] [l3F63B3JR0KY7qbJ5cyJAg][.opendistro-ism-config][1]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[.opendistro-ism-config], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, expand_wildcards_hidden=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], routing='null', preference='_shards:1|_primary', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=null, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={\\\\\\\"size\\\\\\\":100,\\\\\\\"query\\\\\\\":{\\\\\\\"match_all\\\\\\\":{\\\\\\\"boost\\\\\\\":1.0}},\\\\\\\"version\\\\\\\":true,\\\\\\\"seq_no_primary_term\\\\\\\":true,\\\\\\\"sort\\\\\\\":[{\\\\\\\"_id\\\\\\\":{\\\\\\\"order\\\\\\\":\\\\\\\"asc\\\\\\\",\\\\\\\"missing\\\\\\\":\\\\\\\"_last\\\\\\\",\\\\\\\"unmapped_type\\\\\\\":\\\\\\\"keyword\\\\\\\"}}],\\\\\\\"search_after\\\\\\\":[\\\\\\\"\\\\\\\"]}, cancelAfterTimeInterval=null, pipeline=null}] lastShard [true][2024-02-25T09:00:44,638][DEBUG][o.o.a.s.TransportSearchAction] [f92acfa0c58f3643980f1cada9df945d] #[org.opensearch.OpenSearchException,java.util.concurrent.ExecutionException,org.opensearch.core.common.breaker.CircuitBreakingException]#All shards failed for phase: [query]\\\\nOpenSearchException[java.util.concurrent.ExecutionException: CircuitBreakingException[[fielddata] Data too large, data for [_id] would be [3469348057/3.2gb], which is larger than the limit of [515396075/491.5mb]]]; nested: ExecutionException[CircuitBreakingException[[fielddata] Data too large, data for [_id] would be [3469348057/3.2gb], which is larger than the limit of [515396075/491.5mb]]]; nested: CircuitBreakingException[[fielddata] Data too large, data for [_id] would be [3469348057/3.2gb], which is larger than the limit of [515396075/491.5mb]];\\\\n        at org.opensearch.index.fielddata.plain.AbstractIndexOrdinalsFieldData.load(AbstractIndexOrdinalsFieldData.java:116)\\\\n        at org.opensearch.index.fielddata.plain.AbstractIndexOrdinalsFieldData.load(AbstractIndexOrdinalsFieldData.java:62)\\\\n        at org.opensearch.index.mapper.IdFieldMapper$IdFieldType$1$1.load(IdFieldMapper.java:209)\\\\n        at org.opensearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource.getValues(BytesRefFieldComparatorSource.java:91)\\\\n        at org.opensearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource$2.getBinaryDocValues(BytesRefFieldComparatorSource.java:141)\\\\n        at org.apache.lucene.search.FieldComparator$TermValComparator.getLeafComparator(FieldComparator.java:280)\\\\n        at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:176)\\\\n        at org.apache.lucene.search.TopFieldCollector$TopFieldLeafCollector.<init>(TopFieldCollector.java:64)\\\\n        at org.apache.lucene.search.TopFieldCollector$PagingFieldCollector$1.<init>(TopFieldCollector.java:254)\\\\n        at org.apache.lucene.search.TopFieldCollector$PagingFieldCollector.getLeafCollector(TopFieldCollector.java:254)\\\\n        at org.opensearch.search.internal.ContextIndexSearcher.searchLeaf(ContextIndexSearcher.java:306)\\\\n        at org.opensearch.search.internal.ContextIndexSearcher.search(ContextIndexSearcher.java:281)\\\\n        at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:551)\\\\n        at org.opensearch.search.query.QueryPhase.searchWithCollector(QueryPhase.java:360)\\\\n        at org.opensearch.search.query.QueryPhase$DefaultQueryPhaseSearcher.searchWithCollector(QueryPhase.java:447)\\\\n        at org.opensearch.search.query.QueryPhase$DefaultQueryPhaseSearcher.searchWith(QueryPhase.java:431)\\\\n        at org.opensearch.search.query.QueryPhaseSearcherWrapper.searchWith(QueryPhaseSearcherWrapper.java:65)\\\\n        at org.opensearch.neuralsearch.search.query.HybridQueryPhaseSearcher.searchWith(HybridQueryPhaseSearcher.java:66)\\\\n        at org.opensearch.search.query.QueryPhase.executeInternal(QueryPhase.java:282)\\\\n        at org.opensearch.search.query.QueryPhase.execute(QueryPhase.java:155)\\\\n        at org.opensearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:533)\\\\n        at org.opensearch.search.SearchService.executeQueryPhase(SearchService.java:597)\\\\n        at org.opensearch.search.SearchService$2.lambda$onResponse$0(SearchService.java:566)\\\\n        at org.opensearch.action.ActionRunnable.lambda$supply$0(ActionRunnable.java:74)\\\\n        at org.opensearch.action.ActionRunnable$2.doRun(ActionRunnable.java:89)\\\\n        at org.opensearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:917)\\\\n        at org.opensearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:52)\\\\n        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\\\\n        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\\\\n        at java.base/java.lang.Thread.run(Thread.java:833)\\\\n Related component Search:Resiliency To Reproduce One way to potentially reproduce this is Create an index with field data cache enabled on some of the text value fields. Ingest data till field data cache reaches (say 20%). Use GET /_cat/fielddata for monitoring. Set breaker limit to 1%. Execute heavy search queries (resulting in >1% of data size) on fields with field data cache enabled. Expected behavior A validation should be added in OpenSearch to reject update setting request if indices.breaker.fielddata.limit is less than indices.fielddata.cache.size. Default value of indices.breaker.fielddata.limit is 40% of JVM and default cache size is unbounded. We should also consider setting the default cache size to be less than default breaker limit (say 38%). Additional Details Plugins Please list all plugins currently enabled. Screenshots If applicable, add screenshots to help explain your problem. Host/Environment (please complete the following information): OS: [e.g. iOS] Version [e.g. 22] Additional context Add any other context about the problem here. Metadata Metadata Assignees No one assigned Labels SearchSearch query, autocomplete ...etcSearch query, autocomplete ...etcSearch:ResiliencybugSomething isn't workingSomething isn't workinglucene Type No type Projects Search Project Board Status Later (6 months plus) Show more project fields Milestone No milestone Relationships None yet Development No branches or pull requests Issue actions Footer \\u00a9 2026 GitHub, Inc. Footer navigation Terms Privacy Security Status Community Docs Contact Manage cookies Do not share my personal information You can\\u2019t perform that action at this time.\\\"}]}\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Search for error resolution\n",
    "parameters = {\n",
    "    \"question\": \"How to fix circuit breaker errors in OpenSearch\"\n",
    "}\n",
    "\n",
    "print(\"‚ùì Question: How to fix circuit breaker errors in OpenSearch\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "response = execute_agent(client, agent_id, parameters)\n",
    "\n",
    "print(\"\\nüîß Troubleshooting Information:\")\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12812a91",
   "metadata": {},
   "source": [
    "## üí° Alternative Configuration: Google Custom Search\n",
    "\n",
    "If you have Google Custom Search credentials, you can use this configuration:\n",
    "\n",
    "```python\n",
    "# Google Custom Search configuration (requires API key)\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"WebSearchTool\",\n",
    "        \"parameters\": {\n",
    "            \"engine\": \"google\",\n",
    "            \"engine_id\": \"your_google_engine_id\",\n",
    "            \"api_key\": \"your_google_api_key\",\n",
    "            \"input\": \"${parameters.question}\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "### Getting Google Custom Search Credentials:\n",
    "1. Create a Google Custom Search Engine at: https://programmablesearchengine.google.com/\n",
    "2. Get your Engine ID from the control panel\n",
    "3. Get an API key from: https://developers.google.com/custom-search/v1/overview\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea8fc77",
   "metadata": {},
   "source": [
    "## üí° Alternative Configuration: Custom Search API\n",
    "\n",
    "For custom search endpoints:\n",
    "\n",
    "```python\n",
    "# Custom search API configuration\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"WebSearchTool\",\n",
    "        \"parameters\": {\n",
    "            \"engine\": \"custom\",\n",
    "            \"endpoint\": \"https://api.your-search-engine.com/search\",\n",
    "            \"custom_res_url_jsonpath\": \"$.data[*].link\",\n",
    "            \"Authorization\": \"Bearer your_api_token\",\n",
    "            \"query_key\": \"q\",\n",
    "            \"offset_key\": \"offset\",\n",
    "            \"limit_key\": \"limit\",\n",
    "            \"input\": \"${parameters.question}\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "### Custom API Parameters:\n",
    "- **endpoint**: Your search API URL\n",
    "- **custom_res_url_jsonpath**: JSONPath to extract result URLs\n",
    "- **Authorization**: Authentication header\n",
    "- **query_key**: URL parameter name for search query\n",
    "- **offset_key**: URL parameter for pagination offset\n",
    "- **limit_key**: URL parameter for result limit\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f193498",
   "metadata": {},
   "source": [
    "## üéì Key Takeaways\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **WebSearchTool Capabilities**:\n",
    "   - ‚úÖ **DuckDuckGo**: No API key, easy setup, good for testing\n",
    "   - ‚úÖ **Google Custom Search**: More results, requires credentials\n",
    "   - ‚úÖ **Custom APIs**: Integrate any search endpoint\n",
    "   - ‚úÖ External knowledge augmentation for agents\n",
    "\n",
    "2. **Search Engine Comparison**:\n",
    "   | Engine | API Key | Cost | Results Quality | Setup |\n",
    "   |--------|---------|------|-----------------|-------|\n",
    "   | DuckDuckGo | ‚ùå Not Required | Free | Good | Easy |\n",
    "   | Google | ‚úÖ Required | Free tier + paid | Excellent | Moderate |\n",
    "   | Custom | ‚úÖ Required | Varies | Varies | Complex |\n",
    "\n",
    "3. **Practical Use Cases**:\n",
    "   - üìö **Documentation Lookup**: Find external docs and guides\n",
    "   - üì∞ **Current Events**: Get real-time information\n",
    "   - üîç **Research**: Gather external context for queries\n",
    "   - üéì **Learning**: Help users find educational content\n",
    "   - üîß **Troubleshooting**: Find solutions to technical problems\n",
    "\n",
    "4. **Integration Patterns**:\n",
    "   ```python\n",
    "   # Hybrid agent: Internal + External search\n",
    "   tools = [\n",
    "       {\"type\": \"VectorDBTool\", ...},    # Internal semantic search\n",
    "       {\"type\": \"WebSearchTool\", ...},   # External web search\n",
    "       {\"type\": \"MLModelTool\", ...}      # Synthesize answers\n",
    "   ]\n",
    "   ```\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "- ‚úÖ **Start with DuckDuckGo** for development (no credentials needed)\n",
    "- ‚úÖ **Cache Results** to avoid repeated API calls\n",
    "- ‚úÖ **Rate Limiting** respect search engine limits\n",
    "- ‚úÖ **Fallback Strategy** have backup search engines\n",
    "- ‚úÖ **Result Filtering** parse and validate search results\n",
    "\n",
    "### Security Considerations:\n",
    "\n",
    "- üîí **API Keys**: Store in environment variables, not code\n",
    "- üîí **Input Validation**: Sanitize user queries\n",
    "- üîí **Result Verification**: Validate external content\n",
    "- üîí **Privacy**: Be aware of data sent to external services\n",
    "\n",
    "### Performance Tips:\n",
    "\n",
    "- ‚ö° **Parallel Searches**: Run internal and external searches concurrently\n",
    "- ‚ö° **Result Limits**: Fetch only what you need\n",
    "- ‚ö° **Timeout Configuration**: Set appropriate timeouts\n",
    "- ‚ö° **Error Handling**: Gracefully handle search failures\n",
    "\n",
    "### Combining Internal and External Search:\n",
    "\n",
    "```python\n",
    "# Example workflow:\n",
    "# 1. Search internal indices (VectorDBTool)\n",
    "# 2. If no results, search web (WebSearchTool)\n",
    "# 3. Synthesize answer from both sources (MLModelTool)\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"VectorDBTool\",\n",
    "        \"parameters\": {\n",
    "            \"index\": \"knowledge_base\",\n",
    "            \"embedding_field\": \"embedding\",\n",
    "            \"source_field\": [\"content\"],\n",
    "            \"input\": \"${parameters.question}\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"WebSearchTool\",\n",
    "        \"parameters\": {\n",
    "            \"engine\": \"duckduckgo\",\n",
    "            \"input\": \"${parameters.question}\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8ba1ac",
   "metadata": {},
   "source": [
    "## üßπ Cleanup (Optional)\n",
    "\n",
    "Uncomment and run this cell to clean up resources created in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b581321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delete the flow agent\n",
    "# cleanup_resources(\n",
    "#     client=client,\n",
    "#     agent_ids=[agent_id]\n",
    "# )\n",
    "\n",
    "# print(\"‚úÖ Cleanup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33ad019",
   "metadata": {},
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "Now that you understand WebSearchTool, explore:\n",
    "- **RAGTool**: Combine web search with retrieval-augmented generation\n",
    "- **MLModelTool**: Synthesize information from multiple sources\n",
    "- **AgentTool**: Build multi-agent systems with specialized search agents\n",
    "- **VectorDBTool**: Combine semantic search with web search\n",
    "\n",
    "---\n",
    "\n",
    "üìö **Resources**:\n",
    "- [DuckDuckGo Instant Answer API](https://duckduckgo.com/api)\n",
    "- [Google Custom Search](https://developers.google.com/custom-search/v1/overview)\n",
    "- [ML Commons Agent Tools](https://opensearch.org/docs/latest/ml-commons-plugin/agents-tools/)\n",
    "- [Web Search Tool Documentation](https://opensearch.org/docs/latest/ml-commons-plugin/agents-tools/tools/web-search-tool/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-ml-search-with-opensearch-intermediate (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
