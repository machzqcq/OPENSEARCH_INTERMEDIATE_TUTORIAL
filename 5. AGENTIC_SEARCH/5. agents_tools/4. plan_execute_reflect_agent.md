# Plan-Execute-Reflect Agent - Advanced Agent Workflow

## Overview

This document explains the **Plan-Execute-Reflect (PER) Agent Pattern**, an advanced workflow where an AI agent:

1. **PLAN**: Breaks down a complex problem into actionable steps
2. **EXECUTE**: Performs each step and collects results
3. **REFLECT**: Analyzes results, identifies gaps, and refines the approach

## Workflow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PLAN-EXECUTE-REFLECT AGENT LOOP                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  Question/Task                                                       â”‚
â”‚      â”‚                                                               â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚                                v                                    â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚                    â”‚   PLAN PHASE      â”‚  Agent thinks about       â”‚
â”‚                    â”‚                   â”‚  solution approach        â”‚
â”‚                    â”‚ - Identify steps  â”‚                           â”‚
â”‚                    â”‚ - Select tools    â”‚                           â”‚
â”‚                    â”‚ - Create plan     â”‚                           â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                            â”‚                                       â”‚
â”‚                            v                                       â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚                    â”‚ EXECUTE PHASE     â”‚  Agent executes plan      â”‚
â”‚                    â”‚                   â”‚  using available tools    â”‚
â”‚                    â”‚ - Tool 1: Search  â”‚                           â”‚
â”‚                    â”‚ - Tool 2: Analyze â”‚                           â”‚
â”‚                    â”‚ - Collect results â”‚                           â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                            â”‚                                       â”‚
â”‚                            v                                       â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚                    â”‚ REFLECT PHASE     â”‚  Agent evaluates results  â”‚
â”‚                    â”‚                   â”‚  and decides next steps   â”‚
â”‚                    â”‚ - Check completeness                          â”‚
â”‚                    â”‚ - Identify gaps   â”‚                           â”‚
â”‚                    â”‚ - Success or retryâ”‚                           â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                            â”‚                                       â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚         â”‚                  â”‚                  â”‚                   â”‚
â”‚     Success            Need More          Complete               â”‚
â”‚         â”‚              Information         Loop                  â”‚
â”‚         v              â”‚                   v                     â”‚
â”‚   Final Answer         â””â”€â”€â†’ (Back to PLAN)  Done                â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Mermaid Diagram

### Agent Workflow

```mermaid
flowchart TD
    A["ğŸš€ START: User Question/Task"] --> B["ğŸ’­ PLAN PHASE"]
    B --> B1["Analyze the problem"]
    B --> B2["Break into sub-tasks"]
    B --> B3["Decide which tools to use"]
    B1 --> C["âš™ï¸ EXECUTE PHASE"]
    B2 --> C
    B3 --> C
    
    C --> C1["ğŸ” Tool 1: Search Products"]
    C --> C2["ğŸ“Š Tool 2: Analyze Data"]
    C --> C3["ğŸ¯ Tool 3: Calculate Metrics"]
    
    C1 --> D["ğŸ¤” REFLECT PHASE"]
    C2 --> D
    C3 --> D
    
    D --> D1{Is Answer Complete?}
    
    D1 -->|âŒ No, Need More Info| E["Identify Gaps"]
    E --> B
    
    D1 -->|âœ… Yes, Success!| F["ğŸ“¤ FINAL ANSWER"]
    
    style A fill:#4A90E2,stroke:#2E5C8A,stroke-width:3px,color:#fff
    style B fill:#F39C12,stroke:#C87F0A,stroke-width:2px,color:#000
    style C fill:#E74C3C,stroke:#C0392B,stroke-width:2px,color:#fff
    style D fill:#27AE60,stroke:#1E8449,stroke-width:2px,color:#fff
    style F fill:#8E44AD,stroke:#663399,stroke-width:3px,color:#fff
    style D1 fill:#F39C12,stroke:#C87F0A,stroke-width:2px,color:#000
```

## Three Critical Phases

| Phase | Focus Question | Activities | LLM Calls |
|-------|---|---|---|
| **PLAN** | "What should I do?" | â€¢ Understand goal<br>â€¢ List sub-tasks<br>â€¢ Choose tools<br>â€¢ Set expectations | 1-2 |
| **EXECUTE** | "Let me do it" | â€¢ Run tools<br>â€¢ Collect output<br>â€¢ Handle errors<br>â€¢ Track progress | 1-N to tools |
| **REFLECT** | "Did it work?" | â€¢ Evaluate results<br>â€¢ Check completeness<br>â€¢ Identify gaps<br>â€¢ Plan next steps | 1-2 |

## Tool Selection in Planning

```
    User Question
         |
         v
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PLANNING AGENT         â”‚
    â”‚ "Which tools do I      â”‚
    â”‚  need for this task?"  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         |
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    |                                  |
    v                                  v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VectorDBTool â”‚              â”‚ SearchIndexTool  â”‚
â”‚              â”‚              â”‚                  â”‚
â”‚ â€¢ Semantic   â”‚              â”‚ â€¢ Keyword        â”‚
â”‚   search     â”‚              â”‚   search         â”‚
â”‚ â€¢ Similarity â”‚              â”‚ â€¢ Filters        â”‚
â”‚   matching   â”‚              â”‚ â€¢ Aggregations   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    |                                  |
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             |
             v
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ REFLECTION AGENT         â”‚
    â”‚ "Do the results answer   â”‚
    â”‚  the user's question?"   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Key Concepts

### 1. PLANNING PHASE

**Goal**: Agent analyzes the complex question and breaks it into actionable sub-tasks

**Activities**:
- Analyze the problem statement
- Break down into smaller, manageable tasks
- Select appropriate tools for each task
- Create an execution plan
- Set expectations for results

**Characteristics**:
- 1-2 LLM calls
- Deterministic planning logic
- Tool-aware reasoning

**Example**: 
- Question: "Find the best office setup for someone with a budget of $500"
- Plan: 
  1. Search for furniture under $500
  2. Search for ergonomic accessories under $500
  3. Combine results based on quality ratings
  4. Summarize recommendations

### 2. EXECUTION PHASE

**Goal**: Agent executes the plan using available tools

**Activities**:
- Call VectorDBTool for semantic searches
- Call MLModelTool for analysis
- Handle tool-specific logic
- Collect and organize results
- Catch and handle errors

**Characteristics**:
- Variable tool calls (1-N)
- Each tool returns structured data
- Sequential or parallel execution possible
- Error handling and retry logic

**Example Tools**:
- `VectorDBTool`: Find products via semantic search
- `MLModelTool`: Analyze/summarize findings
- `CalculatorTool`: Compute totals/percentages

### 3. REFLECTION PHASE

**Goal**: Agent evaluates if results answer the original question

**Activities**:
- Check if results are complete
- Identify information gaps
- Validate result quality
- Decide: Success â†’ Answer | Gap Found â†’ Back to PLAN

**Characteristics**:
- 1-2 LLM calls
- Comparison against original goal
- Quality assessment
- Potential loop-back to PLAN

**Example**:
- Reflection: "Did I find enough high-rated office furniture options?"
- Gap: "I found furniture but not enough accessories"
- Decision: "Go back to PLAN to search for more accessories"

## Advantages of PER Pattern

âœ“ **Better Accuracy**: Structured thinking reduces errors
âœ“ **Self-Correction**: Agent can identify and fix mistakes
âœ“ **Transparency**: Clear reasoning visible in each phase
âœ“ **Reduced Hallucinations**: Validation through reflection
âœ“ **Handles Complexity**: Breaks down multi-step problems effectively
âœ“ **Flexible**: Can adapt the plan based on execution results
âœ“ **Scalable**: Works with multiple tools and data sources

## When to Use Plan-Execute-Reflect

**Best For**:
- Complex, multi-faceted questions
- Analysis requiring multiple data sources
- Comparisons and recommendations
- Questions needing validation/verification
- Tasks requiring iterative refinement
- Ambiguous or poorly-specified goals

**Less Suitable For**:
- Simple lookup queries (use direct tools)
- Time-sensitive operations (PER adds latency)
- Single-step tasks (overkill complexity)

## Implementation Details

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OpenSearch Cluster                    â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Embedding Model                â”‚   â”‚
â”‚  â”‚  (HuggingFace)                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                  â”‚                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Ingest Pipeline            â”‚       â”‚
â”‚  â”‚  (Auto-embedding on index)  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                 â”‚                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Product Index              â”‚       â”‚
â”‚  â”‚  (with vector fields)       â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚ VectorDBTool
                  â”‚ (semantic search)
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OpenAI Agent Framework                â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Agent Flow                     â”‚   â”‚
â”‚  â”‚  - Tool Registry                â”‚   â”‚
â”‚  â”‚  - Execution Engine             â”‚   â”‚
â”‚  â”‚  - Response Parser              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Plan     â”‚        â”‚ MLModelTool  â”‚  â”‚
â”‚  â”‚ Phase    â”‚â—„â”€â”€â”€â”€â”€â”€â–ºâ”‚ (Reasoning)  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â–²                                 â”‚
â”‚       â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                          â”‚
â”‚  â”‚ Reflect  â”‚                          â”‚
â”‚  â”‚ Phase    â”‚                          â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚       â”‚                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
   Final Answer
```

### Data Flow

1. **User Question** â†’ Agent receives query
2. **Plan Phase** â†’ LLM creates execution plan
3. **Tool Selection** â†’ Identify which tools to use
4. **Execution Phase** â†’ Run tools in sequence
   - VectorDBTool searches for products
   - MLModelTool analyzes results
5. **Result Collection** â†’ Organize tool outputs
6. **Reflection Phase** â†’ LLM evaluates completeness
7. **Decision Point**:
   - If complete â†’ Return Final Answer
   - If gaps â†’ Loop back to PLAN with updated context

## Configuration

### Models

- **Embedding Model**: HuggingFace `sentence-transformers/all-MiniLM-L6-v2`
  - Vector dimension: 384
  - Format: TORCH_SCRIPT
  - Auto-deployed in ingest pipeline

- **LLM Model**: OpenAI `gpt-4o-mini`
  - Via remote connector
  - Endpoint: `/v1/chat/completions`
  - Temperature: 0.7 (balanced creativity)

### Tools

- **VectorDBTool**: 
  - Performs semantic search in product index
  - Returns top 10 matching products
  - Includes similarity scores

- **MLModelTool**:
  - Calls OpenAI LLM for reasoning
  - Supports analysis, summarization, recommendations
  - Uses chat completion format

## Sample Queries

### Query 1: Product Discovery & Comparison
```
"What are the best wireless accessories available, and what should I consider when choosing them?"
```

**Expected Agent Flow**:
1. **Plan**: Search for wireless accessories, compare quality vs price
2. **Execute**: Search index, gather top products, analyze features
3. **Reflect**: "Found 5 products, summarize key differences"
4. **Result**: Ranked list with comparison

### Query 2: Inventory Analysis
```
"Find all high-rated furniture that's in stock and recommend a complete office setup under $700"
```

**Expected Agent Flow**:
1. **Plan**: Find furniture, filter by rating/stock, calculate totals
2. **Execute**: Multi-part search, combination analysis
3. **Reflect**: "Do recommended items fit budget and solve use case?"
4. **Result**: Itemized setup recommendation

### Query 3: Multi-tier Analysis
```
"What budget-friendly office solutions would work best for a startup with 5 employees, and why?"
```

**Expected Agent Flow**:
1. **Plan**: Find affordable options, calculate per-employee cost, assess variety
2. **Execute**: Price-filtered search, diversity analysis
3. **Reflect**: "Is this scalable and practical for 5 employees?"
4. **Result**: Recommended bundle with reasoning

## Performance Characteristics

| Aspect | Value |
|--------|-------|
| Average Plan Phase | 2-5 seconds |
| Average Execute Phase | 3-8 seconds |
| Average Reflect Phase | 2-5 seconds |
| Total Per Query | 7-18 seconds |
| Typical Loop Count | 1-2 iterations |
| Max Loops | 5 (configurable) |

## Error Handling

The agent handles:
- Connection timeouts â†’ Retry with backoff
- Empty results â†’ Refine search criteria
- Model errors â†’ Fallback to simpler query
- Malformed responses â†’ Parse multiple formats
- Incomplete data â†’ Request clarification

## Learning Outcomes

After studying this implementation, you'll understand:

1. **Multi-Phase Reasoning**: How to structure AI reasoning into distinct phases
2. **Tool Orchestration**: Coordinating multiple tools for complex tasks
3. **Self-Correction**: Building agents that can identify and fix their own mistakes
4. **Transparency**: Creating visible, auditable decision-making processes
5. **Vector Search**: Semantic search beyond keyword matching
6. **OpenSearch Integration**: Production deployment of ML models
7. **OpenAI API**: Using chat completions for agent reasoning

## References

- **Source File**: `4. plan_execute_reflect_agent.py`
- **Reference Pattern**: `3. openai_agent_tools.py`
- **Alternative Pattern**: `1. ollama_agent_tools.py`
- **Related Examples**: `/5. agents_tools/` directory

## Quick Start

```bash
# 1. Ensure OpenSearch is running
docker-compose up -d

# 2. Set environment variables
export OPENAI_API_KEY="your-api-key"

# 3. Run the agent
cd "5. agents_tools/"
python "4. plan_execute_reflect_agent.py"
```

## Summary

The **Plan-Execute-Reflect pattern** is a powerful approach for building intelligent agents that can tackle complex problems through structured reasoning. By breaking the task into three distinct phases, agents can:

- **Think before acting** (Plan phase)
- **Execute with tools** (Execute phase)  
- **Validate and iterate** (Reflect phase)

This leads to more accurate, transparent, and reliable AI systems that users can understand and trust.
