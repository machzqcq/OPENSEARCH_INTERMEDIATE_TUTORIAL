{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dddce45f",
   "metadata": {},
   "source": [
    "# üîç NeuralSparseSearchTool - Sparse Vector Search\n",
    "\n",
    "```mermaid\n",
    "%%{init: {'theme':'base', 'themeVariables': { 'primaryColor':'#8E44AD', 'primaryTextColor':'#fff', 'primaryBorderColor':'#7D3C98', 'lineColor':'#F39C12', 'secondaryColor':'#3498DB', 'tertiaryColor':'#27AE60', 'fontSize':'16px'}}}%%\n",
    "graph TB\n",
    "    A[üë§ Query Text] --> B[ü§ñ Flow Agent]\n",
    "    B --> C{üîç NeuralSparseSearchTool}\n",
    "    C --> D[üß† Sparse Encoding Model]\n",
    "    D --> E[‚ö° Sparse Vector<br/>term: score pairs]\n",
    "    E --> F[üìä Index Search]\n",
    "    F --> G[üéØ Matched Documents]\n",
    "    G --> H[üìã Ranked Results]\n",
    "    \n",
    "    style A fill:#3498DB,stroke:#2980B9,color:#fff\n",
    "    style C fill:#8E44AD,stroke:#7D3C98,color:#fff\n",
    "    style D fill:#E74C3C,stroke:#C0392B,color:#fff\n",
    "    style E fill:#F39C12,stroke:#D68910,color:#fff\n",
    "    style H fill:#27AE60,stroke:#229954,color:#fff\n",
    "```\n",
    "\n",
    "## üìö Learning Objectives\n",
    "\n",
    "1. ‚úÖ Understand **sparse vectors** vs **dense vectors**\n",
    "2. ‚úÖ Use **neural sparse encoding** models\n",
    "3. ‚úÖ Create **rank_features** indices\n",
    "4. ‚úÖ Perform **efficient semantic search** with sparse representations\n",
    "5. ‚úÖ Compare **sparse search** advantages\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ What is NeuralSparseSearchTool?\n",
    "\n",
    "**NeuralSparseSearchTool** performs semantic search using **sparse vectors**:\n",
    "- ‚ö° **Sparse Encoding**: Only non-zero term scores (e.g., {\"cat\": 0.8, \"pet\": 0.6})\n",
    "- üéØ **Interpretable**: Can see which terms matter\n",
    "- üöÄ **Efficient**: Smaller storage than dense vectors\n",
    "- üìä **rank_features**: Special OpenSearch field type\n",
    "\n",
    "**Sparse vs Dense Vectors**:\n",
    "- Dense: [0.12, -0.45, 0.89, ...] (384-1536 dimensions, all filled)\n",
    "- Sparse: {\"term1\": 0.8, \"term2\": 0.3} (only non-zero values)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47713687",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89faf071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "\n",
    "sys.path.append('..')\n",
    "from agent_helpers import (\n",
    "    get_os_client,\n",
    "    create_flow_agent,\n",
    "    execute_agent,\n",
    "    cleanup_resources\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154efe1e",
   "metadata": {},
   "source": [
    "## Step 2: Initialize Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b29acb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Client ready\n"
     ]
    }
   ],
   "source": [
    "client = get_os_client()\n",
    "print(\"‚úÖ Client ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d144b1e8",
   "metadata": {},
   "source": [
    "## Step 3: Register Sparse Encoding Model\n",
    "\n",
    "We'll use a **sparse encoding model** from HuggingFace (e.g., opensearch-project/opensearch-neural-sparse-encoding-v1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22d0de49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registration response: {\n",
      "  \"task_id\": \"AFtriZsBLQ1mV2UNmSnY\",\n",
      "  \"status\": \"CREATED\"\n",
      "}\n",
      "üìã Registration task: AFtriZsBLQ1mV2UNmSnY\n",
      "‚è≥ Attempt 1: Task state = CREATED\n",
      "‚è≥ Attempt 2: Task state = CREATED\n",
      "‚è≥ Attempt 3: Task state = CREATED\n",
      "‚è≥ Attempt 4: Task state = CREATED\n",
      "‚è≥ Attempt 5: Task state = CREATED\n",
      "‚è≥ Attempt 6: Task state = CREATED\n",
      "‚è≥ Attempt 7: Task state = CREATED\n",
      "‚è≥ Attempt 8: Task state = CREATED\n",
      "‚è≥ Attempt 9: Task state = CREATED\n",
      "‚è≥ Attempt 10: Task state = CREATED\n",
      "‚è≥ Attempt 11: Task state = CREATED\n",
      "‚è≥ Attempt 12: Task state = CREATED\n",
      "‚è≥ Attempt 13: Task state = CREATED\n",
      "‚è≥ Attempt 14: Task state = CREATED\n",
      "‚è≥ Attempt 15: Task state = CREATED\n",
      "‚è≥ Attempt 16: Task state = CREATED\n",
      "‚è≥ Attempt 17: Task state = CREATED\n",
      "‚è≥ Attempt 18: Task state = CREATED\n",
      "‚è≥ Attempt 19: Task state = CREATED\n",
      "‚è≥ Attempt 20: Task state = CREATED\n",
      "‚è≥ Attempt 21: Task state = CREATED\n",
      "‚è≥ Attempt 22: Task state = CREATED\n",
      "‚è≥ Attempt 23: Task state = CREATED\n",
      "‚è≥ Attempt 24: Task state = CREATED\n",
      "‚è≥ Attempt 25: Task state = CREATED\n",
      "‚è≥ Attempt 26: Task state = CREATED\n",
      "‚è≥ Attempt 27: Task state = CREATED\n",
      "‚è≥ Attempt 28: Task state = CREATED\n",
      "‚è≥ Attempt 29: Task state = CREATED\n",
      "‚è≥ Attempt 30: Task state = CREATED\n",
      "‚è≥ Attempt 31: Task state = CREATED\n",
      "‚è≥ Attempt 32: Task state = CREATED\n",
      "‚è≥ Attempt 33: Task state = CREATED\n",
      "‚è≥ Attempt 34: Task state = CREATED\n",
      "‚è≥ Attempt 35: Task state = CREATED\n",
      "‚è≥ Attempt 36: Task state = CREATED\n",
      "‚è≥ Attempt 37: Task state = CREATED\n",
      "‚è≥ Attempt 38: Task state = COMPLETED\n",
      "üì¶ Registered sparse model: AVtriZsBLQ1mV2UNnSlm\n",
      "üöÄ Deploy initiated: {\n",
      "  \"task_id\": \"AltsiZsBLQ1mV2UNuymD\",\n",
      "  \"task_type\": \"DEPLOY_MODEL\",\n",
      "  \"status\": \"CREATED\"\n",
      "}\n",
      "‚è≥ Deployment attempt 1: DEPLOYING\n",
      "‚è≥ Deployment attempt 2: DEPLOYING\n",
      "‚è≥ Deployment attempt 3: DEPLOYED\n",
      "‚úÖ Sparse model deployed!\n"
     ]
    }
   ],
   "source": [
    "# Register sparse encoding model\n",
    "model_name = \"amazon/neural-sparse/opensearch-neural-sparse-encoding-v1\"\n",
    "model_version = \"1.0.1\"\n",
    "\n",
    "register_response = client.transport.perform_request(\n",
    "    'POST',\n",
    "    '/_plugins/_ml/models/_register',\n",
    "    body={\n",
    "        \"name\": model_name,\n",
    "        \"version\": model_version,\n",
    "        \"model_format\": \"TORCH_SCRIPT\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Registration response:\", json.dumps(register_response, indent=2))\n",
    "\n",
    "# Extract model_id from response (might be 'task_id' or 'model_id')\n",
    "sparse_model_id = None\n",
    "if 'task_id' in register_response:\n",
    "    task_id = register_response['task_id']\n",
    "    print(f\"üìã Registration task: {task_id}\")\n",
    "    \n",
    "    # Wait for registration to complete\n",
    "    import time\n",
    "    for i in range(60):  # Increased to 60 attempts (2 minutes)\n",
    "        task_status = client.transport.perform_request(\n",
    "            'GET', f'/_plugins/_ml/tasks/{task_id}'\n",
    "        )\n",
    "        print(f\"‚è≥ Attempt {i+1}: Task state = {task_status.get('state', 'UNKNOWN')}\")\n",
    "        \n",
    "        if task_status['state'] == 'COMPLETED':\n",
    "            sparse_model_id = task_status['model_id']\n",
    "            print(f\"üì¶ Registered sparse model: {sparse_model_id}\")\n",
    "            break\n",
    "        elif task_status['state'] == 'FAILED':\n",
    "            print(f\"‚ùå Registration failed: {task_status.get('error', 'Unknown error')}\")\n",
    "            raise Exception(\"Model registration failed\")\n",
    "        time.sleep(2)\n",
    "    \n",
    "    if sparse_model_id is None:\n",
    "        raise Exception(\"Model registration timed out\")\n",
    "else:\n",
    "    sparse_model_id = register_response['model_id']\n",
    "    print(f\"üì¶ Registered sparse model: {sparse_model_id}\")\n",
    "\n",
    "# Deploy model\n",
    "deploy_response = client.transport.perform_request(\n",
    "    'POST',\n",
    "    f'/_plugins/_ml/models/{sparse_model_id}/_deploy'\n",
    ")\n",
    "print(f\"üöÄ Deploy initiated: {json.dumps(deploy_response, indent=2)}\")\n",
    "\n",
    "# Wait for deployment\n",
    "for i in range(60):  # Increased timeout\n",
    "    status = client.transport.perform_request(\n",
    "        'GET', f'/_plugins/_ml/models/{sparse_model_id}'\n",
    "    )\n",
    "    current_state = status.get('model_state', 'UNKNOWN')\n",
    "    print(f\"‚è≥ Deployment attempt {i+1}: {current_state}\")\n",
    "    \n",
    "    if current_state == 'DEPLOYED':\n",
    "        print(\"‚úÖ Sparse model deployed!\")\n",
    "        break\n",
    "    elif current_state == 'DEPLOY_FAILED':\n",
    "        print(f\"‚ùå Deployment failed: {status}\")\n",
    "        raise Exception(\"Model deployment failed\")\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da090796",
   "metadata": {},
   "source": [
    "## Step 4: Create Ingest Pipeline with Sparse Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d54cec32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pipeline created: sparse_encoding_pipeline\n"
     ]
    }
   ],
   "source": [
    "pipeline_id = \"sparse_encoding_pipeline\"\n",
    "\n",
    "client.ingest.put_pipeline(\n",
    "    id=pipeline_id,\n",
    "    body={\n",
    "        \"description\": \"Sparse encoding pipeline\",\n",
    "        \"processors\": [\n",
    "            {\n",
    "                \"sparse_encoding\": {\n",
    "                    \"model_id\": sparse_model_id,\n",
    "                    \"field_map\": {\n",
    "                        \"text\": \"sparse_embedding\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Pipeline created: {pipeline_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a1b8f4",
   "metadata": {},
   "source": [
    "## Step 5: Create Index with rank_features Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5e07840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created index with rank_features: articles_sparse\n"
     ]
    }
   ],
   "source": [
    "index_name = \"articles_sparse\"\n",
    "\n",
    "if client.indices.exists(index=index_name):\n",
    "    client.indices.delete(index=index_name)\n",
    "\n",
    "client.indices.create(\n",
    "    index=index_name,\n",
    "    body={\n",
    "        \"settings\": {\n",
    "            \"index.default_pipeline\": pipeline_id\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"text\": {\"type\": \"text\"},\n",
    "                \"category\": {\"type\": \"keyword\"},\n",
    "                \"sparse_embedding\": {\"type\": \"rank_features\"}  # Sparse vector field\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Created index with rank_features: {index_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c7797d",
   "metadata": {},
   "source": [
    "## Step 6: Ingest Sample Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33abb7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ingested 5 documents with sparse embeddings\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    {\"text\": \"Machine learning algorithms can predict customer behavior\", \"category\": \"AI\"},\n",
    "    {\"text\": \"Deep neural networks excel at image recognition tasks\", \"category\": \"AI\"},\n",
    "    {\"text\": \"Cloud computing provides scalable infrastructure for businesses\", \"category\": \"Cloud\"},\n",
    "    {\"text\": \"Kubernetes orchestrates containerized applications efficiently\", \"category\": \"DevOps\"},\n",
    "    {\"text\": \"Natural language processing enables chatbots to understand users\", \"category\": \"AI\"},\n",
    "]\n",
    "\n",
    "for doc in documents:\n",
    "    client.index(index=index_name, body=doc, refresh=True)\n",
    "\n",
    "print(f\"‚úÖ Ingested {len(documents)} documents with sparse embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4912a13",
   "metadata": {},
   "source": [
    "## Step 7: Create Agent with NeuralSparseSearchTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "483f85ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Registering flow agent: Sparse_Search_Agent...\n",
      "   ‚úì Agent registered: DVttiZsBLQ1mV2UNbSlA\n",
      "‚úÖ Agent created: DVttiZsBLQ1mV2UNbSlA\n"
     ]
    }
   ],
   "source": [
    "tools = [{\n",
    "    \"type\": \"NeuralSparseSearchTool\",\n",
    "    \"parameters\": {\n",
    "        \"model_id\": sparse_model_id,\n",
    "        \"index\": index_name,\n",
    "        \"embedding_field\": \"sparse_embedding\",\n",
    "        \"source_field\": [\"text\", \"category\"],\n",
    "        \"doc_size\": 3,\n",
    "        \"input\": \"${parameters.question}\"\n",
    "    }\n",
    "}]\n",
    "\n",
    "agent_id = create_flow_agent(\n",
    "    client, \"Sparse_Search_Agent\",\n",
    "    \"Performs semantic search using sparse vectors\",\n",
    "    tools\n",
    ")\n",
    "print(f\"‚úÖ Agent created: {agent_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86e304c",
   "metadata": {},
   "source": [
    "## Step 8: Test Case 1 - AI Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "418c4118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Query: artificial intelligence and predictions\n",
      "============================================================\n",
      "\n",
      "üìä Top Results:\n",
      "{\n",
      "  \"inference_results\": [\n",
      "    {\n",
      "      \"output\": [\n",
      "        {\n",
      "          \"name\": \"response\",\n",
      "          \"result\": \"{\\\"_index\\\":\\\"articles_sparse\\\",\\\"_source\\\":{\\\"text\\\":\\\"Machine learning algorithms can predict customer behavior\\\",\\\"category\\\":\\\"AI\\\"},\\\"_id\\\":\\\"CFttiZsBLQ1mV2UNOCnp\\\",\\\"_score\\\":12.799283}\\n{\\\"_index\\\":\\\"articles_sparse\\\",\\\"_source\\\":{\\\"text\\\":\\\"Natural language processing enables chatbots to understand users\\\",\\\"category\\\":\\\"AI\\\"},\\\"_id\\\":\\\"DFttiZsBLQ1mV2UNOSnH\\\",\\\"_score\\\":5.7580047}\\n{\\\"_index\\\":\\\"articles_sparse\\\",\\\"_source\\\":{\\\"text\\\":\\\"Deep neural networks excel at image recognition tasks\\\",\\\"category\\\":\\\"AI\\\"},\\\"_id\\\":\\\"CVttiZsBLQ1mV2UNOSkk\\\",\\\"_score\\\":5.6482444}\\n\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"question\": \"artificial intelligence and predictions\"}\n",
    "\n",
    "print(\"üîç Query: artificial intelligence and predictions\")\n",
    "print(\"=\"*60)\n",
    "response = execute_agent(client, agent_id, parameters)\n",
    "print(\"\\nüìä Top Results:\")\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bd22fc",
   "metadata": {},
   "source": [
    "## Step 9: Test Case 2 - Container Technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f554d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Query: container orchestration systems\n",
      "============================================================\n",
      "\n",
      "üìä Results:\n",
      "{\n",
      "  \"inference_results\": [\n",
      "    {\n",
      "      \"output\": [\n",
      "        {\n",
      "          \"name\": \"response\",\n",
      "          \"result\": \"{\\\"_index\\\":\\\"articles_sparse\\\",\\\"_source\\\":{\\\"text\\\":\\\"Kubernetes orchestrates containerized applications efficiently\\\",\\\"category\\\":\\\"DevOps\\\"},\\\"_id\\\":\\\"C1ttiZsBLQ1mV2UNOSmS\\\",\\\"_score\\\":17.86498}\\n{\\\"_index\\\":\\\"articles_sparse\\\",\\\"_source\\\":{\\\"text\\\":\\\"Cloud computing provides scalable infrastructure for businesses\\\",\\\"category\\\":\\\"Cloud\\\"},\\\"_id\\\":\\\"ClttiZsBLQ1mV2UNOSla\\\",\\\"_score\\\":3.895081}\\n{\\\"_index\\\":\\\"articles_sparse\\\",\\\"_source\\\":{\\\"text\\\":\\\"Natural language processing enables chatbots to understand users\\\",\\\"category\\\":\\\"AI\\\"},\\\"_id\\\":\\\"DFttiZsBLQ1mV2UNOSnH\\\",\\\"_score\\\":3.2714818}\\n\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"question\": \"container orchestration systems\"}\n",
    "\n",
    "print(\"üîç Query: container orchestration systems\")\n",
    "print(\"=\"*60)\n",
    "response = execute_agent(client, agent_id, parameters)\n",
    "print(\"\\nüìä Results:\")\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9186809",
   "metadata": {},
   "source": [
    "## Step 10: Test Case 3 - Conversational AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ece05ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Query: chatbots and language understanding\n",
      "============================================================\n",
      "\n",
      "üìä Results:\n",
      "{\n",
      "  \"inference_results\": [\n",
      "    {\n",
      "      \"output\": [\n",
      "        {\n",
      "          \"name\": \"response\",\n",
      "          \"result\": \"{\\\"_index\\\":\\\"articles_sparse\\\",\\\"_source\\\":{\\\"text\\\":\\\"Natural language processing enables chatbots to understand users\\\",\\\"category\\\":\\\"AI\\\"},\\\"_id\\\":\\\"DFttiZsBLQ1mV2UNOSnH\\\",\\\"_score\\\":27.292557}\\n{\\\"_index\\\":\\\"articles_sparse\\\",\\\"_source\\\":{\\\"text\\\":\\\"Machine learning algorithms can predict customer behavior\\\",\\\"category\\\":\\\"AI\\\"},\\\"_id\\\":\\\"CFttiZsBLQ1mV2UNOCnp\\\",\\\"_score\\\":4.908008}\\n{\\\"_index\\\":\\\"articles_sparse\\\",\\\"_source\\\":{\\\"text\\\":\\\"Deep neural networks excel at image recognition tasks\\\",\\\"category\\\":\\\"AI\\\"},\\\"_id\\\":\\\"CVttiZsBLQ1mV2UNOSkk\\\",\\\"_score\\\":3.5265918}\\n\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"question\": \"chatbots and language understanding\"}\n",
    "\n",
    "print(\"üîç Query: chatbots and language understanding\")\n",
    "print(\"=\"*60)\n",
    "response = execute_agent(client, agent_id, parameters)\n",
    "print(\"\\nüìä Results:\")\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e8ae8b",
   "metadata": {},
   "source": [
    "## üéì Key Takeaways\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **Sparse vs Dense Vectors**:\n",
    "   ```python\n",
    "   # Dense vector (384 dimensions)\n",
    "   [0.12, -0.45, 0.89, 0.23, ...] # All 384 values stored\n",
    "   \n",
    "   # Sparse vector (rank_features)\n",
    "   {\"ai\": 0.8, \"machine\": 0.6, \"learning\": 0.5} # Only non-zero terms\n",
    "   ```\n",
    "\n",
    "2. **Advantages of Sparse Search**:\n",
    "   | Aspect | Dense Vectors | Sparse Vectors |\n",
    "   |--------|--------------|----------------|\n",
    "   | Storage | 384-1536 floats | ~10-50 terms |\n",
    "   | Interpretability | ‚ùå Black box | ‚úÖ See terms |\n",
    "   | Performance | Good | Very Good |\n",
    "   | Index Size | Larger | Smaller |\n",
    "\n",
    "3. **Configuration**:\n",
    "   ```python\n",
    "   {\n",
    "       \"type\": \"NeuralSparseSearchTool\",\n",
    "       \"parameters\": {\n",
    "           \"model_id\": sparse_model_id,\n",
    "           \"index\": index_name,\n",
    "           \"embedding_field\": \"sparse_embedding\",  # rank_features type\n",
    "           \"source_field\": [\"text\", \"category\"],\n",
    "           \"doc_size\": 3,\n",
    "           \"input\": \"${parameters.question}\"\n",
    "       }\n",
    "   }\n",
    "   ```\n",
    "\n",
    "4. **Sparse Encoding Pipeline**:\n",
    "   ```python\n",
    "   {\n",
    "       \"processors\": [\n",
    "           {\n",
    "               \"sparse_encoding\": {\n",
    "                   \"model_id\": sparse_model_id,\n",
    "                   \"field_map\": {\n",
    "                       \"text\": \"sparse_embedding\"\n",
    "                   }\n",
    "               }\n",
    "           }\n",
    "       ]\n",
    "   }\n",
    "   ```\n",
    "\n",
    "5. **rank_features Field**:\n",
    "   ```python\n",
    "   \"mappings\": {\n",
    "       \"properties\": {\n",
    "           \"sparse_embedding\": {\"type\": \"rank_features\"}\n",
    "       }\n",
    "   }\n",
    "   ```\n",
    "\n",
    "### Use Cases:\n",
    "\n",
    "- üîç **Semantic Search**: Understanding query intent\n",
    "- üìä **Document Retrieval**: Finding relevant content\n",
    "- üéØ **Question Answering**: Matching questions to answers\n",
    "- üöÄ **Efficient Search**: When storage/speed matter\n",
    "\n",
    "### When to Use Sparse vs Dense:\n",
    "\n",
    "**Use Sparse When**:\n",
    "- ‚úÖ Need interpretability (see which terms matched)\n",
    "- ‚úÖ Storage is limited\n",
    "- ‚úÖ Speed is critical\n",
    "- ‚úÖ Text-based search\n",
    "\n",
    "**Use Dense When**:\n",
    "- ‚úÖ Cross-lingual search\n",
    "- ‚úÖ Image/audio embeddings\n",
    "- ‚úÖ Complex semantic relationships\n",
    "- ‚úÖ Maximum accuracy needed\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fc0a1f",
   "metadata": {},
   "source": [
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d5e1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cleanup_resources(\n",
    "# #     client=client,\n",
    "# #     agent_ids=[agent_id],\n",
    "# #     model_ids=[sparse_model_id]\n",
    "# # )\n",
    "# # client.indices.delete(index=index_name)\n",
    "# # client.ingest.delete_pipeline(id=pipeline_id)\n",
    "# # print(\"‚úÖ Cleanup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7067f14",
   "metadata": {},
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "- **VectorDBTool**: Compare with dense vector search\n",
    "- **RAGTool**: Combine sparse search with LLM generation\n",
    "- **Hybrid Search**: Mix sparse + dense + keyword search\n",
    "\n",
    "üìö [Neural Sparse Search Docs](https://opensearch.org/docs/latest/ml-commons-plugin/agents-tools/tools/neural-sparse-search-tool/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-ml-search-with-opensearch-intermediate (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
