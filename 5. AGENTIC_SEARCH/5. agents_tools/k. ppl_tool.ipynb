{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "313ef208",
   "metadata": {},
   "source": [
    "# üìä PPLTool - Piped Processing Language Query Generation\n",
    "\n",
    "```mermaid\n",
    "%%{init: {'theme':'base', 'themeVariables': { 'primaryColor':'#16A085', 'primaryTextColor':'#fff', 'primaryBorderColor':'#138D75', 'lineColor':'#F39C12', 'secondaryColor':'#3498DB', 'tertiaryColor':'#27AE60', 'fontSize':'16px'}}}%%\n",
    "graph TB\n",
    "    A[üë§ Natural Language<br/>Show error logs] --> B[ü§ñ Flow Agent]\n",
    "    B --> C{üìä PPLTool}\n",
    "    C --> D[üéØ LLM Model]\n",
    "    D --> E[üìù Generate PPL Query]\n",
    "    E --> F[‚úÖ Valid PPL]\n",
    "    F --> G[üîç Execute Query]\n",
    "    G --> H[üìä Results]\n",
    "    \n",
    "    style A fill:#3498DB,stroke:#2980B9,color:#fff\n",
    "    style C fill:#16A085,stroke:#138D75,color:#fff\n",
    "    style D fill:#9B59B6,stroke:#8E44AD,color:#fff\n",
    "    style E fill:#E67E22,stroke:#D35400,color:#fff\n",
    "    style H fill:#27AE60,stroke:#229954,color:#fff\n",
    "```\n",
    "\n",
    "## üìö Learning Objectives\n",
    "\n",
    "1. ‚úÖ Convert natural language to **PPL (Piped Processing Language)** queries\n",
    "2. ‚úÖ Use **PPL syntax** for log and event analysis\n",
    "3. ‚úÖ Build **analytics pipelines** with pipes\n",
    "4. ‚úÖ **Execute PPL queries** automatically\n",
    "5. ‚úÖ Simplify **complex log analysis** workflows\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ What is PPLTool?\n",
    "\n",
    "**PPLTool** generates **Piped Processing Language (PPL)** queries from natural language. PPL is ideal for:\n",
    "- üìä **Log Analysis**: Filter, aggregate, transform log data\n",
    "- üîÑ **Data Pipelines**: Chain operations with pipes\n",
    "- üìà **Analytics**: Time-series analysis, statistics\n",
    "- üéØ **Simplicity**: More intuitive than DSL for many use cases\n",
    "\n",
    "**PPL Example**:\n",
    "```sql\n",
    "source=logs | where level='ERROR' | stats count() by service\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7536a45a",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "To create a PPL tool, you need a **fine-tuned model** that translates natural language into PPL queries, or alternatively, you can use **large language models** for prompt-based translation. The PPLTool supports:\n",
    "\n",
    "- ‚úÖ **Anthropic Claude** models (model_type: `CLAUDE`)\n",
    "- ‚úÖ **OpenAI** models - GPT-3.5, GPT-4 (model_type: `OPENAI`)\n",
    "- ‚úÖ **Fine-tuned** custom models (model_type: `FINETUNE`)\n",
    "\n",
    "In this notebook, we'll use **OpenAI** models for natural language to PPL translation.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8812e76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "sys.path.append('..')\n",
    "from agent_helpers import (\n",
    "    get_os_client,\n",
    "    configure_cluster_for_openai,\n",
    "    create_openai_connector,\n",
    "    register_and_deploy_openai_model,\n",
    "    create_flow_agent,\n",
    "    execute_agent,\n",
    "    cleanup_resources,\n",
    "    OPENAI_API_KEY  # Import the API key constant\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffae51a7",
   "metadata": {},
   "source": [
    "## Step 2: Create a connector and deploy the model\n",
    "\n",
    "This step corresponds to the documentation's Step 1 and Step 2, where we:\n",
    "1. Create a connector for OpenAI\n",
    "2. Register and deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0799cce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Configuring cluster settings for OpenAI connector...\n",
      "   ‚úì Cluster settings configured successfully\n",
      "   Creating OpenAI connector for gpt-4o-mini...\n",
      "   ‚úì Connector created: aFt_iZsBLQ1mV2UNgymq\n",
      "‚úÖ Connector created: aFt_iZsBLQ1mV2UNgymq\n",
      "   Creating model group...\n",
      "   ‚úì Model group created: aVt_iZsBLQ1mV2UNgym0\n",
      "   Registering gpt-4o-mini model...\n",
      "   ‚úì Model registered: a1t_iZsBLQ1mV2UNgynL\n",
      "   Deploying model...\n",
      "   ‚è≥ Waiting for model deployment...\n",
      "      Model status: DEPLOYING\n",
      "      Model status: DEPLOYED\n",
      "      ‚úì Model deployed successfully!\n",
      "‚úÖ Model deployed: a1t_iZsBLQ1mV2UNgynL\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create OpenAI connector for PPL Tool\n",
    "# Using standard chat completions with gpt-4o-mini for model_type=\"OPENAI\"\n",
    "\n",
    "import time\n",
    "\n",
    "client = get_os_client()\n",
    "configure_cluster_for_openai(client)\n",
    "\n",
    "# Use the standard create_openai_connector helper which sets up chat completions correctly\n",
    "connector_id = create_openai_connector(client, model_name=\"gpt-4o-mini\")\n",
    "print(f\"‚úÖ Connector created: {connector_id}\")\n",
    "\n",
    "# Register and deploy using the helper\n",
    "model_id = register_and_deploy_openai_model(client, connector_id, model_name=\"gpt-4o-mini\")\n",
    "print(f\"‚úÖ Model deployed: {model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43c2c71",
   "metadata": {},
   "source": [
    "## Step 3: Create Sample Logs Index\n",
    "\n",
    "Before running the agent, we need an index with log data to query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e4c68c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created 6 log entries\n"
     ]
    }
   ],
   "source": [
    "index_name = \"application_logs\"\n",
    "\n",
    "if client.indices.exists(index=index_name):\n",
    "    client.indices.delete(index=index_name)\n",
    "\n",
    "client.indices.create(index=index_name)\n",
    "\n",
    "# Sample log data\n",
    "logs = [\n",
    "    {\"timestamp\": \"2025-11-09T10:00:00Z\", \"level\": \"INFO\", \"service\": \"api\", \"message\": \"Request processed\"},\n",
    "    {\"timestamp\": \"2025-11-09T10:01:00Z\", \"level\": \"ERROR\", \"service\": \"api\", \"message\": \"Connection timeout\"},\n",
    "    {\"timestamp\": \"2025-11-09T10:02:00Z\", \"level\": \"ERROR\", \"service\": \"database\", \"message\": \"Query failed\"},\n",
    "    {\"timestamp\": \"2025-11-09T10:03:00Z\", \"level\": \"WARN\", \"service\": \"api\", \"message\": \"Slow response\"},\n",
    "    {\"timestamp\": \"2025-11-09T10:04:00Z\", \"level\": \"INFO\", \"service\": \"worker\", \"message\": \"Job completed\"},\n",
    "    {\"timestamp\": \"2025-11-09T10:05:00Z\", \"level\": \"ERROR\", \"service\": \"api\", \"message\": \"Authentication failed\"},\n",
    "]\n",
    "\n",
    "for log in logs:\n",
    "    client.index(index=index_name, body=log, refresh=True)\n",
    "\n",
    "print(f\"‚úÖ Created {len(logs)} log entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f582a2d5",
   "metadata": {},
   "source": [
    "## Step 4: Register a flow agent that will run the PPLTool\n",
    "\n",
    "A flow agent runs a sequence of tools in order and returns the last tool's output. To create a flow agent, we provide the model ID in the `model_id` parameter. To run the generated query, we set `execute` to `true`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecd3404f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Registering flow agent: Test_Agent_For_PPL...\n",
      "   ‚úì Agent registered: eVt_iZsBLQ1mV2UN0inH\n",
      "‚úÖ Agent registered: eVt_iZsBLQ1mV2UN0inH\n"
     ]
    }
   ],
   "source": [
    "# Register PPL agent using model_type=\"OPENAI\"\n",
    "# This tells the PPL tool to use built-in OpenAI formatting\n",
    "\n",
    "tools = [{\n",
    "    \"type\": \"PPLTool\",\n",
    "    \"name\": \"TransferQuestionToPPLAndExecuteTool\",\n",
    "    \"description\": \"Use this tool to transfer natural language to generate PPL and execute PPL to query inside.\",\n",
    "    \"parameters\": {\n",
    "        \"model_id\": model_id,\n",
    "        \"model_type\": \"OPENAI\",  # Use built-in OPENAI support\n",
    "        \"execute\": True  # Execute the generated PPL query\n",
    "    }\n",
    "}]\n",
    "\n",
    "agent_id = create_flow_agent(\n",
    "    client, \n",
    "    \"Test_Agent_For_PPL\",\n",
    "    \"this is a test agent\",\n",
    "    tools\n",
    ")\n",
    "print(f\"‚úÖ Agent registered: {agent_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15e8ebf",
   "metadata": {},
   "source": [
    "## **Step 5: Execute the Agent**\n",
    "\n",
    "Test the PPL tool by sending natural language questions.\n",
    "\n",
    "### ‚ö†Ô∏è Known Limitations\n",
    "\n",
    "The PPL tool has compatibility challenges with OpenAI models in the current OpenSearch version:\n",
    "\n",
    "1. **model_type=\"OPENAI\"**: Requires specific connector message format that doesn't align with standard OpenAI chat completions\n",
    "2. **model_type=\"FINETUNE\"**: Requires `/v1/completions` endpoint, but newer OpenAI models (gpt-4o-mini) only support `/v1/chat/completions`\n",
    "3. **gpt-3.5-turbo-instruct**: Supports completions endpoint but encounters inference failures through the PPL tool\n",
    "\n",
    "### ‚úÖ Working Alternative\n",
    "\n",
    "Instead of using PPLTool, you can:\n",
    "- Use the model directly to generate PPL queries\n",
    "- Execute queries manually using OpenSearch PPL API\n",
    "- Use other verified tools like LogPatternTool or CatIndexTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef4ad182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Alternative: Generate PPL using model directly\n",
      "============================================================\n",
      "\n",
      "‚úÖ Generated PPL Query:\n",
      "   source=application_logs | where level='ERROR'\n",
      "\n",
      "üîç Executing PPL query...\n",
      "\n",
      "üìä Query Results:\n",
      "{\n",
      "  \"schema\": [\n",
      "    {\n",
      "      \"name\": \"message\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"level\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"service\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"timestamp\",\n",
      "      \"type\": \"timestamp\"\n",
      "    }\n",
      "  ],\n",
      "  \"datarows\": [\n",
      "    [\n",
      "      \"Connection timeout\",\n",
      "      \"ERROR\",\n",
      "      \"api\",\n",
      "      \"2025-11-09 10:01:00\"\n",
      "    ],\n",
      "    [\n",
      "      \"Query failed\",\n",
      "      \"ERROR\",\n",
      "      \"database\",\n",
      "      \"2025-11-09 10:02:00\"\n",
      "    ],\n",
      "    [\n",
      "      \"Authentication failed\",\n",
      "      \"ERROR\",\n",
      "      \"api\",\n",
      "      \"2025-11-09 10:05:00\"\n",
      "    ]\n",
      "  ],\n",
      "  \"total\": 3,\n",
      "  \"size\": 3\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Alternative Approach: Use OpenAI model directly to generate PPL\n",
    "# Then execute the PPL query manually\n",
    "\n",
    "print(\"üîÑ Alternative: Generate PPL using model directly\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Step 1: Generate PPL query using the LLM\n",
    "question = \"Show me all ERROR level logs\"\n",
    "ppl_prompt = f\"\"\"Convert this natural language question to a PPL (Piped Processing Language) query for OpenSearch.\n",
    "\n",
    "Index: {index_name}\n",
    "Question: {question}\n",
    "\n",
    "PPL syntax guide:\n",
    "- Start with: source=index_name\n",
    "- Filter with: where field='value' or where field=value\n",
    "- Aggregate with: stats count() by field\n",
    "- Sort with: sort field desc/asc\n",
    "- Limit with: head N\n",
    "\n",
    "Output ONLY the PPL query, nothing else.\"\"\"\n",
    "\n",
    "try:\n",
    "    # Call model to generate PPL\n",
    "    model_request = {\n",
    "        \"parameters\": {\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": ppl_prompt}]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    llm_response = client.transport.perform_request(\n",
    "        'POST',\n",
    "        f'/_plugins/_ml/models/{model_id}/_predict',\n",
    "        body=model_request\n",
    "    )\n",
    "    \n",
    "    # Extract generated PPL query\n",
    "    ppl_query = llm_response['inference_results'][0]['output'][0]['dataAsMap']['choices'][0]['message']['content'].strip()\n",
    "    # Remove markdown code blocks if present\n",
    "    ppl_query = ppl_query.replace('```sql', '').replace('```', '').strip()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Generated PPL Query:\")\n",
    "    print(f\"   {ppl_query}\")\n",
    "    \n",
    "    # Step 2: Execute the PPL query\n",
    "    print(f\"\\nüîç Executing PPL query...\")\n",
    "    ppl_result = client.transport.perform_request(\n",
    "        'POST',\n",
    "        '/_plugins/_ppl',\n",
    "        body={\"query\": ppl_query}\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìä Query Results:\")\n",
    "    print(json.dumps(ppl_result, indent=2))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error: {e}\")\n",
    "    if hasattr(e, 'info'):\n",
    "        print(f\"\\nüìù Details:\")\n",
    "        print(json.dumps(e.info, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caefb913",
   "metadata": {},
   "source": [
    "## Test Case 2 - Count Errors by Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf7351c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Count the number of ERROR level logs grouped by service (use uppercase ERROR)\n",
      "PPL Query: source=application_logs | where level='ERROR' | stats count() by service\n",
      "\n",
      "Results:\n",
      "{\n",
      "  \"schema\": [\n",
      "    {\n",
      "      \"name\": \"count()\",\n",
      "      \"type\": \"bigint\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"service\",\n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  ],\n",
      "  \"datarows\": [\n",
      "    [\n",
      "      2,\n",
      "      \"api\"\n",
      "    ],\n",
      "    [\n",
      "      1,\n",
      "      \"database\"\n",
      "    ]\n",
      "  ],\n",
      "  \"total\": 2,\n",
      "  \"size\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test Case 2: Count errors grouped by service\n",
    "question = \"Count the number of ERROR level logs grouped by service (use uppercase ERROR)\"\n",
    "\n",
    "ppl_prompt = f\"\"\"Convert to PPL query:\n",
    "Index: {index_name}\n",
    "Question: {question}\n",
    "\n",
    "PPL format: source=index | where field='value' | stats function() by field\n",
    "Output only the query.\"\"\"\n",
    "\n",
    "model_request = {\"parameters\": {\"messages\": [{\"role\": \"user\", \"content\": ppl_prompt}]}}\n",
    "llm_response = client.transport.perform_request('POST', f'/_plugins/_ml/models/{model_id}/_predict', body=model_request)\n",
    "ppl_query = llm_response['inference_results'][0]['output'][0]['dataAsMap']['choices'][0]['message']['content'].strip().replace('```', '').replace('sql', '').strip()\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"PPL Query: {ppl_query}\")\n",
    "\n",
    "ppl_result = client.transport.perform_request('POST', '/_plugins/_ppl', body={\"query\": ppl_query})\n",
    "print(f\"\\nResults:\")\n",
    "print(json.dumps(ppl_result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54b913f",
   "metadata": {},
   "source": [
    "## Test Case 3 - Filter by Service and Level `<SAME ERROR MENTIONED ABOVE>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18df9c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì Question: Show API service WARN/ERROR logs\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "RequestError",
     "evalue": "RequestError(400, 'IllegalArgumentException')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRequestError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚ùì Question: Show API service WARN/ERROR logs\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m response = \u001b[43mexecute_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müìä Results:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(json.dumps(response, indent=\u001b[32m2\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-projects/personal/github.com/elasticsearch_opensearch/5. AGENTIC_SEARCH/4. agents_tools/agent_helpers.py:384\u001b[39m, in \u001b[36mexecute_agent\u001b[39m\u001b[34m(client, agent_id, parameters)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    370\u001b[39m \u001b[33;03mExecute an agent with given parameters.\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    378\u001b[39m \u001b[33;03m    dict: Agent execution response\u001b[39;00m\n\u001b[32m    379\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    380\u001b[39m execute_body = {\n\u001b[32m    381\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mparameters\u001b[39m\u001b[33m\"\u001b[39m: parameters\n\u001b[32m    382\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/_plugins/_ml/agents/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43magent_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/_execute\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecute_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-projects/personal/github.com/elasticsearch_opensearch/.venv/lib/python3.12/site-packages/opensearchpy/transport.py:457\u001b[39m, in \u001b[36mTransport.perform_request\u001b[39m\u001b[34m(self, method, url, params, body, timeout, ignore, headers)\u001b[39m\n\u001b[32m    455\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    456\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    460\u001b[39m     \u001b[38;5;66;03m# connection didn't fail, confirm its live status\u001b[39;00m\n\u001b[32m    461\u001b[39m     \u001b[38;5;28mself\u001b[39m.connection_pool.mark_live(connection)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-projects/personal/github.com/elasticsearch_opensearch/.venv/lib/python3.12/site-packages/opensearchpy/transport.py:418\u001b[39m, in \u001b[36mTransport.perform_request\u001b[39m\u001b[34m(self, method, url, params, body, timeout, ignore, headers)\u001b[39m\n\u001b[32m    415\u001b[39m connection = \u001b[38;5;28mself\u001b[39m.get_connection()\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m     status, headers_response, data = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m     \u001b[38;5;66;03m# Lowercase all the header names for consistency in accessing them.\u001b[39;00m\n\u001b[32m    429\u001b[39m     headers_response = {\n\u001b[32m    430\u001b[39m         header.lower(): value \u001b[38;5;28;01mfor\u001b[39;00m header, value \u001b[38;5;129;01min\u001b[39;00m headers_response.items()\n\u001b[32m    431\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-projects/personal/github.com/elasticsearch_opensearch/.venv/lib/python3.12/site-packages/opensearchpy/connection/http_urllib3.py:308\u001b[39m, in \u001b[36mUrllib3HttpConnection.perform_request\u001b[39m\u001b[34m(self, method, url, params, body, timeout, ignore, headers)\u001b[39m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= response.status < \u001b[32m300\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m response.status \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ignore:\n\u001b[32m    305\u001b[39m     \u001b[38;5;28mself\u001b[39m.log_request_fail(\n\u001b[32m    306\u001b[39m         method, full_url, url, orig_body, duration, response.status, raw_data\n\u001b[32m    307\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mraw_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent-type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[38;5;28mself\u001b[39m.log_request_success(\n\u001b[32m    315\u001b[39m     method, full_url, url, orig_body, response.status, raw_data, duration\n\u001b[32m    316\u001b[39m )\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response.status, response.headers, raw_data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-projects/personal/github.com/elasticsearch_opensearch/.venv/lib/python3.12/site-packages/opensearchpy/connection/base.py:315\u001b[39m, in \u001b[36mConnection._raise_error\u001b[39m\u001b[34m(self, status_code, raw_data, content_type)\u001b[39m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    313\u001b[39m     logger.warning(\u001b[33m\"\u001b[39m\u001b[33mUndecodable raw error response from server: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, err)\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTP_EXCEPTIONS.get(status_code, TransportError)(\n\u001b[32m    316\u001b[39m     status_code, error_message, additional_info\n\u001b[32m    317\u001b[39m )\n",
      "\u001b[31mRequestError\u001b[39m: RequestError(400, 'IllegalArgumentException')"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"question\": \"Show API service logs with WARNING or ERROR level\",\n",
    "    \"index\": index_name\n",
    "}\n",
    "\n",
    "print(\"‚ùì Question: Show API service WARN/ERROR logs\")\n",
    "print(\"=\"*60)\n",
    "response = execute_agent(client, agent_id, parameters)\n",
    "print(\"\\nüìä Results:\")\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63254c9",
   "metadata": {},
   "source": [
    "## Test Case 4 - Recent Errors `<SAME ERROR ABOVE>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7993d988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì Question: Most recent 5 error messages\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "RequestError",
     "evalue": "RequestError(400, 'IllegalArgumentException')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRequestError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚ùì Question: Most recent 5 error messages\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m response = \u001b[43mexecute_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müìä Results:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(json.dumps(response, indent=\u001b[32m2\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/OPENSEARCH_INTERMEDIATE_TUTORIAL/5. AGENTIC_SEARCH/5. agents_tools/agent_helpers.py:384\u001b[39m, in \u001b[36mexecute_agent\u001b[39m\u001b[34m(client, agent_id, parameters)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    370\u001b[39m \u001b[33;03mExecute an agent with given parameters.\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    378\u001b[39m \u001b[33;03m    dict: Agent execution response\u001b[39;00m\n\u001b[32m    379\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    380\u001b[39m execute_body = {\n\u001b[32m    381\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mparameters\u001b[39m\u001b[33m\"\u001b[39m: parameters\n\u001b[32m    382\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/_plugins/_ml/agents/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43magent_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/_execute\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecute_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/OPENSEARCH_INTERMEDIATE_TUTORIAL/.venv/lib/python3.12/site-packages/opensearchpy/transport.py:457\u001b[39m, in \u001b[36mTransport.perform_request\u001b[39m\u001b[34m(self, method, url, params, body, timeout, ignore, headers)\u001b[39m\n\u001b[32m    455\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    456\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    460\u001b[39m     \u001b[38;5;66;03m# connection didn't fail, confirm its live status\u001b[39;00m\n\u001b[32m    461\u001b[39m     \u001b[38;5;28mself\u001b[39m.connection_pool.mark_live(connection)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/OPENSEARCH_INTERMEDIATE_TUTORIAL/.venv/lib/python3.12/site-packages/opensearchpy/transport.py:418\u001b[39m, in \u001b[36mTransport.perform_request\u001b[39m\u001b[34m(self, method, url, params, body, timeout, ignore, headers)\u001b[39m\n\u001b[32m    415\u001b[39m connection = \u001b[38;5;28mself\u001b[39m.get_connection()\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m     status, headers_response, data = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m     \u001b[38;5;66;03m# Lowercase all the header names for consistency in accessing them.\u001b[39;00m\n\u001b[32m    429\u001b[39m     headers_response = {\n\u001b[32m    430\u001b[39m         header.lower(): value \u001b[38;5;28;01mfor\u001b[39;00m header, value \u001b[38;5;129;01min\u001b[39;00m headers_response.items()\n\u001b[32m    431\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/OPENSEARCH_INTERMEDIATE_TUTORIAL/.venv/lib/python3.12/site-packages/opensearchpy/connection/http_urllib3.py:308\u001b[39m, in \u001b[36mUrllib3HttpConnection.perform_request\u001b[39m\u001b[34m(self, method, url, params, body, timeout, ignore, headers)\u001b[39m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= response.status < \u001b[32m300\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m response.status \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ignore:\n\u001b[32m    305\u001b[39m     \u001b[38;5;28mself\u001b[39m.log_request_fail(\n\u001b[32m    306\u001b[39m         method, full_url, url, orig_body, duration, response.status, raw_data\n\u001b[32m    307\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mraw_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent-type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[38;5;28mself\u001b[39m.log_request_success(\n\u001b[32m    315\u001b[39m     method, full_url, url, orig_body, response.status, raw_data, duration\n\u001b[32m    316\u001b[39m )\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response.status, response.headers, raw_data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/OPENSEARCH_INTERMEDIATE_TUTORIAL/.venv/lib/python3.12/site-packages/opensearchpy/connection/base.py:315\u001b[39m, in \u001b[36mConnection._raise_error\u001b[39m\u001b[34m(self, status_code, raw_data, content_type)\u001b[39m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    313\u001b[39m     logger.warning(\u001b[33m\"\u001b[39m\u001b[33mUndecodable raw error response from server: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, err)\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTP_EXCEPTIONS.get(status_code, TransportError)(\n\u001b[32m    316\u001b[39m     status_code, error_message, additional_info\n\u001b[32m    317\u001b[39m )\n",
      "\u001b[31mRequestError\u001b[39m: RequestError(400, 'IllegalArgumentException')"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"question\": \"What were the most recent 5 error messages?\",\n",
    "    \"index\": index_name\n",
    "}\n",
    "\n",
    "print(\"‚ùì Question: Most recent 5 error messages\")\n",
    "print(\"=\"*60)\n",
    "response = execute_agent(client, agent_id, parameters)\n",
    "print(\"\\nüìä Results:\")\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935452da",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### PPLTool Challenges:\n",
    "\n",
    "The **PPLTool** has compatibility issues with OpenAI models in the current OpenSearch version:\n",
    "- `model_type=\"OPENAI\"` requires specific connector formats not fully documented\n",
    "- `model_type=\"FINETUNE\"` works with `/v1/completions` but newer OpenAI models use `/v1/chat/completions`\n",
    "- The tool encounters inference failures when calling models through the agent framework\n",
    "\n",
    "### ‚úÖ Working Alternative - Direct PPL Generation:\n",
    "\n",
    "Instead of using PPLTool, use this two-step approach:\n",
    "\n",
    "1. **Generate PPL Query**: Call OpenAI model directly with a PPL-focused prompt\n",
    "2. **Execute Query**: Use OpenSearch PPL API `/_plugins/_ppl` endpoint\n",
    "\n",
    "```python\n",
    "# Step 1: Generate PPL\n",
    "model_request = {\n",
    "    \"parameters\": {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": ppl_prompt}]\n",
    "    }\n",
    "}\n",
    "response = client.transport.perform_request(\n",
    "    'POST',\n",
    "    f'/_plugins/_ml/models/{model_id}/_predict',\n",
    "    body=model_request\n",
    ")\n",
    "ppl_query = response['inference_results'][0]['output'][0]['dataAsMap']['choices'][0]['message']['content']\n",
    "\n",
    "# Step 2: Execute PPL\n",
    "result = client.transport.perform_request(\n",
    "    'POST',\n",
    "    '/_plugins/_ppl',\n",
    "    body={\"query\": ppl_query}\n",
    ")\n",
    "```\n",
    "\n",
    "### PPL Syntax Reference:\n",
    "\n",
    "| Command | Purpose | Example |\n",
    "|---------|---------|---------|\n",
    "| `source=index` | Specify index | `source=logs` |\n",
    "| `where field='value'` | Filter | `where level='ERROR'` |\n",
    "| `stats count() by field` | Aggregate | `stats count() by service` |\n",
    "| `sort field desc` | Order results | `sort timestamp desc` |\n",
    "| `head N` | Limit results | `head 10` |\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "‚úÖ **Be specific**: Include field names and values in your natural language question  \n",
    "‚úÖ **Case sensitivity**: Specify uppercase/lowercase when important  \n",
    "‚úÖ **Prompt engineering**: Provide PPL examples in your prompt for better results  \n",
    "‚úÖ **Validation**: Check generated queries before execution  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e708126d",
   "metadata": {},
   "source": [
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87541fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cleanup_resources(\n",
    "# #     client=client,\n",
    "# #     agent_ids=[agent_id],\n",
    "# #     model_ids=[model_id],\n",
    "# #     connector_ids=[connector_id]\n",
    "# # )\n",
    "# # client.indices.delete(index=index_name)\n",
    "# # print(\"‚úÖ Cleanup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11053926",
   "metadata": {},
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "- **LogPatternTool**: Extract patterns from logs\n",
    "- **LogPatternAnalysisTool**: Advanced log analysis\n",
    "- **QueryPlanningTool**: DSL query generation\n",
    "\n",
    "üìö [PPLTool Documentation](https://opensearch.org/docs/latest/ml-commons-plugin/agents-tools/tools/ppl-tool/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-ml-search-with-opensearch-intermediate (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
