![alt text](static_images/ai_ml_search_opensearch_intermediate.jpeg)  
This repo contains tutorials, code, documentation that drives my opensearch INTERMEDIATE level course content. Throughout the course: `OS=opensearch` & `ES=elasticsearch`

# ğŸ‘¨â€ğŸ’¼ ABOUT ME
## ğŸ¯ About Your Instructor

**Pradeep** brings **23+ years** of experience architecting and scaling high-performing teams across the globeâ€”from Fortune 500 enterprises to innovative startups.

### ğŸ’¼ Professional Background
- ğŸ¢ Led enterprise digital transformations in **Data Engineering**, **AI/ML**, and **Modern Application Stacks**
- ğŸŒ Scaled international teams with laser focus on **external customer success**
- ğŸ” Deep expertise in search technologies, distributed systems, and cloud infrastructure

### ğŸ“š Teaching Philosophy
*Pradeep believes that **teaching is the best form of learning**.* This course reflects that philosophyâ€”content designed not just to transfer knowledge, but to build genuine understanding. You'll benefit from real-world patterns, hard-earned lessons, and a practical approach to OpenSearch that comes from hands-on enterprise experience.

# ğŸ“ UDEMY
The previous course (BASIC level) is published [here](https://www.udemy.com/course/ai-ml-search-with-opensearch/)

# ğŸ“‹ PREREQUISITES FOR THE COURSE
- âœ… **Prequel Course**: [BASIC level course](https://www.udemy.com/course/ai-ml-search-with-opensearch/) (recommended but not mandatory)
- ğŸ‘¤ **You should have**: 
  - ğŸ”¥ Eagerness to learn traditional vs. AI/ML-driven search
  - ğŸ§ Linux basics (`ls`, `rm`, `cd`)
  - ğŸ³ Docker/container fundamentals
  - ğŸ Basic Python coding
  - ğŸ”Œ Server/client architecture knowledge
- ğŸ’» **Machine Resources**: See below

## ğŸ“Š Course Topics Overview

<sub>

| ğŸ” TRADITIONAL_SEARCH | ğŸ“¥ INGEST_AND_SEARCH_CONCEPTS | ğŸ¤– AI_SEARCH | ğŸ§  AGENTIC_SEARCH | ğŸš€ REALTIME_PROJECTS |
|-------------------|---------------------------|-----------|----------------|------------------|
| ğŸ“š Core Concepts (Tokenization, Normalization, Stop Words, Synonyms) | ğŸ”€ Ingest Pipelines (Processors, Transformations, Configuration, Use Cases) | ğŸ§  Semantic Search (Dense Embeddings, Vector Similarity, Use Cases, Setup) | ğŸ“Š Vector Embeddings (Embedding Models, Text Embedding, Sparse Encoding, Cross-Encoders, Integration) | ğŸ” Project 1: Search As You Type (Frontend, Backend, Communication, Features, Use Cases) |
| ğŸ—‚ï¸ Analyzers (Standard, Simple, Whitespace, Custom) | ğŸ” Search Pipelines (Query Processing, Result Processing, Aggregation) | ğŸ¯ Hybrid Search (Score Combination, Fusion Methods, Advantages, Implementation) | ğŸ”§ Custom Models (Model Building, Packaging, Integration, Use Cases) | ğŸ“Š Project 2: Performance (Benchmarking, Metrics, Analysis, Insights) |
| ğŸ“ Index Configuration (Field Mappings, Analysis Chains, Inverted Index) | ğŸ“š Bulk Ingestion (High Volume, Batch API, Memory Management, Performance) | âš¡ Neural Sparse (Sparse Vectors, SPLADE Model, Benefits, Learning) | ğŸŒ External LLMs (Providers, Configuration, Optimization, Connectors) | ğŸŒ Project 3: Geo-spatial (Features, Capabilities, Implementation, Use Cases) |
| ğŸ” Query Types (Match, Phrase, Wildcard, Multi-Match, Range) | ğŸ§® Vector Basics (Vector Space, Similarity Metrics, KNN Algorithms, Vector Search) | ğŸš€ Specialized Techniques (Advanced Indexing, Quantization, Optimization, Scaling) | ğŸ§  Agent Systems (Agent Architecture, Tool Definition, Memory Management, Multi-step Reasoning) | ğŸ’¼ Project 4: BI Agent Basic (Features, Database Support, Workflow, Learning) |
| âœ¨ Advanced Features (Edge N-Grams, Regular N-Grams, Shingles) | ğŸ¤– Embeddings & ML (Embedding Models, ML Pipeline, Integration) | ğŸ”„ Architecture Pattern (Input Processing, Storage Layer, Search Methods, Ranking, Results) | ğŸ“ˆ Result Reranking (Cross-Encoders, Reranking Pipeline, Performance, Use Cases) | ğŸ¯ Project 5: Agentic App (Enhancements, Architecture, Features, Capability) |
| ğŸš€ Performance (Optimization, Refresh Rate, Caching) | âš¡ Streaming Data (Data Prepper, Real-time Processing, Use Cases) | ğŸ“Š Comparison Matrix (Dense vs BM25 vs Hybrid vs Neural Sparse) | ğŸ” RAG Flows (Basic RAG, Conversational, Multi-KB, Hybrid, Advanced Features) | ğŸ’­ Project 6: With Memory (Memory System, Interaction, Storage, Experience) |
| ğŸ—ï¸ Data Ingestion (Bulk Loading, Mapping, Document Structure) | ğŸš€ Production Optimization (Index Tuning, Configuration, Monitoring) | ğŸ“ Decision Framework (When to choose each method) | ğŸ”€ Search Strategies (Semantic, Keyword, Hybrid, RRF) | ğŸ“š Project 7: Long-Term Memory (LTM Storage, Knowledge Management, Integration, Capabilities) |
| ğŸ“ Use Cases (E-commerce, Enterprise, Directory, CMS) | ğŸ’¾ Snapshots & Recovery (Backup Strategy, Restore Operations, Disaster Recovery) | ğŸ† Best Practices (Model Selection, Index Config, Query Optimization, Monitoring) | ğŸ› ï¸ Implementation Stack (Backend, Pipeline, Data Storage, Integration) | ğŸ”— Project 8: MCP Server (Protocol, Components, Integration, Ecosystem) |
| | | | ğŸ¢ Production Patterns (Performance, Reliability, Monitoring, Deployment) | ğŸ“ Skill Progression (8 levels from UI to Standards) |
| | | | | ğŸ¯ Selection Guide (For different roles) |
| | | | | ğŸ† Application Domains (E-commerce, BI, Location, Enterprise) |

</sub>

[High Level Course Modules Details](./2.%20HIGH_LEVEL_MODULES.md)

# ğŸš€ MOTIVATION FOR THE COURSE
- ğŸ“Š ES is mature but OpenSearch is the open-source alternative gaining momentum
- ğŸ”— Fortune 500 companies (e.g., Oracle) migrating from ES â†’ OS
- ğŸ’° Cloud-native licensing: Why pay when open-source equivalents exist?
- ğŸ” Own your dataâ€”reduce vendor lock-in on auth, UI, and commoditized features
- ğŸ“ˆ OpenSearch market disruption opportunity with minimal course competition
- ğŸ¯ And many more (follow the course!)

# ğŸ—‚ï¸ ORGANIZATION OF THE COURSE
- ğŸ“ **Tutorial**: Main modules are top-level folders; sub-modules nested deeper
- ğŸ’» **Code**: Python, shell, docker-compose files within each module
- ğŸ“Š **Data**: Subfolder **[0. DATA](./0.%20DATA/)** with downloadable datasets (NOT INCLUDED IN CODE REPOSITORY but downloadable from [here]((https://drive.google.com/drive/folders/1nRRvctDhKB_cC0DicET3XgxUHxml7clz?usp=sharing)))
- ğŸ“½ï¸ **Presentations**: Folder **[PDFS](./PDFS/)** contains all presentation assets (NOT INCLUDED IN CODE REPOSITORY)

# ğŸ“– PRESENTATIONS
- âœ… PDFs and markdown (over .ppt or .pptx format)
- All presentations can be downloaded from [here](https://drive.google.com/drive/folders/1nRRvctDhKB_cC0DicET3XgxUHxml7clz?usp=sharing)
- âœ¨ **Markdown-first approach**: All content co-located with code
  - ğŸ¥ Watch videos + read .md files = complete learning (no context switching!)
  - ğŸ“„ Export to PDF/HTML using Markdown Preview Enhanced (while it is possible to convert markdown to .pptx, there are nuances of how rendering can get messed up)
  - ğŸ¤– AI-friendly formatâ€”markdown is how agents exchange context
  - ğŸ› ï¸ Alternatives: pandoc, marp (though marp lacks mermaid support at this point)
- **I  want instruction material outside of code**. All presentations can be downloaded from [here](https://drive.google.com/drive/folders/1nRRvctDhKB_cC0DicET3XgxUHxml7clz?usp=sharing) 
# ğŸ’¾ DATA
- The file [0. DATA.zip](https://drive.google.com/drive/folders/1nRRvctDhKB_cC0DicET3XgxUHxml7clz?usp=sharing) contains all datasets required for this course and has to be exploded in `0. DATA` folder in the root of the repo (notice there is a space after 0 before DATA in the folder name)

# âš™ï¸ HARDWARE, TOOLS & SOFTWARE
- ğŸ–¥ï¸ **HARDWARE**: 16GB+ RAM, 4+ CPUs, 50GB storage (bare metal or VM)
- ğŸ” **OPENSEARCH**: v3.3.0
- ğŸ§ **SERVER OS**: Ubuntu 20.04/22.04
- ğŸ’» **CLIENT OS**: Windows/macOS/*nix (your choice for IDE)
- ğŸ³ **DOCKER**: v28.4.0+ 
- ğŸ **PROGRAMMING**: Python >=3.12.11+, Shell, SQL/DQL
- ğŸ¨ **IDE**: VS CODE 1.105.1+ with extensions, Jupyter

# ğŸŒ STUDENT ENVIRONMENT
Conform to this infrastructure setup:  
![environment](./static_images/environment.svg)

# â“ WHY NOT WINDOWS SERVER
Most execution happens in Docker, so Windows works too. I recommend *nix if pressed. ğŸ’¬ Email if you run into issues at  [pradeep@automationpractice.com](pradeep@automationpractice.com)

> **Note**: Your client OS can be Windows/macOS/*nixâ€”wherever your IDE runs!

# ğŸ”§ VS CODE EXTENSIONS
All extensions are in [vscode-extensions.txt](./vscode-extensions.txt):
- ğŸ§ *nix: `cat vscode-extensions.txt | xargs -n 1 code --install-extension`
- ğŸ’» PowerShell: `Get-Content vscode-extensions.txt | ForEach-Object { code --install-extension $_ }`
- ğŸªŸ CMD: `for /F "delims=" %i in (vscode-extensions.txt) do code --install-extension %i`
- ğŸ” Or install manually one-by-one

# âš ï¸ GOTCHAS
- ğŸ” **Docker permission denied**: `sudo chmod 666 /var/run/docker.sock`
- ğŸ““ **Notebook first run**: Install ipykernel when prompted ![alt text](static_images/image-3.png)
- â–¶ï¸ **Python in interactive window**: Install Python + Jupyter extensions; enable in Settings ![settings](./static_images/shift_enter_python_interactive.png)
- ğŸŒ **Markdown export to PDF**: Set Chrome path in Markdown Enhanced settings ![chrome path](./static_images/markdown-enhanced-chrome-path.png)

### HyperV ubuntu 22.04 disk expansion
- By default ubuntu vm on hyper-v shows only ~12G on / partition (even though you expand the disk from GUI)
- Follow the below steps to expand space
- Assuming you have the below layout (`df -h`)

```
sda       8:0    0    60G  0 disk 

â”œâ”€sda1    8:1    0  11.9G  0 part /

â”œâ”€sda14   8:14   0     4M  0 part 

â””â”€sda15   8:15   0   106M  0 part /boot/efi
```


##### âš ï¸ Prerequisite: Backup Your Data

While resizing partitions is generally safe, it involves modifying the partition table. Always ensure you have a backup of critical data before proceeding.

---

##### Step 1: Install the necessary tools

Ubuntu usually comes with these, but ensure `cloud-guest-utils` is installed, as it contains the `growpart` tool.

```bash
sudo apt update
sudo apt install cloud-guest-utils -y

```

##### Step 2: Expand the Partition

You need to tell the system to expand the first partition (`1`) on the disk (`/dev/sda`).

> **Note:** In the command below, there is a **space** between the disk name and the partition number.

```bash
sudo growpart /dev/sda 1

```

*If successful, you will see a message saying: `CHANGED: partition=1...*`

##### Step 3: Expand the Filesystem

Now that the "container" (the partition) is larger, you need to tell the filesystem (likely ext4) to grow and fill that new space.

```bash
sudo resize2fs /dev/sda1

```

##### Step 4: Verify the changes

Run `lsblk` again to see the new partition size, and use `df -h` to verify that the OS sees the extra space.

```bash
lsblk
df -h /

```