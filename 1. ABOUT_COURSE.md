![alt text](static_images/ai_ml_search_opensearch_intermediate.jpeg)  
This repo contains tutorials, code, documentation that drives my opensearch INTERMEDIATE level course content. Throughout the course: `OS=opensearch` & `ES=elasticsearch`

# ðŸ‘¨â€ðŸ’¼ ABOUT ME
## ðŸŽ¯ About Your Instructor

**Pradeep** brings **23+ years** of experience architecting and scaling high-performing teams across the globeâ€”from Fortune 500 enterprises to innovative startups.

### ðŸ’¼ Professional Background
- ðŸ¢ Led enterprise digital transformations in **Data Engineering**, **AI/ML**, and **Modern Application Stacks**
- ðŸŒ Scaled international teams with laser focus on **external customer success**
- ðŸ” Deep expertise in search technologies, distributed systems, and cloud infrastructure

### ðŸ“š Teaching Philosophy
*Pradeep believes that **teaching is the best form of learning**.* This course reflects that philosophyâ€”content designed not just to transfer knowledge, but to build genuine understanding. You'll benefit from real-world patterns, hard-earned lessons, and a practical approach to OpenSearch that comes from hands-on enterprise experience.

# ðŸŽ“ UDEMY
The previous course (BASIC level) is published [here](https://www.udemy.com/course/ai-ml-search-with-opensearch/)

# ðŸ“‹ PREREQUISITES FOR THE COURSE
- âœ… **Prequel Course**: [BASIC level course](https://www.udemy.com/course/ai-ml-search-with-opensearch/) (recommended but not mandatory)
- ðŸ‘¤ **You should have**: 
  - ðŸ”¥ Eagerness to learn traditional vs. AI/ML-driven search
  - ðŸ§ Linux basics (`ls`, `rm`, `cd`)
  - ðŸ³ Docker/container fundamentals
  - ðŸ Basic Python coding
  - ðŸ”Œ Server/client architecture knowledge
- ðŸ’» **Machine Resources**: See below

## ðŸ“Š Course Topics Overview

| ðŸ” TRADITIONAL_SEARCH | ðŸ“¥ INGEST_AND_SEARCH_CONCEPTS | ðŸ¤– AI_SEARCH | ðŸ§  AGENTIC_SEARCH | ðŸš€ REALTIME_PROJECTS |
|-------------------|---------------------------|-----------|----------------|------------------|
| ðŸ“š Core Concepts (Tokenization, Normalization, Stop Words, Synonyms) | ðŸ”€ Ingest Pipelines (Processors, Transformations, Configuration, Use Cases) | ðŸ§  Semantic Search (Dense Embeddings, Vector Similarity, Use Cases, Setup) | ðŸ“Š Vector Embeddings (Embedding Models, Text Embedding, Sparse Encoding, Cross-Encoders, Integration) | ðŸ” Project 1: Search As You Type (Frontend, Backend, Communication, Features, Use Cases) |
| ðŸ—‚ï¸ Analyzers (Standard, Simple, Whitespace, Custom) | ðŸ” Search Pipelines (Query Processing, Result Processing, Aggregation) | ðŸŽ¯ Hybrid Search (Score Combination, Fusion Methods, Advantages, Implementation) | ðŸ”§ Custom Models (Model Building, Packaging, Integration, Use Cases) | ðŸ“Š Project 2: Performance (Benchmarking, Metrics, Analysis, Insights) |
| ðŸ“ Index Configuration (Field Mappings, Analysis Chains, Inverted Index) | ðŸ“š Bulk Ingestion (High Volume, Batch API, Memory Management, Performance) | âš¡ Neural Sparse (Sparse Vectors, SPLADE Model, Benefits, Learning) | ðŸŒ External LLMs (Providers, Configuration, Optimization, Connectors) | ðŸŒ Project 3: Geo-spatial (Features, Capabilities, Implementation, Use Cases) |
| ðŸ”Ž Query Types (Match, Phrase, Wildcard, Multi-Match, Range) | ðŸ§® Vector Basics (Vector Space, Similarity Metrics, KNN Algorithms, Vector Search) | ðŸš€ Specialized Techniques (Advanced Indexing, Quantization, Optimization, Scaling) | ðŸ§  Agent Systems (Agent Architecture, Tool Definition, Memory Management, Multi-step Reasoning) | ðŸ’¼ Project 4: BI Agent Basic (Features, Database Support, Workflow, Learning) |
| âœ¨ Advanced Features (Edge N-Grams, Regular N-Grams, Shingles) | ðŸ¤– Embeddings & ML (Embedding Models, ML Pipeline, Integration) | ðŸ”„ Architecture Pattern (Input Processing, Storage Layer, Search Methods, Ranking, Results) | ðŸ“ˆ Result Reranking (Cross-Encoders, Reranking Pipeline, Performance, Use Cases) | ðŸŽ¯ Project 5: Agentic App (Enhancements, Architecture, Features, Capability) |
| ðŸš€ Performance (Optimization, Refresh Rate, Caching) | âš¡ Streaming Data (Data Prepper, Real-time Processing, Use Cases) | ðŸ“Š Comparison Matrix (Dense vs BM25 vs Hybrid vs Neural Sparse) | ðŸ” RAG Flows (Basic RAG, Conversational, Multi-KB, Hybrid, Advanced Features) | ðŸ’­ Project 6: With Memory (Memory System, Interaction, Storage, Experience) |
| ðŸ—ï¸ Data Ingestion (Bulk Loading, Mapping, Document Structure) | ðŸš€ Production Optimization (Index Tuning, Configuration, Monitoring) | ðŸŽ“ Decision Framework (When to choose each method) | ðŸ”€ Search Strategies (Semantic, Keyword, Hybrid, RRF) | ðŸ“š Project 7: Long-Term Memory (LTM Storage, Knowledge Management, Integration, Capabilities) |
| ðŸŽ“ Use Cases (E-commerce, Enterprise, Directory, CMS) | ðŸ’¾ Snapshots & Recovery (Backup Strategy, Restore Operations, Disaster Recovery) | ðŸ† Best Practices (Model Selection, Index Config, Query Optimization, Monitoring) | ðŸ› ï¸ Implementation Stack (Backend, Pipeline, Data Storage, Integration) | ðŸ”— Project 8: MCP Server (Protocol, Components, Integration, Ecosystem) |
| | | | ðŸ¢ Production Patterns (Performance, Reliability, Monitoring, Deployment) | ðŸŽ“ Skill Progression (8 levels from UI to Standards) |
| | | | | ðŸŽ¯ Selection Guide (For different roles) |
| | | | | ðŸ† Application Domains (E-commerce, BI, Location, Enterprise) |


[High Level Course Modules Details](./2.%20HIGH_LEVEL_MODULES.md)

# ðŸš€ MOTIVATION FOR THE COURSE
- ðŸ“Š ES is mature but OpenSearch is the open-source alternative gaining momentum
- ðŸ”— Fortune 500 companies (e.g., Oracle) migrating from ES â†’ OS
- ðŸ’° Cloud-native licensing: Why pay when open-source equivalents exist?
- ðŸ” Own your dataâ€”reduce vendor lock-in on auth, UI, and commoditized features
- ðŸ“ˆ OpenSearch market disruption opportunity with minimal course competition
- ðŸŽ¯ And many more (follow the course!)

# ðŸ—‚ï¸ ORGANIZATION OF THE COURSE
- ðŸ“ **Tutorial**: Main modules are top-level folders; sub-modules nested deeper
- ðŸ’» **Code**: Python, shell, docker-compose files within each module
- ðŸ“Š **Data**: Subfolder **[0. DATA](./0.%20DATA/)** with downloadable datasets (NOT INCLUDED IN CODE REPOSITORY but downloadable from [here]((https://drive.google.com/drive/folders/1nRRvctDhKB_cC0DicET3XgxUHxml7clz?usp=sharing)))
- ðŸ“½ï¸ **Presentations**: Folder **[PDFS](./PDFS/)** contains all presentation assets

# ðŸ“– PRESENTATIONS
- âœ… PDFs and markdown (over .ppt or .pptx format)
- All presentations can be downloaded from [here](https://drive.google.com/drive/folders/1nRRvctDhKB_cC0DicET3XgxUHxml7clz?usp=sharing)
- âœ¨ **Markdown-first approach**: All content co-located with code
  - ðŸŽ¥ Watch videos + read .md files = complete learning (no context switching!)
  - ðŸ“„ Export to PDF/HTML using Markdown Preview Enhanced (while it is possible to convert markdown to .pptx, there are nuances of how rendering can get messed up)
  - ðŸ¤– AI-friendly formatâ€”markdown is how agents exchange context
  - ðŸ› ï¸ Alternatives: pandoc, marp (though marp lacks mermaid support at this point)
- **I  want instruction material outside of code**. All presentations can be downloaded from [here](https://drive.google.com/drive/folders/1nRRvctDhKB_cC0DicET3XgxUHxml7clz?usp=sharing) 
# ðŸ’¾ DATA
- The file [0. DATA.zip](https://drive.google.com/drive/folders/1nRRvctDhKB_cC0DicET3XgxUHxml7clz?usp=sharing) contains all datasets required for this course and has to be exploded in `0. DATA` folder in the root of the repo (notice there is a space after 0 before DATA in the folder name)

# âš™ï¸ HARDWARE, TOOLS & SOFTWARE
- ðŸ–¥ï¸ **HARDWARE**: 16GB+ RAM, 4+ CPUs, 50GB storage (bare metal or VM)
- ðŸ” **OPENSEARCH**: v3.3.0
- ðŸ§ **SERVER OS**: Ubuntu 20.04/22.04
- ðŸ’» **CLIENT OS**: Windows/macOS/*nix (your choice for IDE)
- ðŸ³ **DOCKER**: v28.4.0+ 
- ðŸ **PROGRAMMING**: Python >=3.12.11+, Shell, SQL/DQL
- ðŸŽ¨ **IDE**: VS CODE 1.105.1+ with extensions, Jupyter

# ðŸŒ STUDENT ENVIRONMENT
Conform to this infrastructure setup:  
![environment](./static_images/environment.svg)

# â“ WHY NOT WINDOWS SERVER
Most execution happens in Docker, so Windows works too. I recommend *nix if pressed. ðŸ’¬ Email if you run into issues at  [pradeep@automationpractice.com](pradeep@automationpractice.com)

> **Note**: Your client OS can be Windows/macOS/*nixâ€”wherever your IDE runs!

# ðŸ”§ VS CODE EXTENSIONS
All extensions are in [vscode-extensions.txt](./vscode-extensions.txt):
- ðŸ§ *nix: `cat vscode-extensions.txt | xargs -n 1 code --install-extension`
- ðŸ’» PowerShell: `Get-Content vscode-extensions.txt | ForEach-Object { code --install-extension $_ }`
- ðŸªŸ CMD: `for /F "delims=" %i in (vscode-extensions.txt) do code --install-extension %i`
- ðŸ” Or install manually one-by-one

# âš ï¸ GOTCHAS
- ðŸ” **Docker permission denied**: `sudo chmod 666 /var/run/docker.sock`
- ðŸ““ **Notebook first run**: Install ipykernel when prompted ![alt text](static_images/image-3.png)
- â–¶ï¸ **Python in interactive window**: Install Python + Jupyter extensions; enable in Settings ![settings](./static_images/shift_enter_python_interactive.png)
- ðŸŒ **Markdown export to PDF**: Set Chrome path in Markdown Enhanced settings ![chrome path](./static_images/markdown-enhanced-chrome-path.png)

### HyperV ubuntu 22.04 disk expansion
- By default ubuntu vm on hyper-v shows only ~12G on / partition (even though you expand the disk from GUI)
- Follow the below steps to expand space
- Assuming you have the below layout (`df -h`)

```
sda       8:0    0    60G  0 disk 

â”œâ”€sda1    8:1    0  11.9G  0 part /

â”œâ”€sda14   8:14   0     4M  0 part 

â””â”€sda15   8:15   0   106M  0 part /boot/efi
```


##### âš ï¸ Prerequisite: Backup Your Data

While resizing partitions is generally safe, it involves modifying the partition table. Always ensure you have a backup of critical data before proceeding.

---

##### Step 1: Install the necessary tools

Ubuntu usually comes with these, but ensure `cloud-guest-utils` is installed, as it contains the `growpart` tool.

```bash
sudo apt update
sudo apt install cloud-guest-utils -y

```

##### Step 2: Expand the Partition

You need to tell the system to expand the first partition (`1`) on the disk (`/dev/sda`).

> **Note:** In the command below, there is a **space** between the disk name and the partition number.

```bash
sudo growpart /dev/sda 1

```

*If successful, you will see a message saying: `CHANGED: partition=1...*`

##### Step 3: Expand the Filesystem

Now that the "container" (the partition) is larger, you need to tell the filesystem (likely ext4) to grow and fill that new space.

```bash
sudo resize2fs /dev/sda1

```

##### Step 4: Verify the changes

Run `lsblk` again to see the new partition size, and use `df -h` to verify that the OS sees the extra space.

```bash
lsblk
df -h /

```