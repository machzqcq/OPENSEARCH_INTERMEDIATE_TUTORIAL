{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e883f21",
   "metadata": {},
   "source": [
    "# OpenSearch ML Ingestion & Search Pipeline Workflow\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[\"[DATA] Load SQUAD Dataset<br/>87,599 rows to 1000 sampled\"] -->|Analyze Schema| B[\"[MAPPING] Auto-Generate Mappings<br/>exclude_from_vectors: id only\"]\n",
    "    \n",
    "    B -->|\"Approach 1<br/>create_vectors=False\"| C[\"[INDEX] 1: No Vectors<br/>squad_sample_no_vectors<br/>5 fields\"]\n",
    "    B -->|\"Approach 2<br/>create_vectors=True\"| D[\"[INDEX] 2: Manual Vectors<br/>squad_sample_with_vectors<br/>8 vector fields - empty\"]\n",
    "    \n",
    "    B -->|\"Approach 3<br/>create_vectors=True<br/>+ pipeline\"| E[\"[ML SETUP] Configure Components\"]\n",
    "    \n",
    "    E -->|\"1. Configure\"| F[\"[SETTINGS] ML Settings<br/>Allow ML on data nodes<br/>Disable access control\"]\n",
    "    F -->|\"2. Deploy\"| G[\"[MODEL] ML Model<br/>msmarco-distilbert-base-tas-b<br/>768 dims, HNSW, L2\"]\n",
    "    G -->|\"3. Create\"| H[\"[PIPELINE] Ingest Pipeline<br/>squad_embedding_pipeline<br/>Fields: title, context, question\"]\n",
    "    \n",
    "    H -->|\"4. Index + Ingest\"| I[\"[INDEX] 3: Auto-Embeddings<br/>squad_sample_with_pipeline<br/>8 vector fields - populated\"]\n",
    "    \n",
    "    C -->|\"1000 docs\"| J[\"[READY] All Indices<br/>Ready for Search\"]\n",
    "    D -->|\"1000 docs\"| J\n",
    "    I -->|\"1000 docs\"| J\n",
    "    \n",
    "    J -->|\"Search Methods\"| K[\"[SEMANTIC] Semantic Search<br/>k-NN neural queries\"]\n",
    "    J -->|\"Search Methods\"| L[\"[KEYWORD] Keyword Search<br/>BM25 multi-match\"]\n",
    "    J -->|\"Search Methods\"| M[\"[HYBRID] Hybrid Search<br/>Keyword + Semantic\"]\n",
    "    \n",
    "    M -->|\"Tune\"| N[\"[TUNING] Relevance Tuning<br/>Boost adjustment<br/>Field-level boosting\"]\n",
    "    \n",
    "    K -->|Results| O[\"[ANALYSIS] Compare & Analyze<br/>Precision vs Recall<br/>Performance metrics\"]\n",
    "    L -->|Results| O\n",
    "    M -->|Results| O\n",
    "    N -->|Results| O\n",
    "    \n",
    "    style A fill:#e1f5ff,stroke:#01579b,stroke-width:3px,color:#000\n",
    "    style B fill:#f3e5f5,stroke:#4a148c,stroke-width:3px,color:#000\n",
    "    style C fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000\n",
    "    style D fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000\n",
    "    style E fill:#e8f5e9,stroke:#1b5e20,stroke-width:3px,color:#000\n",
    "    style F fill:#fce4ec,stroke:#880e4f,stroke-width:2px,color:#000\n",
    "    style G fill:#fce4ec,stroke:#880e4f,stroke-width:2px,color:#000\n",
    "    style H fill:#fce4ec,stroke:#880e4f,stroke-width:2px,color:#000\n",
    "    style I fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000\n",
    "    style J fill:#c8e6c9,stroke:#2e7d32,stroke-width:4px,color:#000\n",
    "    style K fill:#bbdefb,stroke:#0d47a1,stroke-width:2px,color:#000\n",
    "    style L fill:#bbdefb,stroke:#0d47a1,stroke-width:2px,color:#000\n",
    "    style M fill:#b39ddb,stroke:#4527a0,stroke-width:3px,color:#000\n",
    "    style N fill:#ffccbc,stroke:#bf360c,stroke-width:2px,color:#000\n",
    "    style O fill:#a5d6a7,stroke:#1b5e20,stroke-width:3px,color:#000\n",
    "```\n",
    "\n",
    "## Complete Workflow Overview\n",
    "\n",
    "**Part 1: Data Ingestion** (3 Approaches)\n",
    "- **Basic Ingestion**: Traditional keyword search without embeddings\n",
    "- **Manual Vector Fields**: Pre-computed embeddings from external models  \n",
    "- **Automatic Embeddings**: ML-powered embedding generation via ingest pipelines (RECOMMENDED)\n",
    "\n",
    "**Part 2: Search & Relevance** (4 Methods)\n",
    "- **Keyword Search (BM25)**: Fast exact-match search\n",
    "- **Semantic Search (k-NN)**: Meaning-based vector similarity\n",
    "- **Hybrid Search**: Combines keyword + semantic for best results (RECOMMENDED)\n",
    "- **Relevance Tuning**: Boost adjustments and field-level prioritization\n",
    "\n",
    "**Vector Fields Created**: `title_embedding`, `context_embedding`, `question_embedding` (768 dimensions each)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c3fc44",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bb0b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Get the current working directory of the notebook\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "DATA_DIR = os.path.abspath(os.path.join(current_dir, '../../0. DATA'))\n",
    "\n",
    "# Construct the path to the directory levels up\n",
    "module_paths = [os.path.abspath(os.path.join(current_dir, '../../')),] \n",
    "\n",
    "# Add the module path to sys.path if it's not already there\n",
    "for module_path in module_paths:\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "try:\n",
    "    import helpers as hp\n",
    "except ImportError as e:\n",
    "    raise ImportError(f\"Error importing modules: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a39a322",
   "metadata": {},
   "source": [
    "## üê≥ Docker Setup\n",
    "- **If docker compose up fails , start it manually from shell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec0de4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting fully optimized OpenSearch cluster...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "time=\"2025-11-03T10:06:25-05:00\" level=warning msg=\"The \\\"LD_LIBRARY_PATH\\\" variable is not set. Defaulting to a blank string.\"\n",
      "time=\"2025-11-03T10:06:25-05:00\" level=warning msg=\"The \\\"LD_LIBRARY_PATH\\\" variable is not set. Defaulting to a blank string.\"\n",
      " Network 3ingest_and_search_concepts_opensearch-net  Creating\n",
      " Network 3ingest_and_search_concepts_opensearch-net  Created\n",
      " Volume \"3ingest_and_search_concepts_opensearch-data\"  Creating\n",
      " Volume \"3ingest_and_search_concepts_opensearch-data\"  Created\n",
      " Container opensearch-node1  Creating\n",
      " Container opensearch-dashboards  Creating\n",
      " Container opensearch-dashboards  Created\n",
      " Container opensearch-node1  Created\n",
      " Container opensearch-dashboards  Starting\n",
      " Container opensearch-node1  Starting\n",
      " Container opensearch-dashboards  Started\n",
      " Container opensearch-node1  Started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Waiting for cluster to initialize...\n",
      "üè• Checking cluster health...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   536  100   536    0     0   2335      0 --:--:-- --:--:-- --:--:--  2340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"cluster_name\" : \"docker-cluster\",\n",
      "  \"status\" : \"green\",\n",
      "  \"timed_out\" : false,\n",
      "  \"number_of_nodes\" : 1,\n",
      "  \"number_of_data_nodes\" : 1,\n",
      "  \"discovered_master\" : true,\n",
      "  \"discovered_cluster_manager\" : true,\n",
      "  \"active_primary_shards\" : 4,\n",
      "  \"active_shards\" : 4,\n",
      "  \"relocating_shards\" : 0,\n",
      "  \"initializing_shards\" : 0,\n",
      "  \"unassigned_shards\" : 0,\n",
      "  \"delayed_unassigned_shards\" : 0,\n",
      "  \"number_of_pending_tasks\" : 0,\n",
      "  \"number_of_in_flight_fetch\" : 0,\n",
      "  \"task_max_waiting_in_queue_millis\" : 0,\n",
      "  \"active_shards_percent_as_number\" : 100.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ../..\n",
    "echo \"üöÄ Starting fully optimized OpenSearch cluster...\"\n",
    "\n",
    "# Start the optimized cluster\n",
    "docker compose -f docker-compose-opensearch-single.yml down -v\n",
    "docker compose -f docker-compose-opensearch-single.yml up -d\n",
    "\n",
    "# Wait for startup\n",
    "echo \"‚è≥ Waiting for cluster to initialize...\"\n",
    "sleep 45\n",
    "\n",
    "# Check cluster health\n",
    "echo \"üè• Checking cluster health...\"\n",
    "curl -k -u admin:Developer@123 https://localhost:9200/_cluster/health?pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc735af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to OpenSearch cluster\n"
     ]
    }
   ],
   "source": [
    "from opensearchpy import OpenSearch\n",
    "from opensearch_py_ml.ml_commons import MLCommonClient\n",
    "import time\n",
    "import pandas as pd\n",
    "from opensearchpy import OpenSearch, helpers\n",
    "\n",
    "IS_AUTH = True # Set to False if security is disabled\n",
    "HOST = 'localhost'  # Replace with your OpenSearch host, if running everything locally use 'localhost'\n",
    "\n",
    "if IS_AUTH:\n",
    "    # Initialize the OpenSearch client\n",
    "    os_client = OpenSearch(\n",
    "        hosts=[{'host': HOST, 'port': 9200}],\n",
    "        http_auth=('admin', 'Developer@123'),  # Replace with your credentials\n",
    "        use_ssl=True,\n",
    "        verify_certs=False,\n",
    "        ssl_show_warn=False\n",
    "    )\n",
    "else:\n",
    "    # Initialize the OpenSearch client without authentication\n",
    "    os_client = OpenSearch(\n",
    "        hosts=[{'host': HOST, 'port': 9200}],\n",
    "        use_ssl=False,\n",
    "        verify_certs=False,\n",
    "        ssl_assert_hostname = False,\n",
    "        ssl_show_warn=False\n",
    "    )\n",
    "\n",
    "# Initialize ML Commons client\n",
    "ml_client = MLCommonClient(os_client)\n",
    "\n",
    "# Check if cluster is up\n",
    "if (os_client.ping()):\n",
    "    print(\"Connected to OpenSearch cluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f948126e",
   "metadata": {},
   "source": [
    "## Read SQUAD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0cab0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id is unique i.e. primary key\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index        0.000126\n",
       "id           6.098487\n",
       "title        5.291620\n",
       "context     83.031409\n",
       "question     9.089622\n",
       "answers     16.039856\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total memory usage: 119.55 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.output_area pre {white-space: pre-wrap; word-break: break-word;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the SQuAD training dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>{'text': ['a copper statue of Christ'], 'answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>{'text': ['the Main Building'], 'answer_start'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>{'text': ['a Marian place of prayer and reflec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>{'text': ['a golden statue of the Virgin Mary'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                     title  \\\n",
       "0  5733be284776f41900661182  University_of_Notre_Dame   \n",
       "1  5733be284776f4190066117f  University_of_Notre_Dame   \n",
       "2  5733be284776f41900661180  University_of_Notre_Dame   \n",
       "3  5733be284776f41900661181  University_of_Notre_Dame   \n",
       "4  5733be284776f4190066117e  University_of_Notre_Dame   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                             answers  \n",
       "0  {'text': ['Saint Bernadette Soubirous'], 'answ...  \n",
       "1  {'text': ['a copper statue of Christ'], 'answe...  \n",
       "2  {'text': ['the Main Building'], 'answer_start'...  \n",
       "3  {'text': ['a Marian place of prayer and reflec...  \n",
       "4  {'text': ['a golden statue of the Virgin Mary'...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One row as dictionary:\n",
      "{\n",
      "    \"id\": \"5733be284776f41900661182\",\n",
      "    \"title\": \"University_of_Notre_Dame\",\n",
      "    \"context\": \"Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \\\"Venite Ad Me Omnes\\\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\",\n",
      "    \"question\": \"To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\",\n",
      "    \"answers\": {\n",
      "        \"text\": [\n",
      "            \"Saint Bernadette Soubirous\"\n",
      "        ],\n",
      "        \"answer_start\": [\n",
      "            515\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import json\n",
    "df_squad_train = pd.read_parquet(f\"{DATA_DIR}/SQUAD-train.parquet\")\n",
    "\n",
    "# Check id is unique i.e. count of rows is same as count of unique ids\n",
    "if {len(df_squad_train)} == {df_squad_train['id'].nunique()}:\n",
    "    print(\"id is unique i.e. primary key\")\n",
    "else:\n",
    "    print(\"id is not unique\")\n",
    "\n",
    "# Print pandas memory usage in MB\n",
    "memory_usage = df_squad_train.memory_usage(deep=True)\n",
    "memory_usage_mb = memory_usage / (1024 * 1024)\n",
    "display(memory_usage_mb)\n",
    "print(f\"\\nTotal memory usage: {memory_usage_mb.sum():.2f} MB\")\n",
    "\n",
    "# Enable word wrap for better readability in Jupyter Notebook\n",
    "display(HTML(\"<style>.output_area pre {white-space: pre-wrap; word-break: break-word;}</style>\")) \n",
    "# Display the first few rows of the dataframe\n",
    "print(\"First few rows of the SQuAD training dataset:\")\n",
    "display(df_squad_train.head())\n",
    "\n",
    "# Print one row as dictionary pretty print\n",
    "print(\"One row as dictionary:\")\n",
    "import numpy as np\n",
    "\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(item) for item in obj]\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "row_dict = df_squad_train.iloc[0].to_dict()\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(json.dumps(convert_to_serializable(row_dict), indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc90a9e",
   "metadata": {},
   "source": [
    "## Understanding Unicode Characters in JSON Output\n",
    "\n",
    "When displaying JSON data that contains special characters (like accented letters, non-Latin scripts, etc.), we use `ensure_ascii=False` in `json.dumps()`.\n",
    "\n",
    "**Why?**\n",
    "- By default, `json.dumps()` escapes all non-ASCII characters (e.g., `√°` becomes `\\u00e1`)\n",
    "- With `ensure_ascii=False`, special characters are displayed in their actual form\n",
    "- This makes the output much more readable for international text\n",
    "\n",
    "**Example:**\n",
    "- ‚ùå Without `ensure_ascii=False`: `\"Bansk\\u00e1 Akad\\u00e9mia\"`\n",
    "- ‚úÖ With `ensure_ascii=False`: `\"Bansk√° Akad√©mia\"`\n",
    "\n",
    "Both representations are valid JSON, but the second is more human-readable!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6620266a",
   "metadata": {},
   "source": [
    "## Create Generic Function to Generate OpenSearch Mappings from DataFrame\n",
    "\n",
    "This function analyzes a pandas DataFrame and automatically generates OpenSearch index mappings based on the column data types.\n",
    "\n",
    "**Key Features:**\n",
    "- Maps pandas dtypes to appropriate OpenSearch field types\n",
    "- Optionally creates corresponding `knn_vector` fields for text columns to support semantic search\n",
    "- The vector fields are configured with:\n",
    "  - Dimensions: 768 (standard for many embedding models)\n",
    "  - Method: HNSW (Hierarchical Navigable Small World graphs)\n",
    "  - Space type: L2 (Euclidean distance)\n",
    "  - Engine: Lucene\n",
    "- Handles nested objects and arrays by using the `nested` type\n",
    "- Returns a complete index body structure ready for index creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faf7ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_opensearch_mappings(df, create_vectors=False, pipeline_name=None, exclude_from_vectors=None):\n",
    "    \"\"\"\n",
    "    Create OpenSearch index mappings from a pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame to generate mappings from\n",
    "    create_vectors : bool, default=False\n",
    "        If True, creates corresponding knn_vector fields for text columns\n",
    "        with dimensions=768, method=hnsw, space_type=l2, engine=lucene\n",
    "    pipeline_name : str, optional\n",
    "        If provided, sets this as the default_pipeline in index settings.\n",
    "        Used for automatic embedding generation during ingestion.\n",
    "    exclude_from_vectors : list of str, optional\n",
    "        List of field names to exclude from vector creation.\n",
    "        Default is ['id', 'title'] if not provided.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        A dictionary containing the index body with mappings suitable for \n",
    "        OpenSearch index creation\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    >>> mappings = create_opensearch_mappings(df, create_vectors=True, exclude_from_vectors=['id', 'title', 'metadata'])\n",
    "    >>> os_client.indices.create(index='my_index', body=mappings)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    # Set default exclusion list if not provided\n",
    "    if exclude_from_vectors is None:\n",
    "        exclude_from_vectors = ['id']\n",
    "    \n",
    "    # Define dtype mapping from pandas to OpenSearch\n",
    "    dtype_mapping = {\n",
    "        'int64': 'long',\n",
    "        'int32': 'integer',\n",
    "        'int16': 'short',\n",
    "        'int8': 'byte',\n",
    "        'float64': 'double',\n",
    "        'float32': 'float',\n",
    "        'bool': 'boolean',\n",
    "        'datetime64[ns]': 'date',\n",
    "        'object': 'text',  # Default for object types (strings)\n",
    "    }\n",
    "    \n",
    "    properties = {}\n",
    "    \n",
    "    for column in df.columns:\n",
    "        dtype_str = str(df[column].dtype)\n",
    "        \n",
    "        # Handle datetime types\n",
    "        if 'datetime' in dtype_str:\n",
    "            properties[column] = {'type': 'date'}\n",
    "        \n",
    "        # Handle boolean\n",
    "        elif dtype_str == 'bool':\n",
    "            properties[column] = {'type': 'boolean'}\n",
    "        \n",
    "        # Handle numeric types\n",
    "        elif dtype_str in ['int64', 'int32', 'int16', 'int8']:\n",
    "            properties[column] = {'type': dtype_mapping.get(dtype_str, 'long')}\n",
    "        \n",
    "        elif dtype_str in ['float64', 'float32']:\n",
    "            properties[column] = {'type': dtype_mapping.get(dtype_str, 'double')}\n",
    "        \n",
    "        # Handle object types (strings, nested structures)\n",
    "        elif dtype_str == 'object':\n",
    "            # Check if column contains nested structures (dict/list)\n",
    "            sample_value = df[column].dropna().iloc[0] if not df[column].dropna().empty else None\n",
    "            \n",
    "            if isinstance(sample_value, (dict, list)):\n",
    "                # Use nested type for complex structures\n",
    "                properties[column] = {'type': 'nested'}\n",
    "            else:\n",
    "                # Standard text field with keyword sub-field\n",
    "                properties[column] = {\n",
    "                    'type': 'text',\n",
    "                    'fields': {\n",
    "                        'keyword': {\n",
    "                            'type': 'keyword',\n",
    "                            'ignore_above': 256\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                # Optionally create vector field for text columns\n",
    "                # Exclude specified fields from vector creation\n",
    "                if create_vectors and column not in exclude_from_vectors:\n",
    "                    vector_field_name = f\"{column}_embedding\"\n",
    "                    properties[vector_field_name] = {\n",
    "                        'type': 'knn_vector',\n",
    "                        'dimension': 768,\n",
    "                        'method': {\n",
    "                            'name': 'hnsw',\n",
    "                            'space_type': 'l2',\n",
    "                            'engine': 'lucene',\n",
    "                            'parameters': {}\n",
    "                        }\n",
    "                    }\n",
    "        \n",
    "        # Default fallback\n",
    "        else:\n",
    "            properties[column] = {'type': 'text'}\n",
    "    \n",
    "    # Create the settings object\n",
    "    settings = {\n",
    "        'index': {\n",
    "            'number_of_shards': 1,\n",
    "            'number_of_replicas': 1,\n",
    "            'knn': create_vectors  # Enable k-NN only if vectors are being created\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Add default_pipeline if provided\n",
    "    if pipeline_name:\n",
    "        settings['default_pipeline'] = pipeline_name\n",
    "    \n",
    "    # Create the complete index body\n",
    "    index_body = {\n",
    "        'settings': settings,\n",
    "        'mappings': {\n",
    "            'properties': properties\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return index_body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eca125",
   "metadata": {},
   "source": [
    "## Sample SQUAD Dataset and Generate Mappings\n",
    "\n",
    "Sample 1000 rows from the SQUAD training dataset to create a smaller dataset for testing.\n",
    "Then generate OpenSearch mappings without vector fields (create_vectors=False) to see the basic mapping structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95d915f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 87599 rows\n",
      "Sampled dataset size: 1000 rows\n",
      "\n",
      "Dataset columns: ['id', 'title', 'context', 'question', 'answers']\n",
      "Dataset dtypes:\n",
      "id          object\n",
      "title       object\n",
      "context     object\n",
      "question    object\n",
      "answers     object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56de4d9ecffd8e1900b4b7e2</td>\n",
       "      <td>Institute_of_technology</td>\n",
       "      <td>The world's first institution of technology or technical university with tertiary technical education is the Bansk√° Akad√©mia in Bansk√° ≈†tiavnica, Slovakia, founded in 1735, Academy since December 13, 1762 established by queen Maria Theresa in order to train specialists of silver and gold mining and metallurgy in neighbourhood. Teaching started in 1764. Later the department of Mathematics, Mechanics and Hydraulics and department of Forestry were settled. University buildings are still at their place today and are used for teaching. University has launched the first book of electrotechnics in the world.</td>\n",
       "      <td>What year was the Bansk√° Akad√©mia founded?</td>\n",
       "      <td>{'text': ['1735'], 'answer_start': [167]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>572674a05951b619008f7319</td>\n",
       "      <td>Film_speed</td>\n",
       "      <td>The standard specifies how speed ratings should be reported by the camera. If the noise-based speed (40:1) is higher than the saturation-based speed, the noise-based speed should be reported, rounded downwards to a standard value (e.g. 200, 250, 320, or 400). The rationale is that exposure according to the lower saturation-based speed would not result in a visibly better image. In addition, an exposure latitude can be specified, ranging from the saturation-based speed to the 10:1 noise-based speed. If the noise-based speed (40:1) is lower than the saturation-based speed, or undefined because of high noise, the saturation-based speed is specified, rounded upwards to a standard value, because using the noise-based speed would lead to overexposed images. The camera may also report the SOS-based speed (explicitly as being an SOS speed), rounded to the nearest standard speed rating.</td>\n",
       "      <td>What is another speed that can also be reported by the camera?</td>\n",
       "      <td>{'text': ['SOS-based speed'], 'answer_start': [793]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5730bb058ab72b1400f9c72c</td>\n",
       "      <td>Sumer</td>\n",
       "      <td>The most impressive and famous of Sumerian buildings are the ziggurats, large layered platforms which supported temples. Sumerian cylinder seals also depict houses built from reeds not unlike those built by the Marsh Arabs of Southern Iraq until as recently as 400 CE. The Sumerians also developed the arch, which enabled them to develop a strong type of dome. They built this by constructing and linking several arches. Sumerian temples and palaces made use of more advanced materials and techniques,[citation needed] such as buttresses, recesses, half columns, and clay nails.</td>\n",
       "      <td>Where were the use of advanced materials and techniques on display in Sumer?</td>\n",
       "      <td>{'text': ['Sumerian temples and palaces'], 'answer_start': [421]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>572781a5f1498d1400e8fa1f</td>\n",
       "      <td>Ann_Arbor,_Michigan</td>\n",
       "      <td>Ann Arbor has a council-manager form of government. The City Council has 11 voting members: the mayor and 10 city council members. The mayor and city council members serve two-year terms: the mayor is elected every even-numbered year, while half of the city council members are up for election annually (five in even-numbered and five in odd-numbered years). Two council members are elected from each of the city's five wards. The mayor is elected citywide. The mayor is the presiding officer of the City Council and has the power to appoint all Council committee members as well as board and commission members, with the approval of the City Council. The current mayor of Ann Arbor is Christopher Taylor, a Democrat who was elected as mayor in 2014. Day-to-day city operations are managed by a city administrator chosen by the city council.</td>\n",
       "      <td>Who is elected every even numbered year?</td>\n",
       "      <td>{'text': ['mayor'], 'answer_start': [192]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>572843ce4b864d190016485c</td>\n",
       "      <td>John_von_Neumann</td>\n",
       "      <td>Shortly before his death, when he was already quite ill, von Neumann headed the United States government's top secret ICBM committee, and it would sometimes meet in his home. Its purpose was to decide on the feasibility of building an ICBM large enough to carry a thermonuclear weapon. Von Neumann had long argued that while the technical obstacles were sizable, they could be overcome in time. The SM-65 Atlas passed its first fully functional test in 1959, two years after his death. The feasibility of an ICBM owed as much to improved, smaller warheads as it did to developments in rocketry, and his understanding of the former made his advice invaluable.</td>\n",
       "      <td>What was the purpose of top secret ICBM committee?</td>\n",
       "      <td>{'text': ['decide on the feasibility of building an ICBM large enough to carry a thermonuclear weapon'], 'answer_start': [194]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                    title                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     context  \\\n",
       "0  56de4d9ecffd8e1900b4b7e2  Institute_of_technology                                                                                                                                                                                                                                                                                            The world's first institution of technology or technical university with tertiary technical education is the Bansk√° Akad√©mia in Bansk√° ≈†tiavnica, Slovakia, founded in 1735, Academy since December 13, 1762 established by queen Maria Theresa in order to train specialists of silver and gold mining and metallurgy in neighbourhood. Teaching started in 1764. Later the department of Mathematics, Mechanics and Hydraulics and department of Forestry were settled. University buildings are still at their place today and are used for teaching. University has launched the first book of electrotechnics in the world.   \n",
       "1  572674a05951b619008f7319               Film_speed  The standard specifies how speed ratings should be reported by the camera. If the noise-based speed (40:1) is higher than the saturation-based speed, the noise-based speed should be reported, rounded downwards to a standard value (e.g. 200, 250, 320, or 400). The rationale is that exposure according to the lower saturation-based speed would not result in a visibly better image. In addition, an exposure latitude can be specified, ranging from the saturation-based speed to the 10:1 noise-based speed. If the noise-based speed (40:1) is lower than the saturation-based speed, or undefined because of high noise, the saturation-based speed is specified, rounded upwards to a standard value, because using the noise-based speed would lead to overexposed images. The camera may also report the SOS-based speed (explicitly as being an SOS speed), rounded to the nearest standard speed rating.   \n",
       "2  5730bb058ab72b1400f9c72c                    Sumer                                                                                                                                                                                                                                                                                                                          The most impressive and famous of Sumerian buildings are the ziggurats, large layered platforms which supported temples. Sumerian cylinder seals also depict houses built from reeds not unlike those built by the Marsh Arabs of Southern Iraq until as recently as 400 CE. The Sumerians also developed the arch, which enabled them to develop a strong type of dome. They built this by constructing and linking several arches. Sumerian temples and palaces made use of more advanced materials and techniques,[citation needed] such as buttresses, recesses, half columns, and clay nails.   \n",
       "3  572781a5f1498d1400e8fa1f      Ann_Arbor,_Michigan                                                   Ann Arbor has a council-manager form of government. The City Council has 11 voting members: the mayor and 10 city council members. The mayor and city council members serve two-year terms: the mayor is elected every even-numbered year, while half of the city council members are up for election annually (five in even-numbered and five in odd-numbered years). Two council members are elected from each of the city's five wards. The mayor is elected citywide. The mayor is the presiding officer of the City Council and has the power to appoint all Council committee members as well as board and commission members, with the approval of the City Council. The current mayor of Ann Arbor is Christopher Taylor, a Democrat who was elected as mayor in 2014. Day-to-day city operations are managed by a city administrator chosen by the city council.   \n",
       "4  572843ce4b864d190016485c         John_von_Neumann                                                                                                                                                                                                                                          Shortly before his death, when he was already quite ill, von Neumann headed the United States government's top secret ICBM committee, and it would sometimes meet in his home. Its purpose was to decide on the feasibility of building an ICBM large enough to carry a thermonuclear weapon. Von Neumann had long argued that while the technical obstacles were sizable, they could be overcome in time. The SM-65 Atlas passed its first fully functional test in 1959, two years after his death. The feasibility of an ICBM owed as much to improved, smaller warheads as it did to developments in rocketry, and his understanding of the former made his advice invaluable.   \n",
       "\n",
       "                                                                       question                                                                                                                          answers  \n",
       "0                                    What year was the Bansk√° Akad√©mia founded?                                                                                        {'text': ['1735'], 'answer_start': [167]}  \n",
       "1                What is another speed that can also be reported by the camera?                                                                             {'text': ['SOS-based speed'], 'answer_start': [793]}  \n",
       "2  Where were the use of advanced materials and techniques on display in Sumer?                                                                {'text': ['Sumerian temples and palaces'], 'answer_start': [421]}  \n",
       "3                                      Who is elected every even numbered year?                                                                                       {'text': ['mayor'], 'answer_start': [192]}  \n",
       "4                            What was the purpose of top secret ICBM committee?  {'text': ['decide on the feasibility of building an ICBM large enough to carry a thermonuclear weapon'], 'answer_start': [194]}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample 1000 rows from the SQUAD training dataset\n",
    "df_squad_sample = df_squad_train.sample(n=1000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Original dataset size: {len(df_squad_train)} rows\")\n",
    "print(f\"Sampled dataset size: {len(df_squad_sample)} rows\")\n",
    "print(f\"\\nDataset columns: {list(df_squad_sample.columns)}\")\n",
    "print(f\"Dataset dtypes:\\n{df_squad_sample.dtypes}\")\n",
    "\n",
    "# Display the first few rows of the sampled dataset\n",
    "display(df_squad_sample.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2324667",
   "metadata": {},
   "source": [
    "## Create Index and Ingest Data Without Vector Fields\n",
    "\n",
    "Generate OpenSearch mappings for the sampled dataset with `create_vectors=False`, create the index, and ingest the data.\n",
    "\n",
    "**Steps:**\n",
    "1. Generate mappings without vector fields\n",
    "2. Delete the index if it already exists\n",
    "3. Create a new index with the generated mappings\n",
    "4. Prepare data for bulk ingestion\n",
    "5. Use async bulk helpers to efficiently ingest 1000 documents\n",
    "6. Verify the ingestion by checking document count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6071b2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated OpenSearch mappings (without vector fields):\n",
      "{\n",
      "  \"settings\": {\n",
      "    \"index\": {\n",
      "      \"number_of_shards\": 1,\n",
      "      \"number_of_replicas\": 1,\n",
      "      \"knn\": false\n",
      "    }\n",
      "  },\n",
      "  \"mappings\": {\n",
      "    \"properties\": {\n",
      "      \"id\": {\n",
      "        \"type\": \"text\",\n",
      "        \"fields\": {\n",
      "          \"keyword\": {\n",
      "            \"type\": \"keyword\",\n",
      "            \"ignore_above\": 256\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"title\": {\n",
      "        \"type\": \"text\",\n",
      "        \"fields\": {\n",
      "          \"keyword\": {\n",
      "            \"type\": \"keyword\",\n",
      "            \"ignore_above\": 256\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"context\": {\n",
      "        \"type\": \"text\",\n",
      "        \"fields\": {\n",
      "          \"keyword\": {\n",
      "            \"type\": \"keyword\",\n",
      "            \"ignore_above\": 256\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"question\": {\n",
      "        \"type\": \"text\",\n",
      "        \"fields\": {\n",
      "          \"keyword\": {\n",
      "            \"type\": \"keyword\",\n",
      "            \"ignore_above\": 256\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"answers\": {\n",
      "        \"type\": \"nested\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "============================================================\n",
      "Creating index: squad_sample_no_vectors\n",
      "Index created successfully: {'acknowledged': True, 'shards_acknowledged': True, 'index': 'squad_sample_no_vectors'}\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Starting bulk ingestion of 1000 documents...\n",
      "Bulk ingestion completed in 0.23 seconds\n",
      "Successfully indexed: 1000 documents\n",
      "Failed: [] documents\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Total documents in index 'squad_sample_no_vectors': 1000\n",
      "============================================================\n",
      "\n",
      "Sample document from index:\n",
      "{\n",
      "  \"_index\": \"squad_sample_no_vectors\",\n",
      "  \"_id\": \"56de4d9ecffd8e1900b4b7e2\",\n",
      "  \"_score\": 1.0,\n",
      "  \"_source\": {\n",
      "    \"id\": \"56de4d9ecffd8e1900b4b7e2\",\n",
      "    \"title\": \"Institute_of_technology\",\n",
      "    \"context\": \"The world's first institution of technology or technical university with tertiary technical education is the Bansk√° Akad√©mia in Bansk√° ≈†tiavnica, Slovakia, founded in 1735, Academy since December 13, 1762 established by queen Maria Theresa in order to train specialists of silver and gold mining and metallurgy in neighbourhood. Teaching started in 1764. Later the department of Mathematics, Mechanics and Hydraulics and department of Forestry were settled. University buildings are still at their place today and are used for teaching. University has launched the first book of electrotechnics in the world.\",\n",
      "    \"question\": \"What year was the Bansk√° Akad√©mia founded?\",\n",
      "    \"answers\": {\n",
      "      \"text\": [\n",
      "        \"1735\"\n",
      "      ],\n",
      "      \"answer_start\": [\n",
      "        167\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "CPU times: user 47 ms, sys: 997 Œºs, total: 48 ms\n",
      "Wall time: 1.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Define index name\n",
    "index_name = \"squad_sample_no_vectors\"\n",
    "\n",
    "# Step 1: Generate mappings without vector fields\n",
    "mappings_without_vectors = create_opensearch_mappings(df_squad_sample, create_vectors=False)\n",
    "\n",
    "print(\"Generated OpenSearch mappings (without vector fields):\")\n",
    "print(json.dumps(mappings_without_vectors, indent=2))\n",
    "\n",
    "# Step 2: Delete index if it exists\n",
    "if os_client.indices.exists(index=index_name):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Deleting existing index: {index_name}\")\n",
    "    os_client.indices.delete(index=index_name)\n",
    "    print(f\"Index deleted successfully\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "# Step 3: Create the index with mappings\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Creating index: {index_name}\")\n",
    "response = os_client.indices.create(index=index_name, body=mappings_without_vectors)\n",
    "print(f\"Index created successfully: {response}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Step 4: Prepare data for bulk ingestion\n",
    "def generate_bulk_data(df, index_name):\n",
    "    \"\"\"\n",
    "    Generator function to prepare data for bulk ingestion.\n",
    "    Yields documents in the format required by opensearch helpers.bulk()\n",
    "    \"\"\"\n",
    "    for idx, row in df.iterrows():\n",
    "        # Convert row to dictionary\n",
    "        doc = row.to_dict()\n",
    "        \n",
    "        # Convert numpy types to native Python types\n",
    "        for key, value in doc.items():\n",
    "            if isinstance(value, (np.integer, np.floating)):\n",
    "                doc[key] = value.item()\n",
    "            elif isinstance(value, np.ndarray):\n",
    "                doc[key] = value.tolist()\n",
    "        \n",
    "        # Yield document with index name and _id\n",
    "        yield {\n",
    "            \"_index\": index_name,\n",
    "            \"_id\": doc.get('id', idx),  # Use 'id' field if available, otherwise use index\n",
    "            \"_source\": doc\n",
    "        }\n",
    "\n",
    "# Step 5: Bulk ingest using async helpers for better performance\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Starting bulk ingestion of {len(df_squad_sample)} documents...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Use bulk helper for async ingestion\n",
    "success, failed = helpers.bulk(\n",
    "    os_client,\n",
    "    generate_bulk_data(df_squad_sample, index_name),\n",
    "    chunk_size=500,  # Process 500 documents at a time\n",
    "    request_timeout=60,\n",
    "    raise_on_error=False,\n",
    "    raise_on_exception=False\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Bulk ingestion completed in {elapsed_time:.2f} seconds\")\n",
    "print(f\"Successfully indexed: {success} documents\")\n",
    "print(f\"Failed: {failed} documents\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Step 6: Verify ingestion\n",
    "time.sleep(1)  # Wait for refresh\n",
    "os_client.indices.refresh(index=index_name)\n",
    "count_response = os_client.count(index=index_name)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Total documents in index '{index_name}': {count_response['count']}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Show a sample document\n",
    "search_response = os_client.search(index=index_name, body={\"query\": {\"match_all\": {}}, \"size\": 1})\n",
    "print(f\"\\nSample document from index:\")\n",
    "print(json.dumps(search_response['hits']['hits'][0], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8c1d89",
   "metadata": {},
   "source": [
    "## Create Index with Vector Fields (Manual Approach - No Pipeline)\n",
    "\n",
    "Generate OpenSearch mappings with `create_vectors=True`, create the index, and ingest the data WITHOUT an ingest pipeline.\n",
    "\n",
    "**Important:** This approach creates vector fields but does NOT generate embeddings automatically. The embedding fields will be empty unless you manually generate and provide embeddings during ingestion.\n",
    "\n",
    "**Steps:**\n",
    "1. Generate mappings with vector fields enabled (no pipeline)\n",
    "2. Delete the index if it already exists\n",
    "3. Create a new index with vector-enabled mappings\n",
    "4. Use async bulk helpers to efficiently ingest 1000 documents\n",
    "5. Verify the ingestion and show field count comparison\n",
    "\n",
    "**Use Case:** This approach is useful when:\n",
    "- You want to generate embeddings externally (e.g., using a custom Python model)\n",
    "- You need to pre-process or cache embeddings before ingestion\n",
    "- You want to use a different embedding model than what's deployed in OpenSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "580ed981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated OpenSearch mappings (WITH vector fields):\n",
      "{\n",
      "  \"settings\": {\n",
      "    \"index\": {\n",
      "      \"number_of_shards\": 1,\n",
      "      \"number_of_replicas\": 1,\n",
      "      \"knn\": true\n",
      "    }\n",
      "  },\n",
      "  \"mappings\": {\n",
      "    \"properties\": {\n",
      "      \"id\": {\n",
      "        \"type\": \"text\",\n",
      "        \"fields\": {\n",
      "          \"keyword\": {\n",
      "            \"type\": \"keyword\",\n",
      "            \"ignore_above\": 256\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"title\": {\n",
      "        \"type\": \"text\",\n",
      "        \"fields\": {\n",
      "          \"keyword\": {\n",
      "            \"type\": \"keyword\",\n",
      "            \"ignore_above\": 256\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"title_embedding\": {\n",
      "        \"type\": \"knn_vector\",\n",
      "        \"dimension\": 768,\n",
      "        \"method\": {\n",
      "          \"name\": \"hnsw\",\n",
      "          \"space_type\": \"l2\",\n",
      "          \"engine\": \"lucene\",\n",
      "          \"parameters\": {}\n",
      "        }\n",
      "      },\n",
      "      \"context\": {\n",
      "        \"type\": \"text\",\n",
      "        \"fields\": {\n",
      "          \"keyword\": {\n",
      "            \"type\": \"keyword\",\n",
      "            \"ignore_above\": 256\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"context_embedding\": {\n",
      "        \"type\": \"knn_vector\",\n",
      "        \"dimension\": 768,\n",
      "        \"method\": {\n",
      "          \"name\": \"hnsw\",\n",
      "          \"space_type\": \"l2\",\n",
      "          \"engine\": \"lucene\",\n",
      "          \"parameters\": {}\n",
      "        }\n",
      "      },\n",
      "      \"question\": {\n",
      "        \"type\": \"text\",\n",
      "        \"fields\": {\n",
      "          \"keyword\": {\n",
      "            \"type\": \"keyword\",\n",
      "            \"ignore_above\": 256\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"question_embedding\": {\n",
      "        \"type\": \"knn_vector\",\n",
      "        \"dimension\": 768,\n",
      "        \"method\": {\n",
      "          \"name\": \"hnsw\",\n",
      "          \"space_type\": \"l2\",\n",
      "          \"engine\": \"lucene\",\n",
      "          \"parameters\": {}\n",
      "        }\n",
      "      },\n",
      "      \"answers\": {\n",
      "        \"type\": \"nested\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "============================================================\n",
      "Number of fields without vectors: 5\n",
      "Number of fields with vectors: 8\n",
      "Additional vector fields created: 3\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Creating index: squad_sample_with_vectors\n",
      "Index created successfully: {'acknowledged': True, 'shards_acknowledged': True, 'index': 'squad_sample_with_vectors'}\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Starting bulk ingestion of 1000 documents...\n",
      "Bulk ingestion completed in 0.17 seconds\n",
      "Successfully indexed: 1000 documents\n",
      "Failed: [] documents\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Total documents in index 'squad_sample_with_vectors': 1000\n",
      "============================================================\n",
      "\n",
      "Index mappings (showing vector fields):\n",
      "Vector fields created: ['context_embedding', 'question_embedding', 'title_embedding']\n",
      "\n",
      "Sample document from index:\n",
      "{\n",
      "  \"_index\": \"squad_sample_with_vectors\",\n",
      "  \"_id\": \"56de4d9ecffd8e1900b4b7e2\",\n",
      "  \"_score\": 1.0,\n",
      "  \"_source\": {\n",
      "    \"id\": \"56de4d9ecffd8e1900b4b7e2\",\n",
      "    \"title\": \"Institute_of_technology\",\n",
      "    \"context\": \"The world's first institution of technology or technical university with tertiary technical education is the Bansk√° Akad√©mia in Bansk√° ≈†tiavnica, Slovakia, founded in 1735, Academy since December 13, 1762 established by queen Maria Theresa in order to train specialists of silver and gold mining and metallurgy in neighbourhood. Teaching started in 1764. Later the department of Mathematics, Mechanics and Hydraulics and department of Forestry were settled. University buildings are still at their place today and are used for teaching. University has launched the first book of electrotechnics in the world.\",\n",
      "    \"question\": \"What year was the Bansk√° Akad√©mia founded?\",\n",
      "    \"answers\": {\n",
      "      \"text\": [\n",
      "        \"1735\"\n",
      "      ],\n",
      "      \"answer_start\": [\n",
      "        167\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "CPU times: user 41.2 ms, sys: 1.1 ms, total: 42.3 ms\n",
      "Wall time: 1.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Define index name\n",
    "index_name_with_vectors = \"squad_sample_with_vectors\"\n",
    "\n",
    "# Step 1: Generate mappings with vector fields\n",
    "mappings_with_vectors = create_opensearch_mappings(df_squad_sample, create_vectors=True)\n",
    "\n",
    "print(\"Generated OpenSearch mappings (WITH vector fields):\")\n",
    "print(json.dumps(mappings_with_vectors, indent=2, ensure_ascii=False))\n",
    "\n",
    "# Show the difference in field count\n",
    "fields_without = len(mappings_without_vectors['mappings']['properties'])\n",
    "fields_with = len(mappings_with_vectors['mappings']['properties'])\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Number of fields without vectors: {fields_without}\")\n",
    "print(f\"Number of fields with vectors: {fields_with}\")\n",
    "print(f\"Additional vector fields created: {fields_with - fields_without}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Step 2: Delete index if it exists\n",
    "if os_client.indices.exists(index=index_name_with_vectors):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Deleting existing index: {index_name_with_vectors}\")\n",
    "    os_client.indices.delete(index=index_name_with_vectors)\n",
    "    print(f\"Index deleted successfully\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "# Step 3: Create the index with vector-enabled mappings\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Creating index: {index_name_with_vectors}\")\n",
    "response = os_client.indices.create(index=index_name_with_vectors, body=mappings_with_vectors)\n",
    "print(f\"Index created successfully: {response}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Step 4: Bulk ingest using async helpers\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Starting bulk ingestion of {len(df_squad_sample)} documents...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Note: For a production system with vector fields, you would generate embeddings\n",
    "# for text fields before ingestion. This example ingests without embeddings.\n",
    "success, failed = helpers.bulk(\n",
    "    os_client,\n",
    "    generate_bulk_data(df_squad_sample, index_name_with_vectors),\n",
    "    chunk_size=500,\n",
    "    request_timeout=60,\n",
    "    raise_on_error=False,\n",
    "    raise_on_exception=False\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Bulk ingestion completed in {elapsed_time:.2f} seconds\")\n",
    "print(f\"Successfully indexed: {success} documents\")\n",
    "print(f\"Failed: {failed} documents\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Step 5: Verify ingestion\n",
    "time.sleep(1)  # Wait for refresh\n",
    "os_client.indices.refresh(index=index_name_with_vectors)\n",
    "count_response = os_client.count(index=index_name_with_vectors)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Total documents in index '{index_name_with_vectors}': {count_response['count']}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Get index mappings to verify vector fields\n",
    "mappings_response = os_client.indices.get_mapping(index=index_name_with_vectors)\n",
    "print(f\"\\nIndex mappings (showing vector fields):\")\n",
    "properties = mappings_response[index_name_with_vectors]['mappings']['properties']\n",
    "vector_fields = [k for k in properties.keys() if k.endswith('_embedding')]\n",
    "print(f\"Vector fields created: {vector_fields}\")\n",
    "\n",
    "# Show a sample document\n",
    "search_response = os_client.search(index=index_name_with_vectors, body={\"query\": {\"match_all\": {}}, \"size\": 1})\n",
    "print(f\"\\nSample document from index:\")\n",
    "print(json.dumps(search_response['hits']['hits'][0], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f039b0c",
   "metadata": {},
   "source": [
    "## Setup ML Model and Ingest Pipeline for Automatic Embeddings\n",
    "\n",
    "Before creating an index with vector fields that automatically generates embeddings, we need to:\n",
    "\n",
    "1. **Register and deploy a pre-trained embedding model** from HuggingFace\n",
    "2. **Create an ingest pipeline** that uses this model to generate embeddings automatically during indexing\n",
    "3. **Configure the index** to use this pipeline as the default pipeline\n",
    "\n",
    "This setup enables automatic embedding generation during document ingestion, eliminating the need to manually create embeddings before indexing.\n",
    "\n",
    "**Model Details:**\n",
    "- Model: `huggingface/sentence-transformers/msmarco-distilbert-base-tas-b`\n",
    "- Version: 1.0.1\n",
    "- Format: TORCH_SCRIPT\n",
    "- Dimensions: 768\n",
    "- Use case: Semantic search, question-answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f258aa",
   "metadata": {},
   "source": [
    "## Configure ML Settings\n",
    "\n",
    "Configure OpenSearch to allow ML operations on data nodes.\n",
    "\n",
    "**Note:** In production environments with dedicated ML nodes, this configuration is not needed. For development/testing, we allow ML operations on data nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "555eb4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ML Configuration Status:\n",
      "================================================================================\n",
      "‚úì ML settings configured successfully\n",
      "  - ML operations allowed on data nodes: True\n",
      "  - Model access control: Disabled\n",
      "  - Native memory threshold: 99%\n",
      "\n",
      "‚úì Cluster is ready for ML model deployment\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Configure cluster to allow ML operations\n",
    "ml_settings = {\n",
    "    \"persistent\": {\n",
    "        \"plugins.ml_commons.only_run_on_ml_node\": False,\n",
    "        \"plugins.ml_commons.model_access_control_enabled\": False,\n",
    "        \"plugins.ml_commons.native_memory_threshold\": 99\n",
    "    }\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = os_client.cluster.put_settings(body=ml_settings)\n",
    "    print(\"=\"*80)\n",
    "    print(\"ML Configuration Status:\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"‚úì ML settings configured successfully\")\n",
    "    print(\"  - ML operations allowed on data nodes: True\")\n",
    "    print(\"  - Model access control: Disabled\")\n",
    "    print(\"  - Native memory threshold: 99%\")\n",
    "    print(\"\\n‚úì Cluster is ready for ML model deployment\")\n",
    "    print(\"=\"*80)\n",
    "except Exception as e:\n",
    "    print(f\"‚ö† Warning: Could not configure ML settings: {e}\")\n",
    "    print(\"  If ML nodes are properly configured, this error can be ignored\")\n",
    "    print(\"  Proceeding with model deployment...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c465015e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Registering and deploying ML model...\n",
      "================================================================================\n",
      "Model was registered successfully. Model Id:  1kdFSpoBL6Mh-OCJpWi8\n",
      "1kdFSpoBL6Mh-OCJpWi8\n",
      "Task ID: 2EdFSpoBL6Mh-OCJ-Wga\n",
      "Model deployed successfully\n",
      "Model ID: 1kdFSpoBL6Mh-OCJpWi8\n",
      "\n",
      "Waiting for model deployment...\n",
      "Current model state: DEPLOYED\n",
      "‚úì Model deployed successfully!\n",
      "\n",
      "================================================================================\n",
      "Model is ready for use\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Register and deploy the sentence transformer model\n",
    "print(\"=\"*80)\n",
    "print(\"Registering and deploying ML model...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "model_response = ml_client.register_pretrained_model(\n",
    "    model_name=\"huggingface/sentence-transformers/msmarco-distilbert-base-tas-b\",\n",
    "    model_version=\"1.0.1\",\n",
    "    model_format=\"TORCH_SCRIPT\",\n",
    "    deploy_model=True,\n",
    "    wait_until_deployed=True\n",
    ")\n",
    "model_id = model_response\n",
    "print(f\"Model ID: {model_id}\")\n",
    "\n",
    "# Step 2: Wait for model to be fully deployed\n",
    "print(\"\\nWaiting for model deployment...\")\n",
    "max_wait_time = 300  # 5 minutes max wait\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    model_info = ml_client.get_model_info(model_id)\n",
    "    model_state = model_info.get('model_state', 'UNKNOWN')\n",
    "    print(f\"Current model state: {model_state}\")\n",
    "    \n",
    "    if model_state == 'DEPLOYED':\n",
    "        print(\"‚úì Model deployed successfully!\")\n",
    "        break\n",
    "    \n",
    "    if time.time() - start_time > max_wait_time:\n",
    "        print(\"‚ö† Warning: Model deployment timeout. Proceeding anyway...\")\n",
    "        break\n",
    "    \n",
    "    time.sleep(5)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Model is ready for use\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbd3555",
   "metadata": {},
   "source": [
    "## Create Ingest Pipeline for Automatic Embedding Generation\n",
    "\n",
    "Create an ingest pipeline that automatically generates embeddings for text fields during document ingestion.\n",
    "\n",
    "The pipeline uses the `text_embedding` processor which:\n",
    "- Takes text from specified source fields\n",
    "- Generates 768-dimensional embeddings using the deployed model\n",
    "- Stores embeddings in corresponding vector fields\n",
    "- Runs automatically for every document ingested into indices using this pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e13d5b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing pipeline: squad_embedding_pipeline\n",
      "‚úì Ingest pipeline created: squad_embedding_pipeline\n",
      "  Text fields to embed: ['title', 'context', 'question']\n",
      "  Excluded fields: ['id']\n",
      "  Field mappings: {'title': 'title_embedding', 'context': 'context_embedding', 'question': 'question_embedding'}\n",
      "\n",
      "================================================================================\n",
      "Pipeline 'squad_embedding_pipeline' is ready to use\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create a dynamic ingest pipeline based on text fields in the DataFrame\n",
    "def create_embedding_pipeline(df, model_id, pipeline_name=\"squad_embedding_pipeline\", exclude_from_embeddings=None):\n",
    "    \"\"\"\n",
    "    Create an ingest pipeline that generates embeddings for text fields.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame to analyze for text fields\n",
    "    model_id : str\n",
    "        The ID of the deployed ML model\n",
    "    pipeline_name : str\n",
    "        Name for the ingest pipeline\n",
    "    exclude_from_embeddings : list of str, optional\n",
    "        List of field names to exclude from embedding generation.\n",
    "        Default is ['id'] if not provided.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str : The pipeline name\n",
    "    \"\"\"\n",
    "    # Set default exclusion list if not provided\n",
    "    if exclude_from_embeddings is None:\n",
    "        exclude_from_embeddings = ['id']\n",
    "    \n",
    "    # Identify text fields (excluding nested structures and excluded fields)\n",
    "    text_fields = []\n",
    "    for column in df.columns:\n",
    "        dtype_str = str(df[column].dtype)\n",
    "        if dtype_str == 'object':\n",
    "            sample_value = df[column].dropna().iloc[0] if not df[column].dropna().empty else None\n",
    "            if not isinstance(sample_value, (dict, list)) and column not in exclude_from_embeddings:\n",
    "                text_fields.append(column)\n",
    "    \n",
    "    # Create field_map for text_embedding processor\n",
    "    field_map = {}\n",
    "    for field in text_fields:\n",
    "        field_map[field] = f\"{field}_embedding\"\n",
    "    \n",
    "    # Create pipeline body\n",
    "    pipeline_body = {\n",
    "        \"description\": f\"Embedding pipeline for {pipeline_name}\",\n",
    "        \"processors\": [\n",
    "            {\n",
    "                \"text_embedding\": {\n",
    "                    \"model_id\": model_id,\n",
    "                    \"field_map\": field_map\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Delete pipeline if it exists\n",
    "    try:\n",
    "        os_client.ingest.delete_pipeline(id=pipeline_name)\n",
    "        print(f\"Deleted existing pipeline: {pipeline_name}\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Create the pipeline\n",
    "    os_client.ingest.put_pipeline(id=pipeline_name, body=pipeline_body)\n",
    "    print(f\"‚úì Ingest pipeline created: {pipeline_name}\")\n",
    "    print(f\"  Text fields to embed: {text_fields}\")\n",
    "    print(f\"  Excluded fields: {exclude_from_embeddings}\")\n",
    "    print(f\"  Field mappings: {field_map}\")\n",
    "    \n",
    "    return pipeline_name\n",
    "\n",
    "# Create the pipeline with custom exclusions\n",
    "pipeline_name = create_embedding_pipeline(\n",
    "    df_squad_sample, \n",
    "    model_id,\n",
    "    exclude_from_embeddings=['id']  # Exclude only id, include title for better semantic matching\n",
    ")\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Pipeline '{pipeline_name}' is ready to use\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bc6b1b",
   "metadata": {},
   "source": [
    "## Create Index with Pipeline and Ingest Data with Auto-Generated Embeddings\n",
    "\n",
    "Now create an index that uses the ingest pipeline to automatically generate embeddings during document ingestion.\n",
    "\n",
    "**Key Configuration:**\n",
    "- `index.knn: true` - Enables k-NN functionality\n",
    "- `default_pipeline: \"squad_embedding_pipeline\"` - Automatically processes all documents through the pipeline\n",
    "- Vector fields are created for each text field to store the embeddings\n",
    "\n",
    "**What happens during ingestion:**\n",
    "1. Documents are sent to OpenSearch\n",
    "2. The ingest pipeline intercepts them\n",
    "3. Text fields are extracted and sent to the ML model\n",
    "4. The model generates 768-dimensional embeddings\n",
    "5. Embeddings are stored in the corresponding `_embedding` fields\n",
    "6. The complete document (with embeddings) is indexed\n",
    "\n",
    "This approach eliminates the need to manually generate embeddings before ingestion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c1de504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated OpenSearch mappings (WITH vector fields and pipeline):\n",
      "{\n",
      "  \"settings\": {\n",
      "    \"index\": {\n",
      "      \"number_of_shards\": 1,\n",
      "      \"number_of_replicas\": 1,\n",
      "      \"knn\": true\n",
      "    },\n",
      "    \"default_pipeline\": \"squad_embedding_pipeline\"\n",
      "  },\n",
      "  \"mappings\": {\n",
      "    \"properties\": {\n",
      "      \"id\": {\n",
      "        \"type\": \"text\",\n",
      "        \"fields\": {\n",
      "          \"keyword\": {\n",
      "            \"type\": \"keyword\",\n",
      "            \"ignore_above\": 256\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"title\": {\n",
      "        \"type\": \"text\",\n",
      "        \"fields\": {\n",
      "          \"keyword\": {\n",
      "            \"type\": \"keyword\",\n",
      "            \"ignore_above\": 256\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"title_embedding\": {\n",
      "        \"type\": \"knn_vector\",\n",
      "        \"dimension\": 768,\n",
      "        \"method\": {\n",
      "          \"name\": \"hnsw\",\n",
      "          \"space_type\": \"l2\",\n",
      "          \"engine\": \"lucene\",\n",
      "          \"parameters\": {}\n",
      "        }\n",
      "      },\n",
      "      \"context\": {\n",
      "        \"type\": \"text\",\n",
      "        \"fields\": {\n",
      "          \"keyword\": {\n",
      "            \"type\": \"keyword\",\n",
      "            \"ignore_above\": 256\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"context_embedding\": {\n",
      "        \"type\": \"knn_vector\",\n",
      "        \"dimension\": 768,\n",
      "        \"method\": {\n",
      "          \"name\": \"hnsw\",\n",
      "          \"space_type\": \"l2\",\n",
      "          \"engine\": \"lucene\",\n",
      "          \"parameters\": {}\n",
      "        }\n",
      "      },\n",
      "      \"question\": {\n",
      "        \"type\": \"text\",\n",
      "        \"fields\": {\n",
      "          \"keyword\": {\n",
      "            \"type\": \"keyword\",\n",
      "            \"ignore_above\": 256\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"question_embedding\": {\n",
      "        \"type\": \"knn_vector\",\n",
      "        \"dimension\": 768,\n",
      "        \"method\": {\n",
      "          \"name\": \"hnsw\",\n",
      "          \"space_type\": \"l2\",\n",
      "          \"engine\": \"lucene\",\n",
      "          \"parameters\": {}\n",
      "        }\n",
      "      },\n",
      "      \"answers\": {\n",
      "        \"type\": \"nested\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "Index settings configuration:\n",
      "  - index.knn: True\n",
      "  - default_pipeline: squad_embedding_pipeline\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Creating index: squad_sample_with_pipeline\n",
      "Index created successfully: {'acknowledged': True, 'shards_acknowledged': True, 'index': 'squad_sample_with_pipeline'}\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Starting bulk ingestion of 1000 documents...\n",
      "Note: Using small sample because embedding generation takes time\n",
      "Bulk ingestion completed in 51.71 seconds\n",
      "Successfully indexed: 1000 documents\n",
      "Failed: [] documents\n",
      "Average time per document: 0.05 seconds\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Total documents in index 'squad_sample_with_pipeline': 1000\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Embedding fields in document:\n",
      "  - question_embedding: 768 dimensions\n",
      "    First 5 values: [-0.11519323, 0.10003627, -0.049435705, 0.34308067, -0.10649807]\n",
      "  - context_embedding: 768 dimensions\n",
      "    First 5 values: [-0.2098125, 0.0030736453, 0.16832288, 0.22088492, -0.005630876]\n",
      "  - title_embedding: 768 dimensions\n",
      "    First 5 values: [-0.18073381, 0.18010539, -0.09481455, -0.120119594, -0.03326916]\n",
      "================================================================================\n",
      "\n",
      "Sample document with embeddings:\n",
      "{\n",
      "  \"question\": \"In babies, what is another element impacting immune response?\",\n",
      "  \"question_embedding\": \"[768 dimensions]\",\n",
      "  \"context\": \"Maternal factors also play a role in the body‚Äôs immune response. At birth, most of the immunoglobulin present is maternal IgG. Because IgM, IgD, IgE and IgA don‚Äôt cross the placenta, they are almost undetectable at birth. Some IgA is provided by breast milk. These passively-acquired antibodies can protect the newborn for up to 18 months, but their response is usually short-lived and of low affinity. These antibodies can also produce a negative response. If a child is exposed to the antibody for a particular antigen before being exposed to the antigen itself then the child will produce a dampened response. Passively acquired maternal antibodies can suppress the antibody response to active immunization. Similarly the response of T-cells to vaccination differs in children compared to adults, and vaccines that induce Th1 responses in adults do not readily elicit these same responses in neonates. Between six to nine months after birth, a child‚Äôs immune system begins to respond more strongly to glycoproteins, but there is usually no marked improvement in their response to polysaccharides until they are at least one year old. This can be the reason for distinct time frames found in vaccination schedules.\",\n",
      "  \"answers\": {\n",
      "    \"answer_start\": [\n",
      "      0\n",
      "    ],\n",
      "    \"text\": [\n",
      "      \"Maternal factors\"\n",
      "    ]\n",
      "  },\n",
      "  \"id\": \"5706e36d9e06ca38007e91e1\",\n",
      "  \"context_embedding\": \"[768 dimensions]\",\n",
      "  \"title\": \"Immunology\",\n",
      "  \"title_embedding\": \"[768 dimensions]\"\n",
      "}\n",
      "CPU times: user 182 ms, sys: 9.15 ms, total: 191 ms\n",
      "Wall time: 53.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Define index name\n",
    "index_name_with_pipeline = \"squad_sample_with_pipeline\"\n",
    "\n",
    "# Step 1: Generate mappings with vector fields AND pipeline configuration\n",
    "mappings_with_pipeline = create_opensearch_mappings(\n",
    "    df_squad_sample, \n",
    "    create_vectors=True,\n",
    "    pipeline_name=pipeline_name\n",
    ")\n",
    "\n",
    "print(\"Generated OpenSearch mappings (WITH vector fields and pipeline):\")\n",
    "print(json.dumps(mappings_with_pipeline, indent=2, ensure_ascii=False))\n",
    "\n",
    "# Verify the settings include both knn and default_pipeline\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Index settings configuration:\")\n",
    "print(f\"  - index.knn: {mappings_with_pipeline['settings']['index']['knn']}\")\n",
    "print(f\"  - default_pipeline: {mappings_with_pipeline['settings'].get('default_pipeline', 'Not set')}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Step 2: Delete index if it exists\n",
    "if os_client.indices.exists(index=index_name_with_pipeline):\n",
    "    print(f\"\\nDeleting existing index: {index_name_with_pipeline}\")\n",
    "    os_client.indices.delete(index=index_name_with_pipeline)\n",
    "    print(f\"Index deleted successfully\")\n",
    "\n",
    "# Step 3: Create the index with pipeline-enabled mappings\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Creating index: {index_name_with_pipeline}\")\n",
    "response = os_client.indices.create(index=index_name_with_pipeline, body=mappings_with_pipeline)\n",
    "print(f\"Index created successfully: {response}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Step 4: Ingest a SMALL sample (to test embedding generation)\n",
    "# Note: Using only 100 documents for testing because embedding generation is compute-intensive\n",
    "df_small_sample = df_squad_sample.head(1000)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Starting bulk ingestion of {len(df_small_sample)} documents...\")\n",
    "print(\"Note: Using small sample because embedding generation takes time\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Use bulk helper - the pipeline will automatically generate embeddings\n",
    "success, failed = helpers.bulk(\n",
    "    os_client,\n",
    "    generate_bulk_data(df_small_sample, index_name_with_pipeline),\n",
    "    chunk_size=5,  # Smaller chunks for embedding generation\n",
    "    request_timeout=120,  # Longer timeout for model inference\n",
    "    raise_on_error=False,\n",
    "    raise_on_exception=False\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Bulk ingestion completed in {elapsed_time:.2f} seconds\")\n",
    "print(f\"Successfully indexed: {success} documents\")\n",
    "print(f\"Failed: {failed} documents\")\n",
    "print(f\"Average time per document: {elapsed_time/len(df_small_sample):.2f} seconds\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Step 5: Verify ingestion and check embeddings\n",
    "time.sleep(2)  # Wait for refresh\n",
    "os_client.indices.refresh(index=index_name_with_pipeline)\n",
    "count_response = os_client.count(index=index_name_with_pipeline)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Total documents in index '{index_name_with_pipeline}': {count_response['count']}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Fetch a document to verify embeddings were generated\n",
    "search_response = os_client.search(\n",
    "    index=index_name_with_pipeline, \n",
    "    body={\"query\": {\"match_all\": {}}, \"size\": 1}\n",
    ")\n",
    "\n",
    "if search_response['hits']['hits']:\n",
    "    doc = search_response['hits']['hits'][0]['_source']\n",
    "    \n",
    "    # Check which embedding fields exist\n",
    "    embedding_fields = [k for k in doc.keys() if k.endswith('_embedding')]\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Embedding fields in document:\")\n",
    "    for field in embedding_fields:\n",
    "        embedding = doc[field]\n",
    "        if isinstance(embedding, list):\n",
    "            print(f\"  - {field}: {len(embedding)} dimensions\")\n",
    "            print(f\"    First 5 values: {embedding[:5]}\")\n",
    "        else:\n",
    "            print(f\"  - {field}: {embedding}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\nSample document with embeddings:\")\n",
    "    # Show document without full embedding arrays for readability\n",
    "    doc_summary = {k: v if not k.endswith('_embedding') else f\"[{len(v)} dimensions]\" \n",
    "                   for k, v in doc.items()}\n",
    "    print(json.dumps(doc_summary, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91e25864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "FINAL VERIFICATION - All Indices Comparison\n",
      "====================================================================================================\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Index: squad_sample_no_vectors\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  Documents: 1,000\n",
      "  Total Fields: 5\n",
      "  Vector Fields: 0\n",
      "  KNN Enabled: false\n",
      "  Default Pipeline: None\n",
      "  Index Size: 1.35 MB\n",
      "  Status: ‚úì Ready\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Index: squad_sample_with_vectors\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  Documents: 1,000\n",
      "  Total Fields: 8\n",
      "  Vector Fields: 3\n",
      "    ‚îî‚îÄ context_embedding, question_embedding, title_embedding\n",
      "  KNN Enabled: true\n",
      "  Default Pipeline: None\n",
      "  Index Size: 1.35 MB\n",
      "  Status: ‚úì Ready\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Index: squad_sample_with_pipeline\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  Documents: 1,000\n",
      "  Total Fields: 8\n",
      "  Vector Fields: 3\n",
      "    ‚îî‚îÄ context_embedding, question_embedding, title_embedding\n",
      "  KNN Enabled: true\n",
      "  Default Pipeline: squad_embedding_pipeline\n",
      "  Index Size: 10.43 MB\n",
      "  Embeddings Status: ‚úì Populated (768 dimensions)\n",
      "  Status: ‚úì Ready\n",
      "\n",
      "====================================================================================================\n",
      "All indices created successfully with different configurations!\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Final verification of all three indices\n",
    "all_indices = [\n",
    "    \"squad_sample_no_vectors\",\n",
    "    \"squad_sample_with_vectors\",\n",
    "    \"squad_sample_with_pipeline\"\n",
    "]\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"FINAL VERIFICATION - All Indices Comparison\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for idx_name in all_indices:\n",
    "    if os_client.indices.exists(index=idx_name):\n",
    "        # Get document count\n",
    "        count = os_client.count(index=idx_name)['count']\n",
    "        \n",
    "        # Get index stats\n",
    "        stats = os_client.indices.stats(index=idx_name)\n",
    "        size_in_bytes = stats['indices'][idx_name]['total']['store']['size_in_bytes']\n",
    "        size_in_mb = size_in_bytes / (1024 * 1024)\n",
    "        \n",
    "        # Get field count and settings\n",
    "        mappings = os_client.indices.get_mapping(index=idx_name)\n",
    "        settings = os_client.indices.get_settings(index=idx_name)\n",
    "        \n",
    "        field_count = len(mappings[idx_name]['mappings']['properties'])\n",
    "        vector_fields = [k for k in mappings[idx_name]['mappings']['properties'].keys() \n",
    "                        if k.endswith('_embedding')]\n",
    "        \n",
    "        # Check for pipeline\n",
    "        pipeline = settings[idx_name]['settings']['index'].get('default_pipeline', 'None')\n",
    "        knn_enabled = settings[idx_name]['settings']['index'].get('knn', 'false')\n",
    "        \n",
    "        print(f\"\\n{'‚îÄ'*100}\")\n",
    "        print(f\"Index: {idx_name}\")\n",
    "        print(f\"{'‚îÄ'*100}\")\n",
    "        print(f\"  Documents: {count:,}\")\n",
    "        print(f\"  Total Fields: {field_count}\")\n",
    "        print(f\"  Vector Fields: {len(vector_fields)}\")\n",
    "        if vector_fields:\n",
    "            print(f\"    ‚îî‚îÄ {', '.join(vector_fields)}\")\n",
    "        print(f\"  KNN Enabled: {knn_enabled}\")\n",
    "        print(f\"  Default Pipeline: {pipeline}\")\n",
    "        print(f\"  Index Size: {size_in_mb:.2f} MB\")\n",
    "        \n",
    "        # Check if embeddings are actually populated (only for pipeline index)\n",
    "        if idx_name == \"squad_sample_with_pipeline\" and vector_fields:\n",
    "            sample = os_client.search(index=idx_name, body={\"query\": {\"match_all\": {}}, \"size\": 1})\n",
    "            if sample['hits']['hits']:\n",
    "                first_vec_field = vector_fields[0]\n",
    "                embedding = sample['hits']['hits'][0]['_source'].get(first_vec_field)\n",
    "                if embedding and isinstance(embedding, list) and len(embedding) > 0:\n",
    "                    print(f\"  Embeddings Status: ‚úì Populated ({len(embedding)} dimensions)\")\n",
    "                else:\n",
    "                    print(f\"  Embeddings Status: ‚úó Empty\")\n",
    "        \n",
    "        print(f\"  Status: ‚úì Ready\")\n",
    "    else:\n",
    "        print(f\"\\nIndex: {idx_name}\")\n",
    "        print(f\"  Status: ‚úó Not found\")\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"All indices created successfully with different configurations!\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62202502",
   "metadata": {},
   "source": [
    "## Final Summary - Complete ML Pipeline Implementation\n",
    "\n",
    "This notebook successfully demonstrated three approaches to indexing with OpenSearch:\n",
    "\n",
    "### ‚úÖ Approach 1: Basic Ingestion (No Vectors)\n",
    "- **Index**: `squad_sample_no_vectors`\n",
    "- **Documents**: 1000\n",
    "- **Fields**: 5 (id, title, context, question, answers)\n",
    "- **Use Case**: Traditional keyword search\n",
    "- **Ingestion Time**: ~0.35 seconds\n",
    "\n",
    "### ‚úÖ Approach 2: Manual Vector Fields (No Pipeline)\n",
    "- **Index**: `squad_sample_with_vectors`\n",
    "- **Documents**: 1000\n",
    "- **Fields**: 9 (5 text + 4 vector fields)\n",
    "- **Vector Fields**: Defined but NOT populated\n",
    "- **Use Case**: When you want to generate embeddings externally\n",
    "- **Ingestion Time**: ~0.36 seconds\n",
    "\n",
    "### ‚úÖ Approach 3: Automatic Embeddings with Ingest Pipeline (RECOMMENDED)\n",
    "- **Index**: `squad_sample_with_pipeline`\n",
    "- **Documents**: 10 (small sample for testing)\n",
    "- **Fields**: 9 (5 text + 4 vector fields with actual embeddings)\n",
    "- **Vector Fields**: AUTOMATICALLY populated during ingestion\n",
    "- **Model**: `msmarco-distilbert-base-tas-b` (768 dimensions)\n",
    "- **Pipeline**: `squad_embedding_pipeline`\n",
    "- **Settings**: \n",
    "  - `index.knn: true` - Enables k-NN search\n",
    "  - `default_pipeline: squad_embedding_pipeline` - Auto-processes all documents\n",
    "- **Ingestion Time**: ~0.11 seconds per document (includes ML inference)\n",
    "- **Use Case**: Production semantic search with automatic embedding generation\n",
    "\n",
    "### üéØ Key Achievements:\n",
    "\n",
    "1. **Created a generic `create_opensearch_mappings()` function** that:\n",
    "   - Automatically generates mappings from pandas DataFrames\n",
    "   - Optionally creates vector fields\n",
    "   - Supports pipeline configuration\n",
    "\n",
    "2. **Deployed ML model** on OpenSearch cluster for embedding generation\n",
    "\n",
    "3. **Created dynamic ingest pipeline** that automatically:\n",
    "   - Identifies text fields\n",
    "   - Generates embeddings using ML model\n",
    "   - Stores embeddings in corresponding vector fields\n",
    "\n",
    "4. **Demonstrated actual embeddings**: Each document now has 768-dimensional vectors for semantic search\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "- Implement semantic search queries using k-NN\n",
    "- Test hybrid search (keyword + semantic)\n",
    "- Index the full dataset (1000 documents)\n",
    "- Implement relevance tuning and ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcadf1be",
   "metadata": {},
   "source": [
    "# üîé Part 2: Semantic Search and Hybrid Queries\n",
    "\n",
    "Now that we have indices with embeddings, let's implement advanced search capabilities:\n",
    "1. **k-NN Semantic Search** - Find semantically similar documents using vector similarity\n",
    "2. **Hybrid Search** - Combine keyword and semantic search for better results\n",
    "3. **Relevance Tuning** - Adjust ranking and scoring to improve search quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913a8317",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Semantic Search using k-NN\n",
    "\n",
    "Semantic search finds documents based on meaning rather than exact keyword matches. We'll use k-NN (k-Nearest Neighbors) to find the most similar documents based on vector embeddings.\n",
    "\n",
    "**How it works:**\n",
    "1. Convert the search query into a vector embedding using the same ML model\n",
    "2. Use k-NN to find documents with similar embeddings\n",
    "3. Return the top-k most similar results\n",
    "\n",
    "**Example Query:** \"What is the capital of France?\"\n",
    "- This will find documents about French geography, Paris, government, etc.\n",
    "- Even if the exact words don't match, semantically similar content will be returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61a0b277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üîç SEMANTIC SEARCH EXAMPLE 1: French Capital\n",
      "====================================================================================================\n",
      "\n",
      "Query: 'What is the capital of France?'\n",
      "Searching in index: squad_sample_with_pipeline\n",
      "Target field: context_embedding\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Found 3 results\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìÑ Result 1 (Score: 0.0175)\n",
      "   Title: Paris\n",
      "   Question: For how many years did the socialists governed the region?\n",
      "   Context (first 200 chars): The Region of √éle de France, including Paris and its surrounding communities, is governed by the Regional Council, which has its headquarters in the 7th arrondissement of Paris. It is composed of 209 ...\n",
      "   ------------------------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Result 2 (Score: 0.0174)\n",
      "   Title: Paris\n",
      "   Question: What is the most viewed television network in France?\n",
      "   Context (first 200 chars): The most-viewed network in France, TF1, is in nearby Boulogne-Billancourt; France 2, France 3, Canal+, France 5, M6 (Neuilly-sur-Seine), Arte, D8, W9, NT1, NRJ 12, La Cha√Æne parlementaire, France 4, B...\n",
      "   ------------------------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Result 3 (Score: 0.0172)\n",
      "   Title: Catalan_language\n",
      "   Question: What is the official language of France?\n",
      "   Context (first 200 chars): Nowadays, France only recognizes French as an official language. Nevertheless, on 10 December 2007, the General Council of the Pyr√©n√©es-Orientales officially recognized Catalan as one of the languages...\n",
      "   ------------------------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def semantic_search_knn(query_text, index_name, field_to_search=\"context\", k=5, model_id=None):\n",
    "    \"\"\"\n",
    "    Perform semantic search using k-NN with neural search.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    query_text : str\n",
    "        The search query text\n",
    "    index_name : str\n",
    "        Name of the index to search\n",
    "    field_to_search : str\n",
    "        The field to search (e.g., 'context', 'question')\n",
    "    k : int\n",
    "        Number of top results to return\n",
    "    model_id : str, optional\n",
    "        Model ID for embedding generation. If not provided, uses ingest pipeline.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Search results with scores\n",
    "    \"\"\"\n",
    "    # Use neural query for automatic embedding generation\n",
    "    search_body = {\n",
    "        \"size\": k,\n",
    "        \"query\": {\n",
    "            \"neural\": {\n",
    "                f\"{field_to_search}_embedding\": {\n",
    "                    \"query_text\": query_text,\n",
    "                    \"model_id\": model_id,\n",
    "                    \"k\": k\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\"id\", \"title\", field_to_search, \"question\"]\n",
    "    }\n",
    "    \n",
    "    return os_client.search(index=index_name, body=search_body)\n",
    "\n",
    "\n",
    "# Example 1: Search for questions about French capital\n",
    "print(\"=\"*100)\n",
    "print(\"üîç SEMANTIC SEARCH EXAMPLE 1: French Capital\")\n",
    "print(\"=\"*100)\n",
    "query = \"What is the capital of France?\"\n",
    "print(f\"\\nQuery: '{query}'\")\n",
    "print(f\"Searching in index: squad_sample_with_pipeline\")\n",
    "print(f\"Target field: context_embedding\")\n",
    "\n",
    "results = semantic_search_knn(\n",
    "    query_text=query,\n",
    "    index_name=\"squad_sample_with_pipeline\",\n",
    "    field_to_search=\"context\",\n",
    "    k=3,\n",
    "    model_id=model_id\n",
    ")\n",
    "\n",
    "print(f\"\\n{'‚îÄ'*100}\")\n",
    "print(f\"Found {results['hits']['total']['value']} results\")\n",
    "print(f\"{'‚îÄ'*100}\")\n",
    "\n",
    "for i, hit in enumerate(results['hits']['hits'], 1):\n",
    "    score = hit['_score']\n",
    "    source = hit['_source']\n",
    "    \n",
    "    print(f\"\\nüìÑ Result {i} (Score: {score:.4f})\")\n",
    "    print(f\"   Title: {source.get('title', 'N/A')}\")\n",
    "    print(f\"   Question: {source.get('question', 'N/A')}\")\n",
    "    print(f\"   Context (first 200 chars): {source.get('context', 'N/A')[:200]}...\")\n",
    "    print(f\"   {'-'*96}\")\n",
    "\n",
    "print(f\"\\n{'='*100}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e03f9315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üîç SEMANTIC SEARCH EXAMPLE 2: Scientific Concepts\n",
      "====================================================================================================\n",
      "\n",
      "Query: 'How does photosynthesis work in plants?'\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Found 3 results\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìÑ Result 1 (Score: 0.0169)\n",
      "   Title: Hunter-gatherer\n",
      "   Question: What is the manipulation of the landscape associated with?\n",
      "   Context (first 200 chars): Many hunter-gatherers consciously manipulate the landscape through cutting or burning undesirable plants while encouraging desirable ones, some even going to the extent of slash-and-burn to create hab...\n",
      "   ------------------------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Result 2 (Score: 0.0161)\n",
      "   Title: Planck_constant\n",
      "   Question: What is the term used when photoelectrons act virtually at the same time?\n",
      "   Context (first 200 chars): The \"photoelectrons\" emitted as a result of the photoelectric effect have a certain kinetic energy, which can be measured. This kinetic energy (for each photoelectron) is independent of the intensity ...\n",
      "   ------------------------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Result 3 (Score: 0.0156)\n",
      "   Title: Insect\n",
      "   Question: What do many insects adaptively utilize in self-defense from predators?\n",
      "   Context (first 200 chars): Insects were among the earliest terrestrial herbivores and acted as major selection agents on plants. Plants evolved chemical defenses against this herbivory and the insects, in turn, evolved mechanis...\n",
      "   ------------------------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Search for scientific concepts\n",
    "print(\"=\"*100)\n",
    "print(\"üîç SEMANTIC SEARCH EXAMPLE 2: Scientific Concepts\")\n",
    "print(\"=\"*100)\n",
    "query = \"How does photosynthesis work in plants?\"\n",
    "print(f\"\\nQuery: '{query}'\")\n",
    "\n",
    "results = semantic_search_knn(\n",
    "    query_text=query,\n",
    "    index_name=\"squad_sample_with_pipeline\",\n",
    "    field_to_search=\"context\",\n",
    "    k=3,\n",
    "    model_id=model_id\n",
    ")\n",
    "\n",
    "print(f\"\\n{'‚îÄ'*100}\")\n",
    "print(f\"Found {results['hits']['total']['value']} results\")\n",
    "print(f\"{'‚îÄ'*100}\")\n",
    "\n",
    "for i, hit in enumerate(results['hits']['hits'], 1):\n",
    "    score = hit['_score']\n",
    "    source = hit['_source']\n",
    "    \n",
    "    print(f\"\\nüìÑ Result {i} (Score: {score:.4f})\")\n",
    "    print(f\"   Title: {source.get('title', 'N/A')}\")\n",
    "    print(f\"   Question: {source.get('question', 'N/A')}\")\n",
    "    print(f\"   Context (first 200 chars): {source.get('context', 'N/A')[:200]}...\")\n",
    "    print(f\"   {'-'*96}\")\n",
    "\n",
    "print(f\"\\n{'='*100}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231a2839",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Hybrid Search (Keyword + Semantic)\n",
    "\n",
    "Hybrid search combines the best of both worlds:\n",
    "- **Keyword Search (BM25)**: Exact term matching, good for specific queries\n",
    "- **Semantic Search (k-NN)**: Meaning-based matching, good for conceptual queries\n",
    "\n",
    "**Benefits:**\n",
    "- Better recall: Finds documents that keyword search might miss\n",
    "- Better precision: Combines semantic similarity with keyword relevance\n",
    "- Flexible scoring: Can adjust weights between keyword and semantic components\n",
    "\n",
    "**Implementation:**\n",
    "We'll use a `bool` query with `should` clauses to combine both approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf14658a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üîç HYBRID SEARCH EXAMPLE 1: Equal Keyword + Semantic Weights\n",
      "====================================================================================================\n",
      "\n",
      "Query: 'What are the main causes of World War II?'\n",
      "Keyword Boost: 1.0, Semantic Boost: 1.0\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Found 1000 results\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìÑ Result 1 (Score: 10.0258)\n",
      "   Title: The_Times\n",
      "   Question: During World War II, the Soviet double agent who was corresponding for The Times in Spain in the 1930s later joined what agency?\n",
      "   Context (first 150 chars): Kim Philby, a Soviet double agent, was a correspondent for the newspaper in Spain during the Spanish Civil War of the late 1930s. Philby was admired f...\n",
      "   ------------------------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Result 2 (Score: 8.7955)\n",
      "   Title: Franco-Prussian_War\n",
      "   Question: Which specific fear was a factor in causing World War I?\n",
      "   Context (first 150 chars): The German states proclaimed their union as the German Empire under the Prussian king, Wilhelm I, uniting Germany as a nation-state. The Treaty of Fra...\n",
      "   ------------------------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Result 3 (Score: 8.0182)\n",
      "   Title: Houston\n",
      "   Question: What world event caused this increased need for petrochemicals?\n",
      "   Context (first 150 chars): When World War II started, tonnage levels at the port decreased and shipping activities were suspended; however, the war did provide economic benefits...\n",
      "   ------------------------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Result 4 (Score: 7.7528)\n",
      "   Title: Molotov%E2%80%93Ribbentrop_Pact\n",
      "   Question: What agreement gave Germany many regions of Russia in the first world war?\n",
      "   Context (first 150 chars): The outcome of the First World War was disastrous for both the German Reich and the Russian Soviet Federative Socialist Republic. During the war, the ...\n",
      "   ------------------------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Result 5 (Score: 7.6754)\n",
      "   Title: Switzerland\n",
      "   Question: How many refugees did Switzerland intern during World War II?\n",
      "   Context (first 150 chars): Switzerland's trade was blockaded by both the Allies and by the Axis. Economic cooperation and extension of credit to the Third Reich varied according...\n",
      "   ------------------------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def hybrid_search(query_text, index_name, fields_to_search=[\"title\", \"context\", \"question\"], \n",
    "                  k=5, model_id=None, keyword_boost=1.0, semantic_boost=1.0):\n",
    "    \"\"\"\n",
    "    Perform hybrid search combining keyword (BM25) and semantic (k-NN) search.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    query_text : str\n",
    "        The search query text\n",
    "    index_name : str\n",
    "        Name of the index to search\n",
    "    fields_to_search : list of str\n",
    "        Fields to search in (both keyword and semantic)\n",
    "        Default includes title for better semantic matching\n",
    "    k : int\n",
    "        Number of top results to return\n",
    "    model_id : str, optional\n",
    "        Model ID for embedding generation\n",
    "    keyword_boost : float\n",
    "        Boost factor for keyword search (default: 1.0)\n",
    "    semantic_boost : float\n",
    "        Boost factor for semantic search (default: 1.0)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Search results with combined scores\n",
    "    \"\"\"\n",
    "    # Build keyword queries for each field\n",
    "    keyword_queries = []\n",
    "    for field in fields_to_search:\n",
    "        keyword_queries.append({\n",
    "            \"match\": {\n",
    "                field: {\n",
    "                    \"query\": query_text,\n",
    "                    \"boost\": keyword_boost\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Build semantic queries for each field\n",
    "    semantic_queries = []\n",
    "    for field in fields_to_search:\n",
    "        semantic_queries.append({\n",
    "            \"neural\": {\n",
    "                f\"{field}_embedding\": {\n",
    "                    \"query_text\": query_text,\n",
    "                    \"model_id\": model_id,\n",
    "                    \"k\": k * 2,  # Retrieve more candidates for better results\n",
    "                    \"boost\": semantic_boost\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Combine queries using bool should\n",
    "    search_body = {\n",
    "        \"size\": k,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"should\": keyword_queries + semantic_queries,\n",
    "                \"minimum_should_match\": 1\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\"id\", \"title\", \"context\", \"question\"],\n",
    "        \"explain\": False  # Set to True to see score calculation details\n",
    "    }\n",
    "    \n",
    "    return os_client.search(index=index_name, body=search_body)\n",
    "\n",
    "\n",
    "# Example 1: Hybrid search with equal weights\n",
    "print(\"=\"*100)\n",
    "print(\"üîç HYBRID SEARCH EXAMPLE 1: Equal Keyword + Semantic Weights\")\n",
    "print(\"=\"*100)\n",
    "query = \"What are the main causes of World War II?\"\n",
    "print(f\"\\nQuery: '{query}'\")\n",
    "print(f\"Keyword Boost: 1.0, Semantic Boost: 1.0\")\n",
    "\n",
    "results = hybrid_search(\n",
    "    query_text=query,\n",
    "    index_name=\"squad_sample_with_pipeline\",\n",
    "    fields_to_search=[\"context\", \"question\"],\n",
    "    k=5,\n",
    "    model_id=model_id,\n",
    "    keyword_boost=1.0,\n",
    "    semantic_boost=1.0\n",
    ")\n",
    "\n",
    "print(f\"\\n{'‚îÄ'*100}\")\n",
    "print(f\"Found {results['hits']['total']['value']} results\")\n",
    "print(f\"{'‚îÄ'*100}\")\n",
    "\n",
    "for i, hit in enumerate(results['hits']['hits'], 1):\n",
    "    score = hit['_score']\n",
    "    source = hit['_source']\n",
    "    \n",
    "    print(f\"\\nüìÑ Result {i} (Score: {score:.4f})\")\n",
    "    print(f\"   Title: {source.get('title', 'N/A')}\")\n",
    "    print(f\"   Question: {source.get('question', 'N/A')}\")\n",
    "    print(f\"   Context (first 150 chars): {source.get('context', 'N/A')[:150]}...\")\n",
    "    print(f\"   {'-'*96}\")\n",
    "\n",
    "print(f\"\\n{'='*100}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833a5bac",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Relevance Tuning and Ranking\n",
    "\n",
    "Relevance tuning allows you to control how search results are scored and ranked. We'll explore several techniques:\n",
    "\n",
    "1. **Boost Adjustment**: Control the weight of keyword vs semantic search\n",
    "2. **Field-Level Boosting**: Prioritize certain fields (e.g., title > content)\n",
    "3. **Function Score**: Custom scoring based on document properties\n",
    "4. **Rescore**: Re-rank top results with more expensive scoring\n",
    "\n",
    "**Use Cases:**\n",
    "- Emphasize exact matches over semantic similarity\n",
    "- Boost recent documents or popular content\n",
    "- Penalize low-quality or outdated content\n",
    "- Customize ranking for specific business needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f54e97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üéØ RELEVANCE TUNING TEST 1: Favor Semantic Search\n",
      "====================================================================================================\n",
      "\n",
      "Query: 'scientific discoveries in biology'\n",
      "Configuration: Keyword Boost: 0.5, Semantic Boost: 2.0\n",
      "Expected: Results based more on meaning than exact word matches\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Top 3 Results (Semantic-Heavy)\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìÑ Result 1 (Score: 2.7932)\n",
      "   Title: History_of_science\n",
      "   Question: What language did the important scientific works get translated into for universities and monasterie...\n",
      "   ------------------------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Result 2 (Score: 2.0583)\n",
      "   Title: History_of_science\n",
      "   Question: What book was printed by Isaac Newton in 1687?...\n",
      "   ------------------------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Result 3 (Score: 1.7411)\n",
      "   Title: Intellectual_property\n",
      "   Question: When did French author A. Nion mention intellectual property?...\n",
      "   ------------------------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Favor semantic search over keyword search\n",
    "print(\"=\"*100)\n",
    "print(\"üéØ RELEVANCE TUNING TEST 1: Favor Semantic Search\")\n",
    "print(\"=\"*100)\n",
    "query = \"scientific discoveries in biology\"\n",
    "print(f\"\\nQuery: '{query}'\")\n",
    "print(f\"Configuration: Keyword Boost: 0.5, Semantic Boost: 2.0\")\n",
    "print(f\"Expected: Results based more on meaning than exact word matches\")\n",
    "\n",
    "results_semantic_heavy = hybrid_search(\n",
    "    query_text=query,\n",
    "    index_name=\"squad_sample_with_pipeline\",\n",
    "    fields_to_search=[\"context\", \"question\"],\n",
    "    k=3,\n",
    "    model_id=model_id,\n",
    "    keyword_boost=0.5,\n",
    "    semantic_boost=2.0\n",
    ")\n",
    "\n",
    "print(f\"\\n{'‚îÄ'*100}\")\n",
    "print(f\"Top 3 Results (Semantic-Heavy)\")\n",
    "print(f\"{'‚îÄ'*100}\")\n",
    "\n",
    "for i, hit in enumerate(results_semantic_heavy['hits']['hits'], 1):\n",
    "    score = hit['_score']\n",
    "    source = hit['_source']\n",
    "    \n",
    "    print(f\"\\nüìÑ Result {i} (Score: {score:.4f})\")\n",
    "    print(f\"   Title: {source.get('title', 'N/A')}\")\n",
    "    print(f\"   Question: {source.get('question', 'N/A')[:100]}...\")\n",
    "    print(f\"   {'-'*96}\")\n",
    "\n",
    "print(f\"\\n{'='*100}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3372459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üéØ RELEVANCE TUNING TEST 2: Favor Keyword Search\n",
      "====================================================================================================\n",
      "\n",
      "Query: 'Paris France capital city'\n",
      "Configuration: Keyword Boost: 2.0, Semantic Boost: 0.5\n",
      "Expected: Results with exact keyword matches ranked higher\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Top 3 Results (Keyword-Heavy)\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìÑ Result 1 (Score: 21.8448)\n",
      "   Title: Paris\n",
      "   Question: What is the most viewed television network in France?...\n",
      "   ------------------------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Result 2 (Score: 16.6591)\n",
      "   Title: Police\n",
      "   Question: How many policing districts was Paris divided into?...\n",
      "   ------------------------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Result 3 (Score: 16.1849)\n",
      "   Title: North_Carolina\n",
      "   Question: What city became the capital of North Carolina in 1766?...\n",
      "   ------------------------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Favor keyword search for precision\n",
    "print(\"=\"*100)\n",
    "print(\"üéØ RELEVANCE TUNING TEST 2: Favor Keyword Search\")\n",
    "print(\"=\"*100)\n",
    "query = \"Paris France capital city\"\n",
    "print(f\"\\nQuery: '{query}'\")\n",
    "print(f\"Configuration: Keyword Boost: 2.0, Semantic Boost: 0.5\")\n",
    "print(f\"Expected: Results with exact keyword matches ranked higher\")\n",
    "\n",
    "results_keyword_heavy = hybrid_search(\n",
    "    query_text=query,\n",
    "    index_name=\"squad_sample_with_pipeline\",\n",
    "    fields_to_search=[\"context\", \"question\"],\n",
    "    k=3,\n",
    "    model_id=model_id,\n",
    "    keyword_boost=2.0,\n",
    "    semantic_boost=0.5\n",
    ")\n",
    "\n",
    "print(f\"\\n{'‚îÄ'*100}\")\n",
    "print(f\"Top 3 Results (Keyword-Heavy)\")\n",
    "print(f\"{'‚îÄ'*100}\")\n",
    "\n",
    "for i, hit in enumerate(results_keyword_heavy['hits']['hits'], 1):\n",
    "    score = hit['_score']\n",
    "    source = hit['_source']\n",
    "    \n",
    "    print(f\"\\nüìÑ Result {i} (Score: {score:.4f})\")\n",
    "    print(f\"   Title: {source.get('title', 'N/A')}\")\n",
    "    print(f\"   Question: {source.get('question', 'N/A')[:100]}...\")\n",
    "    print(f\"   {'-'*96}\")\n",
    "\n",
    "print(f\"\\n{'='*100}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b22cf59",
   "metadata": {},
   "source": [
    "### Advanced: Field-Level Boosting\n",
    "\n",
    "Sometimes you want to give more weight to matches in specific fields. For example:\n",
    "- Matches in `title` should score higher than matches in `context`\n",
    "- Matches in `question` might be more relevant than matches in long text\n",
    "\n",
    "This is useful when you know certain fields are more important for your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1493eb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üéØ FIELD-LEVEL BOOSTING: Prioritize Title and Question\n",
      "====================================================================================================\n",
      "\n",
      "Query: 'American Revolution independence'\n",
      "Field Boosts: title=3.0, question=2.0, context=1.0\n",
      "Expected: Matches in title/question ranked higher than context\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Top 5 Results (Field-Boosted)\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìÑ Result 1 (Score: 5.9339)\n",
      "   Title: Spanish_language_in_the_United_States\n",
      "   Question: Are there studies on Hispanic-American language?...\n",
      "   ------------------------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Result 2 (Score: 5.7725)\n",
      "   Title: Law_of_the_United_States\n",
      "   Question: What type of system is American Federalism?...\n",
      "   ------------------------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Result 3 (Score: 5.6861)\n",
      "   Title: Sony_Music_Entertainment\n",
      "   Question: In what year did CDs come to the American market?...\n",
      "   ------------------------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Result 4 (Score: 5.6461)\n",
      "   Title: 51st_state\n",
      "   Question: Who wrote the book The American State of Canaan?...\n",
      "   ------------------------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Result 5 (Score: 5.5436)\n",
      "   Title: The_Blitz\n",
      "   Question: What was the name of the American observer?...\n",
      "   ------------------------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def field_boosted_search(query_text, index_name, field_boosts=None, k=5, model_id=None):\n",
    "    \"\"\"\n",
    "    Perform search with field-level boosting.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    query_text : str\n",
    "        The search query text\n",
    "    index_name : str\n",
    "        Name of the index to search\n",
    "    field_boosts : dict\n",
    "        Dictionary mapping field names to boost values\n",
    "        Example: {\"title\": 3.0, \"question\": 2.0, \"context\": 1.0}\n",
    "    k : int\n",
    "        Number of top results to return\n",
    "    model_id : str, optional\n",
    "        Model ID for embedding generation\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Search results with field-boosted scores\n",
    "    \"\"\"\n",
    "    if field_boosts is None:\n",
    "        field_boosts = {\"title\": 2.0, \"question\": 1.5, \"context\": 1.0}\n",
    "    \n",
    "    # Build queries with field-specific boosts\n",
    "    should_queries = []\n",
    "    \n",
    "    for field, boost in field_boosts.items():\n",
    "        # Keyword query\n",
    "        should_queries.append({\n",
    "            \"match\": {\n",
    "                field: {\n",
    "                    \"query\": query_text,\n",
    "                    \"boost\": boost\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        # Semantic query (if embedding field exists)\n",
    "        should_queries.append({\n",
    "            \"neural\": {\n",
    "                f\"{field}_embedding\": {\n",
    "                    \"query_text\": query_text,\n",
    "                    \"model_id\": model_id,\n",
    "                    \"k\": k * 2,\n",
    "                    \"boost\": boost\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    search_body = {\n",
    "        \"size\": k,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"should\": should_queries,\n",
    "                \"minimum_should_match\": 1\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\"id\", \"title\", \"context\", \"question\"]\n",
    "    }\n",
    "    \n",
    "    return os_client.search(index=index_name, body=search_body)\n",
    "\n",
    "\n",
    "# Example: Prioritize title and question over context\n",
    "print(\"=\"*100)\n",
    "print(\"üéØ FIELD-LEVEL BOOSTING: Prioritize Title and Question\")\n",
    "print(\"=\"*100)\n",
    "query = \"American Revolution independence\"\n",
    "print(f\"\\nQuery: '{query}'\")\n",
    "print(f\"Field Boosts: title=3.0, question=2.0, context=1.0\")\n",
    "print(f\"Expected: Matches in title/question ranked higher than context\")\n",
    "\n",
    "results_field_boosted = field_boosted_search(\n",
    "    query_text=query,\n",
    "    index_name=\"squad_sample_with_pipeline\",\n",
    "    field_boosts={\"title\": 3.0, \"question\": 2.0, \"context\": 1.0},\n",
    "    k=5,\n",
    "    model_id=model_id\n",
    ")\n",
    "\n",
    "print(f\"\\n{'‚îÄ'*100}\")\n",
    "print(f\"Top 5 Results (Field-Boosted)\")\n",
    "print(f\"{'‚îÄ'*100}\")\n",
    "\n",
    "for i, hit in enumerate(results_field_boosted['hits']['hits'], 1):\n",
    "    score = hit['_score']\n",
    "    source = hit['_source']\n",
    "    \n",
    "    print(f\"\\nüìÑ Result {i} (Score: {score:.4f})\")\n",
    "    print(f\"   Title: {source.get('title', 'N/A')}\")\n",
    "    print(f\"   Question: {source.get('question', 'N/A')[:120]}...\")\n",
    "    print(f\"   {'-'*96}\")\n",
    "\n",
    "print(f\"\\n{'='*100}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d19236",
   "metadata": {},
   "source": [
    "## üìä Comparison: Keyword vs Semantic vs Hybrid\n",
    "\n",
    "Let's compare all three search approaches side-by-side to understand their strengths and weaknesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b9a3277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "üî¨ SEARCH COMPARISON\n",
      "========================================================================================================================\n",
      "Query: 'How do plants create energy from sunlight?'\n",
      "Index: squad_sample_with_pipeline\n",
      "Top 3 results for each method\n",
      "========================================================================================================================\n",
      "\n",
      "‚ñ∂‚ñ∂‚ñ∂ METHOD 1: KEYWORD SEARCH (BM25) ‚óÄ‚óÄ‚óÄ\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "1. Score: 7.3968 | Title: Green\n",
      "2. Score: 5.7558 | Title: Hydrogen\n",
      "3. Score: 5.0061 | Title: Energy\n",
      "\n",
      "‚ñ∂‚ñ∂‚ñ∂ METHOD 2: SEMANTIC SEARCH (k-NN) ‚óÄ‚óÄ‚óÄ\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "1. Score: 0.0175 | Title: Hydrogen\n",
      "2. Score: 0.0169 | Title: Green\n",
      "3. Score: 0.0153 | Title: Hunter-gatherer\n",
      "\n",
      "‚ñ∂‚ñ∂‚ñ∂ METHOD 3: HYBRID SEARCH (Keyword + Semantic) ‚óÄ‚óÄ‚óÄ\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "1. Score: 9.0087 | Title: Green\n",
      "2. Score: 8.8831 | Title: Energy\n",
      "3. Score: 8.6001 | Title: Hydrogen\n",
      "\n",
      "========================================================================================================================\n",
      "üí° INSIGHTS:\n",
      "  ‚Ä¢ Keyword Search: Good for exact matches, specific terms\n",
      "  ‚Ä¢ Semantic Search: Good for conceptual queries, finds similar meaning\n",
      "  ‚Ä¢ Hybrid Search: Best of both - combines precision and recall\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "def keyword_only_search(query_text, index_name, fields=[\"title\", \"context\", \"question\"], k=5):\n",
    "    \"\"\"Traditional keyword search using BM25. Searches across title, context, and question fields.\"\"\"\n",
    "    search_body = {\n",
    "        \"size\": k,\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": query_text,\n",
    "                \"fields\": fields\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\"id\", \"title\", \"context\", \"question\"]\n",
    "    }\n",
    "    return os_client.search(index=index_name, body=search_body)\n",
    "\n",
    "\n",
    "def compare_search_methods(query_text, index_name=\"squad_sample_with_pipeline\", k=3):\n",
    "    \"\"\"Compare keyword, semantic, and hybrid search side-by-side.\"\"\"\n",
    "    \n",
    "    print(\"=\"*120)\n",
    "    print(f\"üî¨ SEARCH COMPARISON\")\n",
    "    print(\"=\"*120)\n",
    "    print(f\"Query: '{query_text}'\")\n",
    "    print(f\"Index: {index_name}\")\n",
    "    print(f\"Top {k} results for each method\")\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    # 1. Keyword-only search\n",
    "    print(f\"\\n{'‚ñ∂'*3} METHOD 1: KEYWORD SEARCH (BM25) {'‚óÄ'*3}\")\n",
    "    print(f\"{'‚îÄ'*120}\")\n",
    "    keyword_results = keyword_only_search(query_text, index_name, k=k)\n",
    "    \n",
    "    for i, hit in enumerate(keyword_results['hits']['hits'], 1):\n",
    "        print(f\"{i}. Score: {hit['_score']:.4f} | Title: {hit['_source'].get('title', 'N/A')[:60]}\")\n",
    "    \n",
    "    # 2. Semantic-only search\n",
    "    print(f\"\\n{'‚ñ∂'*3} METHOD 2: SEMANTIC SEARCH (k-NN) {'‚óÄ'*3}\")\n",
    "    print(f\"{'‚îÄ'*120}\")\n",
    "    semantic_results = semantic_search_knn(query_text, index_name, field_to_search=\"context\", k=k, model_id=model_id)\n",
    "    \n",
    "    for i, hit in enumerate(semantic_results['hits']['hits'], 1):\n",
    "        print(f\"{i}. Score: {hit['_score']:.4f} | Title: {hit['_source'].get('title', 'N/A')[:60]}\")\n",
    "    \n",
    "    # 3. Hybrid search\n",
    "    print(f\"\\n{'‚ñ∂'*3} METHOD 3: HYBRID SEARCH (Keyword + Semantic) {'‚óÄ'*3}\")\n",
    "    print(f\"{'‚îÄ'*120}\")\n",
    "    hybrid_results = hybrid_search(query_text, index_name, k=k, model_id=model_id)\n",
    "    \n",
    "    for i, hit in enumerate(hybrid_results['hits']['hits'], 1):\n",
    "        print(f\"{i}. Score: {hit['_score']:.4f} | Title: {hit['_source'].get('title', 'N/A')[:60]}\")\n",
    "    \n",
    "    print(f\"\\n{'='*120}\")\n",
    "    print(\"üí° INSIGHTS:\")\n",
    "    print(\"  ‚Ä¢ Keyword Search: Good for exact matches, specific terms\")\n",
    "    print(\"  ‚Ä¢ Semantic Search: Good for conceptual queries, finds similar meaning\")\n",
    "    print(\"  ‚Ä¢ Hybrid Search: Best of both - combines precision and recall\")\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    return {\n",
    "        \"keyword\": keyword_results,\n",
    "        \"semantic\": semantic_results,\n",
    "        \"hybrid\": hybrid_results\n",
    "    }\n",
    "\n",
    "\n",
    "# Run comparison\n",
    "query = \"How do plants create energy from sunlight?\"\n",
    "comparison_results = compare_search_methods(query, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58ec6e9",
   "metadata": {},
   "source": [
    "## üéì Summary: Search Methods and Best Practices\n",
    "\n",
    "### ‚úÖ What We've Implemented:\n",
    "\n",
    "#### 1. **Semantic Search (k-NN)**\n",
    "- ‚úì Uses neural embeddings to find semantically similar documents\n",
    "- ‚úì Great for conceptual queries and finding related content\n",
    "- ‚úì Handles synonyms, paraphrasing, and language variations\n",
    "- ‚ö†Ô∏è May miss exact keyword matches\n",
    "\n",
    "#### 2. **Hybrid Search (Keyword + Semantic)**\n",
    "- ‚úì Combines BM25 keyword matching with k-NN semantic search\n",
    "- ‚úì Provides both precision (exact matches) and recall (similar concepts)\n",
    "- ‚úì Adjustable weights via boost parameters\n",
    "- ‚úì **RECOMMENDED for production use cases**\n",
    "\n",
    "#### 3. **Relevance Tuning**\n",
    "- ‚úì Boost adjustment: Control keyword vs semantic weight\n",
    "- ‚úì Field-level boosting: Prioritize important fields (title > context)\n",
    "- ‚úì Customizable scoring for business requirements\n",
    "\n",
    "### üìã Best Practices:\n",
    "\n",
    "| Use Case | Recommended Method | Settings |\n",
    "|----------|-------------------|----------|\n",
    "| **Question Answering** | Hybrid Search | keyword_boost=1.0, semantic_boost=1.5 |\n",
    "| **Exact Product Search** | Keyword-Heavy Hybrid | keyword_boost=2.0, semantic_boost=0.5 |\n",
    "| **Content Discovery** | Semantic-Heavy Hybrid | keyword_boost=0.5, semantic_boost=2.0 |\n",
    "| **Enterprise Search** | Hybrid + Field Boosting | title=3.0, question=2.0, context=1.0 |\n",
    "\n",
    "### üöÄ Next Steps for Production:\n",
    "\n",
    "1. **Experiment with boost values** on your specific data and queries\n",
    "2. **A/B test different configurations** to measure user satisfaction\n",
    "3. **Monitor query performance** and adjust based on metrics (latency, relevance)\n",
    "4. **Implement query expansion** and synonyms for better coverage\n",
    "5. **Use re-scoring** for top results with more expensive ranking functions\n",
    "6. **Add filters** (date ranges, categories) to narrow results before scoring\n",
    "7. **Implement caching** for frequently used queries\n",
    "\n",
    "### üìä Performance Characteristics:\n",
    "\n",
    "- **Keyword Search**: Fast (< 10ms), good for large datasets\n",
    "- **Semantic Search**: Slower (50-200ms), depends on k and index size\n",
    "- **Hybrid Search**: Medium (20-100ms), balanced approach\n",
    "\n",
    "**Note**: Actual performance depends on cluster size, index size, hardware, and query complexity.\n",
    "\n",
    "### üéØ Field Configuration:\n",
    "\n",
    "**Vector Embeddings Created For:**\n",
    "- ‚úì `title` - Enables semantic matching on document titles\n",
    "- ‚úì `context` - Main content field for semantic search\n",
    "- ‚úì `question` - Question field for Q&A matching\n",
    "\n",
    "**Excluded From Vectors:**\n",
    "- ‚úó `id` - Unique identifier, no semantic value\n",
    "\n",
    "**Why Include Title in Vectors?**\n",
    "- Titles often contain key concepts and are semantically meaningful\n",
    "- Matching on title embeddings improves relevance for title-focused queries\n",
    "- Supports scenarios where users search for topics by name/title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f12a8eb",
   "metadata": {},
   "source": [
    "## ‚úÖ Title Embeddings Configuration Summary\n",
    "\n",
    "This notebook now includes **title embeddings** for better semantic search capabilities:\n",
    "\n",
    "### üîß Configuration Changes:\n",
    "\n",
    "1. **`create_opensearch_mappings()`**\n",
    "   - Default exclusion: `['id']` (title is now included)\n",
    "   - Creates `title_embedding` vector field (768 dimensions)\n",
    "\n",
    "2. **`create_embedding_pipeline()`**\n",
    "   - Default exclusion: `['id']` (title is now included)\n",
    "   - Pipeline generates embeddings for: `title`, `context`, `question`\n",
    "\n",
    "3. **Search Functions Updated:**\n",
    "   - ‚úÖ `keyword_only_search()`: Searches `[\"title\", \"context\", \"question\"]`\n",
    "   - ‚úÖ `hybrid_search()`: Searches `[\"title\", \"context\", \"question\"]` by default\n",
    "   - ‚úÖ `field_boosted_search()`: Includes title with boost=2.0 (higher than context)\n",
    "   - ‚úÖ `semantic_search_knn()`: Can search title_embedding by passing `field_to_search=\"title\"`\n",
    "\n",
    "### üìä Vector Fields Created:\n",
    "\n",
    "| Field | Vector Field | Dimensions | Purpose |\n",
    "|-------|-------------|------------|---------|\n",
    "| `title` | `title_embedding` | 768 | Semantic matching on document titles |\n",
    "| `context` | `context_embedding` | 768 | Main content semantic search |\n",
    "| `question` | `question_embedding` | 768 | Question-answer matching |\n",
    "\n",
    "### üéØ Benefits of Title Embeddings:\n",
    "\n",
    "1. **Better Topic Matching**: Titles often contain the main topic/concept\n",
    "2. **Improved Relevance**: Documents with semantically similar titles rank higher\n",
    "3. **Field-Level Boosting**: Can prioritize title matches over content matches\n",
    "4. **Flexible Search**: Users can search specifically on titles or across all fields\n",
    "\n",
    "### üí° Example Usage:\n",
    "\n",
    "```python\n",
    "# Search only in title embeddings\n",
    "results = semantic_search_knn(\n",
    "    query_text=\"Machine Learning\",\n",
    "    index_name=\"squad_sample_with_pipeline\",\n",
    "    field_to_search=\"title\",\n",
    "    k=5,\n",
    "    model_id=model_id\n",
    ")\n",
    "\n",
    "# Hybrid search across all fields including title\n",
    "results = hybrid_search(\n",
    "    query_text=\"artificial intelligence\",\n",
    "    index_name=\"squad_sample_with_pipeline\",\n",
    "    fields_to_search=[\"title\", \"context\", \"question\"],  # Default\n",
    "    k=5,\n",
    "    model_id=model_id\n",
    ")\n",
    "\n",
    "# Boost title matches higher\n",
    "results = field_boosted_search(\n",
    "    query_text=\"deep learning\",\n",
    "    index_name=\"squad_sample_with_pipeline\",\n",
    "    field_boosts={\"title\": 3.0, \"question\": 2.0, \"context\": 1.0},\n",
    "    k=5,\n",
    "    model_id=model_id\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-ml-search-with-opensearch (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
