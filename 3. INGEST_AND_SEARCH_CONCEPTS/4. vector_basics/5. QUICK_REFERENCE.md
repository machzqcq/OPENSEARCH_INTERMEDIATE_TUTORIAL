# KNN Methods and Engines Quick Reference Guide

## üéØ Quick Decision Matrix

### What Method Should I Use?

| Your Priority | HNSW | IVF |
|---|---|---|
| **Query Speed** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Query Quality** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Memory Usage** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Indexing Speed** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Training Required** | ‚ùå No | ‚úÖ Yes |
| **Scalability** | ‚úÖ Billions | ‚úÖ Billions |

**‚Üí Choose HNSW** if: Query performance and quality matter most
**‚Üí Choose IVF** if: Memory is limited and you can tolerate training

---

## ‚öôÔ∏è What Engine Should I Use?

| Scenario | Recommended Engine | Why |
|---|---|---|
| **Large-scale (100M+ vectors)** | **Faiss** | Optimized, GPU-capable, lowest latency |
| **Medium-scale (10M - 100M)** | **Faiss or Lucene** | Both viable, Faiss for advanced features |
| **Small-scale (< 10M)** | **Lucene** | Simpler, better filtering, lower overhead |
| **Need filtering** | **Lucene** | Smart filtering integrated into search |
| **Highest performance** | **Faiss** | Industry-leading, SIMD optimized |
| **Legacy system** | Consider migrating from **NMSLIB** | NMSLIB deprecated in 3.0.0+ |

---

## üìê Configuration Quick-Start Templates

### Template 1: HNSW with Faiss (General Purpose)
```json
{
  "method": {
    "name": "hnsw",
    "engine": "faiss",
    "space_type": "l2",
    "parameters": {
      "ef_construction": 128,
      "m": 16,
      "ef_search": 100
    }
  }
}
```
**Use for:** General similarity search, balanced performance

---

### Template 2: HNSW with Lucene (Filtering)
```json
{
  "method": {
    "name": "hnsw",
    "engine": "lucene",
    "space_type": "cosinesimil",
    "parameters": {
      "ef_construction": 128,
      "m": 16
    }
  }
}
```
**Use for:** Need filtering with vector search

---

### Template 3: IVF with Faiss (Large Scale)
```json
{
  "method": {
    "name": "ivf",
    "engine": "faiss",
    "space_type": "l2",
    "parameters": {
      "nlist": 128,
      "nprobes": 10
    }
  }
}
```
**Use for:** Hundreds of millions or billions of vectors

---

### Template 4: IVF with PQ Compression (Memory Limited)
```json
{
  "method": {
    "name": "ivf",
    "engine": "faiss",
    "space_type": "l2",
    "parameters": {
      "nlist": 128,
      "nprobes": 10,
      "encoder": {
        "name": "pq",
        "parameters": {
          "m": 8,
          "code_size": 8
        }
      }
    }
  }
}
```
**Use for:** Very limited memory, acceptable accuracy loss

---

## üßÆ Memory Calculation Formulas

### HNSW Memory (in GB)
```
Memory = 1.1 * (4 * dimension + 8 * m) * num_vectors / (1024 * 1024 * 1024)

Example: 1M vectors, 256D, m=16
= 1.1 * (4 * 256 + 8 * 16) * 1,000,000 / (1024¬≥)
= 1.267 GB
```

### IVF Memory (in GB)
```
Memory = 1.1 * (((4 * dimension) * num_vectors) + (4 * nlist * dimension)) / (1024¬≥)

Example: 1M vectors, 256D, nlist=128
= 1.1 * (((4 * 256) * 1,000,000) + (4 * 128 * 256)) / (1024¬≥)
= 1.126 GB
```

---

## üîÑ Space Type vs Engine Support Matrix

| Space Type | HNSW | IVF | Notes |
|---|---|---|---|
| **l2** | Faiss‚úÖ, Lucene‚úÖ | Faiss‚úÖ | Default, Euclidean distance |
| **cosinesimil** | Faiss‚úÖ, Lucene‚úÖ | Faiss‚úÖ | For normalized vectors |
| **innerproduct** | Faiss‚úÖ, Lucene‚úÖ | Faiss‚úÖ | For embeddings from language models |
| **l1** | Faiss‚ùå, Lucene‚ùå | Faiss‚ùå | Manhattan distance - not in HNSW |
| **linf** | Faiss‚ùå, Lucene‚ùå | Faiss‚ùå | Chebyshev distance - not in HNSW |
| **hamming** | Faiss‚úÖ (binary) | Faiss‚úÖ | Binary vectors only |

---

## üìä Performance Characteristics

### Query Latency (Typical)
- **HNSW**: 5-50ms (depends on ef_search, k, dimension)
- **IVF**: 10-100ms (depends on nprobes, k, dimension)

### Memory Usage (1M vectors, 256D)
- **HNSW (m=16)**: ~1.27 GB
- **IVF (nlist=128)**: ~1.13 GB
- **IVF + PQ**: ~0.2-0.4 GB

### Indexing Latency (1M vectors)
- **HNSW**: Medium
- **IVF**: Faster (once training is done)

---

## üéì Recommendation by Use Case

### Use Case 1: Real-time Semantic Search
```json
Engine: Faiss
Method: HNSW
Space: cosinesimil
Reason: Fast queries, high quality, normalized embedding vectors
```

### Use Case 2: E-commerce Product Search
```json
Engine: Lucene
Method: HNSW
Space: l2
Reason: Need filtering by category/price, good performance
```

### Use Case 3: Large-scale Document Embedding
```json
Engine: Faiss
Method: IVF (if memory critical) or HNSW (if quality critical)
Space: cosinesimil
Reason: Billions of documents, multiple optimization options
```

### Use Case 4: Mobile/Edge Deployment
```json
Engine: Lucene
Method: HNSW
Space: cosinesimil
Reason: Smaller dataset, simpler operations, low overhead
```

### Use Case 5: GPU-Accelerated Search
```json
Engine: Faiss
Method: HNSW or IVF
Space: l2 or cosinesimil
Reason: Faiss has GPU support, best performance
```

---

## ‚ö†Ô∏è Common Mistakes to Avoid

1. **Using NMSLIB in OpenSearch 3.0+** ‚ùå
   - **Solution:** Migrate to Faiss or Lucene

2. **Not normalizing vectors for cosinesimil** ‚ùå
   - **Solution:** Always normalize before indexing for angle-based metrics

3. **Using IVF without training** ‚ùå
   - **Solution:** Use the Train API first for IVF indices

4. **Undersizing `nlist` for IVF** ‚ùå
   - **Solution:** nlist should be at least training_data_size / 100

5. **Setting `nprobes` too high** ‚ùå
   - **Solution:** Start with nprobes = 1-2, increase if needed

6. **Not monitoring memory usage** ‚ùå
   - **Solution:** Plan memory with formula before deploying

---

## üîÑ Migration Path

If you're currently using NMSLIB:

1. **For large-scale (> 10M):**
   - Migrate to: **Faiss HNSW** or **Faiss IVF**
   - Reindex your data
   - Gain: Better performance, advanced features

2. **For small-scale (< 10M):**
   - Migrate to: **Lucene HNSW**
   - Reindex your data
   - Gain: Better filtering, simpler operations

---

## üìö Further Learning

Check the notebook sections:
- Section 3: Detailed method explanations and examples
- Section 4: Engine characteristics and support matrix
- Section 5: Creating indices with different configurations
- Section 8: Performance analysis and memory estimation
