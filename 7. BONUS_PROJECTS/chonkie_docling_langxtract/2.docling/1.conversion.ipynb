{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "971cb562",
   "metadata": {},
   "source": [
    "# Docling Comprehensive Tutorial\n",
    "\n",
    "This notebook provides a complete guide to using **Docling**, a powerful document conversion and processing library. We'll explore everything from basic conversions to advanced pipelines with VLMs, ASR, custom OCR configurations, and more.\n",
    "\n",
    "## üìö Learning Path\n",
    "\n",
    "The diagram below illustrates all concepts covered in this tutorial:\n",
    "\n",
    "```mermaid\n",
    "graph TB\n",
    "    Start([üöÄ Start]):::startEnd --> Basics\n",
    "    \n",
    "    subgraph Basics[üî∞ Core Conversion]\n",
    "        B1[Minimal Conversion]\n",
    "        B2[Custom Configuration]\n",
    "        B3[Batch Processing]\n",
    "        B4[Multi-Format Support]\n",
    "    end\n",
    "    \n",
    "    subgraph Backends[üíæ Backends]\n",
    "        BE1[CSV Backend]\n",
    "        BE2[XML & RAG]\n",
    "    end\n",
    "    \n",
    "    subgraph Pipelines[ü§ñ Advanced Pipelines]\n",
    "        P1[VLM Pipeline - Minimal]\n",
    "        P2[VLM - Compare Models]\n",
    "        P3[VLM - API Model]\n",
    "        P4[ASR Pipeline]\n",
    "    end\n",
    "    \n",
    "    subgraph Exports[üì§ Exporting Results]\n",
    "        E1[Export Figures]\n",
    "        E2[Export Tables]\n",
    "        E3[Multimodal Export]\n",
    "    end\n",
    "    \n",
    "    subgraph OCR[üëÅÔ∏è Advanced OCR]\n",
    "        O1[Full Page OCR]\n",
    "        O2[Tesseract Lang Detection]\n",
    "        O3[RapidOCR Custom Models]\n",
    "        O4[SuryaOCR Custom Models]\n",
    "    end\n",
    "    \n",
    "    subgraph Advanced[‚ö° Enhancements]\n",
    "        A1[Accelerator Options]\n",
    "        A2[PII Obfuscation]\n",
    "        A3[Translation]\n",
    "    end\n",
    "    \n",
    "    Basics --> Backends\n",
    "    Backends --> Pipelines\n",
    "    Pipelines --> Exports\n",
    "    Exports --> OCR\n",
    "    OCR --> Advanced\n",
    "    Advanced --> End([üéØ Complete]):::startEnd\n",
    "    \n",
    "    classDef startEnd fill:#ff6b6b,stroke:#c92a2a,stroke-width:3px,color:#fff\n",
    "    classDef basics fill:#4ecdc4,stroke:#2a9d8f,stroke-width:2px\n",
    "    classDef pipelines fill:#95e1d3,stroke:#38ada9,stroke-width:2px\n",
    "    classDef exports fill:#ffd93d,stroke:#f6b93b,stroke-width:2px\n",
    "    classDef ocr fill:#a8e6cf,stroke:#6bcf9f,stroke-width:2px\n",
    "    classDef advanced fill:#ff8b94,stroke:#ff6b7a,stroke-width:2px\n",
    "    \n",
    "    class B1,B2,B3,B4 basics\n",
    "    class P1,P2,P3,P4 pipelines\n",
    "    class E1,E2,E3 exports\n",
    "    class O1,O2,O3,O4 ocr\n",
    "    class A1,A2,A3 advanced\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7b0c47",
   "metadata": {},
   "source": [
    "---\n",
    "# üî∞ Part 1: Core Conversion\n",
    "\n",
    "## 1. Minimal Conversion\n",
    "\n",
    "The simplest way to use Docling - convert a document with default settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ce28bc",
   "metadata": {},
   "source": [
    "### üìñ Concept Overview\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to perform a basic document conversion with default settings\n",
    "- Understanding the `DocumentConverter` class\n",
    "- Converting PDFs, images, and other formats to markdown\n",
    "- Checking conversion status\n",
    "\n",
    "**Key concepts:**\n",
    "- `DocumentConverter()` - The main entry point for conversions\n",
    "- `convert()` - Converts a single document\n",
    "- `export_to_markdown()` - Exports the result as markdown text\n",
    "\n",
    "This is the simplest way to get started with Docling!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b6919e",
   "metadata": {},
   "source": [
    "## üìÅ Create Mock Data\n",
    "\n",
    "Since we won't assume any data exists, let's create all the mock files we'll need for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5271dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created data directory: c:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\2.docling\\docling_tutorial_data\n",
      "‚úÖ Created PDF: docling_tutorial_data\\sample_document.pdf\n",
      "‚úÖ Created CSV: docling_tutorial_data\\employees.csv\n",
      "‚úÖ Created XML: docling_tutorial_data\\library.xml\n",
      "‚úÖ Created image: docling_tutorial_data\\sample_text_image.png\n",
      "‚úÖ Created multilingual image: docling_tutorial_data\\multilingual_sample.png\n",
      "üìù Audio file placeholder: docling_tutorial_data\\sample_speech.mp3\n",
      "   (For ASR examples, you would need a real audio file)\n",
      "‚úÖ Created HTML: docling_tutorial_data\\sample_page.html\n",
      "\n",
      "============================================================\n",
      "üéâ All mock data files created successfully!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import io\n",
    "\n",
    "# Create data directory\n",
    "data_dir = Path(\"docling_tutorial_data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Created data directory: {data_dir.absolute()}\")\n",
    "\n",
    "# 1. Create a mock PDF using reportlab\n",
    "try:\n",
    "    from reportlab.lib.pagesizes import letter\n",
    "    from reportlab.pdfgen import canvas\n",
    "    from reportlab.lib.utils import ImageReader\n",
    "    \n",
    "    pdf_path = data_dir / \"sample_document.pdf\"\n",
    "    c = canvas.Canvas(str(pdf_path), pagesize=letter)\n",
    "    \n",
    "    # Page 1\n",
    "    c.setFont(\"Helvetica-Bold\", 24)\n",
    "    c.drawString(100, 750, \"Docling Tutorial Sample Document\")\n",
    "    c.setFont(\"Helvetica\", 12)\n",
    "    c.drawString(100, 720, \"This is a sample PDF created for demonstrating Docling's capabilities.\")\n",
    "    c.drawString(100, 700, \"It contains multiple pages with text, tables, and images.\")\n",
    "    \n",
    "    # Add a simple table\n",
    "    c.setFont(\"Helvetica-Bold\", 14)\n",
    "    c.drawString(100, 650, \"Sample Table:\")\n",
    "    c.setFont(\"Helvetica\", 10)\n",
    "    y = 630\n",
    "    table_data = [\n",
    "        [\"Employee ID\", \"Name\", \"Department\", \"Salary\"],\n",
    "        [\"001\", \"John Doe\", \"Engineering\", \"$75,000\"],\n",
    "        [\"002\", \"Jane Smith\", \"Marketing\", \"$65,000\"],\n",
    "        [\"003\", \"Bob Johnson\", \"Sales\", \"$70,000\"]\n",
    "    ]\n",
    "    for row in table_data:\n",
    "        c.drawString(100, y, \" | \".join(row))\n",
    "        y -= 15\n",
    "    \n",
    "    c.showPage()\n",
    "    \n",
    "    # Page 2\n",
    "    c.setFont(\"Helvetica-Bold\", 18)\n",
    "    c.drawString(100, 750, \"Page 2: Additional Content\")\n",
    "    c.setFont(\"Helvetica\", 12)\n",
    "    c.drawString(100, 720, \"This page contains more text for testing multi-page conversion.\")\n",
    "    c.drawString(100, 700, \"Docling can extract text from complex layouts efficiently.\")\n",
    "    \n",
    "    c.save()\n",
    "    print(f\"‚úÖ Created PDF: {pdf_path}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è reportlab not installed. Creating a simple text file instead.\")\n",
    "    pdf_path = data_dir / \"sample_document.txt\"\n",
    "    with open(pdf_path, \"w\") as f:\n",
    "        f.write(\"Docling Tutorial Sample Document\\n\")\n",
    "        f.write(\"This is a sample text file for demonstration.\\n\")\n",
    "    print(f\"‚úÖ Created text file: {pdf_path}\")\n",
    "\n",
    "# 2. Create sample CSV\n",
    "csv_path = data_dir / \"employees.csv\"\n",
    "with open(csv_path, \"w\", newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"EmployeeID\", \"Name\", \"Department\", \"Email\", \"Salary\"])\n",
    "    writer.writerow([\"E001\", \"Alice Johnson\", \"Engineering\", \"alice@company.com\", \"95000\"])\n",
    "    writer.writerow([\"E002\", \"Bob Martinez\", \"Product\", \"bob@company.com\", \"87000\"])\n",
    "    writer.writerow([\"E003\", \"Carol White\", \"Marketing\", \"carol@company.com\", \"72000\"])\n",
    "    writer.writerow([\"E004\", \"David Brown\", \"Sales\", \"david@company.com\", \"68000\"])\n",
    "    writer.writerow([\"E005\", \"Eva Green\", \"HR\", \"eva@company.com\", \"65000\"])\n",
    "\n",
    "print(f\"‚úÖ Created CSV: {csv_path}\")\n",
    "\n",
    "# 3. Create sample XML\n",
    "xml_path = data_dir / \"library.xml\"\n",
    "xml_content = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<library>\n",
    "    <metadata>\n",
    "        <name>Tech Books Collection</name>\n",
    "        <location>Main Branch</location>\n",
    "        <established>2020</established>\n",
    "    </metadata>\n",
    "    <books>\n",
    "        <book id=\"1\">\n",
    "            <title>Introduction to Machine Learning</title>\n",
    "            <author>Dr. Sarah Anderson</author>\n",
    "            <year>2023</year>\n",
    "            <isbn>978-0-123456-78-9</isbn>\n",
    "            <category>AI/ML</category>\n",
    "            <available>true</available>\n",
    "        </book>\n",
    "        <book id=\"2\">\n",
    "            <title>Advanced Python Programming</title>\n",
    "            <author>Michael Chen</author>\n",
    "            <year>2024</year>\n",
    "            <isbn>978-0-987654-32-1</isbn>\n",
    "            <category>Programming</category>\n",
    "            <available>false</available>\n",
    "        </book>\n",
    "        <book id=\"3\">\n",
    "            <title>Data Structures and Algorithms</title>\n",
    "            <author>Lisa Rodriguez</author>\n",
    "            <year>2022</year>\n",
    "            <isbn>978-0-555666-77-8</isbn>\n",
    "            <category>Computer Science</category>\n",
    "            <available>true</available>\n",
    "        </book>\n",
    "    </books>\n",
    "</library>\n",
    "\"\"\"\n",
    "with open(xml_path, \"w\", encoding='utf-8') as f:\n",
    "    f.write(xml_content)\n",
    "\n",
    "print(f\"‚úÖ Created XML: {xml_path}\")\n",
    "\n",
    "# 4. Create sample images for OCR testing\n",
    "img_path = data_dir / \"sample_text_image.png\"\n",
    "img = Image.new('RGB', (800, 400), color=(255, 255, 255))\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "# Use default font\n",
    "try:\n",
    "    font_large = ImageFont.truetype(\"arial.ttf\", 36)\n",
    "    font_medium = ImageFont.truetype(\"arial.ttf\", 24)\n",
    "    font_small = ImageFont.truetype(\"arial.ttf\", 18)\n",
    "except:\n",
    "    font_large = ImageFont.load_default()\n",
    "    font_medium = ImageFont.load_default()\n",
    "    font_small = ImageFont.load_default()\n",
    "\n",
    "draw.text((50, 30), \"Docling OCR Test Image\", fill=(0, 0, 0), font=font_large)\n",
    "draw.text((50, 100), \"This image contains text that will be extracted\", fill=(50, 50, 50), font=font_medium)\n",
    "draw.text((50, 150), \"using Optical Character Recognition (OCR).\", fill=(50, 50, 50), font=font_medium)\n",
    "\n",
    "# Draw a simple table\n",
    "draw.text((50, 220), \"Sample Table:\", fill=(0, 0, 0), font=font_medium)\n",
    "draw.rectangle([50, 250, 750, 350], outline=(0, 0, 0), width=2)\n",
    "draw.line([50, 280, 750, 280], fill=(0, 0, 0), width=2)\n",
    "draw.line([300, 250, 300, 350], fill=(0, 0, 0), width=1)\n",
    "draw.line([550, 250, 550, 350], fill=(0, 0, 0), width=1)\n",
    "\n",
    "draw.text((100, 255), \"Product\", fill=(0, 0, 0), font=font_small)\n",
    "draw.text((350, 255), \"Quantity\", fill=(0, 0, 0), font=font_small)\n",
    "draw.text((600, 255), \"Price\", fill=(0, 0, 0), font=font_small)\n",
    "\n",
    "draw.text((100, 290), \"Laptop\", fill=(0, 0, 0), font=font_small)\n",
    "draw.text((380, 290), \"15\", fill=(0, 0, 0), font=font_small)\n",
    "draw.text((600, 290), \"$1200\", fill=(0, 0, 0), font=font_small)\n",
    "\n",
    "draw.text((100, 320), \"Mouse\", fill=(0, 0, 0), font=font_small)\n",
    "draw.text((380, 320), \"50\", fill=(0, 0, 0), font=font_small)\n",
    "draw.text((600, 320), \"$25\", fill=(0, 0, 0), font=font_small)\n",
    "\n",
    "img.save(img_path)\n",
    "print(f\"‚úÖ Created image: {img_path}\")\n",
    "\n",
    "# 5. Create a second image with different content\n",
    "img2_path = data_dir / \"multilingual_sample.png\"\n",
    "img2 = Image.new('RGB', (600, 300), color=(240, 248, 255))\n",
    "draw2 = ImageDraw.Draw(img2)\n",
    "\n",
    "draw2.text((50, 30), \"Multilingual Text Sample\", fill=(0, 0, 139), font=font_medium)\n",
    "draw2.text((50, 80), \"English: Hello, World!\", fill=(0, 0, 0), font=font_small)\n",
    "draw2.text((50, 110), \"Spanish: ¬°Hola, Mundo!\", fill=(0, 0, 0), font=font_small)\n",
    "draw2.text((50, 140), \"French: Bonjour, le Monde!\", fill=(0, 0, 0), font=font_small)\n",
    "draw2.text((50, 170), \"German: Hallo, Welt!\", fill=(0, 0, 0), font=font_small)\n",
    "\n",
    "img2.save(img2_path)\n",
    "print(f\"‚úÖ Created multilingual image: {img2_path}\")\n",
    "\n",
    "# 6. Create a mock audio file placeholder (we'll note it's for ASR demos)\n",
    "audio_placeholder = data_dir / \"sample_speech.mp3\"\n",
    "# Note: Creating actual audio requires additional libraries\n",
    "# For now, we'll just note where it should be\n",
    "print(f\"üìù Audio file placeholder: {audio_placeholder}\")\n",
    "print(\"   (For ASR examples, you would need a real audio file)\")\n",
    "\n",
    "# 7. Create HTML sample\n",
    "html_path = data_dir / \"sample_page.html\"\n",
    "html_content = \"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Sample Web Page</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Welcome to Docling Demo</h1>\n",
    "    <p>This is a sample HTML page that can be converted using Docling.</p>\n",
    "    <h2>Features</h2>\n",
    "    <ul>\n",
    "        <li>Convert HTML to structured documents</li>\n",
    "        <li>Preserve formatting and structure</li>\n",
    "        <li>Extract text and metadata</li>\n",
    "    </ul>\n",
    "    <table border=\"1\">\n",
    "        <tr>\n",
    "            <th>Feature</th>\n",
    "            <th>Status</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Text Extraction</td>\n",
    "            <td>‚úì Supported</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Image Processing</td>\n",
    "            <td>‚úì Supported</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "with open(html_path, \"w\", encoding='utf-8') as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "print(f\"‚úÖ Created HTML: {html_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ All mock data files created successfully!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7b0c47",
   "metadata": {},
   "source": [
    "---\n",
    "# üî∞ Part 1: Core Conversion\n",
    "\n",
    "## 1. Minimal Conversion\n",
    "\n",
    "The simplest way to use Docling - convert a document with default settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ce28bc",
   "metadata": {},
   "source": [
    "### üìñ Concept Overview\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to perform a basic document conversion with default settings\n",
    "- Understanding the `DocumentConverter` class\n",
    "- Converting PDFs, images, and other formats to markdown\n",
    "- Checking conversion status\n",
    "\n",
    "**Key concepts:**\n",
    "- `DocumentConverter()` - The main entry point for conversions\n",
    "- `convert()` - Converts a single document\n",
    "- `export_to_markdown()` - Exports the result as markdown text\n",
    "\n",
    "This is the simplest way to get started with Docling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bc5ad6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 16:29:18,107 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-13 16:29:18,109 - INFO - Going to convert document batch...\n",
      "2026-01-13 16:29:18,110 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e15bc6f248154cc62f8db15ef18a8ab7\n",
      "2026-01-13 16:29:18,110 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2026-01-13 16:29:18,119 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:29:18,124 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:29:18,124 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:29:18,207 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:29:18,209 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:29:18,210 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:29:18,245 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:29:18,256 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:29:18,257 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "2026-01-13 16:29:18,352 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2026-01-13 16:29:18,352 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-13 16:29:18,834 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-13 16:29:19,278 - INFO - Processing document sample_document.pdf\n",
      "2026-01-13 16:29:19,614 - INFO - Finished converting document sample_document.pdf in 1.52 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion Status: ConversionStatus.SUCCESS\n",
      "\n",
      "============================================================\n",
      "Markdown Output:\n",
      "============================================================\n",
      "## Docling Tutorial Sample Document\n",
      "\n",
      "This is a sample PDF created for demonstrating Docling's capabilities.\n",
      "\n",
      "It contains multiple pages with text, tables, and images.\n",
      "\n",
      "## Sample Table:\n",
      "\n",
      "Employee ID | Name | Department | Salary 001 | John Doe | Engineering | $75,000 002 | Jane Smith | Marketing | $65,000 003 | Bob Johnson | Sales | $70,000\n",
      "\n",
      "## Page 2: Additional Content\n",
      "\n",
      "This page contains more text for testing multi-page conversion.\n",
      "\n",
      "Docling can extract text from complex layouts efficiently.\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "# Initialize the converter with default settings\n",
    "converter = DocumentConverter()\n",
    "\n",
    "# Convert the document\n",
    "source = data_dir / \"sample_document.pdf\"\n",
    "result = converter.convert(source)\n",
    "\n",
    "# Display the result\n",
    "print(\"Conversion Status:\", result.status)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Markdown Output:\")\n",
    "print(\"=\"*60)\n",
    "print(result.document.export_to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c9cf16",
   "metadata": {},
   "source": [
    "## 2. Custom Convert\n",
    "\n",
    "Configure specific options for the conversion pipeline, such as enabling OCR, table structure recognition, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcf30dc",
   "metadata": {},
   "source": [
    "### üìñ Concept Overview\n",
    "\n",
    "**What you'll learn:**\n",
    "- Customizing pipeline options for better control\n",
    "- Enabling OCR (Optical Character Recognition)\n",
    "- Configuring table structure recognition\n",
    "- Fine-tuning conversion behavior\n",
    "\n",
    "**Key concepts:**\n",
    "- `PdfPipelineOptions` - Configuration for PDF processing\n",
    "- `do_ocr` - Enable/disable OCR\n",
    "- `do_table_structure` - Enable table detection\n",
    "- `TableStructureOptions` - Configure table extraction accuracy\n",
    "\n",
    "Use custom configuration when you need more control over how documents are processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38b095b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 16:27:55,536 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-13 16:27:55,541 - INFO - Going to convert document batch...\n",
      "2026-01-13 16:27:55,541 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e15bc6f248154cc62f8db15ef18a8ab7\n",
      "2026-01-13 16:27:55,541 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2026-01-13 16:27:55,554 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:27:55,558 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:27:55,559 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:27:55,622 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:27:55,624 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:27:55,625 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:27:55,674 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:27:55,681 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:27:55,681 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "2026-01-13 16:27:55,770 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2026-01-13 16:27:55,771 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-13 16:27:56,168 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-13 16:27:56,616 - INFO - Processing document sample_document.pdf\n",
      "2026-01-13 16:27:56,988 - INFO - Finished converting document sample_document.pdf in 1.45 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conversion Status: ConversionStatus.SUCCESS\n",
      "üìä OCR Enabled: True\n",
      "üìã Table Structure Recognition: True\n",
      "\n",
      "Document excerpt:\n",
      "## Docling Tutorial Sample Document\n",
      "\n",
      "This is a sample PDF created for demonstrating Docling's capabilities.\n",
      "\n",
      "It contains multiple pages with text, tables, and images.\n",
      "\n",
      "## Sample Table:\n",
      "\n",
      "Employee ID | Name | Department | Salary 001 | John Doe | Engineering | $75,000 002 | Jane Smith | Marketing | $65,000 003 | Bob Johnson | Sales | $70,000\n",
      "\n",
      "## Page 2: Additional Content\n",
      "\n",
      "This page contains more text for testing multi-page conversion.\n",
      "\n",
      "Docling can extract text from complex layouts efficiently....\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions, TableStructureOptions\n",
    "\n",
    "# Configure pipeline options\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.do_ocr = True\n",
    "pipeline_options.do_table_structure = True\n",
    "pipeline_options.table_structure_options = TableStructureOptions(\n",
    "    do_cell_matching=True,\n",
    "    mode=\"accurate\"  # Options: \"fast\", \"accurate\"\n",
    ")\n",
    "\n",
    "# Create converter with custom configuration\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Convert with custom settings\n",
    "result = doc_converter.convert(data_dir / \"sample_document.pdf\")\n",
    "\n",
    "print(f\"‚úÖ Conversion Status: {result.status}\")\n",
    "print(f\"üìä OCR Enabled: {pipeline_options.do_ocr}\")\n",
    "print(f\"üìã Table Structure Recognition: {pipeline_options.do_table_structure}\")\n",
    "print(\"\\nDocument excerpt:\")\n",
    "print(result.document.export_to_markdown()[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e296dde",
   "metadata": {},
   "source": [
    "## 3. Batch Convert\n",
    "\n",
    "Process multiple documents efficiently in a single operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c9228b",
   "metadata": {},
   "source": [
    "### üìñ Concept Overview\n",
    "\n",
    "**What you'll learn:**\n",
    "- Converting multiple documents efficiently\n",
    "- Using `convert_all()` for batch processing\n",
    "- Handling different file formats in one operation\n",
    "- Processing conversion results\n",
    "\n",
    "**Key concepts:**\n",
    "- `convert_all()` - Batch conversion method\n",
    "- Iterating over results\n",
    "- Status checking for each document\n",
    "\n",
    "Batch processing is essential for production workloads with many documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06171b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 16:27:33,270 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-13 16:27:33,272 - INFO - Going to convert document batch...\n",
      "2026-01-13 16:27:33,272 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e15bc6f248154cc62f8db15ef18a8ab7\n",
      "2026-01-13 16:27:33,274 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2026-01-13 16:27:33,285 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:27:33,288 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:27:33,289 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:27:33,351 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:27:33,353 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:27:33,353 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:27:33,401 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:27:33,410 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:27:33,411 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Conversion Results:\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 16:27:33,510 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2026-01-13 16:27:33,510 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-13 16:27:33,945 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-13 16:27:34,392 - INFO - Processing document sample_document.pdf\n",
      "2026-01-13 16:27:34,791 - INFO - Finished converting document sample_document.pdf in 1.51 sec.\n",
      "2026-01-13 16:27:34,793 - INFO - detected formats: [<InputFormat.IMAGE: 'image'>]\n",
      "2026-01-13 16:27:34,796 - INFO - Going to convert document batch...\n",
      "2026-01-13 16:27:34,796 - INFO - Processing document sample_text_image.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ File: sample_document.pdf\n",
      "   Status: ConversionStatus.SUCCESS\n",
      "   Preview: ## Docling Tutorial Sample Document\n",
      "\n",
      "This is a sample PDF created for demonstrating Docling's capabilities.\n",
      "\n",
      "It contains multiple pages with text, tab...\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 16:27:37,751 - INFO - Finished converting document sample_text_image.png in 2.95 sec.\n",
      "2026-01-13 16:27:37,753 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2026-01-13 16:27:37,755 - INFO - Going to convert document batch...\n",
      "2026-01-13 16:27:37,756 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2026-01-13 16:27:37,756 - INFO - Processing document sample_page.html\n",
      "2026-01-13 16:27:37,757 - INFO - Finished converting document sample_page.html in 0.01 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ File: sample_text_image.png\n",
      "   Status: ConversionStatus.SUCCESS\n",
      "   Preview: ## Docling OCR Test Image\n",
      "\n",
      "This image contains text that will be extracted using Optical Character Recognition (OCR).\n",
      "\n",
      "## Sample Table:\n",
      "\n",
      "| Product   |...\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìÑ File: sample_page.html\n",
      "   Status: ConversionStatus.SUCCESS\n",
      "   Preview: # Welcome to Docling Demo\n",
      "\n",
      "This is a sample HTML page that can be converted using Docling.\n",
      "\n",
      "## Features\n",
      "\n",
      "- Convert HTML to structured documents\n",
      "- Pres...\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "# List of documents to convert\n",
    "input_sources = [\n",
    "    data_dir / \"sample_document.pdf\",\n",
    "    data_dir / \"sample_text_image.png\",\n",
    "    data_dir / \"sample_page.html\"\n",
    "]\n",
    "\n",
    "converter = DocumentConverter()\n",
    "\n",
    "# Convert all documents\n",
    "results = converter.convert_all(input_sources)\n",
    "\n",
    "# Process results\n",
    "print(\"Batch Conversion Results:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for result in results:\n",
    "    print(f\"\\nüìÑ File: {result.input.file.name}\")\n",
    "    print(f\"   Status: {result.status}\")\n",
    "    if result.status.name == 'SUCCESS':\n",
    "        doc_preview = result.document.export_to_markdown()[:150]\n",
    "        print(f\"   Preview: {doc_preview}...\")\n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e282f8",
   "metadata": {},
   "source": [
    "## 4. Multi-Format Support\n",
    "\n",
    "Docling supports various input formats: PDF, DOCX, PPTX, images, HTML, and more. You can control which formats to allow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0617c430",
   "metadata": {},
   "source": [
    "### üìñ Concept Overview\n",
    "\n",
    "**What you'll learn:**\n",
    "- Understanding all supported input formats\n",
    "- Restricting allowed formats for security/performance\n",
    "- Format-specific handling\n",
    "- Working with PDF, DOCX, images, HTML, and more\n",
    "\n",
    "**Key concepts:**\n",
    "- `InputFormat` enum - All available formats\n",
    "- `allowed_formats` - Whitelist specific formats\n",
    "- Format detection and handling\n",
    "\n",
    "Docling supports 10+ document formats out of the box!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1168048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 15:55:37,162 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-13 15:55:37,349 - INFO - Going to convert document batch...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Input Formats:\n",
      "============================================================\n",
      "  ‚Ä¢ DOCX: docx\n",
      "  ‚Ä¢ PPTX: pptx\n",
      "  ‚Ä¢ HTML: html\n",
      "  ‚Ä¢ IMAGE: image\n",
      "  ‚Ä¢ PDF: pdf\n",
      "  ‚Ä¢ ASCIIDOC: asciidoc\n",
      "  ‚Ä¢ MD: md\n",
      "  ‚Ä¢ CSV: csv\n",
      "  ‚Ä¢ XLSX: xlsx\n",
      "  ‚Ä¢ XML_USPTO: xml_uspto\n",
      "  ‚Ä¢ XML_JATS: xml_jats\n",
      "  ‚Ä¢ METS_GBS: mets_gbs\n",
      "  ‚Ä¢ JSON_DOCLING: json_docling\n",
      "  ‚Ä¢ AUDIO: audio\n",
      "  ‚Ä¢ VTT: vtt\n",
      "\n",
      "============================================================\n",
      "\n",
      "Converting multiple formats:\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 15:55:37,351 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e15bc6f248154cc62f8db15ef18a8ab7\n",
      "2026-01-13 15:55:37,370 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-13 15:55:37,376 - WARNING - The plugin surya-ocr will not be loaded because Docling is being executed with allow_external_plugins=false.\n",
      "2026-01-13 15:55:37,377 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2026-01-13 15:55:37,395 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-13 15:55:37,405 - WARNING - The plugin surya-ocr will not be loaded because Docling is being executed with allow_external_plugins=false.\n",
      "2026-01-13 15:55:37,406 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2026-01-13 15:55:38,127 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2026-01-13 15:55:38,144 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 15:55:38,161 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 15:55:38,161 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 15:55:38,317 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 15:55:38,317 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 15:55:38,317 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 15:55:38,363 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 15:55:38,393 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 15:55:38,393 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "2026-01-13 15:55:38,500 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2026-01-13 15:55:38,508 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-13 15:55:38,520 - WARNING - The plugin surya-ocr will not be loaded because Docling is being executed with allow_external_plugins=false.\n",
      "2026-01-13 15:55:38,520 - INFO - Registered layout engines: ['docling_layout_default', 'docling_experimental_table_crops_layout']\n",
      "2026-01-13 15:55:42,899 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-13 15:55:43,717 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-13 15:55:43,718 - WARNING - The plugin surya-ocr will not be loaded because Docling is being executed with allow_external_plugins=false.\n",
      "2026-01-13 15:55:43,718 - INFO - Registered table structure engines: ['docling_tableformer']\n",
      "2026-01-13 15:55:43,801 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-13 15:55:44,392 - INFO - Processing document sample_document.pdf\n",
      "2026-01-13 15:55:45,600 - INFO - Finished converting document sample_document.pdf in 8.45 sec.\n",
      "2026-01-13 15:55:45,606 - INFO - detected formats: [<InputFormat.IMAGE: 'image'>]\n",
      "2026-01-13 15:55:45,609 - INFO - Going to convert document batch...\n",
      "2026-01-13 15:55:45,610 - INFO - Processing document sample_text_image.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ .PDF: sample_document.pdf - ConversionStatus.SUCCESS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 15:55:48,502 - INFO - Finished converting document sample_text_image.png in 2.89 sec.\n",
      "2026-01-13 15:55:48,502 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2026-01-13 15:55:48,508 - INFO - Going to convert document batch...\n",
      "2026-01-13 15:55:48,508 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2026-01-13 15:55:48,508 - INFO - Processing document sample_page.html\n",
      "2026-01-13 15:55:48,508 - INFO - Finished converting document sample_page.html in 0.01 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ .PNG: sample_text_image.png - ConversionStatus.SUCCESS\n",
      "‚úÖ .HTML: sample_page.html - ConversionStatus.SUCCESS\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "\n",
    "# Show all available formats\n",
    "print(\"Available Input Formats:\")\n",
    "print(\"=\"*60)\n",
    "for fmt in InputFormat:\n",
    "    print(f\"  ‚Ä¢ {fmt.name}: {fmt.value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Create converter with specific allowed formats\n",
    "converter = DocumentConverter(\n",
    "    allowed_formats=[\n",
    "        InputFormat.PDF,\n",
    "        InputFormat.IMAGE,\n",
    "        InputFormat.HTML,\n",
    "        InputFormat.DOCX\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Try converting different format types\n",
    "test_files = [\n",
    "    data_dir / \"sample_document.pdf\",\n",
    "    data_dir / \"sample_text_image.png\",\n",
    "    data_dir / \"sample_page.html\"\n",
    "]\n",
    "\n",
    "print(\"\\nConverting multiple formats:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for file in test_files:\n",
    "    if file.exists():\n",
    "        try:\n",
    "            result = converter.convert(file)\n",
    "            print(f\"‚úÖ {file.suffix.upper()}: {file.name} - {result.status}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå {file.name}: {str(e)[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3198033f",
   "metadata": {},
   "source": [
    "### Allow external plugins\n",
    "- e.g. surya_ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60ff4b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 16:01:37,936 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-13 16:01:37,940 - INFO - Going to convert document batch...\n",
      "2026-01-13 16:01:37,940 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 19290a5a28cef23fbe50840b45d241ba\n",
      "2026-01-13 16:01:37,957 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-13 16:01:37,957 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2026-01-13 16:01:37,970 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-13 16:01:37,970 - INFO - Loading plugin 'surya-ocr'\n",
      "2026-01-13 16:01:37,971 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract', 'suryaocr']\n",
      "2026-01-13 16:01:37,971 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2026-01-13 16:01:37,989 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:01:37,993 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:01:37,994 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:01:38,074 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:01:38,078 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:01:38,078 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:01:38,129 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:01:38,129 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:01:38,129 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "2026-01-13 16:01:38,244 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2026-01-13 16:01:38,257 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-13 16:01:38,258 - INFO - Registered layout engines: ['docling_layout_default', 'docling_experimental_table_crops_layout']\n",
      "2026-01-13 16:01:38,258 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-13 16:01:38,757 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-13 16:01:38,757 - INFO - Registered table structure engines: ['docling_tableformer']\n",
      "2026-01-13 16:01:38,812 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-13 16:01:39,275 - INFO - Processing document sample_document.pdf\n",
      "2026-01-13 16:01:39,641 - INFO - Finished converting document sample_document.pdf in 1.70 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Docling Tutorial Sample Document\n",
      "\n",
      "This is a sample PDF created for demonstrating Docling's capabilities.\n",
      "\n",
      "It contains multiple pages with text, tables, and images.\n",
      "\n",
      "## Sample Table:\n",
      "\n",
      "Employee ID | Name | Department | Salary 001 | John Doe | Engineering | $75,000 002 | Jane Smith | Marketing | $65,000 003 | Bob Johnson | Sales | $70,000\n",
      "\n",
      "## Page 2: Additional Content\n",
      "\n",
      "This page contains more text for testing multi-page conversion.\n",
      "\n",
      "Docling can extract text from complex layouts efficiently.\n"
     ]
    }
   ],
   "source": [
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "\n",
    "# 1. Initialize pipeline options and enable external plugins\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.allow_external_plugins = True  # Required for 3rd-party modules\n",
    "\n",
    "# 2. (Optional) Configure specific options from your plugin\n",
    "# pipeline_options.ocr_options = YourCustomPluginOptions() \n",
    "\n",
    "# 3. Setup the converter with these options\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "# 4. Use the converter as normal\n",
    "source = data_dir / \"sample_document.pdf\"\n",
    "result = doc_converter.convert(source)\n",
    "print(result.document.export_to_markdown())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adcc6a9",
   "metadata": {},
   "source": [
    "---\n",
    "# üíæ Part 2: Backends\n",
    "\n",
    "## 5. CSV Backend\n",
    "\n",
    "Docling can process CSV files and convert them to structured documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb9cc9b",
   "metadata": {},
   "source": [
    "## 6. XML Backend (RAG Ready)\n",
    "\n",
    "Convert XML documents and make them ready for RAG (Retrieval-Augmented Generation) applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0e8218",
   "metadata": {},
   "source": [
    "### üìñ Concept Overview\n",
    "\n",
    "**What you'll learn:**\n",
    "- Parsing XML documents\n",
    "- Preparing documents for RAG applications\n",
    "- Chunking content for vector databases\n",
    "- Exporting structured data\n",
    "\n",
    "**Key concepts:**\n",
    "- XML document processing\n",
    "- `iterate_items()` - Walk through document structure\n",
    "- `export_to_dict()` - Get structured representation\n",
    "- RAG (Retrieval-Augmented Generation) preparation\n",
    "\n",
    "XML backend helps prepare documents for AI/ML pipelines and search systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fedfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "# Convert XML file\n",
    "converter = DocumentConverter()\n",
    "xml_source = data_dir / \"library.xml\"\n",
    "\n",
    "result = converter.convert(xml_source)\n",
    "\n",
    "print(\"XML Conversion Result:\")\n",
    "print(\"=\"*60)\n",
    "markdown_output = result.document.export_to_markdown()\n",
    "print(markdown_output)\n",
    "\n",
    "# For RAG applications, you can chunk the content\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Document Structure for RAG:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Iterate through document items\n",
    "for item, level in result.document.iterate_items():\n",
    "    if hasattr(item, 'text') and item.text:\n",
    "        print(f\"Level {level}: {item.text[:100]}...\")\n",
    "        \n",
    "# Export to dict format (useful for vector databases)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Exportable Dict Format:\")\n",
    "print(\"=\"*60)\n",
    "doc_dict = result.document.export_to_dict()\n",
    "print(f\"Keys: {list(doc_dict.keys())}\")\n",
    "print(f\"Document name: {doc_dict.get('name', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20c4e94",
   "metadata": {},
   "source": [
    "---\n",
    "# ü§ñ Part 3: Advanced Pipelines\n",
    "\n",
    "## 7. Minimal VLM Pipeline\n",
    "\n",
    "Use Vision Language Models (VLMs) for advanced document understanding, especially useful for complex layouts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5387028",
   "metadata": {},
   "source": [
    "## 8. Compare VLM Models\n",
    "\n",
    "Compare different VLM models to find the best one for your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6650a9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è VLM features require: pip install docling[vlm]\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import VlmPipelineOptions\n",
    "\n",
    "try:\n",
    "    from docling.pipeline.vlm_pipeline import VlmPipeline\n",
    "    from docling import vlm_model_specs\n",
    "    \n",
    "    # Available VLM models\n",
    "    print(\"Available VLM Model Specs:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    vlm_models = [\n",
    "        (\"SMOLDOCLING_TRANSFORMERS\", vlm_model_specs.SMOLDOCLING_TRANSFORMERS),\n",
    "        (\"GRANITEDOCLING_TRANSFORMERS\", vlm_model_specs.GRANITEDOCLING_TRANSFORMERS),\n",
    "    ]\n",
    "    \n",
    "    for model_name, model_spec in vlm_models:\n",
    "        print(f\"\\nüì¶ {model_name}\")\n",
    "        print(f\"   Type: {type(model_spec).__name__}\")\n",
    "    \n",
    "    # Example: Use a specific model\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Converting with SmolDocling Model:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    pipeline_options = VlmPipelineOptions(\n",
    "        vlm_options=vlm_model_specs.SMOLDOCLING_TRANSFORMERS\n",
    "    )\n",
    "    \n",
    "    converter = DocumentConverter(\n",
    "        format_options={\n",
    "            InputFormat.PDF: PdfFormatOption(\n",
    "                pipeline_cls=VlmPipeline,\n",
    "                pipeline_options=pipeline_options\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    result = converter.convert(data_dir / \"sample_document.pdf\")\n",
    "    print(f\"‚úÖ Conversion Status: {result.status}\")\n",
    "    print(f\"\\nFirst 300 chars:\\n{result.document.export_to_markdown()[:300]}...\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è VLM features require: pip install docling[vlm]\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Model comparison requires model downloads: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c482ed45",
   "metadata": {},
   "source": [
    "## 9. VLM Pipeline with API Model\n",
    "\n",
    "Use remote API models (like GPT-4V) instead of local models to reduce compute requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8375ce30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLM API Configuration Example:\n",
      "============================================================\n",
      "\n",
      "# To use an API-based VLM model:\n",
      "\n",
      "from docling.datamodel.pipeline_options import VlmPipelineOptions, ApiVlmOptions\n",
      "\n",
      "api_options = ApiVlmOptions(\n",
      "    api_url=\"https://api.openai.com/v1/chat/completions\",\n",
      "    api_key=\"your-api-key-here\",\n",
      "    model_name=\"gpt-4-vision-preview\"\n",
      ")\n",
      "\n",
      "pipeline_options = VlmPipelineOptions(\n",
      "    vlm_options=api_options\n",
      ")\n",
      "\n",
      "converter = DocumentConverter(\n",
      "    format_options={\n",
      "        InputFormat.PDF: PdfFormatOption(\n",
      "            pipeline_cls=VlmPipeline,\n",
      "            pipeline_options=pipeline_options\n",
      "        )\n",
      "    }\n",
      ")\n",
      "\n",
      "# This offloads processing to the API instead of local compute\n",
      "result = converter.convert(\"document.pdf\")\n",
      "\n",
      "\n",
      "üí° Benefits of API-based VLM:\n",
      "   ‚Ä¢ No local GPU required\n",
      "   ‚Ä¢ Access to latest models\n",
      "   ‚Ä¢ Scalable processing\n",
      "   ‚Ä¢ Pay per use\n",
      "\n",
      "‚ö†Ô∏è Note: Requires API credentials and internet connection\n"
     ]
    }
   ],
   "source": [
    "from docling.datamodel.pipeline_options import VlmPipelineOptions\n",
    "\n",
    "# Configuration example for API-based VLM\n",
    "print(\"VLM API Configuration Example:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "config_example = \"\"\"\n",
    "# To use an API-based VLM model:\n",
    "\n",
    "from docling.datamodel.pipeline_options import VlmPipelineOptions, ApiVlmOptions\n",
    "\n",
    "api_options = ApiVlmOptions(\n",
    "    api_url=\"https://api.openai.com/v1/chat/completions\",\n",
    "    api_key=\"your-api-key-here\",\n",
    "    model_name=\"gpt-4-vision-preview\"\n",
    ")\n",
    "\n",
    "pipeline_options = VlmPipelineOptions(\n",
    "    vlm_options=api_options\n",
    ")\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_cls=VlmPipeline,\n",
    "            pipeline_options=pipeline_options\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "# This offloads processing to the API instead of local compute\n",
    "result = converter.convert(\"document.pdf\")\n",
    "\"\"\"\n",
    "\n",
    "print(config_example)\n",
    "\n",
    "print(\"\\nüí° Benefits of API-based VLM:\")\n",
    "print(\"   ‚Ä¢ No local GPU required\")\n",
    "print(\"   ‚Ä¢ Access to latest models\")\n",
    "print(\"   ‚Ä¢ Scalable processing\")\n",
    "print(\"   ‚Ä¢ Pay per use\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Note: Requires API credentials and internet connection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504f2ce8",
   "metadata": {},
   "source": [
    "## 10. Minimal ASR Pipeline\n",
    "\n",
    "Use Automatic Speech Recognition (ASR) to transcribe audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99546732",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 16:04:22,860 - INFO - detected formats: [<InputFormat.AUDIO: 'audio'>]\n",
      "2026-01-12 16:04:22,860 - INFO - Going to convert document batch...\n",
      "2026-01-12 16:04:22,860 - INFO - Initializing pipeline for AsrPipeline with options hash f13ce7fb9c9ff942ac42023aa9fd5569\n",
      "2026-01-12 16:04:22,860 - INFO - artifacts-path: None\n",
      "2026-01-12 16:04:22,860 - INFO - accelerator_options: num_threads=4 device='auto' cuda_use_flash_attention2=False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è ASR pipeline requires: pip install docling[asr]\n",
      "   Also requires ffmpeg to be installed on your system\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter, AudioFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "\n",
    "try:\n",
    "    from docling.pipeline.asr_pipeline import AsrPipeline\n",
    "    \n",
    "    # Check if we have an audio file\n",
    "    audio_file = data_dir / \"sample_speech.mp3\"\n",
    "    \n",
    "    if audio_file.exists() and audio_file.stat().st_size > 0:\n",
    "        # Configure ASR pipeline\n",
    "        converter = DocumentConverter(\n",
    "            format_options={\n",
    "                InputFormat.AUDIO: AudioFormatOption(pipeline_cls=AsrPipeline)\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Convert audio to text\n",
    "        result = converter.convert(audio_file)\n",
    "        \n",
    "        print(\"ASR Pipeline Result:\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Status: {result.status}\")\n",
    "        print(\"\\nTranscription:\")\n",
    "        print(result.document.export_to_markdown())\n",
    "    else:\n",
    "        print(\"üìù ASR Pipeline Configuration Example:\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"\"\"\n",
    "# To use ASR pipeline with a real audio file:\n",
    "\n",
    "from docling.document_converter import DocumentConverter, AudioFormatOption\n",
    "from docling.pipeline.asr_pipeline import AsrPipeline\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.AUDIO: AudioFormatOption(pipeline_cls=AsrPipeline)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Supported audio formats: MP3, WAV, M4A, FLAC, etc.\n",
    "result = converter.convert(\"speech.mp3\")\n",
    "transcription = result.document.export_to_markdown()\n",
    "        \"\"\")\n",
    "        \n",
    "        print(\"\\nüí° ASR Features:\")\n",
    "        print(\"   ‚Ä¢ Automatic language detection\")\n",
    "        print(\"   ‚Ä¢ Speaker diarization (when available)\")\n",
    "        print(\"   ‚Ä¢ Timestamp support\")\n",
    "        print(\"   ‚Ä¢ Multiple audio format support\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è ASR pipeline requires: pip install docling[asr]\")\n",
    "    print(\"   Also requires ffmpeg to be installed on your system\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d34b1e5",
   "metadata": {},
   "source": [
    "---\n",
    "# üì§ Part 4: Exporting Results\n",
    "\n",
    "## 11. Export Figures\n",
    "\n",
    "Extract and save figures/images from documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42c4404",
   "metadata": {},
   "source": [
    "## 12. Export Tables\n",
    "\n",
    "Extract tables and export them in various formats (DataFrame, HTML, CSV, Markdown)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8b96f0",
   "metadata": {},
   "source": [
    "### üìñ Concept Overview\n",
    "\n",
    "**What you'll learn:**\n",
    "- Extracting tables from documents\n",
    "- Exporting tables as DataFrames, CSV, HTML, Markdown\n",
    "- Table structure recognition\n",
    "- Programmatic table manipulation\n",
    "\n",
    "**Key concepts:**\n",
    "- `document.tables` - Access detected tables\n",
    "- `export_to_dataframe()` - Convert to pandas\n",
    "- `export_to_html()` / `export_to_csv()` - Various formats\n",
    "\n",
    "Table extraction is crucial for data analysis and structured information retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc4c04c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 16:22:02,196 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-13 16:22:02,199 - INFO - Going to convert document batch...\n",
      "2026-01-13 16:22:02,200 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e15bc6f248154cc62f8db15ef18a8ab7\n",
      "2026-01-13 16:22:02,201 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2026-01-13 16:22:02,217 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:22:02,222 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:22:02,223 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:22:02,285 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:22:02,286 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:22:02,287 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:22:02,331 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:22:02,344 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:22:02,344 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "2026-01-13 16:22:02,435 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2026-01-13 16:22:02,435 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-13 16:22:03,075 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-13 16:22:03,513 - INFO - Processing document sample_document.pdf\n",
      "2026-01-13 16:22:03,908 - INFO - Finished converting document sample_document.pdf in 1.72 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Extraction Results:\n",
      "============================================================\n",
      "üìä Total tables found: 0\n",
      "\n",
      "No tables found in the document.\n",
      "Tables can be extracted from PDFs, images with OCR, and structured documents.\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "import pandas as pd\n",
    "\n",
    "# Convert document\n",
    "converter = DocumentConverter()\n",
    "result = converter.convert(data_dir / \"sample_document.pdf\")\n",
    "\n",
    "print(\"Table Extraction Results:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create output directory for tables\n",
    "tables_dir = data_dir / \"extracted_tables\"\n",
    "tables_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Extract tables\n",
    "table_count = len(result.document.tables) if hasattr(result.document, 'tables') else 0\n",
    "print(f\"üìä Total tables found: {table_count}\\n\")\n",
    "\n",
    "if table_count > 0:\n",
    "    for i, table in enumerate(result.document.tables):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Table {i+1}:\")\n",
    "        print('='*60)\n",
    "        \n",
    "        # Export as DataFrame\n",
    "        try:\n",
    "            df = table.export_to_dataframe()\n",
    "            print(\"\\nüìã DataFrame Preview:\")\n",
    "            print(df)\n",
    "            \n",
    "            # Save as CSV\n",
    "            csv_path = tables_dir / f\"table_{i+1}.csv\"\n",
    "            df.to_csv(csv_path, index=False)\n",
    "            print(f\"\\n‚úÖ Saved as CSV: {csv_path.name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not export DataFrame: {e}\")\n",
    "        \n",
    "        # Export as HTML\n",
    "        try:\n",
    "            html = table.export_to_html()\n",
    "            html_path = tables_dir / f\"table_{i+1}.html\"\n",
    "            with open(html_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(html)\n",
    "            print(f\"‚úÖ Saved as HTML: {html_path.name}\")\n",
    "            print(f\"\\nHTML Preview:\\n{html[:200]}...\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not export HTML: {e}\")\n",
    "        \n",
    "        # Export as Markdown\n",
    "        try:\n",
    "            markdown = table.export_to_markdown()\n",
    "            md_path = tables_dir / f\"table_{i+1}.md\"\n",
    "            with open(md_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(markdown)\n",
    "            print(f\"‚úÖ Saved as Markdown: {md_path.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not export Markdown: {e}\")\n",
    "\n",
    "    print(f\"\\nüìÅ Tables saved to: {tables_dir.absolute()}\")\n",
    "else:\n",
    "    print(\"No tables found in the document.\")\n",
    "    print(\"Tables can be extracted from PDFs, images with OCR, and structured documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652fdce9",
   "metadata": {},
   "source": [
    "## 13. Export Multimodal\n",
    "\n",
    "Export documents with combined text, layout, and visual information for multimodal AI applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8980b85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 16:20:16,126 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-13 16:20:16,129 - INFO - Going to convert document batch...\n",
      "2026-01-13 16:20:16,130 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 43d100e5a88a3c7f4833eb75adbe811f\n",
      "2026-01-13 16:20:16,130 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2026-01-13 16:20:16,141 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:20:16,146 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:20:16,147 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:20:16,213 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:20:16,215 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:20:16,215 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:20:16,267 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:20:16,275 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:20:16,276 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "2026-01-13 16:20:16,367 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2026-01-13 16:20:16,368 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-13 16:20:16,798 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-13 16:20:17,246 - INFO - Processing document sample_document.pdf\n",
      "2026-01-13 16:20:17,663 - INFO - Finished converting document sample_document.pdf in 1.53 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multimodal Export:\n",
      "============================================================\n",
      "üì¶ Document Structure Keys: ['schema_name', 'version', 'name', 'origin', 'furniture', 'body', 'groups', 'texts', 'pictures', 'tables']\n",
      "üìÑ Document Name: sample_document\n",
      "\n",
      "üìñ Pages: 2\n",
      "   Page 1: 52888 chars of data\n",
      "   Page 2: 26784 chars of data\n",
      "\n",
      "‚úÖ Multimodal data saved to: multimodal_export.json\n",
      "\n",
      "============================================================\n",
      "Parquet Export for ML Pipelines:\n",
      "============================================================\n",
      "‚úÖ Saved 8 chunks to Parquet\n",
      "üìÅ File: document_chunks.parquet\n",
      "\n",
      "DataFrame preview:\n",
      "                                                text  level               type\n",
      "0                   Docling Tutorial Sample Document      1  SectionHeaderItem\n",
      "1  This is a sample PDF created for demonstrating...      1           TextItem\n",
      "2  It contains multiple pages with text, tables, ...      1           TextItem\n",
      "3                                      Sample Table:      1  SectionHeaderItem\n",
      "4  Employee ID | Name | Department | Salary 001 |...      1           TextItem\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "import json\n",
    "\n",
    "# Configure for multimodal export\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.generate_page_images = True\n",
    "pipeline_options.generate_picture_images = True\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "result = converter.convert(data_dir / \"sample_document.pdf\")\n",
    "\n",
    "print(\"Multimodal Export:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Export to dict (contains full structure)\n",
    "doc_dict = result.document.export_to_dict()\n",
    "\n",
    "print(f\"üì¶ Document Structure Keys: {list(doc_dict.keys())[:10]}\")\n",
    "print(f\"üìÑ Document Name: {doc_dict.get('name', 'N/A')}\")\n",
    "\n",
    "# Export metadata\n",
    "if 'metadata' in doc_dict:\n",
    "    print(f\"\\nüìã Metadata:\")\n",
    "    for key, value in list(doc_dict['metadata'].items())[:5]:\n",
    "        print(f\"   {key}: {value}\")\n",
    "\n",
    "# Page information\n",
    "if 'pages' in doc_dict:\n",
    "    print(f\"\\nüìñ Pages: {len(doc_dict['pages'])}\")\n",
    "    for page_num, page_data in list(doc_dict['pages'].items())[:2]:\n",
    "        print(f\"   Page {page_num}: {len(str(page_data))} chars of data\")\n",
    "\n",
    "# Save multimodal data as JSON\n",
    "multimodal_path = data_dir / \"multimodal_export.json\"\n",
    "with open(multimodal_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(doc_dict, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n‚úÖ Multimodal data saved to: {multimodal_path.name}\")\n",
    "\n",
    "# Document for Parquet export (useful for ML pipelines)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Parquet Export for ML Pipelines:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "    from docling_core.transforms.chunker import HybridChunker\n",
    "    \n",
    "    # Prepare data for Parquet\n",
    "    chunks = []\n",
    "    for item, level in result.document.iterate_items():\n",
    "        if hasattr(item, 'text') and item.text:\n",
    "            chunks.append({\n",
    "                'text': item.text,\n",
    "                'level': level,\n",
    "                'type': type(item).__name__\n",
    "            })\n",
    "    \n",
    "    if chunks:\n",
    "        df = pd.DataFrame(chunks)\n",
    "        parquet_path = data_dir / \"document_chunks.parquet\"\n",
    "        df.to_parquet(parquet_path)\n",
    "        print(f\"‚úÖ Saved {len(chunks)} chunks to Parquet\")\n",
    "        print(f\"üìÅ File: {parquet_path.name}\")\n",
    "        print(f\"\\nDataFrame preview:\")\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(\"No chunks to export\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Parquet export requires: pip install pandas pyarrow\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Parquet export error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48013742",
   "metadata": {},
   "source": [
    "---\n",
    "# üëÅÔ∏è Part 5: Advanced OCR\n",
    "\n",
    "## 14. Full Page OCR\n",
    "\n",
    "Force full-page OCR instead of using native text extraction (useful for scanned documents)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fe2439",
   "metadata": {},
   "source": [
    "## 15. Tesseract Language Detection\n",
    "\n",
    "Use Tesseract OCR with automatic language detection or specify languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571246ba",
   "metadata": {},
   "source": [
    "### üìñ Concept Overview\n",
    "\n",
    "**What you'll learn:**\n",
    "- Using Tesseract OCR engine\n",
    "- Automatic language detection\n",
    "- Specifying multiple languages\n",
    "- Page segmentation modes\n",
    "\n",
    "**Key concepts:**\n",
    "- `TesseractCliOcrOptions` - Tesseract configuration\n",
    "- `lang` parameter - Language specification\n",
    "- `psm` - Page segmentation mode\n",
    "- Language packs and installation\n",
    "\n",
    "Tesseract is a mature, open-source OCR engine with 100+ language support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82694215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 16:18:04,604 - INFO - detected formats: [<InputFormat.IMAGE: 'image'>]\n",
      "2026-01-13 16:18:04,606 - INFO - Going to convert document batch...\n",
      "2026-01-13 16:18:04,606 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 533c34cfcb200dfad02d3e0d118afa57\n",
      "2026-01-13 16:18:04,648 - INFO - command: C://Program Files//Tesseract-OCR//tesseract.exe --list-langs\n",
      "2026-01-13 16:18:04,689 - INFO - Accelerator device: 'cuda:0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesseract Language Detection Configuration:\n",
      "============================================================\n",
      "\n",
      "# 1. Auto-detect language\n",
      "from docling.datamodel.pipeline_options import TesseractCliOcrOptions\n",
      "\n",
      "pipeline_options = PdfPipelineOptions()\n",
      "pipeline_options.do_ocr = True\n",
      "pipeline_options.ocr_options = TesseractCliOcrOptions(\n",
      "    lang=[\"auto\"]  # Automatic language detection\n",
      ")\n",
      "\n",
      "# 2. Specify multiple languages\n",
      "pipeline_options.ocr_options = TesseractCliOcrOptions(\n",
      "    lang=[\"eng\", \"fra\", \"deu\", \"spa\"]  # English, French, German, Spanish\n",
      ")\n",
      "\n",
      "# 3. Single language for better accuracy\n",
      "pipeline_options.ocr_options = TesseractCliOcrOptions(\n",
      "    lang=[\"eng\"],  # English only\n",
      "    psm=6  # Page segmentation mode (6 = uniform block of text)\n",
      ")\n",
      "\n",
      "converter = DocumentConverter(\n",
      "    format_options={\n",
      "        InputFormat.IMAGE: ImageFormatOption(pipeline_options=pipeline_options)\n",
      "    }\n",
      ")\n",
      "\n",
      "\n",
      "üí° Common Tesseract Language Codes:\n",
      "============================================================\n",
      "  eng          - English\n",
      "  fra          - French\n",
      "  deu          - German\n",
      "  spa          - Spanish\n",
      "  ita          - Italian\n",
      "  por          - Portuguese\n",
      "  rus          - Russian\n",
      "  jpn          - Japanese\n",
      "  chi_sim      - Chinese (Simplified)\n",
      "  chi_tra      - Chinese (Traditional)\n",
      "  ara          - Arabic\n",
      "  hin          - Hindi\n",
      "\n",
      "‚ö†Ô∏è Note: Tesseract requires:\n",
      "   1. System installation: sudo apt-get install tesseract-ocr\n",
      "   2. Language packs: sudo apt-get install tesseract-ocr-[lang]\n",
      "   3. Python package: pip install pytesseract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 16:18:05,184 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-13 16:18:05,629 - INFO - Processing document sample_text_image.png\n",
      "2026-01-13 16:18:05,707 - INFO - command: C://Program Files//Tesseract-OCR//tesseract.exe --psm 0 -l osd C:\\Users\\PMACHA~1\\AppData\\Local\\Temp\\tmp4e6sloq9.png stdout\n",
      "2026-01-13 16:18:06,054 - INFO - command: C://Program Files//Tesseract-OCR//tesseract.exe -l eng C:\\Users\\PMACHA~1\\AppData\\Local\\Temp\\tmp4e6sloq9.png stdout tsv\n",
      "2026-01-13 16:18:06,602 - INFO - Finished converting document sample_text_image.png in 1.98 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Tesseract OCR Result:\n",
      "============================================================\n",
      "## Docling OCR Test Image\n",
      "\n",
      "This image contains text that will be extracted using Optical Character Recognition (OCR).\n",
      "\n",
      "## Sample Table:\n",
      "\n",
      "| Laptop   |   15 | $1200   |\n",
      "|----------|------|---------|\n",
      "| Mouse    |   50 | $25     |\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter, ImageFormatOption\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "\n",
    "print(\"Tesseract Language Detection Configuration:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Configuration examples\n",
    "config_examples = \"\"\"\n",
    "# 1. Auto-detect language\n",
    "from docling.datamodel.pipeline_options import TesseractCliOcrOptions\n",
    "\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.do_ocr = True\n",
    "pipeline_options.ocr_options = TesseractCliOcrOptions(\n",
    "    lang=[\"auto\"]  # Automatic language detection\n",
    ")\n",
    "\n",
    "# 2. Specify multiple languages\n",
    "pipeline_options.ocr_options = TesseractCliOcrOptions(\n",
    "    lang=[\"eng\", \"fra\", \"deu\", \"spa\"]  # English, French, German, Spanish\n",
    ")\n",
    "\n",
    "# 3. Single language for better accuracy\n",
    "pipeline_options.ocr_options = TesseractCliOcrOptions(\n",
    "    lang=[\"eng\"],  # English only\n",
    "    psm=6  # Page segmentation mode (6 = uniform block of text)\n",
    ")\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.IMAGE: ImageFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "print(config_examples)\n",
    "\n",
    "print(\"\\nüí° Common Tesseract Language Codes:\")\n",
    "print(\"=\"*60)\n",
    "languages = {\n",
    "    'eng': 'English',\n",
    "    'fra': 'French',\n",
    "    'deu': 'German',\n",
    "    'spa': 'Spanish',\n",
    "    'ita': 'Italian',\n",
    "    'por': 'Portuguese',\n",
    "    'rus': 'Russian',\n",
    "    'jpn': 'Japanese',\n",
    "    'chi_sim': 'Chinese (Simplified)',\n",
    "    'chi_tra': 'Chinese (Traditional)',\n",
    "    'ara': 'Arabic',\n",
    "    'hin': 'Hindi'\n",
    "}\n",
    "\n",
    "for code, name in languages.items():\n",
    "    print(f\"  {code:12} - {name}\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Note: Tesseract requires:\")\n",
    "print(\"   1. System installation: sudo apt-get install tesseract-ocr\")\n",
    "print(\"   2. Language packs: sudo apt-get install tesseract-ocr-[lang]\")\n",
    "print(\"   3. Python package: pip install pytesseract\")\n",
    "\n",
    "# Test with multilingual sample\n",
    "try:\n",
    "    from docling.datamodel.pipeline_options import TesseractCliOcrOptions\n",
    "    \n",
    "    pipeline_options = PdfPipelineOptions()\n",
    "    pipeline_options.do_ocr = True\n",
    "    pipeline_options.ocr_options = TesseractCliOcrOptions(lang=[\"eng\"])\n",
    "    pipeline_options.ocr_options.tesseract_cmd='C://Program Files//Tesseract-OCR//tesseract.exe'  # Example for Windows; adjust as needed\n",
    "    \n",
    "    converter = DocumentConverter(\n",
    "        format_options={\n",
    "            InputFormat.IMAGE: ImageFormatOption(pipeline_options=pipeline_options)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    result = converter.convert(data_dir / \"multilingual_sample.png\") #data_dir / \"sample_text_image.png\" #data_dir / \"multilingual_sample.png\"\n",
    "    print(\"\\n‚úÖ Tesseract OCR Result:\")\n",
    "    print(\"=\"*60)\n",
    "    print(result.document.export_to_markdown())\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"\\n‚ö†Ô∏è Tesseract not available in this environment\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è Tesseract error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e769f2",
   "metadata": {},
   "source": [
    "## 16. RapidOCR with Custom Models\n",
    "\n",
    "Use RapidOCR with custom ONNX model paths for detection and recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1446f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 16:12:45,410 - INFO - detected formats: [<InputFormat.IMAGE: 'image'>]\n",
      "2026-01-12 16:12:45,410 - INFO - Going to convert document batch...\n",
      "2026-01-12 16:12:45,415 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 332bedb9a442cccff51646a28356cc8a\n",
      "2026-01-12 16:12:45,432 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-12 16:12:45,435 - WARNING - The plugin surya-ocr will not be loaded because Docling is being executed with allow_external_plugins=false.\n",
      "2026-01-12 16:12:45,436 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2026-01-12 16:12:45,446 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-12 16:12:45,446 - WARNING - The plugin surya-ocr will not be loaded because Docling is being executed with allow_external_plugins=false.\n",
      "2026-01-12 16:12:45,454 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RapidOCR Custom Models Configuration:\n",
      "============================================================\n",
      "\n",
      "# RapidOCR allows using custom ONNX models\n",
      "from docling.datamodel.pipeline_options import PdfPipelineOptions, RapidOcrOptions\n",
      "\n",
      "# Configure with custom model paths\n",
      "pipeline_options = PdfPipelineOptions()\n",
      "pipeline_options.do_ocr = True\n",
      "\n",
      "# Specify custom ONNX model paths\n",
      "pipeline_options.ocr_options = RapidOcrOptions(\n",
      "    det_model_path=\"/path/to/detection_model.onnx\",\n",
      "    rec_model_path=\"/path/to/recognition_model.onnx\",\n",
      "    cls_model_path=\"/path/to/classification_model.onnx\"  # Optional\n",
      ")\n",
      "\n",
      "# Or use default RapidOCR models\n",
      "pipeline_options.ocr_options = RapidOcrOptions()\n",
      "\n",
      "converter = DocumentConverter(\n",
      "    format_options={\n",
      "        InputFormat.IMAGE: ImageFormatOption(pipeline_options=pipeline_options)\n",
      "    }\n",
      ")\n",
      "\n",
      "result = converter.convert(\"image.png\")\n",
      "\n",
      "\n",
      "üí° RapidOCR Features:\n",
      "============================================================\n",
      "  ‚úì Fast inference with ONNX Runtime\n",
      "  ‚úì Lightweight models\n",
      "  ‚úì CPU-friendly\n",
      "  ‚úì Support for custom trained models\n",
      "  ‚úì Good for production deployments\n",
      "\n",
      "üì¶ Model Types:\n",
      "  ‚Ä¢ Detection Model (det): Locates text regions\n",
      "  ‚Ä¢ Recognition Model (rec): Converts regions to text\n",
      "  ‚Ä¢ Classification Model (cls): Determines text orientation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 16:12:47,479 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2026-01-12 16:12:47,488 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-12 16:12:47,518 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\1. chunking\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-12 16:12:47,518 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\1. chunking\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-12 16:12:47,599 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-12 16:12:47,600 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\1. chunking\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-12 16:12:47,600 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\1. chunking\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-12 16:12:47,644 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-12 16:12:47,655 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\1. chunking\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-12 16:12:47,657 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\1. chunking\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "2026-01-12 16:12:47,767 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-12 16:12:47,769 - WARNING - The plugin surya-ocr will not be loaded because Docling is being executed with allow_external_plugins=false.\n",
      "2026-01-12 16:12:47,769 - INFO - Registered layout engines: ['docling_layout_default', 'docling_experimental_table_crops_layout']\n",
      "2026-01-12 16:12:50,200 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-12 16:12:51,173 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-12 16:12:51,174 - WARNING - The plugin surya-ocr will not be loaded because Docling is being executed with allow_external_plugins=false.\n",
      "2026-01-12 16:12:51,175 - INFO - Registered table structure engines: ['docling_tableformer']\n",
      "2026-01-12 16:12:51,228 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-12 16:12:51,539 - INFO - Processing document sample_text_image.png\n",
      "2026-01-12 16:12:54,629 - INFO - Finished converting document sample_text_image.png in 9.22 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ RapidOCR Result:\n",
      "============================================================\n",
      "## Docling OCR Test Image\n",
      "\n",
      "This image contains text that will be extracted using Optical Character Recognition (OCR).\n",
      "\n",
      "## Sample Table:\n",
      "\n",
      "| Product   |   Quantity | Price   |\n",
      "|-----------|------------|---------|\n",
      "| Laptop    |         15 | $1200   |\n",
      "| Mouse     |         50 | $25     |\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter, ImageFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "\n",
    "print(\"RapidOCR Custom Models Configuration:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "config_example = \"\"\"\n",
    "# RapidOCR allows using custom ONNX models\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions, RapidOcrOptions\n",
    "\n",
    "# Configure with custom model paths\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.do_ocr = True\n",
    "\n",
    "# Specify custom ONNX model paths\n",
    "pipeline_options.ocr_options = RapidOcrOptions(\n",
    "    det_model_path=\"/path/to/detection_model.onnx\",\n",
    "    rec_model_path=\"/path/to/recognition_model.onnx\",\n",
    "    cls_model_path=\"/path/to/classification_model.onnx\"  # Optional\n",
    ")\n",
    "\n",
    "# Or use default RapidOCR models\n",
    "pipeline_options.ocr_options = RapidOcrOptions()\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.IMAGE: ImageFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "result = converter.convert(\"image.png\")\n",
    "\"\"\"\n",
    "\n",
    "print(config_example)\n",
    "\n",
    "print(\"\\nüí° RapidOCR Features:\")\n",
    "print(\"=\"*60)\n",
    "print(\"  ‚úì Fast inference with ONNX Runtime\")\n",
    "print(\"  ‚úì Lightweight models\")\n",
    "print(\"  ‚úì CPU-friendly\")\n",
    "print(\"  ‚úì Support for custom trained models\")\n",
    "print(\"  ‚úì Good for production deployments\")\n",
    "\n",
    "print(\"\\nüì¶ Model Types:\")\n",
    "print(\"  ‚Ä¢ Detection Model (det): Locates text regions\")\n",
    "print(\"  ‚Ä¢ Recognition Model (rec): Converts regions to text\")\n",
    "print(\"  ‚Ä¢ Classification Model (cls): Determines text orientation\")\n",
    "\n",
    "# Try with default RapidOCR\n",
    "try:\n",
    "    from docling.datamodel.pipeline_options import RapidOcrOptions\n",
    "    \n",
    "    pipeline_options = PdfPipelineOptions()\n",
    "    pipeline_options.do_ocr = True\n",
    "    pipeline_options.ocr_options = RapidOcrOptions()\n",
    "    \n",
    "    converter = DocumentConverter(\n",
    "        format_options={\n",
    "            InputFormat.IMAGE: ImageFormatOption(pipeline_options=pipeline_options)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    result = converter.convert(data_dir / \"sample_text_image.png\")\n",
    "    print(\"\\n‚úÖ RapidOCR Result:\")\n",
    "    print(\"=\"*60)\n",
    "    print(result.document.export_to_markdown()[:400])\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"\\n‚ö†Ô∏è RapidOCR requires: pip install rapidocr-onnxruntime\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è RapidOCR error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a971d81",
   "metadata": {},
   "source": [
    "## 17. SuryaOCR with Custom Models\n",
    "\n",
    "Use SuryaOCR, a modern OCR engine with support for custom models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f994db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 16:02:28,467 - INFO - detected formats: [<InputFormat.IMAGE: 'image'>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 16:02:28,471 - INFO - Going to convert document batch...\n",
      "2026-01-13 16:02:28,472 - INFO - Initializing pipeline for StandardPdfPipeline with options hash c3e46052a277609cda7a92f3807bd9c4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SuryaOCR Custom Models Configuration:\n",
      "============================================================\n",
      "\n",
      "# SuryaOCR - Advanced OCR with custom model support\n",
      "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
      "from docling_surya.options import SuryaOcrOptions\n",
      "\n",
      "pipeline_options = PdfPipelineOptions()\n",
      "pipeline_options.do_ocr = True\n",
      "\n",
      "# Configure SuryaOCR\n",
      "pipeline_options.ocr_options = SuryaOcrOptions(\n",
      "    lang=[\"en\"],  # Supported languages\n",
      "    # Custom model paths (optional)\n",
      "    det_model_path=\"/path/to/detection_model\",\n",
      "    rec_model_path=\"/path/to/recognition_model\"\n",
      ")\n",
      "\n",
      "converter = DocumentConverter(\n",
      "    format_options={\n",
      "        InputFormat.IMAGE: ImageFormatOption(pipeline_options=pipeline_options)\n",
      "    }\n",
      ")\n",
      "\n",
      "result = converter.convert(\"document.png\")\n",
      "\n",
      "\n",
      "üí° SuryaOCR Features:\n",
      "============================================================\n",
      "  ‚úì Modern transformer-based architecture\n",
      "  ‚úì High accuracy on complex layouts\n",
      "  ‚úì Multilingual support\n",
      "  ‚úì Custom model fine-tuning\n",
      "  ‚úì Good for handwriting and difficult text\n",
      "\n",
      "üìã Supported Languages:\n",
      "  ‚Ä¢ English (en)\n",
      "  ‚Ä¢ Spanish (es)\n",
      "  ‚Ä¢ French (fr)\n",
      "  ‚Ä¢ German (de)\n",
      "  ‚Ä¢ Chinese (zh)\n",
      "  ‚Ä¢ And many more...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading manifest.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 262/262 [00:00<?, ?B/s] \n",
      "Downloading text_recognition model to C:\\Users\\pmacharla\\.cache\\docling\\models\\SuryaOcr\\text_recognition/2025_09_23:   0%|          | 0/12 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "Downloading vocab_math.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.1k/20.1k [00:00<00:00, 3.07MB/s]\n",
      "Downloading .gitattributes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.48k/1.48k [00:00<00:00, 227kB/s]\n",
      "Downloading training_args.bin: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.45k/7.45k [00:00<00:00, 616kB/s]\n",
      "Downloading special_tokens_map.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 278/278 [00:00<00:00, 36.1kB/s]cr\\text_recognition/2025_09_23:   8%|‚ñä         | 1/12 [00:00<00:01,  7.87it/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "Downloading tokenizer_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 694/694 [00:00<00:00, 82.3kB/s]\n",
      "Downloading specials_dict.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43.5k/43.5k [00:00<00:00, 5.99MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading specials.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19.6k/19.6k [00:00<00:00, 1.54MB/s]\n",
      "Downloading preprocessor_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 419/419 [00:00<00:00, 75.8kB/s]\n",
      "Downloading README.md: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.05k/5.05k [00:00<00:00, 1.15MB/s]\n",
      "Downloading config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50.2k/50.2k [00:00<00:00, 8.67MB/s]\n",
      "Downloading processor_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 411/411 [00:00<?, ?B/s] \n",
      "Downloading model.safetensors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.34G/1.34G [02:44<00:00, 8.76MB/s]\n",
      "Downloading text_recognition model to C:\\Users\\pmacharla\\.cache\\docling\\models\\SuryaOcr\\text_recognition/2025_09_23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [02:44<00:00, 13.73s/it]\n",
      "Downloading manifest.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:00<?, ?B/s] \n",
      "Downloading text_detection model to C:\\Users\\pmacharla\\.cache\\docling\\models\\SuryaOcr\\text_detection/2025_05_07:   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "Downloading preprocessor_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 373/373 [00:00<00:00, 591kB/s]\n",
      "Downloading README.md: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 393/393 [00:00<?, ?B/s] \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading .gitattributes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.48k/1.48k [00:00<00:00, 1.17MB/s]\n",
      "Downloading config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 858/858 [00:00<00:00, 199kB/s]\n",
      "Downloading training_args.bin: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.49k/5.49k [00:00<00:00, 2.41MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading model.safetensors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 73.4M/73.4M [00:05<00:00, 12.9MB/s]\n",
      "Downloading text_detection model to C:\\Users\\pmacharla\\.cache\\docling\\models\\SuryaOcr\\text_detection/2025_05_07: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:06<00:00,  1.01s/it]\n",
      "2026-01-13 16:05:20,873 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-13 16:05:21,360 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-13 16:05:21,895 - INFO - Processing document sample_text_image.png\n",
      "Detecting bboxes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.71it/s]\n",
      "Recognizing Text: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  9.79it/s]\n",
      "2026-01-13 16:05:24,061 - INFO - Finished converting document sample_text_image.png in 175.58 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ SuryaOCR Result:\n",
      "============================================================\n",
      "## Docling OCR Test Image\n",
      "\n",
      "This image contains text that will be extracted using Optical Character Recognition (OCR).\n",
      "\n",
      "## Sample Table:\n",
      "\n",
      "| Product   |   Quantity | Price   |\n",
      "|-----------|------------|---------|\n",
      "| Laptop    |         15 | $1200   |\n",
      "| Mouse     |         50 | $25     |\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter, ImageFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "\n",
    "print(\"SuryaOCR Custom Models Configuration:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "config_example = \"\"\"\n",
    "# SuryaOCR - Advanced OCR with custom model support\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling_surya.options import SuryaOcrOptions\n",
    "\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.do_ocr = True\n",
    "\n",
    "# Configure SuryaOCR\n",
    "pipeline_options.ocr_options = SuryaOcrOptions(\n",
    "    lang=[\"en\"],  # Supported languages\n",
    "    # Custom model paths (optional)\n",
    "    det_model_path=\"/path/to/detection_model\",\n",
    "    rec_model_path=\"/path/to/recognition_model\"\n",
    ")\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.IMAGE: ImageFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "result = converter.convert(\"document.png\")\n",
    "\"\"\"\n",
    "\n",
    "print(config_example)\n",
    "\n",
    "print(\"\\nüí° SuryaOCR Features:\")\n",
    "print(\"=\"*60)\n",
    "print(\"  ‚úì Modern transformer-based architecture\")\n",
    "print(\"  ‚úì High accuracy on complex layouts\")\n",
    "print(\"  ‚úì Multilingual support\")\n",
    "print(\"  ‚úì Custom model fine-tuning\")\n",
    "print(\"  ‚úì Good for handwriting and difficult text\")\n",
    "\n",
    "print(\"\\nüìã Supported Languages:\")\n",
    "print(\"  ‚Ä¢ English (en)\")\n",
    "print(\"  ‚Ä¢ Spanish (es)\")\n",
    "print(\"  ‚Ä¢ French (fr)\")\n",
    "print(\"  ‚Ä¢ German (de)\")\n",
    "print(\"  ‚Ä¢ Chinese (zh)\")\n",
    "print(\"  ‚Ä¢ And many more...\")\n",
    "\n",
    "# Try with SuryaOCR\n",
    "try:\n",
    "    from docling_surya import SuryaOcrOptions\n",
    "    from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "\n",
    "    pipeline_options = PdfPipelineOptions(\n",
    "    do_ocr=True,\n",
    "    ocr_model=\"suryaocr\",           # Plugin engine name\n",
    "    allow_external_plugins=True,     # Required for third-party plugins\n",
    "    ocr_options=SuryaOcrOptions(\n",
    "        lang=[\"en\"],                 # OCR language(s)\n",
    "        use_gpu=True,                # Optional: force GPU\n",
    "    ),\n",
    ")\n",
    "    \n",
    "    converter = DocumentConverter(\n",
    "        format_options={\n",
    "            InputFormat.IMAGE: ImageFormatOption(pipeline_options=pipeline_options)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    result = converter.convert(data_dir / \"sample_text_image.png\")\n",
    "    print(\"\\n‚úÖ SuryaOCR Result:\")\n",
    "    print(\"=\"*60)\n",
    "    print(result.document.export_to_markdown()[:400])\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"\\n‚ö†Ô∏è SuryaOCR requires: pip install docling-surya\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è SuryaOCR error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07ab5f6",
   "metadata": {},
   "source": [
    "---\n",
    "# ‚ö° Part 6: Performance & Enhancement\n",
    "\n",
    "## 18. Accelerator Options\n",
    "\n",
    "Configure hardware acceleration for optimal performance (CPU, CUDA, MPS)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45de547",
   "metadata": {},
   "source": [
    "## 19. PII Obfuscation\n",
    "\n",
    "Detect and obfuscate Personally Identifiable Information (PII) in documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9440bc1e",
   "metadata": {},
   "source": [
    "### üìñ Concept Overview\n",
    "\n",
    "**What you'll learn:**\n",
    "- Detecting personally identifiable information (PII)\n",
    "- Obfuscating sensitive data\n",
    "- Regular expressions for pattern matching\n",
    "- Using NER models for advanced detection\n",
    "\n",
    "**Key concepts:**\n",
    "- PII types (names, emails, SSN, credit cards)\n",
    "- Pattern-based detection\n",
    "- NER (Named Entity Recognition)\n",
    "- Compliance requirements (GDPR, HIPAA, CCPA)\n",
    "\n",
    "PII obfuscation is critical for protecting privacy and meeting compliance requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10d6ddfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 16:07:50,136 - INFO - detected formats: [<InputFormat.CSV: 'csv'>]\n",
      "2026-01-13 16:07:50,136 - INFO - Going to convert document batch...\n",
      "2026-01-13 16:07:50,139 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2026-01-13 16:07:50,140 - INFO - Processing document employees.csv\n",
      "2026-01-13 16:07:50,141 - INFO - Parsing CSV with delimiter: \",\"\n",
      "2026-01-13 16:07:50,141 - INFO - Detected 6 lines\n",
      "2026-01-13 16:07:50,142 - INFO - Finished converting document employees.csv in 0.02 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PII Obfuscation:\n",
      "============================================================\n",
      "Original Document:\n",
      "------------------------------------------------------------\n",
      "| EmployeeID   | Name          | Department   | Email             |   Salary |\n",
      "|--------------|---------------|--------------|-------------------|----------|\n",
      "| E001         | Alice Johnson | Engineering  | alice@company.com |    95000 |\n",
      "| E002         | Bob Martinez  | Product      | bob@company.com   |    87000 |\n",
      "| E003         | Carol White   | Marketing    | carol@company.com |    72000 |\n",
      "| E004         | David Brown   | Sales        | david@company.com |    68000 |\n",
      "| E005         | Eva Green     | HR           | eva@company.com   |    65000 |\n",
      "\n",
      "============================================================\n",
      "Obfuscated Document:\n",
      "------------------------------------------------------------\n",
      "| EmployeeID   | Name          | Department   | Email             |   Salary |\n",
      "|--------------|---------------|--------------|-------------------|----------|\n",
      "| E001         | [NAME] | Engineering  | [EMAIL] |    95000 |\n",
      "| E002         | [NAME]  | Product      | [EMAIL]   |    87000 |\n",
      "| E003         | [NAME]   | Marketing    | [EMAIL] |    72000 |\n",
      "| E004         | [NAME]   | Sales        | [EMAIL] |    68000 |\n",
      "| E005         | [NAME]     | HR           | [EMAIL]   |    65000 |\n",
      "\n",
      "============================================================\n",
      "Advanced PII Detection with NER:\n",
      "============================================================\n",
      "\n",
      "# Using GLiNER for PII detection\n",
      "try:\n",
      "    from gliner import GLiNER\n",
      "\n",
      "    # Load GLiNER model for NER\n",
      "    model = GLiNER.from_pretrained(\"urchade/gliner_base\")\n",
      "\n",
      "    # Define PII entities to detect\n",
      "    labels = [\"person\", \"email\", \"phone number\", \"social security number\", \n",
      "              \"credit card\", \"address\", \"organization\"]\n",
      "\n",
      "    # Detect entities\n",
      "    entities = model.predict_entities(original_text, labels)\n",
      "\n",
      "    # Obfuscate detected entities\n",
      "    obfuscated = original_text\n",
      "    for entity in sorted(entities, key=lambda x: x['start'], reverse=True):\n",
      "        start, end = entity['start'], entity['end']\n",
      "        entity_type = entity['label'].upper().replace(' ', '_')\n",
      "        obfuscated = obfuscated[:start] + f'[{entity_type}]' + obfuscated[end:]\n",
      "\n",
      "    print(obfuscated)\n",
      "\n",
      "except ImportError:\n",
      "    print(\"Install GLiNER: pip install gliner\")\n",
      "\n",
      "\n",
      "üí° PII Types Commonly Obfuscated:\n",
      "  ‚Ä¢ Names (PERSON)\n",
      "  ‚Ä¢ Email addresses (EMAIL)\n",
      "  ‚Ä¢ Phone numbers (PHONE)\n",
      "  ‚Ä¢ Social Security Numbers (SSN)\n",
      "  ‚Ä¢ Credit Card Numbers (CREDIT_CARD)\n",
      "  ‚Ä¢ Addresses (ADDRESS)\n",
      "  ‚Ä¢ Bank Account Numbers (ACCOUNT)\n",
      "  ‚Ä¢ Passport Numbers (PASSPORT)\n",
      "  ‚Ä¢ Medical Record Numbers (MRN)\n",
      "\n",
      "‚ö†Ô∏è Compliance:\n",
      "  ‚Ä¢ GDPR (Europe)\n",
      "  ‚Ä¢ HIPAA (Healthcare - USA)\n",
      "  ‚Ä¢ CCPA (California - USA)\n",
      "  ‚Ä¢ Use PII obfuscation before sharing documents\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "import re\n",
    "\n",
    "print(\"PII Obfuscation:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Convert document\n",
    "converter = DocumentConverter()\n",
    "result = converter.convert(data_dir / \"employees.csv\")\n",
    "\n",
    "print(\"Original Document:\")\n",
    "print(\"-\"*60)\n",
    "original_text = result.document.export_to_markdown()\n",
    "print(original_text)\n",
    "\n",
    "# PII Detection and Obfuscation Functions\n",
    "def obfuscate_emails(text):\n",
    "    \"\"\"Replace email addresses with [EMAIL]\"\"\"\n",
    "    return re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '[EMAIL]', text)\n",
    "\n",
    "def obfuscate_phone_numbers(text):\n",
    "    \"\"\"Replace phone numbers with [PHONE]\"\"\"\n",
    "    patterns = [\n",
    "        r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b',  # US format\n",
    "        r'\\b\\(\\d{3}\\)\\s*\\d{3}[-.]?\\d{4}\\b',  # (123) 456-7890\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        text = re.sub(pattern, '[PHONE]', text)\n",
    "    return text\n",
    "\n",
    "def obfuscate_ssn(text):\n",
    "    \"\"\"Replace SSN with [SSN]\"\"\"\n",
    "    return re.sub(r'\\b\\d{3}-\\d{2}-\\d{4}\\b', '[SSN]', text)\n",
    "\n",
    "def obfuscate_credit_cards(text):\n",
    "    \"\"\"Replace credit card numbers with [CREDIT_CARD]\"\"\"\n",
    "    return re.sub(r'\\b\\d{4}[-\\s]?\\d{4}[-\\s]?\\d{4}[-\\s]?\\d{4}\\b', '[CREDIT_CARD]', text)\n",
    "\n",
    "def obfuscate_names(text, names_list):\n",
    "    \"\"\"Replace specific names with [NAME]\"\"\"\n",
    "    for name in names_list:\n",
    "        text = text.replace(name, '[NAME]')\n",
    "    return text\n",
    "\n",
    "# Apply obfuscation\n",
    "names_to_obfuscate = [\"Alice Johnson\", \"Bob Martinez\", \"Carol White\", \"David Brown\", \"Eva Green\"]\n",
    "salaries_pattern = r'\\$\\d{1,3}(,\\d{3})*(\\.\\d{2})?'\n",
    "\n",
    "obfuscated_text = original_text\n",
    "obfuscated_text = obfuscate_emails(obfuscated_text)\n",
    "obfuscated_text = obfuscate_phone_numbers(obfuscated_text)\n",
    "obfuscated_text = obfuscate_ssn(obfuscated_text)\n",
    "obfuscated_text = obfuscate_credit_cards(obfuscated_text)\n",
    "obfuscated_text = obfuscate_names(obfuscated_text, names_to_obfuscate)\n",
    "obfuscated_text = re.sub(salaries_pattern, '[SALARY]', obfuscated_text)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Obfuscated Document:\")\n",
    "print(\"-\"*60)\n",
    "print(obfuscated_text)\n",
    "\n",
    "# Advanced PII detection with NER models\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Advanced PII Detection with NER:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pii_detection_example = \"\"\"\n",
    "# Using GLiNER for PII detection\n",
    "try:\n",
    "    from gliner import GLiNER\n",
    "    \n",
    "    # Load GLiNER model for NER\n",
    "    model = GLiNER.from_pretrained(\"urchade/gliner_base\")\n",
    "    \n",
    "    # Define PII entities to detect\n",
    "    labels = [\"person\", \"email\", \"phone number\", \"social security number\", \n",
    "              \"credit card\", \"address\", \"organization\"]\n",
    "    \n",
    "    # Detect entities\n",
    "    entities = model.predict_entities(original_text, labels)\n",
    "    \n",
    "    # Obfuscate detected entities\n",
    "    obfuscated = original_text\n",
    "    for entity in sorted(entities, key=lambda x: x['start'], reverse=True):\n",
    "        start, end = entity['start'], entity['end']\n",
    "        entity_type = entity['label'].upper().replace(' ', '_')\n",
    "        obfuscated = obfuscated[:start] + f'[{entity_type}]' + obfuscated[end:]\n",
    "    \n",
    "    print(obfuscated)\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"Install GLiNER: pip install gliner\")\n",
    "\"\"\"\n",
    "\n",
    "print(pii_detection_example)\n",
    "\n",
    "print(\"\\nüí° PII Types Commonly Obfuscated:\")\n",
    "print(\"  ‚Ä¢ Names (PERSON)\")\n",
    "print(\"  ‚Ä¢ Email addresses (EMAIL)\")\n",
    "print(\"  ‚Ä¢ Phone numbers (PHONE)\")\n",
    "print(\"  ‚Ä¢ Social Security Numbers (SSN)\")\n",
    "print(\"  ‚Ä¢ Credit Card Numbers (CREDIT_CARD)\")\n",
    "print(\"  ‚Ä¢ Addresses (ADDRESS)\")\n",
    "print(\"  ‚Ä¢ Bank Account Numbers (ACCOUNT)\")\n",
    "print(\"  ‚Ä¢ Passport Numbers (PASSPORT)\")\n",
    "print(\"  ‚Ä¢ Medical Record Numbers (MRN)\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Compliance:\")\n",
    "print(\"  ‚Ä¢ GDPR (Europe)\")\n",
    "print(\"  ‚Ä¢ HIPAA (Healthcare - USA)\")\n",
    "print(\"  ‚Ä¢ CCPA (California - USA)\")\n",
    "print(\"  ‚Ä¢ Use PII obfuscation before sharing documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b32ed82",
   "metadata": {},
   "source": [
    "## 20. Translation\n",
    "\n",
    "Translate document content while preserving structure and formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5c12db",
   "metadata": {},
   "source": [
    "### üìñ Concept Overview\n",
    "\n",
    "**What you'll learn:**\n",
    "- Translating document content programmatically\n",
    "- Preserving document structure during translation\n",
    "- Using translation APIs (Google, DeepL, AWS, Azure)\n",
    "- Maintaining formatting and layout\n",
    "\n",
    "**Key concepts:**\n",
    "- `iterate_items()` - Walk through document elements\n",
    "- Translation service integration\n",
    "- Structure preservation\n",
    "- Quality checking with back-translation\n",
    "\n",
    "Translation enables multilingual document processing while maintaining the original structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6d8dafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 16:06:14,254 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-13 16:06:14,257 - INFO - Going to convert document batch...\n",
      "2026-01-13 16:06:14,257 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e15bc6f248154cc62f8db15ef18a8ab7\n",
      "2026-01-13 16:06:14,258 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2026-01-13 16:06:14,275 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:06:14,278 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:06:14,278 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:06:14,354 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:06:14,356 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:06:14,357 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:06:14,405 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:06:14,406 [RapidOCR] download_file.py:60: File exists and is valid: C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-13 16:06:14,413 [RapidOCR] main.py:53: Using C:\\git-projects\\personal\\github.com\\OPENSEARCH_INTERMEDIATE_TUTORIAL\\7. BONUS_PROJECTS\\chonkie_docling_langxtract\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Translation:\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 16:06:14,500 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2026-01-13 16:06:14,507 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-13 16:06:15,062 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-13 16:06:15,505 - INFO - Processing document sample_document.pdf\n",
      "2026-01-13 16:06:15,924 - INFO - Finished converting document sample_document.pdf in 1.67 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Document (English):\n",
      "------------------------------------------------------------\n",
      "## Docling Tutorial Sample Document\n",
      "\n",
      "This is a sample PDF created for demonstrating Docling's capabilities.\n",
      "\n",
      "It contains multiple pages with text, tables, and images.\n",
      "\n",
      "## Sample Table:\n",
      "\n",
      "Employee ID | Name | Department | Salary 001 | John Doe | Engineering | $75,000 002 | Jane Smith | Marketing | $65,000 003 | Bob Johnson | Sales | $70,000\n",
      "\n",
      "## Page 2: Additional Content\n",
      "\n",
      "This page contains more text for testing multi-page conversion.\n",
      "\n",
      "Docling can extract text from complex layouts efficiently....\n",
      "\n",
      "============================================================\n",
      "Translated Document (Spanish):\n",
      "------------------------------------------------------------\n",
      "## Docling Tutorial Muestra Documento\n",
      "\n",
      "Este es un sample PDF created for demonstrating Docling's capabilities.\n",
      "\n",
      "It contains multiple pages with text, tables, and images.\n",
      "\n",
      "## Muestra Tabla:\n",
      "\n",
      "Empleado ID | Name | Departamento | Salary 001 | John Doe | Engineering | $75,000 002 | Jane Smith | Marketing | $65,000 003 | Bob Johnson | Sales | $70,000\n",
      "\n",
      "## Page 2: Additional Content\n",
      "\n",
      "This page contains more text for testing multi-page conversion.\n",
      "\n",
      "Docling can extract text from complex layouts efficientl...\n",
      "\n",
      "============================================================\n",
      "Translation with Structure Preservation:\n",
      "============================================================\n",
      "\n",
      "# Professional Translation Pipeline\n",
      "from docling.document_converter import DocumentConverter\n",
      "\n",
      "def translate_document(doc_result, target_lang=\"es\", translation_service=\"google\"):\n",
      "    '''\n",
      "    Translate document while preserving structure\n",
      "\n",
      "    Args:\n",
      "        doc_result: Docling conversion result\n",
      "        target_lang: Target language code (ISO 639-1)\n",
      "        translation_service: 'google', 'azure', 'deepl', 'aws'\n",
      "\n",
      "    Returns:\n",
      "        Translated document with preserved structure\n",
      "    '''\n",
      "\n",
      "    # Initialize translation client\n",
      "    if translation_service == \"google\":\n",
      "        from google.cloud import translate_v2\n",
      "        translator = translate_v2.Client()\n",
      "    elif translation_service == \"deepl\":\n",
      "        import deepl\n",
      "        translator = deepl.Translator(\"YOUR_API_KEY\")\n",
      "\n",
      "    # Iterate through document items\n",
      "    for item, level in doc_result.document.iterate_items():\n",
      "        if hasattr(item, 'text') and item.text:\n",
      "            # Translate text while preserving formatting\n",
      "            original = item.text\n",
      "\n",
      "            # Call translation API\n",
      "            if translation_service == \"google\":\n",
      "                result = translator.translate(original, target_language=target_lang)\n",
      "                item.text = result['translatedText']\n",
      "            elif translation_service == \"deepl\":\n",
      "                result = translator.translate_text(original, target_lang=target_lang.upper())\n",
      "                item.text = result.text\n",
      "\n",
      "    return doc_result\n",
      "\n",
      "# Usage\n",
      "converter = DocumentConverter()\n",
      "result = converter.convert(\"document.pdf\")\n",
      "translated_result = translate_document(result, target_lang=\"es\", translation_service=\"google\")\n",
      "\n",
      "# Export translated document\n",
      "translated_md = translated_result.document.export_to_markdown()\n",
      "\n",
      "\n",
      "üìö Popular Translation Services:\n",
      "============================================================\n",
      "\n",
      "1. Google Cloud Translation API\n",
      "   - 100+ languages\n",
      "   - High quality\n",
      "   - pip install google-cloud-translate\n",
      "\n",
      "2. DeepL API\n",
      "   - 30+ languages\n",
      "   - Very natural translations\n",
      "   - pip install deepl\n",
      "\n",
      "3. AWS Translate\n",
      "   - 75+ languages\n",
      "   - Scalable\n",
      "   - boto3 library\n",
      "\n",
      "4. Azure Translator\n",
      "   - 100+ languages\n",
      "   - Custom models available\n",
      "   - pip install azure-ai-translation-text\n",
      "\n",
      "üí° Best Practices:\n",
      "  ‚úì Preserve document structure (tables, lists, headings)\n",
      "  ‚úì Handle special characters and formatting\n",
      "  ‚úì Batch translate for efficiency\n",
      "  ‚úì Cache translations to reduce API calls\n",
      "  ‚úì Maintain metadata (page numbers, sections)\n",
      "  ‚úì Quality check with back-translation\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "print(\"Document Translation:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Convert document\n",
    "converter = DocumentConverter()\n",
    "result = converter.convert(data_dir / \"sample_document.pdf\")\n",
    "\n",
    "print(\"Original Document (English):\")\n",
    "print(\"-\"*60)\n",
    "original_text = result.document.export_to_markdown()\n",
    "print(original_text[:500] + \"...\")\n",
    "\n",
    "# Mock translation function (in production, use a real translation API)\n",
    "def mock_translate(text, target_lang=\"es\"):\n",
    "    \"\"\"\n",
    "    Mock translation function\n",
    "    In production, use services like:\n",
    "    - Google Translate API\n",
    "    - AWS Translate\n",
    "    - Azure Translator\n",
    "    - DeepL API\n",
    "    \"\"\"\n",
    "    translations = {\n",
    "        \"en\": {\n",
    "            \"Sample\": {\"es\": \"Muestra\", \"fr\": \"√âchantillon\", \"de\": \"Beispiel\"},\n",
    "            \"Document\": {\"es\": \"Documento\", \"fr\": \"Document\", \"de\": \"Dokument\"},\n",
    "            \"Table\": {\"es\": \"Tabla\", \"fr\": \"Tableau\", \"de\": \"Tabelle\"},\n",
    "            \"Employee\": {\"es\": \"Empleado\", \"fr\": \"Employ√©\", \"de\": \"Mitarbeiter\"},\n",
    "            \"Department\": {\"es\": \"Departamento\", \"fr\": \"D√©partement\", \"de\": \"Abteilung\"},\n",
    "            \"This is a\": {\"es\": \"Este es un\", \"fr\": \"C'est un\", \"de\": \"Dies ist ein\"},\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    translated = text\n",
    "    for eng_word, trans_dict in translations[\"en\"].items():\n",
    "        if target_lang in trans_dict:\n",
    "            translated = translated.replace(eng_word, trans_dict[target_lang])\n",
    "    \n",
    "    return translated\n",
    "\n",
    "# Translate to Spanish\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Translated Document (Spanish):\")\n",
    "print(\"-\"*60)\n",
    "translated_text = mock_translate(original_text, target_lang=\"es\")\n",
    "print(translated_text[:500] + \"...\")\n",
    "\n",
    "# Advanced translation with structure preservation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Translation with Structure Preservation:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "translation_example = \"\"\"\n",
    "# Professional Translation Pipeline\n",
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "def translate_document(doc_result, target_lang=\"es\", translation_service=\"google\"):\n",
    "    '''\n",
    "    Translate document while preserving structure\n",
    "    \n",
    "    Args:\n",
    "        doc_result: Docling conversion result\n",
    "        target_lang: Target language code (ISO 639-1)\n",
    "        translation_service: 'google', 'azure', 'deepl', 'aws'\n",
    "    \n",
    "    Returns:\n",
    "        Translated document with preserved structure\n",
    "    '''\n",
    "    \n",
    "    # Initialize translation client\n",
    "    if translation_service == \"google\":\n",
    "        from google.cloud import translate_v2\n",
    "        translator = translate_v2.Client()\n",
    "    elif translation_service == \"deepl\":\n",
    "        import deepl\n",
    "        translator = deepl.Translator(\"YOUR_API_KEY\")\n",
    "    \n",
    "    # Iterate through document items\n",
    "    for item, level in doc_result.document.iterate_items():\n",
    "        if hasattr(item, 'text') and item.text:\n",
    "            # Translate text while preserving formatting\n",
    "            original = item.text\n",
    "            \n",
    "            # Call translation API\n",
    "            if translation_service == \"google\":\n",
    "                result = translator.translate(original, target_language=target_lang)\n",
    "                item.text = result['translatedText']\n",
    "            elif translation_service == \"deepl\":\n",
    "                result = translator.translate_text(original, target_lang=target_lang.upper())\n",
    "                item.text = result.text\n",
    "    \n",
    "    return doc_result\n",
    "\n",
    "# Usage\n",
    "converter = DocumentConverter()\n",
    "result = converter.convert(\"document.pdf\")\n",
    "translated_result = translate_document(result, target_lang=\"es\", translation_service=\"google\")\n",
    "\n",
    "# Export translated document\n",
    "translated_md = translated_result.document.export_to_markdown()\n",
    "\"\"\"\n",
    "\n",
    "print(translation_example)\n",
    "\n",
    "print(\"\\nüìö Popular Translation Services:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "1. Google Cloud Translation API\n",
    "   - 100+ languages\n",
    "   - High quality\n",
    "   - pip install google-cloud-translate\n",
    "\n",
    "2. DeepL API\n",
    "   - 30+ languages\n",
    "   - Very natural translations\n",
    "   - pip install deepl\n",
    "\n",
    "3. AWS Translate\n",
    "   - 75+ languages\n",
    "   - Scalable\n",
    "   - boto3 library\n",
    "\n",
    "4. Azure Translator\n",
    "   - 100+ languages\n",
    "   - Custom models available\n",
    "   - pip install azure-ai-translation-text\n",
    "\"\"\")\n",
    "\n",
    "print(\"üí° Best Practices:\")\n",
    "print(\"  ‚úì Preserve document structure (tables, lists, headings)\")\n",
    "print(\"  ‚úì Handle special characters and formatting\")\n",
    "print(\"  ‚úì Batch translate for efficiency\")\n",
    "print(\"  ‚úì Cache translations to reduce API calls\")\n",
    "print(\"  ‚úì Maintain metadata (page numbers, sections)\")\n",
    "print(\"  ‚úì Quality check with back-translation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d606b5c5",
   "metadata": {},
   "source": [
    "---\n",
    "# üéì Conclusion\n",
    "\n",
    "## Summary\n",
    "\n",
    "Congratulations! You've completed the comprehensive Docling tutorial covering:\n",
    "\n",
    "### ‚úÖ What We Covered\n",
    "\n",
    "1. **Core Conversion** (4 topics)\n",
    "   - Minimal conversion\n",
    "   - Custom configuration\n",
    "   - Batch processing\n",
    "   - Multi-format support\n",
    "\n",
    "2. **Backends** (2 topics)\n",
    "   - CSV processing\n",
    "   - XML for RAG applications\n",
    "\n",
    "3. **Advanced Pipelines** (4 topics)\n",
    "   - VLM (Vision Language Models)\n",
    "   - VLM model comparison\n",
    "   - API-based VLM\n",
    "   - ASR (Automatic Speech Recognition)\n",
    "\n",
    "4. **Exporting Results** (3 topics)\n",
    "   - Figure extraction\n",
    "   - Table export (CSV, HTML, Markdown)\n",
    "   - Multimodal export\n",
    "\n",
    "5. **Advanced OCR** (4 topics)\n",
    "   - Full page OCR\n",
    "   - Tesseract with language detection\n",
    "   - RapidOCR with custom models\n",
    "   - SuryaOCR with custom models\n",
    "\n",
    "6. **Performance & Enhancement** (3 topics)\n",
    "   - Hardware acceleration (CPU/GPU)\n",
    "   - PII obfuscation\n",
    "   - Document translation\n",
    "\n",
    "### üöÄ Next Steps\n",
    "\n",
    "1. **Explore Advanced Features**\n",
    "   - Fine-tune VLM models for specific domains\n",
    "   - Integrate with vector databases for RAG\n",
    "   - Build production pipelines\n",
    "\n",
    "2. **Performance Optimization**\n",
    "   - Benchmark different configurations\n",
    "   - Implement caching strategies\n",
    "   - Scale with distributed processing\n",
    "\n",
    "3. **Integration Projects**\n",
    "   - Document search systems\n",
    "   - Automated compliance checking\n",
    "   - Multilingual document processing\n",
    "\n",
    "### üìñ Resources\n",
    "\n",
    "- **Documentation**: https://docling-project.github.io/docling/\n",
    "- **GitHub**: https://github.com/docling-project/docling\n",
    "- **Community**: Join discussions and contribute!\n",
    "\n",
    "### üí¨ Feedback\n",
    "\n",
    "This tutorial was designed to be comprehensive and hands-on. Each section included:\n",
    "- ‚úì Executable code examples\n",
    "- ‚úì Mock data generation\n",
    "- ‚úì Best practices\n",
    "- ‚úì Configuration examples\n",
    "\n",
    "Happy document processing with Docling! üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-chunking-with-chonkie (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
