{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29c6bf5c",
   "metadata": {},
   "source": [
    "# Chonkie Chefs - Complete Guide\n",
    "\n",
    "This notebook demonstrates all Chef types in Chonkie: **TextChef**, **MarkdownChef**, and **TableChef**.\n",
    "\n",
    "## What are Chefs?\n",
    "\n",
    "Chefs are processors that convert raw files into structured Document objects. Each Chef specializes in different file types:\n",
    "\n",
    "- **TextChef**: Processes plain text files ‚Üí `Document`\n",
    "- **MarkdownChef**: Processes markdown files ‚Üí `MarkdownDocument` (with tables, code, images)\n",
    "- **TableChef**: Processes CSV/Excel/Markdown tables ‚Üí `MarkdownTable` objects\n",
    "\n",
    "## Key Features:\n",
    "- ‚úÖ Process single files or batch process multiple files\n",
    "- ‚úÖ Returns structured Document objects ready for chunking\n",
    "- ‚úÖ UTF-8 encoding support for international text\n",
    "- ‚úÖ Works seamlessly in pipelines or standalone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08819998",
   "metadata": {},
   "source": [
    "## Visual Overview\n",
    "\n",
    "```mermaid\n",
    "%%{init: {'theme':'base', 'themeVariables': { 'primaryColor':'#ff6b6b','primaryTextColor':'#fff','primaryBorderColor':'#c92a2a','lineColor':'#339af0','secondaryColor':'#51cf66','tertiaryColor':'#ffd43b','background':'#f8f9fa','mainBkg':'#e3fafc','secondBkg':'#fff3bf','tertiaryBkg':'#ffe3e3','textColor':'#212529','fontSize':'16px'}}}%%\n",
    "\n",
    "graph TB\n",
    "    Start([üç≥ Chefs<br/>File Processors]):::startClass\n",
    "    \n",
    "    Start --> ChefType{Choose Chef Type}:::decisionClass\n",
    "    \n",
    "    ChefType -->|Plain Text| TextChef[\"üìÑ TextChef<br/>No parameters needed\"]:::textClass\n",
    "    ChefType -->|Markdown| MDChef[\"üìù MarkdownChef<br/>Optional: tokenizer\"]:::mdClass\n",
    "    ChefType -->|Tables| TableChef[\"üìä TableChef<br/>Requires pandas\"]:::tableClass\n",
    "    \n",
    "    TextChef --> TextInput{Input Type}:::decisionClass\n",
    "    MDChef --> MDInput{Input Type}:::decisionClass\n",
    "    TableChef --> TableInput{Input Type}:::decisionClass\n",
    "    \n",
    "    TextInput -->|Single| TextSingle[\"process(path)\"]:::methodClass\n",
    "    TextInput -->|Multiple| TextBatch[\"process_batch(paths)\"]:::methodClass\n",
    "    \n",
    "    MDInput -->|Single| MDSingle[\"process(path)\"]:::methodClass\n",
    "    MDInput -->|Multiple| MDBatch[\"process_batch(paths)\"]:::methodClass\n",
    "    \n",
    "    TableInput -->|Single| TableSingle[\"process(path or string)\"]:::methodClass\n",
    "    TableInput -->|Multiple| TableBatch[\"process_batch(paths)\"]:::methodClass\n",
    "    \n",
    "    TextSingle --> TextOutput[\"üì¶ Document<br/>id, content, metadata\"]:::outputClass\n",
    "    TextBatch --> TextOutput\n",
    "    \n",
    "    MDSingle --> MDOutput[\"üì¶ MarkdownDocument<br/>+ tables, code, images, chunks\"]:::mdOutputClass\n",
    "    MDBatch --> MDOutput\n",
    "    \n",
    "    TableSingle --> TableOutput[\"üì¶ list of MarkdownTable<br/>or None\"]:::tableOutputClass\n",
    "    TableBatch --> TableOutput\n",
    "    \n",
    "    TextOutput --> Integration{Integration}:::decisionClass\n",
    "    MDOutput --> Integration\n",
    "    TableOutput --> Integration\n",
    "    \n",
    "    Integration -->|With Chunker| Chunking[\"‚ö° Add Chunking<br/>doc.chunks = chunks\"]:::chunkClass\n",
    "    Integration -->|Pipeline| Pipeline[\"üîó Full Pipeline<br/>fetch ‚Üí process ‚Üí chunk\"]:::pipelineClass\n",
    "    Integration -->|Standalone| Direct[\"üîß Direct Processing<br/>Work with Documents\"]:::standaloneClass\n",
    "    \n",
    "    classDef startClass fill:#4c6ef5,stroke:#364fc7,stroke-width:3px,color:#fff\n",
    "    classDef decisionClass fill:#7950f2,stroke:#5f3dc4,stroke-width:2px,color:#fff\n",
    "    classDef textClass fill:#20c997,stroke:#087f5b,stroke-width:2px,color:#fff\n",
    "    classDef mdClass fill:#ff6b6b,stroke:#c92a2a,stroke-width:2px,color:#fff\n",
    "    classDef tableClass fill:#ffd43b,stroke:#fab005,stroke-width:2px,color:#333\n",
    "    classDef methodClass fill:#748ffc,stroke:#4c6ef5,stroke-width:2px,color:#fff\n",
    "    classDef outputClass fill:#51cf66,stroke:#37b24d,stroke-width:2px,color:#fff\n",
    "    classDef mdOutputClass fill:#ff922b,stroke:#e8590c,stroke-width:2px,color:#fff\n",
    "    classDef tableOutputClass fill:#ffd43b,stroke:#fab005,stroke-width:2px,color:#333\n",
    "    classDef chunkClass fill:#69db7c,stroke:#40c057,stroke-width:2px,color:#fff\n",
    "    classDef pipelineClass fill:#845ef7,stroke:#5f3dc4,stroke-width:2px,color:#fff\n",
    "    classDef standaloneClass fill:#ff922b,stroke:#e8590c,stroke-width:2px,color:#fff\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac039be",
   "metadata": {},
   "source": [
    "## Setup - Create Mock Files\n",
    "\n",
    "First, we'll create a set of valid sample files (txt, md, csv, xlsx) to demonstrate each Chef.\n",
    "**Note:** This step resets the `test_chef_files` directory to ensure a clean state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9e40d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created test files:\n",
      "üìÅ test_chef_files/\n",
      "  üìÑ article.txt (463 bytes)\n",
      "  üìÑ data_science.txt (260 bytes)\n",
      "  üìÑ inventory.xlsx (5026 bytes)\n",
      "  üìÑ notes.txt (135 bytes)\n",
      "  üìÑ products.csv (128 bytes)\n",
      "  üìÑ readme.md (253 bytes)\n",
      "  üìÑ sales.csv (108 bytes)\n",
      "  üìÑ tutorial.md (563 bytes)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Create test directory\n",
    "test_dir = Path(\"./test_chef_files\")\n",
    "if test_dir.exists():\n",
    "    shutil.rmtree(test_dir)\n",
    "test_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# 1. Create plain text files for TextChef\n",
    "text_files = {\n",
    "    \"article.txt\": \"\"\"Machine Learning in Modern Applications\n",
    "\n",
    "Machine learning has revolutionized how we build software applications. From recommendation systems to natural language processing, ML models are everywhere. This article explores the key concepts and practical applications of machine learning in today's technology landscape.\n",
    "\n",
    "Key areas include supervised learning, unsupervised learning, and reinforcement learning. Each approach has its own strengths and use cases.\"\"\",\n",
    "    \n",
    "    \"notes.txt\": \"\"\"Quick Notes:\n",
    "- Remember to test the new feature\n",
    "- Update documentation\n",
    "- Review pull requests\n",
    "- Schedule team meeting for next week\"\"\",\n",
    "    \n",
    "    \"data_science.txt\": \"\"\"Data Science Pipeline\n",
    "\n",
    "The modern data science pipeline consists of several stages:\n",
    "1. Data Collection\n",
    "2. Data Cleaning\n",
    "3. Feature Engineering\n",
    "4. Model Training\n",
    "5. Model Evaluation\n",
    "6. Deployment\n",
    "\n",
    "Each stage is critical for building robust ML systems.\"\"\"\n",
    "}\n",
    "\n",
    "for filename, content in text_files.items():\n",
    "    (test_dir / filename).write_text(content, encoding='utf-8')\n",
    "\n",
    "# 2. Create markdown files for MarkdownChef\n",
    "markdown_files = {\n",
    "    \"tutorial.md\": \"\"\"# Python Programming Tutorial\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Python is a versatile programming language loved by developers worldwide.\n",
    "\n",
    "### Getting Started\n",
    "\n",
    "```python\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "    return True\n",
    "```\n",
    "\n",
    "## Data Structures\n",
    "\n",
    "| Type | Mutable | Example |\n",
    "|------|---------|---------|\n",
    "| List | Yes | [1, 2, 3] |\n",
    "| Tuple | No | (1, 2, 3) |\n",
    "| Dict | Yes | {\"key\": \"value\"} |\n",
    "| Set | Yes | {1, 2, 3} |\n",
    "\n",
    "## Resources\n",
    "\n",
    "![Python Logo](https://python.org/logo.png)\n",
    "\n",
    "For more information, visit [Python.org](https://python.org).\n",
    "\"\"\",\n",
    "    \n",
    "    \"readme.md\": \"\"\"# Project README\n",
    "\n",
    "## Overview\n",
    "\n",
    "This project demonstrates advanced concepts.\n",
    "\n",
    "```javascript\n",
    "const greeting = (name) => {\n",
    "    return `Hello, ${name}!`;\n",
    "}\n",
    "```\n",
    "\n",
    "## Installation\n",
    "\n",
    "Run the following command:\n",
    "\n",
    "```bash\n",
    "pip install chonkie\n",
    "```\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "for filename, content in markdown_files.items():\n",
    "    (test_dir / filename).write_text(content, encoding='utf-8')\n",
    "\n",
    "# 3. Create CSV files for TableChef\n",
    "products_data = pd.DataFrame({\n",
    "    'ProductID': [1, 2, 3, 4, 5],\n",
    "    'Name': ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Webcam'],\n",
    "    'Price': [999.99, 29.99, 79.99, 299.99, 89.99],\n",
    "    'Stock': [15, 150, 75, 30, 50]\n",
    "})\n",
    "products_data.to_csv(test_dir / \"products.csv\", index=False)\n",
    "\n",
    "sales_data = pd.DataFrame({\n",
    "    'Date': ['2026-01-01', '2026-01-02', '2026-01-03'],\n",
    "    'Region': ['North', 'South', 'East'],\n",
    "    'Sales': [15000, 22000, 18500],\n",
    "    'Units': [120, 180, 145]\n",
    "})\n",
    "sales_data.to_csv(test_dir / \"sales.csv\", index=False)\n",
    "\n",
    "# 4. Create Excel file for TableChef\n",
    "with pd.ExcelWriter(test_dir / \"inventory.xlsx\") as writer:\n",
    "    inventory = pd.DataFrame({\n",
    "        'Item': ['Widget A', 'Widget B', 'Widget C'],\n",
    "        'Quantity': [100, 250, 175],\n",
    "        'Location': ['Warehouse 1', 'Warehouse 2', 'Warehouse 1']\n",
    "    })\n",
    "    inventory.to_excel(writer, sheet_name='Inventory', index=False)\n",
    "\n",
    "print(\"‚úÖ Created test files:\")\n",
    "print(f\"üìÅ {test_dir}/\")\n",
    "for file in sorted(test_dir.iterdir()):\n",
    "    size = file.stat().st_size\n",
    "    print(f\"  üìÑ {file.name} ({size} bytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844166bb",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Install Chonkie with table support for TableChef:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "121da61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All Chefs imported successfully!\n",
      "  üìÑ TextChef: <class 'chonkie.chef.text.TextChef'>\n",
      "  üìù MarkdownChef: <class 'chonkie.chef.markdown.MarkdownChef'>\n",
      "  üìä TableChef: <class 'chonkie.chef.table.TableChef'>\n"
     ]
    }
   ],
   "source": [
    "# Install chonkie with table support\n",
    "# !pip install \"chonkie[table]\"\n",
    "\n",
    "from chonkie import TextChef, MarkdownChef, TableChef\n",
    "\n",
    "print(\"‚úÖ All Chefs imported successfully!\")\n",
    "print(f\"  üìÑ TextChef: {TextChef}\")\n",
    "print(f\"  üìù MarkdownChef: {MarkdownChef}\")\n",
    "print(f\"  üìä TableChef: {TableChef}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b913f6eb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: TextChef\n",
    "\n",
    "## 1. TextChef - Single File Processing\n",
    "\n",
    "Process a single text file into a Document object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "325434d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ TextChef - Single File Result:\n",
      "  Document ID: doc_b0bf88dd80d7458db59bfdbeda8fb8f9\n",
      "  Content Length: 459 characters\n",
      "  Metadata: {}\n",
      "\n",
      "üìñ Content Preview (first 200 chars):\n",
      "  Machine Learning in Modern Applications\n",
      "\n",
      "Machine learning has revolutionized how we build software applications. From recommendation systems to natural language processing, ML models are everywhere. T...\n"
     ]
    }
   ],
   "source": [
    "# Initialize TextChef (no parameters needed)\n",
    "text_chef = TextChef()\n",
    "\n",
    "# Process a single text file\n",
    "doc = text_chef.process(\"./test_chef_files/article.txt\")\n",
    "\n",
    "print(\"üìÑ TextChef - Single File Result:\")\n",
    "print(f\"  Document ID: {doc.id}\")\n",
    "print(f\"  Content Length: {len(doc.content)} characters\")\n",
    "print(f\"  Metadata: {doc.metadata}\")\n",
    "print(f\"\\nüìñ Content Preview (first 200 chars):\")\n",
    "print(f\"  {doc.content[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e49c557",
   "metadata": {},
   "source": [
    "## 2. TextChef - Batch Processing\n",
    "\n",
    "Process multiple text files at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ade11c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ TextChef - Batch Processing Result:\n",
      "  Processed 3 documents\n",
      "\n",
      "  1. doc_7a8d09a84ccf45ca95d70855cd94d34a\n",
      "     Content: 459 characters\n",
      "     Preview: Machine Learning in Modern Applications\n",
      "\n",
      "Machine learning ha...\n",
      "\n",
      "  2. doc_db049c911f4d4c6aa283a9dd1695c521\n",
      "     Content: 131 characters\n",
      "     Preview: Quick Notes:\n",
      "- Remember to test the new feature\n",
      "- Update doc...\n",
      "\n",
      "  3. doc_4034198e48fc44a6baf73174c1c293b2\n",
      "     Content: 250 characters\n",
      "     Preview: Data Science Pipeline\n",
      "\n",
      "The modern data science pipeline cons...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_chef = TextChef()\n",
    "\n",
    "# Process multiple text files\n",
    "file_paths = [\n",
    "    \"./test_chef_files/article.txt\",\n",
    "    \"./test_chef_files/notes.txt\",\n",
    "    \"./test_chef_files/data_science.txt\"\n",
    "]\n",
    "\n",
    "docs = text_chef.process_batch(file_paths)\n",
    "\n",
    "print(f\"üìÑ TextChef - Batch Processing Result:\")\n",
    "print(f\"  Processed {len(docs)} documents\\n\")\n",
    "\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    filename = Path(doc.id).name if hasattr(doc, 'id') else f\"Doc {i}\"\n",
    "    print(f\"  {i}. {filename}\")\n",
    "    print(f\"     Content: {len(doc.content)} characters\")\n",
    "    print(f\"     Preview: {doc.content[:60]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31a0656",
   "metadata": {},
   "source": [
    "## 3. TextChef - Integration with Chunkers\n",
    "\n",
    "Use TextChef output with a chunker to create chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7963e650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° TextChef + Chunker Integration:\n",
      "  Document: doc_763f0cf271d1499bb1b773e957a7c853\n",
      "  Content: 459 characters\n",
      "  Chunks: 7\n",
      "\n",
      "üìù Chunk Samples:\n",
      "  Chunk 1: Machine Learning in Modern Applications\n",
      "...\n",
      "  Chunk 2: \n",
      "Machine learning has revolutionized how we build software a...\n",
      "  Chunk 3: From recommendation systems to natural language processing, ...\n",
      "  ...\n"
     ]
    }
   ],
   "source": [
    "from chonkie import RecursiveChunker\n",
    "\n",
    "# Step 1: Load text file with TextChef\n",
    "text_chef = TextChef()\n",
    "doc = text_chef.process(\"./test_chef_files/article.txt\")\n",
    "\n",
    "# Step 2: Chunk the content\n",
    "chunker = RecursiveChunker(chunk_size=100)\n",
    "chunks = chunker.chunk(doc.content)\n",
    "\n",
    "# Step 3: Store chunks in document\n",
    "doc.chunks = chunks\n",
    "\n",
    "print(\"‚ö° TextChef + Chunker Integration:\")\n",
    "print(f\"  Document: {Path(doc.id).name if hasattr(doc, 'id') else 'N/A'}\")\n",
    "print(f\"  Content: {len(doc.content)} characters\")\n",
    "print(f\"  Chunks: {len(doc.chunks)}\")\n",
    "print(f\"\\nüìù Chunk Samples:\")\n",
    "for i, chunk in enumerate(doc.chunks[:3], 1):\n",
    "    print(f\"  Chunk {i}: {chunk.text[:60]}...\")\n",
    "print(f\"  ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e393fedb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: MarkdownChef\n",
    "\n",
    "## 4. MarkdownChef - Basic Initialization\n",
    "\n",
    "Initialize MarkdownChef with different tokenizer options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37bb5397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù MarkdownChef Initialization Options:\n",
      "\n",
      "  1. Default: MarkdownChef()\n",
      "  2. GPT-2 Tokenizer: MarkdownChef()\n",
      "  3. Character Tokenizer: MarkdownChef()\n",
      "\n",
      "‚úÖ All tokenizer options work!\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Default initialization (character tokenizer)\n",
    "md_chef_default = MarkdownChef()\n",
    "print(\"üìù MarkdownChef Initialization Options:\\n\")\n",
    "print(f\"  1. Default: {md_chef_default}\")\n",
    "\n",
    "# Option 2: With specific tokenizer\n",
    "md_chef_gpt2 = MarkdownChef(tokenizer=\"gpt2\")\n",
    "print(f\"  2. GPT-2 Tokenizer: {md_chef_gpt2}\")\n",
    "\n",
    "# Option 3: With character tokenizer (explicit)\n",
    "md_chef_char = MarkdownChef(tokenizer=\"character\")\n",
    "print(f\"  3. Character Tokenizer: {md_chef_char}\")\n",
    "\n",
    "print(\"\\n‚úÖ All tokenizer options work!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e4d66c",
   "metadata": {},
   "source": [
    "## 5. MarkdownChef - Single File Processing\n",
    "\n",
    "Process a markdown file and extract all components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db46b8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù MarkdownChef - Single File Result:\n",
      "  Document ID: doc_8f2a6fa84db44737a8123d667aaf5a10\n",
      "  Content Length: 535 characters\n",
      "\n",
      "üìä Extracted Components:\n",
      "  Tables: 1\n",
      "  Code Blocks: 1\n",
      "  Images: 1\n",
      "  Text Chunks: 4\n",
      "\n",
      "üìã Table Sample:\n",
      "    Table 1 (pos 241-413):\n",
      "    | Type | Mutable | Example |\n",
      "|------|---------|---------|\n",
      "| List | Yes | [1, 2, 3] |\n",
      "| Tuple | No | ...\n",
      "\n",
      "üíª Code Block Sample:\n",
      "    Code 1 [python] (pos 144-219):\n",
      "    def hello_world():\n",
      "    print(\"Hello, World!\")\n",
      "    return True...\n",
      "\n",
      "üñºÔ∏è Image Sample:\n",
      "    Image 1: Python Logo\n",
      "    URL: https://python.org/logo.png...\n"
     ]
    }
   ],
   "source": [
    "md_chef = MarkdownChef()\n",
    "\n",
    "# Process markdown file\n",
    "doc = md_chef.process(\"./test_chef_files/tutorial.md\")\n",
    "\n",
    "print(\"üìù MarkdownChef - Single File Result:\")\n",
    "print(f\"  Document ID: {doc.id}\")\n",
    "print(f\"  Content Length: {len(doc.content)} characters\")\n",
    "print(f\"\\nüìä Extracted Components:\")\n",
    "print(f\"  Tables: {len(doc.tables)}\")\n",
    "print(f\"  Code Blocks: {len(doc.code)}\")\n",
    "print(f\"  Images: {len(doc.images)}\")\n",
    "print(f\"  Text Chunks: {len(doc.chunks)}\")\n",
    "\n",
    "# Show details of extracted components\n",
    "if doc.tables:\n",
    "    print(f\"\\nüìã Table Sample:\")\n",
    "    for i, table in enumerate(doc.tables, 1):\n",
    "        print(f\"    Table {i} (pos {table.start_index}-{table.end_index}):\")\n",
    "        print(f\"    {table.content[:100]}...\")\n",
    "\n",
    "if doc.code:\n",
    "    print(f\"\\nüíª Code Block Sample:\")\n",
    "    for i, code in enumerate(doc.code, 1):\n",
    "        lang = code.language or \"unknown\"\n",
    "        print(f\"    Code {i} [{lang}] (pos {code.start_index}-{code.end_index}):\")\n",
    "        print(f\"    {code.content[:80]}...\")\n",
    "\n",
    "if doc.images:\n",
    "    print(f\"\\nüñºÔ∏è Image Sample:\")\n",
    "    for i, img in enumerate(doc.images, 1):\n",
    "        print(f\"    Image {i}: {img.alias}\")\n",
    "        print(f\"    URL: {img.content[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1882dd",
   "metadata": {},
   "source": [
    "## 6. MarkdownChef - Batch Processing\n",
    "\n",
    "Process multiple markdown files simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6822ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù MarkdownChef - Batch Processing Result:\n",
      "  Processed 2 markdown documents\n",
      "\n",
      "  1. doc_5a9354b97c3c4bb999a97d9d30c6ce59\n",
      "     Content: 535 characters\n",
      "     Tables: 1 | Code: 1 | Images: 1 | Chunks: 4\n",
      "\n",
      "  2. doc_76a92af1f7db4802bdb781a2978ee158\n",
      "     Content: 234 characters\n",
      "     Tables: 0 | Code: 2 | Images: 0 | Chunks: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "md_chef = MarkdownChef()\n",
    "\n",
    "# Process multiple markdown files\n",
    "md_files = [\n",
    "    \"./test_chef_files/tutorial.md\",\n",
    "    \"./test_chef_files/readme.md\"\n",
    "]\n",
    "\n",
    "docs = md_chef.process_batch(md_files)\n",
    "\n",
    "print(f\"üìù MarkdownChef - Batch Processing Result:\")\n",
    "print(f\"  Processed {len(docs)} markdown documents\\n\")\n",
    "\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    filename = Path(doc.id).name if hasattr(doc, 'id') else f\"Doc {i}\"\n",
    "    print(f\"  {i}. {filename}\")\n",
    "    print(f\"     Content: {len(doc.content)} characters\")\n",
    "    print(f\"     Tables: {len(doc.tables)} | Code: {len(doc.code)} | Images: {len(doc.images)} | Chunks: {len(doc.chunks)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac46f66",
   "metadata": {},
   "source": [
    "## 7. MarkdownChef - Detailed Component Analysis\n",
    "\n",
    "Explore the structure of extracted markdown components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5d0ca7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç MarkdownDocument Structure Analysis:\n",
      "\n",
      "üìã TABLES:\n",
      "\n",
      "  Table 1:\n",
      "    Position: chars 241 to 413\n",
      "    Content:\n",
      "| Type | Mutable | Example |\n",
      "|------|---------|---------|\n",
      "| List | Yes | [1, 2, 3] |\n",
      "| Tuple | No | (1, 2, 3) |\n",
      "| Dict | Yes | {\"key\": \"value\"} |\n",
      "| Set | Yes | {1, 2, 3} |\n",
      "\n",
      "\n",
      "üíª CODE BLOCKS:\n",
      "\n",
      "  Code Block 1:\n",
      "    Language: python\n",
      "    Position: chars 144 to 219\n",
      "    Content Preview:\n",
      "    def hello_world():\n",
      "    print(\"Hello, World!\")\n",
      "    return True\n",
      "\n",
      "üñºÔ∏è IMAGES:\n",
      "\n",
      "  Image 1:\n",
      "    Alt Text: Python Logo\n",
      "    Source: https://python.org/logo.png\n",
      "    Position: chars 428 to 471\n",
      "\n",
      "üìù TEXT CHUNKS: 4 chunks\n",
      "  First chunk: # Python Programming Tutorial\n",
      "\n",
      "## Introduction\n",
      "\n",
      "Python is a versatile programmin...\n",
      "  Last chunk: \n",
      "\n",
      "For more information, visit [Python.org](https://python.org).\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "md_chef = MarkdownChef()\n",
    "doc = md_chef.process(\"./test_chef_files/tutorial.md\")\n",
    "\n",
    "print(\"üîç MarkdownDocument Structure Analysis:\\n\")\n",
    "\n",
    "# Analyze Tables\n",
    "print(\"üìã TABLES:\")\n",
    "for i, table in enumerate(doc.tables, 1):\n",
    "    print(f\"\\n  Table {i}:\")\n",
    "    print(f\"    Position: chars {table.start_index} to {table.end_index}\")\n",
    "    print(f\"    Content:\\n{table.content}\")\n",
    "\n",
    "# Analyze Code Blocks\n",
    "print(\"\\nüíª CODE BLOCKS:\")\n",
    "for i, code in enumerate(doc.code, 1):\n",
    "    print(f\"\\n  Code Block {i}:\")\n",
    "    print(f\"    Language: {code.language or 'Not specified'}\")\n",
    "    print(f\"    Position: chars {code.start_index} to {code.end_index}\")\n",
    "    print(f\"    Content Preview:\")\n",
    "    print(f\"    {code.content[:100]}\")\n",
    "\n",
    "# Analyze Images\n",
    "print(\"\\nüñºÔ∏è IMAGES:\")\n",
    "for i, img in enumerate(doc.images, 1):\n",
    "    print(f\"\\n  Image {i}:\")\n",
    "    print(f\"    Alt Text: {img.alias}\")\n",
    "    print(f\"    Source: {img.content}\")\n",
    "    print(f\"    Position: chars {img.start_index} to {img.end_index}\")\n",
    "    if img.link:\n",
    "        print(f\"    Link: {img.link}\")\n",
    "\n",
    "# Analyze Text Chunks\n",
    "print(f\"\\nüìù TEXT CHUNKS: {len(doc.chunks)} chunks\")\n",
    "if doc.chunks:\n",
    "    print(f\"  First chunk: {doc.chunks[0].text[:80]}...\")\n",
    "    print(f\"  Last chunk: {doc.chunks[-1].text[:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9019f538",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: TableChef\n",
    "\n",
    "## 8. TableChef - Process CSV File\n",
    "\n",
    "Extract table data from CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e6a8834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä TableChef - CSV Processing Result:\n",
      "  Found 1 table(s)\n",
      "\n",
      "  Table 1:\n",
      "    Content:\n",
      "|   ProductID | Name     |   Price |   Stock |\n",
      "|------------:|:---------|--------:|--------:|\n",
      "|           1 | Laptop   |  999.99 |      15 |\n",
      "|           2 | Mouse    |   29.99 |     150 |\n",
      "|           3 | Keyboard |   79.99 |      75 |\n",
      "|           4 | Monitor  |  299.99 |      30 |\n",
      "|           5 | Webcam   |   89.99 |      50 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_chef = TableChef()\n",
    "\n",
    "# Process CSV file\n",
    "doc = table_chef.process(\"./test_chef_files/products.csv\")\n",
    "\n",
    "print(\"üìä TableChef - CSV Processing Result:\")\n",
    "if doc and hasattr(doc, 'tables') and doc.tables:\n",
    "    print(f\"  Found {len(doc.tables)} table(s)\\n\")\n",
    "    for i, table in enumerate(doc.tables, 1):\n",
    "        print(f\"  Table {i}:\")\n",
    "        print(f\"    Content:\\n{table.content}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"  No tables found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d59ce5b",
   "metadata": {},
   "source": [
    "## 9. TableChef - Process Excel File\n",
    "\n",
    "Extract table data from Excel files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "310c2e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä TableChef - Excel Processing Result:\n",
      "  Found 1 table(s)\n",
      "\n",
      "  Table 1:\n",
      "    Content:\n",
      "| Item     |   Quantity | Location    |\n",
      "|:---------|-----------:|:------------|\n",
      "| Widget A |        100 | Warehouse 1 |\n",
      "| Widget B |        250 | Warehouse 2 |\n",
      "| Widget C |        175 | Warehouse 1 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_chef = TableChef()\n",
    "\n",
    "# Process Excel file\n",
    "doc = table_chef.process(\"./test_chef_files/inventory.xlsx\")\n",
    "\n",
    "print(\"üìä TableChef - Excel Processing Result:\")\n",
    "if doc and hasattr(doc, 'tables') and doc.tables:\n",
    "    print(f\"  Found {len(doc.tables)} table(s)\\n\")\n",
    "    for i, table in enumerate(doc.tables, 1):\n",
    "        print(f\"  Table {i}:\")\n",
    "        print(f\"    Content:\\n{table.content}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"  No tables found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e7dee6",
   "metadata": {},
   "source": [
    "## 10. TableChef - Process Markdown String\n",
    "\n",
    "Extract tables from markdown text (not just files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7b57c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä TableChef - Markdown String Processing:\n",
      "  Found 1 table(s)\n",
      "\n",
      "  Table 1:\n",
      "    Position: chars 50 to 236\n",
      "    Content:\n",
      "| Quarter | Revenue | Profit |\n",
      "|---------|---------|--------|\n",
      "| Q1      | $100K   | $25K   |\n",
      "| Q2      | $150K   | $40K   |\n",
      "| Q3      | $180K   | $55K   |\n",
      "| Q4      | $200K   | $70K   |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_chef = TableChef()\n",
    "\n",
    "# Markdown string with table\n",
    "markdown_text = \"\"\"\n",
    "# Sales Report\n",
    "\n",
    "Here are the quarterly results:\n",
    "\n",
    "| Quarter | Revenue | Profit |\n",
    "|---------|---------|--------|\n",
    "| Q1      | $100K   | $25K   |\n",
    "| Q2      | $150K   | $40K   |\n",
    "| Q3      | $180K   | $55K   |\n",
    "| Q4      | $200K   | $70K   |\n",
    "\n",
    "Great progress this year!\n",
    "\"\"\"\n",
    "\n",
    "# Process markdown string\n",
    "doc = table_chef.process(markdown_text)\n",
    "\n",
    "print(\"üìä TableChef - Markdown String Processing:\")\n",
    "if doc and hasattr(doc, 'tables') and doc.tables:\n",
    "    print(f\"  Found {len(doc.tables)} table(s)\\n\")\n",
    "    for i, table in enumerate(doc.tables, 1):\n",
    "        print(f\"  Table {i}:\")\n",
    "        print(f\"    Position: chars {table.start_index} to {table.end_index}\")\n",
    "        print(f\"    Content:\\n{table.content}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"  No tables found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532ded18",
   "metadata": {},
   "source": [
    "## 11. TableChef - Batch Processing\n",
    "\n",
    "Process multiple table sources at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dad6156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä TableChef - Batch Processing Result:\n",
      "  Processed 3 documents with 3 total tables\n",
      "\n",
      "  Table 1 (from document 1):\n",
      "    Header: |   ProductID | Name     |   Price |   Stock |\n",
      "    Rows: 6\n",
      "\n",
      "  Table 2 (from document 2):\n",
      "    Header: | Date       | Region   |   Sales |   Units |\n",
      "    Rows: 4\n",
      "\n",
      "  Table 3 (from document 3):\n",
      "    Header: | Item     |   Quantity | Location    |\n",
      "    Rows: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_chef = TableChef()\n",
    "\n",
    "# Process multiple files\n",
    "table_sources = [\n",
    "    \"./test_chef_files/products.csv\",\n",
    "    \"./test_chef_files/sales.csv\",\n",
    "    \"./test_chef_files/inventory.xlsx\"\n",
    "]\n",
    "\n",
    "docs = table_chef.process_batch(table_sources)\n",
    "\n",
    "print(\"üìä TableChef - Batch Processing Result:\")\n",
    "if docs:\n",
    "    # Count total tables across all documents\n",
    "    total_tables = sum(len(doc.tables) if hasattr(doc, 'tables') else 0 for doc in docs)\n",
    "    print(f\"  Processed {len(docs)} documents with {total_tables} total tables\\n\")\n",
    "    \n",
    "    table_num = 1\n",
    "    for doc_idx, doc in enumerate(docs, 1):\n",
    "        if hasattr(doc, 'tables') and doc.tables:\n",
    "            for table in doc.tables:\n",
    "                print(f\"  Table {table_num} (from document {doc_idx}):\")\n",
    "                lines = table.content.split('\\n')\n",
    "                header = lines[0] if lines else \"N/A\"\n",
    "                print(f\"    Header: {header}\")\n",
    "                print(f\"    Rows: {len(lines) - 1}\")\n",
    "                print()\n",
    "                table_num += 1\n",
    "else:\n",
    "    print(\"  No documents processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effd42c3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Pipeline Integration\n",
    "\n",
    "## 12. Pipeline - TextChef Integration\n",
    "\n",
    "Use TextChef in a complete pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9562805d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó TextChef Pipeline Result:\n",
      "  Document: N/A\n",
      "  Content: 459 characters\n",
      "  Chunks: 7\n",
      "\n",
      "üìù First 2 Chunks:\n",
      "  1. Machine Learning in Modern Applications\n",
      "...\n",
      "  2. \n",
      "Machine learning has revolutionized how we build software application...\n"
     ]
    }
   ],
   "source": [
    "from chonkie.pipeline import Pipeline\n",
    "\n",
    "# Pipeline: Fetch ‚Üí Process with TextChef ‚Üí Chunk\n",
    "doc = (Pipeline()\n",
    "    .fetch_from(\"file\", path=\"./test_chef_files/article.txt\")\n",
    "    .process_with(\"text\")\n",
    "    .chunk_with(\"recursive\", chunk_size=100)\n",
    "    .run())\n",
    "\n",
    "print(\"üîó TextChef Pipeline Result:\")\n",
    "print(f\"  Document: {Path(doc.source).name if hasattr(doc, 'source') else 'N/A'}\")\n",
    "print(f\"  Content: {len(doc.content) if hasattr(doc, 'content') else 'N/A'} characters\")\n",
    "print(f\"  Chunks: {len(doc.chunks)}\")\n",
    "print(f\"\\nüìù First 2 Chunks:\")\n",
    "for i, chunk in enumerate(doc.chunks[:2], 1):\n",
    "    print(f\"  {i}. {chunk.text[:70]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7ddd8a",
   "metadata": {},
   "source": [
    "## 13. Pipeline - MarkdownChef Integration\n",
    "\n",
    "Use MarkdownChef in a complete pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b85bc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó MarkdownChef Pipeline Result:\n",
      "  Document: N/A\n",
      "  Tables: 1\n",
      "  Code Blocks: 1\n",
      "  Images: 1\n",
      "  Text Chunks: 4\n",
      "\n",
      "üíª Code Block Languages:\n",
      "  1. python\n"
     ]
    }
   ],
   "source": [
    "# Pipeline: Fetch ‚Üí Process with MarkdownChef ‚Üí Chunk\n",
    "doc = (Pipeline()\n",
    "    .fetch_from(\"file\", path=\"./test_chef_files/tutorial.md\")\n",
    "    .process_with(\"markdown\", tokenizer=\"character\")\n",
    "    .chunk_with(\"recursive\", chunk_size=150)\n",
    "    .run())\n",
    "\n",
    "print(\"üîó MarkdownChef Pipeline Result:\")\n",
    "print(f\"  Document: {Path(doc.source).name if hasattr(doc, 'source') else 'N/A'}\")\n",
    "print(f\"  Tables: {len(doc.tables)}\")\n",
    "print(f\"  Code Blocks: {len(doc.code)}\")\n",
    "print(f\"  Images: {len(doc.images)}\")\n",
    "print(f\"  Text Chunks: {len(doc.chunks)}\")\n",
    "\n",
    "if doc.code:\n",
    "    print(f\"\\nüíª Code Block Languages:\")\n",
    "    for i, code in enumerate(doc.code, 1):\n",
    "        print(f\"  {i}. {code.language or 'unknown'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c13bd1e",
   "metadata": {},
   "source": [
    "## 14. Pipeline - Full Batch Integration\n",
    "\n",
    "Combine fetching multiple valid files with specific processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c35c94d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Batch Pipeline Result:\n",
      "  Processed 3 documents\n",
      "\n",
      "  1. Doc 1\n",
      "     Chunks: 10\n",
      "     First chunk: Machine Learning in Modern Applications\n",
      "...\n",
      "\n",
      "  2. Doc 2\n",
      "     Chunks: 6\n",
      "     First chunk: Data Science Pipeline\n",
      "\n",
      "The modern data science pip...\n",
      "\n",
      "  3. Doc 3\n",
      "     Chunks: 3\n",
      "     First chunk: Quick Notes:\n",
      "- Remember to test the new feature\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pipeline: Fetch directory ‚Üí Process with TextChef ‚Üí Chunk\n",
    "docs = (Pipeline()\n",
    "    .fetch_from(\"file\", dir=\"./test_chef_files\", ext=[\".txt\"])\n",
    "    .process_with(\"text\")\n",
    "    .chunk_with(\"recursive\", chunk_size=80)\n",
    "    .run())\n",
    "\n",
    "print(\"üîó Batch Pipeline Result:\")\n",
    "print(f\"  Processed {len(docs)} documents\\n\")\n",
    "\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    source = Path(doc.source).name if hasattr(doc, 'source') else f\"Doc {i}\"\n",
    "    print(f\"  {i}. {source}\")\n",
    "    print(f\"     Chunks: {len(doc.chunks)}\")\n",
    "    if doc.chunks:\n",
    "        print(f\"     First chunk: {doc.chunks[0].text[:50]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891cdd17",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: All Chef Types and Capabilities\n",
    "\n",
    "### Chef Comparison Table\n",
    "\n",
    "| Chef | Input Types | Output | Special Features | Use Cases |\n",
    "|------|------------|--------|------------------|-----------|\n",
    "| **TextChef** | .txt files | `Document` | Simple, no params | Plain text processing |\n",
    "| **MarkdownChef** | .md files | `MarkdownDocument` | Extracts tables, code, images | Rich markdown content |\n",
    "| **TableChef** | .csv, .xlsx, md strings | `list[MarkdownTable]` | Requires pandas | Data extraction |\n",
    "\n",
    "### Methods Available\n",
    "\n",
    "All chefs support:\n",
    "- `process(path)` - Process single file/string\n",
    "- `process_batch(paths)` - Process multiple files/strings\n",
    "\n",
    "### Return Types\n",
    "\n",
    "**Document** (TextChef):\n",
    "```python\n",
    "{\n",
    "    id: str,\n",
    "    content: str,\n",
    "    metadata: dict,\n",
    "    chunks: list[Chunk]  # (added after chunking)\n",
    "}\n",
    "```\n",
    "\n",
    "**MarkdownDocument** (MarkdownChef):\n",
    "```python\n",
    "{\n",
    "    id: str,\n",
    "    content: str,\n",
    "    tables: list[MarkdownTable],\n",
    "    code: list[MarkdownCode],\n",
    "    images: list[MarkdownImage],\n",
    "    chunks: list[Chunk],\n",
    "    metadata: dict\n",
    "}\n",
    "```\n",
    "\n",
    "**MarkdownTable** (TableChef):\n",
    "```python\n",
    "{\n",
    "    content: str,\n",
    "    start_index: int,\n",
    "    end_index: int\n",
    "}\n",
    "```\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "‚úÖ **TextChef**: Use for simple text files, articles, notes\n",
    "‚úÖ **MarkdownChef**: Use for documentation, technical content with code samples\n",
    "‚úÖ **TableChef**: Use when you need to extract structured data from tables\n",
    "‚úÖ **Pipeline Integration**: Combine chefs with fetchers and chunkers for complete workflows\n",
    "‚úÖ **Batch Processing**: Process multiple files at once for efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aee1a36",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Remove test files created for this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79a7648f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Test files cleaned up successfully\n"
     ]
    }
   ],
   "source": [
    "# Clean up test files\n",
    "import shutil\n",
    "\n",
    "test_dir = Path(\"./test_chef_files\")\n",
    "if test_dir.exists():\n",
    "    shutil.rmtree(test_dir)\n",
    "    print(\"‚úÖ Test files cleaned up successfully\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Test directory not found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chonkie (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
