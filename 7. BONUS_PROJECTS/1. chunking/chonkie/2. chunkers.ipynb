{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e42fc2f",
   "metadata": {},
   "source": [
    "# ðŸ¦› Chonkie Advanced Chunking Tutorial\n",
    "\n",
    "Welcome to this comprehensive tutorial on **Chonkie** - a powerful open-source library for text chunking in RAG (Retrieval Augmented Generation) applications. This notebook explores various advanced chunking mechanisms and demonstrates how different strategies affect text segmentation.\n",
    "\n",
    "## ðŸ“Š Overview Architecture\n",
    "\n",
    "```mermaid\n",
    "%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#ff6b6b', 'primaryTextColor': '#fff', 'primaryBorderColor': '#ee5a52', 'lineColor': '#4ecdc4', 'secondaryColor': '#45b7d1', 'tertiaryColor': '#96ceb4', 'noteTextColor': '#2d3436', 'noteBkgColor': '#ffeaa7'}}}%%\n",
    "graph TB\n",
    "    A[ðŸ“ Input Text] --> B{Chunking Strategy}\n",
    "    \n",
    "    B --> C1[ðŸ”¢ TokenChunker]\n",
    "    B --> C2[ðŸ“„ SentenceChunker]\n",
    "    B --> C3[ðŸ”„ RecursiveChunker]\n",
    "    B --> C4[ðŸ§  SemanticChunker]\n",
    "    B --> C5[âš¡ LateChunker]\n",
    "    B --> C6[ðŸ’» CodeChunker]\n",
    "    \n",
    "    C1 --> D1[Fixed Token<br/>Boundaries]\n",
    "    C2 --> D2[Sentence<br/>Boundaries]\n",
    "    C3 --> D3[Hierarchical<br/>Splitting]\n",
    "    C4 --> D4[Semantic<br/>Similarity]\n",
    "    C5 --> D5[Document-Level<br/>Context]\n",
    "    C6 --> D6[AST-Based<br/>Structure]\n",
    "    \n",
    "    D1 --> E[ðŸ“¦ Chunked Output]\n",
    "    D2 --> E\n",
    "    D3 --> E\n",
    "    D4 --> E\n",
    "    D5 --> E\n",
    "    D6 --> E\n",
    "    \n",
    "    E --> F[ðŸŽ¨ HTML Visualization]\n",
    "    F --> G[Color-Coded Chunks]\n",
    "    \n",
    "    style A fill:#ff6b6b,stroke:#ee5a52,stroke-width:3px,color:#fff\n",
    "    style B fill:#ffeaa7,stroke:#fdcb6e,stroke-width:3px\n",
    "    style C1 fill:#74b9ff,stroke:#0984e3,stroke-width:2px,color:#fff\n",
    "    style C2 fill:#a29bfe,stroke:#6c5ce7,stroke-width:2px,color:#fff\n",
    "    style C3 fill:#fd79a8,stroke:#e84393,stroke-width:2px,color:#fff\n",
    "    style C4 fill:#55efc4,stroke:#00b894,stroke-width:2px,color:#000\n",
    "    style C5 fill:#ffeaa7,stroke:#fdcb6e,stroke-width:2px\n",
    "    style C6 fill:#81ecec,stroke:#00cec9,stroke-width:2px\n",
    "    style E fill:#dfe6e9,stroke:#b2bec3,stroke-width:3px\n",
    "    style F fill:#fab1a0,stroke:#e17055,stroke-width:2px\n",
    "    style G fill:#00b894,stroke:#00cec9,stroke-width:2px,color:#fff\n",
    "```\n",
    "\n",
    "## ðŸŽ¯ What You'll Learn\n",
    "\n",
    "This tutorial covers:\n",
    "- **TokenChunker**: Fixed-size token-based chunking\n",
    "- **SentenceChunker**: Sentence boundary-preserving chunks\n",
    "- **RecursiveChunker**: Hierarchical recursive splitting\n",
    "- **SemanticChunker**: Similarity-based semantic grouping\n",
    "- **LateChunker**: Document-level contextual embeddings\n",
    "- **CodeChunker**: AST-based code structure chunking\n",
    "\n",
    "Each section demonstrates:\n",
    "1. ðŸ“– How the chunker works\n",
    "2. âš™ï¸ Configuration parameters\n",
    "3. ðŸ” Effect on sample text\n",
    "4. ðŸŽ¨ Visual representation with color-coded chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e6804a",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Installation and Setup\n",
    "\n",
    "First, let's install Chonkie with all the advanced features we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f7bb951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chonkie and all dependencies installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install Chonkie with all advanced features\n",
    "# This includes semantic, code, and visualization capabilities\n",
    "# !pip install -q \"chonkie[all,viz]\"\n",
    "\n",
    "# Import required libraries\n",
    "from chonkie import (\n",
    "    TokenChunker, \n",
    "    SentenceChunker, \n",
    "    RecursiveChunker, \n",
    "    SemanticChunker,\n",
    "    LateChunker,\n",
    "    CodeChunker,\n",
    "    Visualizer\n",
    ")\n",
    "from IPython.display import HTML, display\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Chonkie and all dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864a3266",
   "metadata": {},
   "source": [
    "## ðŸ“š Sample Text for Demonstration\n",
    "\n",
    "We'll use a comprehensive sample text covering multiple topics to demonstrate how different chunking strategies affect the output. This text includes various themes: technology, climate change, and scientific discoveries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee96f378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Sample text length: 18999 characters\n",
      "ðŸ“Š Approximate word count: 2347 words\n",
      "âœ… Sample text ready for chunking!\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"\"\"\n",
    "Artificial Intelligence and Machine Learning Revolution\n",
    "\n",
    "The field of artificial intelligence has undergone tremendous transformation in recent years. Machine learning algorithms have become increasingly sophisticated, enabling computers to perform tasks that once seemed exclusively human. Deep learning, a subset of machine learning, uses neural networks with multiple layers to process complex patterns in data. These networks can recognize images, understand natural language, and even generate creative content.\n",
    "\n",
    "The impact of AI extends across multiple industries. In healthcare, machine learning models can diagnose diseases from medical images with accuracy rivaling expert physicians. Financial institutions use AI for fraud detection, analyzing millions of transactions in real-time to identify suspicious patterns. Autonomous vehicles rely on computer vision and sensor fusion to navigate complex environments safely. Manufacturing plants employ AI-powered robots that can adapt to changing conditions and optimize production processes.\n",
    "\n",
    "However, the rise of AI also presents significant challenges. Questions about bias in machine learning models have sparked important discussions about fairness and accountability. When training data reflects societal prejudices, AI systems can perpetuate and amplify these biases. Privacy concerns arise as organizations collect vast amounts of personal data to train their models. The potential displacement of workers by automation raises economic and social questions that society must address.\n",
    "\n",
    "Climate Change and Environmental Sustainability\n",
    "\n",
    "Climate change represents one of the most pressing challenges facing humanity. Rising global temperatures are causing widespread environmental disruptions. Polar ice caps are melting at unprecedented rates, contributing to sea level rise that threatens coastal communities worldwide. Extreme weather events, including hurricanes, droughts, and wildfires, are becoming more frequent and severe.\n",
    "\n",
    "The primary driver of climate change is the accumulation of greenhouse gases in the atmosphere, particularly carbon dioxide from fossil fuel combustion. Industrial processes, transportation, and electricity generation contribute significantly to these emissions. Deforestation exacerbates the problem by reducing the planet's capacity to absorb carbon dioxide. The concentration of atmospheric CO2 has increased by over 40% since pre-industrial times.\n",
    "\n",
    "Addressing climate change requires coordinated global action. Renewable energy technologies, such as solar and wind power, offer pathways to reduce carbon emissions. Energy efficiency improvements in buildings and transportation can significantly decrease energy consumption. Carbon capture and storage technologies aim to remove CO2 from the atmosphere or prevent its release. International agreements like the Paris Climate Accord establish frameworks for countries to commit to emission reduction targets.\n",
    "\n",
    "Individual actions also play a crucial role in combating climate change. Reducing meat consumption, especially beef, can lower one's carbon footprint substantially. Using public transportation, cycling, or walking instead of driving reduces emissions. Energy-conscious choices in daily life, such as using LED bulbs and efficient appliances, contribute to overall energy conservation. Supporting businesses and policies that prioritize sustainability helps drive systemic change.\n",
    "\n",
    "Scientific Discoveries and Innovation\n",
    "\n",
    "Scientific research continues to unlock mysteries of the universe and develop groundbreaking technologies. The recent detection of gravitational waves confirmed Einstein's century-old predictions and opened a new window for observing cosmic phenomena. CRISPR gene-editing technology has revolutionized biology, enabling precise modifications to DNA with potential applications in treating genetic diseases. Quantum computing promises to solve problems that are intractable for classical computers, with implications for cryptography, drug discovery, and materials science.\n",
    "\n",
    "Advances in neuroscience are revealing the complexities of the human brain. Brain-computer interfaces allow paralyzed individuals to control prosthetic limbs or communicate through thought alone. Understanding neural plasticity has led to new approaches for treating neurological conditions and enhancing cognitive function. Mapping the brain's connectome provides insights into how neural networks give rise to consciousness and behavior.\n",
    "\n",
    "Space exploration has entered an exciting new era. Private companies are developing reusable rockets that dramatically reduce the cost of space access. Missions to Mars are preparing for eventual human colonization of the Red Planet. The James Webb Space Telescope is capturing unprecedented images of distant galaxies, helping astronomers understand the early universe. Exoplanet discoveries have revealed thousands of worlds beyond our solar system, raising profound questions about the existence of extraterrestrial life.\n",
    "\n",
    "The intersection of different scientific disciplines is driving innovation. Bioinformatics combines biology and computer science to analyze genomic data. Nanotechnology manipulates matter at the atomic scale to create new materials with remarkable properties. Synthetic biology engineers organisms to produce valuable compounds, from pharmaceuticals to biofuels. These interdisciplinary approaches are accelerating the pace of discovery and creating solutions to complex problems.\n",
    "\n",
    "Medical Advances and Clinical Applications\n",
    "\n",
    "Modern clinical practice has been revolutionized by advances in medical imaging and diagnostics. Magnetic resonance imaging (MRI) and computed tomography (CT) scanning provide detailed anatomical information enabling early disease detection. Positron emission tomography (PET) combined with CT allows oncologists to identify metastatic lesions and assess treatment response in cancer patients. Electrocardiography (ECG) and echocardiography remain essential tools for evaluating cardiac pathology and ventricular function in patients presenting with arrhythmias or heart failure.\n",
    "\n",
    "Pharmaceutical innovation continues to expand therapeutic options for previously intractable conditions. Monoclonal antibodies targeting specific antigens have transformed treatment protocols for rheumatoid arthritis, inflammatory bowel disease, and various malignancies. Tyrosine kinase inhibitors demonstrate remarkable efficacy in chronic myeloid leukemia and other oncologic conditions. Checkpoint inhibitors unleash the immune system's capacity to recognize and eliminate tumor cells, fundamentally changing approaches to immunotherapy. Biologics production through recombinant DNA technology has enabled the development of insulin analogs, growth hormones, and clotting factors that save countless lives annually.\n",
    "\n",
    "Clinical laboratory science plays a critical role in diagnostic medicine. Complete blood count (CBC) analysis evaluates hematologic parameters including hemoglobin, hematocrit, and white blood cell differentials. Comprehensive metabolic panels assess renal function through creatinine and blood urea nitrogen measurements, hepatic function via bilirubin and transaminase levels, and glucose metabolism through fasting glucose and hemoglobin A1c determinations. Lipid panels quantifying cholesterol, triglycerides, and lipoprotein fractions guide cardiovascular risk stratification and therapeutic intervention.\n",
    "\n",
    "Surgical innovation has enhanced patient outcomes through minimally invasive techniques. Laparoscopic cholecystectomy has largely replaced open approaches for gallbladder disease, reducing postoperative pain and hospitalization duration. Robot-assisted radical prostatectomy offers improved visualization and precision in oncologic urologic procedures. Endoscopic approaches to gastroesophageal reflux disease and bariatric surgery provide alternatives to traditional open surgery. Video-assisted thoracoscopic surgery (VATS) enables lung resection for both malignant and benign pathology with reduced morbidity compared to open thoracotomy.\n",
    "\n",
    "Infectious Disease and Epidemiology\n",
    "\n",
    "Infectious disease management requires understanding microbial pathogenesis and antimicrobial susceptibility. Bacterial infections are treated according to culture results and antibiotic sensitivities determined through disk diffusion or broth microdilution methods. Gram-positive cocci including Streptococcus pneumoniae and Staphylococcus aureus cause community-acquired pneumonia and must be distinguished from gram-negative organisms requiring different empiric therapy. Mycobacterial infections including tuberculosis demand prolonged treatment with isoniazid, rifampin, pyrazinamide, and ethambutol to prevent treatment failure and drug resistance.\n",
    "\n",
    "Viral hepatitis encompasses distinct pathogens with varying transmission routes and clinical consequences. Hepatitis A causes acute inflammation but does not progress to chronicity. Hepatitis B and C virus infections establish chronic viremia, leading to progressive hepatic fibrosis, cirrhosis, and hepatocellular carcinoma in untreated patients. Direct-acting antiviral agents achieve cure rates exceeding 95 percent in hepatitis C genotypes, revolutionizing prognosis for millions of chronically infected patients. Hepatitis B treatment with nucleos(t)ide reverse transcriptase inhibitors suppresses viral replication, preventing disease progression to decompensated cirrhosis.\n",
    "\n",
    "HIV infection remains a significant public health challenge despite effective antiretroviral therapy. Combination antiretroviral regimens utilizing nucleoside reverse transcriptase inhibitors, non-nucleoside reverse transcriptase inhibitors, protease inhibitors, and integrase inhibitors suppress viral replication to undetectable levels. CD4 cell count recovery following immune reconstitution allows discontinuation of opportunistic infection prophylaxis. Virologic failure with emergence of drug-resistant variants necessitates therapeutic drug monitoring and genotypic resistance testing to guide salvage regimens.\n",
    "\n",
    "Chronic Disease Management and Epidemiology\n",
    "\n",
    "Type 2 diabetes mellitus represents a pandemic affecting over 400 million individuals globally. Pathophysiology involves insulin resistance at the cellular level combined with progressive beta cell dysfunction. Management strategies include lifestyle modification, oral hypoglycemic agents including metformin, sulfonylureas, thiazolidinediones, and newer agents such as glucagon-like peptide-1 receptor agonists and sodium-glucose cotransporter-2 inhibitors. Tight glycemic control targeting hemoglobin A1c below 7 percent reduces microvascular complications including diabetic retinopathy, nephropathy, and neuropathy.\n",
    "\n",
    "Hypertension affects approximately 1.1 billion individuals worldwide and represents the leading modifiable risk factor for cardiovascular morbidity and mortality. Pathophysiology involves abnormal vascular tone regulation, fluid retention, and sympathetic nervous system hyperactivity. Pharmacologic management utilizes angiotensin-converting enzyme inhibitors, angiotensin II receptor blockers, calcium channel blockers, thiazide and loop diuretics, and beta-adrenergic antagonists. Blood pressure targets vary by comorbidities, with most guidelines recommending systolic pressure below 130 mmHg to prevent stroke and myocardial infarction.\n",
    "\n",
    "Heart failure affects over 26 million individuals globally and represents a major cause of hospitalization in developed nations. Systolic heart failure results from reduced ejection fraction due to myocardial infarction, cardiomyopathy, or chronic hypertension. Diastolic heart failure involves normal ejection fraction with impaired ventricular relaxation. Management incorporates beta-blockers, ACE inhibitors, aldosterone antagonists, and newer agents including ARNI complexes. Implantable cardioverter-defibrillators and cardiac resynchronization therapy benefit appropriate candidates with reduced ejection fraction.\n",
    "\n",
    "Oncology and Cancer Treatment\n",
    "\n",
    "Malignant neoplasms represent the second leading cause of death globally after cardiovascular disease. Carcinogenesis involves accumulation of genetic mutations in proto-oncogenes and tumor suppressor genes including p53 and RB. Pathologic staging using TNM classification determines prognosis and guides therapeutic recommendations. Screening programs for breast, colorectal, and cervical cancers have reduced mortality through early detection of precancerous lesions and stage I disease.\n",
    "\n",
    "Chemotherapy regimens utilize cytotoxic agents targeting rapidly dividing cells. Alkylating agents damage DNA through formation of covalent bonds. Platinum compounds including cisplatin and carboplatin create interstrand DNA crosslinks preventing replication. Antimetabolites including methotrexate inhibit nucleotide synthesis disrupting DNA and RNA synthesis. Topoisomerase inhibitors prevent DNA unwinding necessary for replication and transcription. Systemic toxicity including myelosuppression, mucositis, and nephrotoxicity necessitates supportive care and dose modification in susceptible patients.\n",
    "\n",
    "Radiation oncology utilizes ionizing radiation to destroy malignant cells. External beam radiotherapy delivers photons or particles through linear accelerators with precise spatial targeting. Intensity-modulated radiation therapy (IMRT) shapes radiation fields to conform to tumor contours while minimizing dose to adjacent normal tissues. Brachytherapy delivers radioactive sources directly into tumors enabling high local doses with rapid dose falloff. Complications including dermatitis, esophagitis, and secondary malignancies require careful risk-benefit analysis during treatment planning.\n",
    "\n",
    "The Future of Work and Education\n",
    "\n",
    "The nature of work is evolving rapidly in response to technological advancement. Remote work has become mainstream, enabled by video conferencing, cloud computing, and collaborative software. This shift challenges traditional notions of the workplace and opens opportunities for global talent collaboration. However, it also raises questions about work-life balance, social isolation, and the need for physical office spaces.\n",
    "\n",
    "Automation and AI are transforming job markets across sectors. Routine tasks in manufacturing, data entry, and customer service are increasingly performed by machines. This trend creates demand for new skills focused on creativity, critical thinking, and human interaction. Workers must engage in continuous learning to remain relevant in evolving industries. Reskilling and upskilling programs help people transition to new careers as job requirements change.\n",
    "\n",
    "Education systems are adapting to prepare students for this dynamic landscape. Online learning platforms provide access to educational resources for millions of people worldwide. Personalized learning powered by AI can adapt to individual student needs and learning styles. Project-based learning emphasizes practical skills and problem-solving abilities. STEM education receives increased focus to meet demand for technical expertise in emerging fields.\n",
    "\n",
    "The gig economy represents a significant shift in employment relationships. Freelancing and contract work offer flexibility but often lack the security and benefits of traditional employment. Platform-based work through services like ride-sharing and delivery apps provides income opportunities but raises concerns about worker protections and fair compensation. Policymakers grapple with updating labor laws to address these new forms of work.\n",
    "\n",
    "Global Health and Pandemics\n",
    "\n",
    "The COVID-19 pandemic highlighted the importance of global health infrastructure and rapid scientific response. Vaccines were developed at unprecedented speed, showcasing the power of international collaboration and biotechnology. The pandemic also exposed disparities in healthcare access and the need for resilient supply chains. Telemedicine became a vital tool, enabling remote consultations and reducing the burden on hospitals. Lessons learned from COVID-19 are shaping preparedness for future pandemics, emphasizing surveillance, early detection, and equitable distribution of medical resources.\n",
    "\n",
    "Arts, Culture, and Society\n",
    "\n",
    "Art and culture continue to evolve alongside technology. Digital art forms, such as NFTs and virtual reality exhibitions, are redefining how people create and experience art. Streaming platforms have transformed music, film, and television distribution, making content accessible to global audiences. Social media influences trends, public opinion, and even political movements. At the same time, there is renewed interest in preserving cultural heritage and supporting local artists. The intersection of technology and culture raises questions about authenticity, ownership, and the impact of algorithms on creative expression.\n",
    "\n",
    "Sports and Human Performance\n",
    "\n",
    "Advancements in sports science and technology are pushing the boundaries of human performance. Wearable devices track athletes' biometrics, optimizing training and recovery. Data analytics inform coaching strategies and player selection. Innovations in equipment design, such as carbon fiber running shoes and aerodynamic bicycles, contribute to record-breaking achievements. The integration of mental health support and mindfulness practices is recognized as essential for athlete well-being. Major sporting events foster international unity and inspire the next generation of competitors.\n",
    "\n",
    "Economics and Globalization\n",
    "\n",
    "The global economy is increasingly interconnected. Supply chain disruptions, trade agreements, and geopolitical tensions influence markets worldwide. Cryptocurrencies and blockchain technology are challenging traditional financial systems, offering new opportunities and risks. Economic inequality remains a pressing issue, with debates about universal basic income, wealth taxes, and social safety nets. Sustainable development goals guide efforts to balance economic growth with environmental protection and social equity.\n",
    "\n",
    "Conclusion and Looking Forward\n",
    "\n",
    "As we navigate these transformative times, the interconnection between technological progress, environmental stewardship, scientific discovery, and societal evolution becomes increasingly apparent. The choices we make today will shape the world for future generations. Balancing innovation with ethical considerations, economic growth with environmental sustainability, and individual freedom with collective responsibility requires thoughtful deliberation and collaborative action.\n",
    "\n",
    "Success in addressing global challenges depends on international cooperation, informed decision-making, and the willingness to adapt long-held assumptions. Education, critical thinking, and open dialogue are essential for navigating complexity and uncertainty. By embracing both the opportunities and responsibilities that come with advancement, humanity can work toward a future that is prosperous, sustainable, and equitable for all.\n",
    "\"\"\"\n",
    "print(f\"ðŸ“ Sample text length: {len(sample_text)} characters\")\n",
    "print(f\"ðŸ“Š Approximate word count: {len(sample_text.split())} words\")\n",
    "print(\"âœ… Sample text ready for chunking!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dda220b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ”¤ Understanding Tokenizers in Chonkie\n",
    "\n",
    "Before diving into chunking strategies, let's explore the different **tokenizers** available in Chonkie. Tokenizers determine how text is split into tokens, which affects chunk sizes and boundaries.\n",
    "\n",
    "## ðŸ“‹ Tokenizer Types\n",
    "\n",
    "Chonkie supports multiple tokenizer types:\n",
    "\n",
    "1. **Built-in Tokenizers**:\n",
    "   - `\"character\"` - Character-level tokenization (1 character = 1 token)\n",
    "   - `\"word\"` - Word-level tokenization (splits on whitespace)\n",
    "   - `\"gpt2\"` - GPT-2 BPE tokenizer (OpenAI's tokenization)\n",
    "\n",
    "2. **Hugging Face Tokenizers**:\n",
    "   - Any tokenizer from the Hugging Face Hub\n",
    "   - Examples: `\"bert-base-uncased\"`, `\"roberta-base\"`, `\"t5-small\"`, etc.\n",
    "\n",
    "The tokenizer choice impacts:\n",
    "- **Chunk size precision**: Character vs. subword vs. word granularity\n",
    "- **Compatibility**: Match your downstream model's tokenizer\n",
    "- **Language support**: Some tokenizers handle multilingual text better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a67315cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¤ Chonkie Built-in Tokenizers:\n",
      "============================================================\n",
      "1. character       - Character-level (fastest, most granular)\n",
      "2. word            - Word-level (simple, whitespace-based)\n",
      "3. gpt2            - GPT-2 BPE (standard for GPT models)\n",
      "\n",
      "âœ… These tokenizers are ready to use without additional downloads!\n",
      "   Example: TokenChunker(tokenizer='gpt2', chunk_size=512)\n"
     ]
    }
   ],
   "source": [
    "## Chonkie Built-in Tokenizers\n",
    "\n",
    "chonkie_tokenizers = [\n",
    "    \"character\",  # Character-level: Each character = 1 token\n",
    "    \"word\",       # Word-level: Splits on whitespace\n",
    "    \"gpt2\"        # GPT-2 BPE tokenizer (default for many models)\n",
    "]\n",
    "\n",
    "print(\"ðŸ”¤ Chonkie Built-in Tokenizers:\")\n",
    "print(\"=\" * 60)\n",
    "for idx, tokenizer in enumerate(chonkie_tokenizers, 1):\n",
    "    descriptions = {\n",
    "        \"character\": \"Character-level (fastest, most granular)\",\n",
    "        \"word\": \"Word-level (simple, whitespace-based)\",\n",
    "        \"gpt2\": \"GPT-2 BPE (standard for GPT models)\"\n",
    "    }\n",
    "    print(f\"{idx}. {tokenizer:15s} - {descriptions[tokenizer]}\")\n",
    "\n",
    "print(\"\\nâœ… These tokenizers are ready to use without additional downloads!\")\n",
    "print(\"   Example: TokenChunker(tokenizer='gpt2', chunk_size=512)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c16babce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤— Popular Hugging Face Tokenizers:\n",
      "============================================================\n",
      "1. bert-base-uncased\n",
      "   â†’ BERT - WordPiece tokenization, 30K vocab\n",
      "2. roberta-base\n",
      "   â†’ RoBERTa - BPE tokenization, 50K vocab\n",
      "3. distilbert-base-uncased\n",
      "   â†’ DistilBERT - Lighter BERT, 30K vocab\n",
      "4. albert-base-v2\n",
      "   â†’ ALBERT - Efficient BERT, shared parameters\n",
      "5. answerdotai/ModernBERT-base\n",
      "   â†’ ModernBERT - Latest architecture, 8K context\n",
      "6. sentence-transformers/all-MiniLM-L6-v2\n",
      "   â†’ MiniLM - Optimized for sentence embeddings\n",
      "7. llama-tokenizer\n",
      "   â†’ LlamaTokenizer - Llama models, large context windows\n",
      "8. t5-base\n",
      "   â†’ T5Tokenizer - Text-to-text transformer, 32K vocab\n",
      "9. xlnet-base-cased\n",
      "   â†’ XLNetTokenizer - Permutation-based, 32K vocab\n",
      "\n",
      "ðŸ’¡ Note: HuggingFace tokenizers will be auto-downloaded on first use\n",
      "   They provide more sophisticated tokenization than simple word/character splitting\n",
      "\n",
      "âš ï¸  Some tokenizers may have compatibility issues with Chonkie.\n",
      "   If you encounter errors, try using a different tokenizer from the list.\n"
     ]
    }
   ],
   "source": [
    "## Popular Hugging Face Tokenizers\n",
    "\n",
    "# Select popular HuggingFace tokenizers that are compatible with Chonkie\n",
    "popular_hf_tokenizers = [\n",
    "    \"bert-base-uncased\",      # BERT - Great for general text\n",
    "    \"roberta-base\",           # RoBERTa - Improved BERT variant\n",
    "    \"distilbert-base-uncased\", # DistilBERT - Faster, lighter BERT\n",
    "    \"albert-base-v2\",         # ALBERT - Parameter-efficient BERT variant\n",
    "    \"answerdotai/ModernBERT-base\",  # ModernBERT - State-of-the-art 2024 model\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\",  # Optimized for embeddings\n",
    "    \"llama-tokenizer\",        # LlamaTokenizer - Llama models, large context\n",
    "    \"t5-base\",                # T5Tokenizer - Text-to-text transformer\n",
    "    \"xlnet-base-cased\"        # XLNetTokenizer - Permutation-based language model\n",
    "]\n",
    "\n",
    "descriptions = {\n",
    "    \"bert-base-uncased\": \"BERT - WordPiece tokenization, 30K vocab\",\n",
    "    \"roberta-base\": \"RoBERTa - BPE tokenization, 50K vocab\",\n",
    "    \"distilbert-base-uncased\": \"DistilBERT - Lighter BERT, 30K vocab\",\n",
    "    \"albert-base-v2\": \"ALBERT - Efficient BERT, shared parameters\",\n",
    "    \"answerdotai/ModernBERT-base\": \"ModernBERT - Latest architecture, 8K context\",\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\": \"MiniLM - Optimized for sentence embeddings\",\n",
    "    \"llama-tokenizer\": \"LlamaTokenizer - Llama models, large context windows\",\n",
    "    \"t5-base\": \"T5Tokenizer - Text-to-text transformer, 32K vocab\",\n",
    "    \"xlnet-base-cased\": \"XLNetTokenizer - Permutation-based, 32K vocab\"\n",
    "}\n",
    "\n",
    "print(\"ðŸ¤— Popular Hugging Face Tokenizers:\")\n",
    "print(\"=\" * 60)\n",
    "for idx, tokenizer in enumerate(popular_hf_tokenizers, 1):\n",
    "    print(f\"{idx}. {tokenizer}\")\n",
    "    print(f\"   â†’ {descriptions[tokenizer]}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Note: HuggingFace tokenizers will be auto-downloaded on first use\")\n",
    "print(\"   They provide more sophisticated tokenization than simple word/character splitting\")\n",
    "print(\"\\nâš ï¸  Some tokenizers may have compatibility issues with Chonkie.\")\n",
    "print(\"   If you encounter errors, try using a different tokenizer from the list.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3933ddb2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ”¢ 1. TokenChunker: Fixed-Size Token-Based Chunking\n",
    "\n",
    "## Overview\n",
    "The **TokenChunker** splits text into chunks based on a fixed number of tokens. This is the most straightforward chunking method and is ideal when you need consistent chunk sizes for token-based models like GPT.\n",
    "\n",
    "### Key Features:\n",
    "- âœ… Fixed token count per chunk\n",
    "- âœ… Configurable overlap between chunks\n",
    "- âœ… Works with various tokenizers (GPT-2, TikToken, etc.)\n",
    "- âœ… Best for maintaining consistent chunk sizes\n",
    "\n",
    "### Use Cases:\n",
    "- Token-limited API calls\n",
    "- Consistent embedding dimensions\n",
    "- Simple text segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fb50b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e5f2a4eb7a4ae58215fb30acdfb552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Tokenizer:', index=2, options=('character', 'word', 'gpt2', 'bert-â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine all available tokenizers for dropdown\n",
    "all_tokenizers = chonkie_tokenizers + popular_hf_tokenizers\n",
    "\n",
    "# Interactive TokenChunker with parameter controls including tokenizer selection\n",
    "@interact(\n",
    "    tokenizer=widgets.Dropdown(\n",
    "        options=all_tokenizers,\n",
    "        value=\"gpt2\",\n",
    "        description='Tokenizer:',\n",
    "        style={'description_width': 'initial'}\n",
    "    ),\n",
    "    chunk_size=widgets.IntSlider(min=64, max=1024, step=64, value=512, description='Chunk Size'),\n",
    "    chunk_overlap=widgets.IntSlider(min=0, max=200, step=10, value=50, description='Overlap')\n",
    ")\n",
    "def visualize_token_chunker(tokenizer=\"gpt2\", chunk_size=512, chunk_overlap=50):\n",
    "    print(f\"ðŸ”„ Using tokenizer: {tokenizer}\")\n",
    "    \n",
    "    # Initialize TokenChunker\n",
    "    token_chunker = TokenChunker(\n",
    "        tokenizer=tokenizer,\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    \n",
    "    # Chunk the sample text\n",
    "    token_chunks = token_chunker.chunk(sample_text)\n",
    "\n",
    "    \n",
    "    # Visualize with colors\n",
    "    viz = Visualizer()\n",
    "    print(\"\\n\\nðŸŽ¨ HTML Visualization with Color-Coded Chunks:\")\n",
    "    viz.save(\"token_chunks_viz.html\", token_chunks)\n",
    "    with open(\"token_chunks_viz.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "        html_content = f.read()\n",
    "    display(HTML(html_content))\n",
    "\n",
    "        # Display statistics\n",
    "    print(\"ðŸ“Š TokenChunker Results:\")\n",
    "    print(f\"Total chunks created: {len(token_chunks)}\")\n",
    "    print(f\"\\nFirst 3 chunks details:\")\n",
    "    for i, chunk in enumerate(token_chunks[:3]):\n",
    "        print(f\"\\nðŸ”¹ Chunk {i+1}:\")\n",
    "        print(f\"  Token count: {chunk.token_count}\")\n",
    "        print(f\"  Character count: {len(chunk.text)}\")\n",
    "        print(f\"  Preview: {chunk.text[:100]}...\")\n",
    "        \n",
    "        # Show overlap with previous chunk\n",
    "        if i > 0 and chunk_overlap > 0:\n",
    "            prev_chunk = token_chunks[i-1]\n",
    "            # Find overlapping text (approximate by comparing end of prev with start of current)\n",
    "            overlap_text = \"\"\n",
    "            for length in range(min(len(prev_chunk.text), len(chunk.text)), 0, -1):\n",
    "                if prev_chunk.text[-length:] == chunk.text[:length]:\n",
    "                    overlap_text = chunk.text[:length]\n",
    "                    break\n",
    "            if overlap_text:\n",
    "                print(f\"  ðŸ”„ Overlap with Chunk {i}: {len(overlap_text)} chars\")\n",
    "                print(f\"     â†’ \\\"{overlap_text[:80]}...\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be752a5",
   "metadata": {},
   "source": [
    "### ðŸŽ¨ Understanding the Color Visualization\n",
    "\n",
    "In all HTML visualizations below, Chonkie's Visualizer displays chunks with the following color scheme:\n",
    "\n",
    "| Visual Element | Meaning |\n",
    "|----------------|---------|\n",
    "| **ðŸŽ¨ Colored Backgrounds** | Each chunk gets a **unique background color** from a rotating palette |\n",
    "| **ðŸ“Š Chunk Boundaries** | Where one background color ends and another begins = chunk boundary |\n",
    "| **ðŸ”„ Overlap Regions** | Text in overlapping regions appears in **both adjacent chunks** with their respective colors |\n",
    "| **ðŸŒˆ Color Cycling** | Colors rotate through a palette (blue, purple, pink, green, yellow, cyan, etc.) |\n",
    "\n",
    "#### Understanding Overlap (when `chunk_overlap` > 0):\n",
    "\n",
    "```\n",
    "Example with overlap=50 tokens:\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Chunk 1 (Blue Background)  â”‚â”€â”€â”€â”\n",
    "â”‚  \"...end of chunk 1 text\"   â”‚   â”‚â† Overlap: These 50 tokens\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   appear in BOTH chunks\n",
    "     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "     â”‚  \"...end of chunk 1 text\"      â”‚\n",
    "     â”‚  Chunk 2 (Purple Background)   â”‚\n",
    "     â”‚  \"beginning of chunk 2...\"     â”‚\n",
    "     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**ðŸ’¡ Key Insight**: Overlapping text will appear twice in the visualization - once with Chunk 1's color and again with Chunk 2's color. This ensures continuity and context preservation across chunk boundaries!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc416a2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ“„ 2. SentenceChunker: Sentence Boundary-Preserving Chunks\n",
    "\n",
    "## Overview\n",
    "The **SentenceChunker** splits text while preserving complete sentences. Unlike TokenChunker which can split mid-sentence, this chunker ensures that each chunk contains only complete sentences, maintaining semantic coherence.\n",
    "\n",
    "### Key Features:\n",
    "- âœ… Preserves sentence boundaries\n",
    "- âœ… Maintains semantic completeness\n",
    "- âœ… Configurable minimum sentences per chunk\n",
    "- âœ… Respects natural language structure\n",
    "\n",
    "### Use Cases:\n",
    "- Question-answering systems\n",
    "- Semantic search applications\n",
    "- When context preservation is critical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba9bdec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b15740720740debe4fd5d05da32249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Tokenizer:', index=2, options=('character', 'word', 'gpt2', 'bert-â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interactive SentenceChunker with parameter controls\n",
    "@interact(\n",
    "    tokenizer=widgets.Dropdown(\n",
    "        options=all_tokenizers,\n",
    "        value=\"gpt2\",\n",
    "        description='Tokenizer:',\n",
    "        style={'description_width': 'initial'}\n",
    "    ),\n",
    "    chunk_size=widgets.IntSlider(min=128, max=1024, step=64, value=512, description='Chunk Size'),\n",
    "    chunk_overlap=widgets.IntSlider(min=0, max=200, step=10, value=50, description='Overlap'),\n",
    "    min_sentences=widgets.IntSlider(min=1, max=5, step=1, value=2, description='Min Sentences')\n",
    ")\n",
    "def visualize_sentence_chunker(tokenizer=\"gpt2\", chunk_size=512, chunk_overlap=50, min_sentences=2):\n",
    "    print(f\"ðŸ”„ Using tokenizer: {tokenizer}\")\n",
    "    \n",
    "    # Initialize SentenceChunker\n",
    "    sentence_chunker = SentenceChunker(\n",
    "        tokenizer=tokenizer,\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        min_sentences_per_chunk=min_sentences,\n",
    "        min_characters_per_sentence=12\n",
    "    )\n",
    "    \n",
    "    # Chunk the sample text\n",
    "    sentence_chunks = sentence_chunker.chunk(sample_text)\n",
    "    \n",
    "    # Visualize with colors\n",
    "    viz = Visualizer()\n",
    "    print(\"\\n\\nðŸŽ¨ HTML Visualization with Color-Coded Chunks:\")\n",
    "    viz.save(\"sentence_chunks_viz.html\", sentence_chunks)\n",
    "    with open(\"sentence_chunks_viz.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "        html_content = f.read()\n",
    "    display(HTML(html_content))\n",
    "\n",
    "    # Display statistics\n",
    "    print(\"ðŸ“Š SentenceChunker Results:\")\n",
    "    print(f\"Total chunks created: {len(sentence_chunks)}\")\n",
    "    print(f\"\\nFirst 3 chunks details:\")\n",
    "    for i, chunk in enumerate(sentence_chunks[:3]):\n",
    "        sentences_count = chunk.text.count('.') + chunk.text.count('!') + chunk.text.count('?')\n",
    "        print(f\"\\nðŸ”¹ Chunk {i+1}:\")\n",
    "        print(f\"  Token count: {chunk.token_count}\")\n",
    "        print(f\"  Approximate sentences: {sentences_count}\")\n",
    "        print(f\"  Preview: {chunk.text[:120]}...\")\n",
    "        \n",
    "        # Show overlap with previous chunk\n",
    "        if i > 0 and chunk_overlap > 0:\n",
    "            prev_chunk = sentence_chunks[i-1]\n",
    "            overlap_text = \"\"\n",
    "            for length in range(min(len(prev_chunk.text), len(chunk.text)), 0, -1):\n",
    "                if prev_chunk.text[-length:] == chunk.text[:length]:\n",
    "                    overlap_text = chunk.text[:length]\n",
    "                    break\n",
    "            if overlap_text:\n",
    "                print(f\"  ðŸ”„ Overlap with Chunk {i}: {len(overlap_text)} chars\")\n",
    "                print(f\"     â†’ \\\"{overlap_text[:80]}...\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b1e84f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ”„ 3. RecursiveChunker: Hierarchical Recursive Splitting\n",
    "\n",
    "## Overview\n",
    "The **RecursiveChunker** uses a hierarchical approach, recursively splitting text using different delimiters (paragraphs, sentences, words, characters). It tries to split at the largest possible delimiter first, then recursively uses smaller delimiters if needed.\n",
    "\n",
    "### Key Features:\n",
    "- âœ… Multi-level delimiter hierarchy\n",
    "- âœ… Preserves document structure\n",
    "- âœ… Intelligent fallback mechanism\n",
    "- âœ… Customizable splitting rules\n",
    "\n",
    "### Use Cases:\n",
    "- Structured documents (books, articles)\n",
    "- Markdown or formatted text\n",
    "- When preserving hierarchical structure matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b40282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef3a4e25cd4434895817720307626b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Tokenizer:', index=2, options=('character', 'word', 'gpt2', 'bert-â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interactive RecursiveChunker with parameter controls\n",
    "@interact(\n",
    "    tokenizer=widgets.Dropdown(\n",
    "        options=all_tokenizers,\n",
    "        value=\"gpt2\",\n",
    "        description='Tokenizer:',\n",
    "        style={'description_width': 'initial'}\n",
    "    ),\n",
    "    chunk_size=widgets.IntSlider(min=128, max=1024, step=64, value=512, description='Chunk Size'),\n",
    "    min_chars=widgets.IntSlider(min=12, max=100, step=4, value=24, description='Min Chars')\n",
    ")\n",
    "def visualize_recursive_chunker(tokenizer=\"gpt2\", chunk_size=512, min_chars=24):\n",
    "    print(f\"ðŸ”„ Using tokenizer: {tokenizer}\")\n",
    "    \n",
    "    # Initialize RecursiveChunker\n",
    "    recursive_chunker = RecursiveChunker(\n",
    "        tokenizer=tokenizer,\n",
    "        chunk_size=chunk_size,\n",
    "        min_characters_per_chunk=min_chars\n",
    "    )\n",
    "    \n",
    "    # Chunk the sample text\n",
    "    recursive_chunks = recursive_chunker.chunk(sample_text)\n",
    "    \n",
    "    # Visualize with colors\n",
    "    viz = Visualizer()\n",
    "    print(\"\\n\\nðŸŽ¨ HTML Visualization with Color-Coded Chunks:\")\n",
    "    viz.save(\"recursive_chunks_viz.html\", recursive_chunks)\n",
    "    with open(\"recursive_chunks_viz.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "        html_content = f.read()\n",
    "    display(HTML(html_content))\n",
    "\n",
    "    # Display statistics\n",
    "    print(\"ðŸ“Š RecursiveChunker Results:\")\n",
    "    print(f\"Total chunks created: {len(recursive_chunks)}\")\n",
    "    print(f\"\\nFirst 3 chunks details:\")\n",
    "    for i, chunk in enumerate(recursive_chunks[:3]):\n",
    "        print(f\"\\nðŸ”¹ Chunk {i+1}:\")\n",
    "        print(f\"  Token count: {chunk.token_count}\")\n",
    "        print(f\"  Character count: {len(chunk.text)}\")\n",
    "        print(f\"  Start index: {chunk.start_index}\")\n",
    "        print(f\"  Preview: {chunk.text[:120]}...\")\n",
    "        \n",
    "        # Show overlap with previous chunk if any exists\n",
    "        if i > 0:\n",
    "            prev_chunk = recursive_chunks[i-1]\n",
    "            overlap_text = \"\"\n",
    "            for length in range(min(len(prev_chunk.text), len(chunk.text)), 0, -1):\n",
    "                if prev_chunk.text[-length:] == chunk.text[:length]:\n",
    "                    overlap_text = chunk.text[:length]\n",
    "                    break\n",
    "            if overlap_text:\n",
    "                print(f\"  ðŸ”„ Overlap with Chunk {i}: {len(overlap_text)} chars\")\n",
    "                print(f\"     â†’ \\\"{overlap_text[:80]}...\\\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63cdc6e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ§  4. SemanticChunker: Similarity-Based Semantic Grouping\n",
    "\n",
    "## Overview\n",
    "The **SemanticChunker** is one of the most advanced chunking strategies. It analyzes the semantic similarity between sentences and groups together content that is semantically related. This ensures that chunks contain topically coherent information.\n",
    "\n",
    "### Key Features:\n",
    "- âœ… Groups semantically similar content\n",
    "- âœ… Uses embeddings to measure similarity\n",
    "- âœ… Savitzky-Golay filtering for smooth boundaries\n",
    "- âœ… Optional skip-window merging for non-consecutive similar groups\n",
    "- âœ… Preserves topical coherence\n",
    "\n",
    "### How It Works:\n",
    "1. Splits text into sentences\n",
    "2. Generates embeddings for each sentence\n",
    "3. Calculates similarity between sentences\n",
    "4. Groups sentences with similarity above threshold\n",
    "5. Applies filtering for smoother boundaries\n",
    "\n",
    "### Use Cases:\n",
    "- Topic-based retrieval systems\n",
    "- When semantic coherence is paramount\n",
    "- Multi-topic documents\n",
    "- RAG applications requiring context preservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2527c442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Embedding Models for SemanticChunker:\n",
      "======================================================================\n",
      "1. minishlab/potion-base-32M\n",
      "   â†’ Model2Vec - Ultra-fast, lightweight (32M params)\n",
      "2. sentence-transformers/all-MiniLM-L6-v2\n",
      "   â†’ MiniLM - Popular, balanced speed/quality\n",
      "3. sentence-transformers/all-mpnet-base-v2\n",
      "   â†’ MPNet - High quality semantic search\n",
      "4. BAAI/bge-small-en-v1.5\n",
      "   â†’ BGE Small - Efficient, strong performance\n",
      "5. BAAI/bge-base-en-v1.5\n",
      "   â†’ BGE Base - Better quality, more compute\n",
      "6. BAAI/bge-large-en-v1.5\n",
      "   â†’ BGE Large - Top-tier quality, 1024 dimensions\n",
      "7. thenlper/gte-small\n",
      "   â†’ GTE - General text embeddings\n",
      "8. jinaai/jina-embeddings-v2-base-en\n",
      "   â†’ Jina v2 - 8K context, bilingual support\n",
      "9. nomic-ai/nomic-embed-text-v1.5\n",
      "   â†’ Nomic - Long context support (8K tokens)\n",
      "10. emilyalsentzer/Bio_ClinicalBERT\n",
      "   â†’ MedEmbed - Specialized for medical/clinical text\n",
      "11. kamalkraj/biobert-base-cased-v1.2\n",
      "   â†’ ClinVec - BioBERT for biomedical literature\n",
      "12. google/gecko-text-embedding\n",
      "   â†’ Google Gecko - Multimodal, high quality\n",
      "13. Alibaba-NLP/gte-large-en-v1.5\n",
      "   â†’ GTE Large - State-of-the-art, 1024 dimensions\n",
      "14. Alibaba-NLP/gte-Qwen2-7B-instruct\n",
      "   â†’ GTE Qwen2 - Instruction-tuned, 7B params\n",
      "   â€¢ Best quality: all-mpnet-base-v2, BAAI/bge-large-en-v1.5, Alibaba-NLP/gte-large-en-v1.5\n",
      "   â€¢ Faster models: minishlab/potion-base-32M, thenlper/gte-small\n",
      "   â€¢ Large-scale: Alibaba-NLP/gte-Qwen2-7B-instruct (7B params, instruction-tuned)\n",
      "   â€¢ Default recommended: minishlab/potion-base-32M (fast + good quality)\n",
      "   â€¢ Medical/Clinical: emilyalsentzer/Bio_ClinicalBERT, kamalkraj/biobert-base-cased-v1.2\n"
     ]
    }
   ],
   "source": [
    "## Embedding Models for Semantic Chunking\n",
    "\n",
    "# Popular embedding models optimized for semantic similarity tasks\n",
    "semantic_embedding_models = [\n",
    "    \"minishlab/potion-base-32M\",           # Model2Vec - Ultra-fast, 32M params\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\",  # Popular, balanced performance\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",  # High quality, general purpose\n",
    "    \"BAAI/bge-small-en-v1.5\",               # BGE - Efficient, strong performance\n",
    "    \"BAAI/bge-base-en-v1.5\",                # BGE - Better quality, slower\n",
    "    \"BAAI/bge-large-en-v1.5\",               # BGE Large - Highest quality BGE\n",
    "    \"thenlper/gte-small\",                   # GTE - General text embeddings\n",
    "    \"jinaai/jina-embeddings-v2-base-en\",    # Jina v2 - 8K context, strong performance\n",
    "    \"nomic-ai/nomic-embed-text-v1.5\",       # Nomic - Long context (8K tokens)\n",
    "    \"emilyalsentzer/Bio_ClinicalBERT\",      # MedEmbed - Medical/clinical domain\n",
    "    \"kamalkraj/biobert-base-cased-v1.2\",    # ClinVec - Biomedical text embeddings\n",
    "    \"google/gecko-text-embedding\",          # Google Gecko - Multimodal embeddings\n",
    "    \"Alibaba-NLP/gte-large-en-v1.5\",        # GTE Large - State-of-the-art, 1024 dims\n",
    "    \"Alibaba-NLP/gte-Qwen2-7B-instruct\",    # GTE Qwen2 - Instruction-tuned, 7B params\n",
    "]\n",
    "\n",
    "print(\"ðŸ§  Embedding Models for SemanticChunker:\")\n",
    "print(\"=\" * 70)\n",
    "for idx, model in enumerate(semantic_embedding_models, 1):\n",
    "    model_descriptions = {\n",
    "        \"minishlab/potion-base-32M\": \"Model2Vec - Ultra-fast, lightweight (32M params)\",\n",
    "        \"sentence-transformers/all-MiniLM-L6-v2\": \"MiniLM - Popular, balanced speed/quality\",\n",
    "        \"sentence-transformers/all-mpnet-base-v2\": \"MPNet - High quality semantic search\",\n",
    "        \"BAAI/bge-small-en-v1.5\": \"BGE Small - Efficient, strong performance\",\n",
    "        \"BAAI/bge-base-en-v1.5\": \"BGE Base - Better quality, more compute\",\n",
    "        \"BAAI/bge-large-en-v1.5\": \"BGE Large - Top-tier quality, 1024 dimensions\",\n",
    "        \"thenlper/gte-small\": \"GTE - General text embeddings\",\n",
    "        \"jinaai/jina-embeddings-v2-base-en\": \"Jina v2 - 8K context, bilingual support\",\n",
    "        \"nomic-ai/nomic-embed-text-v1.5\": \"Nomic - Long context support (8K tokens)\",\n",
    "        \"emilyalsentzer/Bio_ClinicalBERT\": \"MedEmbed - Specialized for medical/clinical text\",\n",
    "        \"kamalkraj/biobert-base-cased-v1.2\": \"ClinVec - BioBERT for biomedical literature\",\n",
    "        \"google/gecko-text-embedding\": \"Google Gecko - Multimodal, high quality\",\n",
    "        \"Alibaba-NLP/gte-large-en-v1.5\": \"GTE Large - State-of-the-art, 1024 dimensions\",\n",
    "        \"Alibaba-NLP/gte-Qwen2-7B-instruct\": \"GTE Qwen2 - Instruction-tuned, 7B params\",\n",
    "    }\n",
    "    print(f\"{idx}. {model}\")\n",
    "    print(f\"   â†’ {model_descriptions[model]}\")\n",
    "\n",
    "print(\"   â€¢ Best quality: all-mpnet-base-v2, BAAI/bge-large-en-v1.5, Alibaba-NLP/gte-large-en-v1.5\")\n",
    "print(\"   â€¢ Faster models: minishlab/potion-base-32M, thenlper/gte-small\")\n",
    "print(\"   â€¢ Large-scale: Alibaba-NLP/gte-Qwen2-7B-instruct (7B params, instruction-tuned)\")\n",
    "print(\"   â€¢ Default recommended: minishlab/potion-base-32M (fast + good quality)\")\n",
    "print(\"   â€¢ Medical/Clinical: emilyalsentzer/Bio_ClinicalBERT, kamalkraj/biobert-base-cased-v1.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d1d678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff3077645a440d28c13ca3ef0e7a15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Embedding:', options=('minishlab/potion-base-32M', 'sentence-transâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interactive SemanticChunker with parameter controls\n",
    "@interact(\n",
    "    embedding_model=widgets.Dropdown(\n",
    "        options=semantic_embedding_models,\n",
    "        value=\"minishlab/potion-base-32M\",\n",
    "        description='Embedding:',\n",
    "        style={'description_width': 'initial'}\n",
    "    ),\n",
    "    threshold=widgets.FloatSlider(min=0.3, max=0.95, step=0.05, value=0.7, description='Threshold'),\n",
    "    chunk_size=widgets.IntSlider(min=128, max=1024, step=64, value=512, description='Chunk Size'),\n",
    "    similarity_window=widgets.IntSlider(min=1, max=5, step=1, value=3, description='Sim Window'),\n",
    "    skip_window=widgets.IntSlider(min=0, max=3, step=1, value=0, description='Skip Window')\n",
    ")\n",
    "def visualize_semantic_chunker(embedding_model=\"minishlab/potion-base-32M\", threshold=0.7, chunk_size=512, similarity_window=3, skip_window=0):\n",
    "    print(f\"ðŸ”„ Using embedding model: {embedding_model}\")\n",
    "    print(\"ðŸ”„ Chunking with SemanticChunker (this may take a moment)...\")\n",
    "    \n",
    "    # Initialize SemanticChunker\n",
    "    semantic_chunker = SemanticChunker(\n",
    "        embedding_model=embedding_model,\n",
    "        threshold=threshold,\n",
    "        chunk_size=chunk_size,\n",
    "        similarity_window=similarity_window,\n",
    "        skip_window=skip_window,\n",
    "        min_sentences_per_chunk=1\n",
    "    )\n",
    "    \n",
    "    # Chunk the sample text\n",
    "    semantic_chunks = semantic_chunker.chunk(sample_text)\n",
    "    \n",
    "    \n",
    "    # Visualize with colors\n",
    "    print(\"\\n\\nðŸŽ¨ HTML Visualization with Color-Coded Chunks:\")\n",
    "    print(\"Notice how semantically similar content is grouped together!\")\n",
    "    viz = Visualizer()\n",
    "    viz.save(\"semantic_chunks_viz.html\", semantic_chunks)\n",
    "    with open(\"semantic_chunks_viz.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "        html_content = f.read()\n",
    "        display(HTML(html_content))\n",
    "\n",
    "        # Display statistics\n",
    "    print(\"\\nðŸ“Š SemanticChunker Results:\")\n",
    "    print(f\"Total chunks created: {len(semantic_chunks)}\")\n",
    "    print(f\"\\nFirst 3 chunks details:\")\n",
    "    for i, chunk in enumerate(semantic_chunks[:3]):\n",
    "        print(f\"\\nðŸ”¹ Chunk {i+1}:\")\n",
    "        print(f\"  Token count: {chunk.token_count}\")\n",
    "        print(f\"  Character count: {len(chunk.text)}\")\n",
    "        print(f\"  Preview: {chunk.text[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b7f6d0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# âš¡ 5. LateChunker: Document-Level Contextual Embeddings\n",
    "\n",
    "## Overview\n",
    "The **LateChunker** implements the \"Late Chunking\" algorithm from the [research paper](https://arxiv.org/abs/2409.04701). Unlike traditional methods that embed each chunk independently, LateChunker first generates a document-level embedding and then derives chunk embeddings from it. This provides richer contextual information.\n",
    "\n",
    "### Key Features:\n",
    "- âœ… Document-level context preservation\n",
    "- âœ… Embeddings capture broader context\n",
    "- âœ… Built on RecursiveChunker base\n",
    "- âœ… Better retrieval performance in RAG systems\n",
    "- âœ… Each chunk includes its embedding\n",
    "\n",
    "### How It Works:\n",
    "1. Encodes entire document into single embedding\n",
    "2. Splits text using recursive rules\n",
    "3. Derives chunk embeddings from document embedding\n",
    "4. Each chunk carries broader contextual information\n",
    "\n",
    "### Use Cases:\n",
    "- Advanced RAG applications\n",
    "- When document-level context is important\n",
    "- Improved retrieval accuracy\n",
    "- Semantic search with rich context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "135adcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561e45a2eb4b45259408395e4acfc95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Embedding:', options=('minishlab/potion-base-32M', 'sentence-transâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interactive LateChunker with parameter controls\n",
    "@interact(\n",
    "    embedding_model=widgets.Dropdown(\n",
    "        options=semantic_embedding_models,\n",
    "        value=\"minishlab/potion-base-32M\",\n",
    "        description='Embedding:',\n",
    "        style={'description_width': 'initial'}\n",
    "    ),\n",
    "    chunk_size=widgets.IntSlider(min=128, max=1024, step=64, value=512, description='Chunk Size'),\n",
    "    min_chars=widgets.IntSlider(min=12, max=100, step=4, value=24, description='Min Chars')\n",
    ")\n",
    "def visualize_late_chunker(embedding_model=\"minishlab/potion-base-32M\", chunk_size=512, min_chars=24):\n",
    "    print(f\"ðŸ”„ Using embedding model: {embedding_model}\")\n",
    "    print(\"ðŸ”„ Chunking with LateChunker (generating document-level embeddings)...\")\n",
    "    \n",
    "    # Initialize LateChunker\n",
    "    late_chunker = LateChunker(\n",
    "        embedding_model=embedding_model,\n",
    "        chunk_size=chunk_size,\n",
    "        min_characters_per_chunk=min_chars\n",
    "    )\n",
    "    \n",
    "    # Chunk the sample text\n",
    "    late_chunks = late_chunker.chunk(sample_text)\n",
    "    \n",
    "    # Display statistics\n",
    "    print(\"\\nðŸ“Š LateChunker Results:\")\n",
    "    print(f\"Total chunks created: {len(late_chunks)}\")\n",
    "    print(f\"\\nFirst 3 chunks details:\")\n",
    "    for i, chunk in enumerate(late_chunks[:3]):\n",
    "        print(f\"\\nðŸ”¹ Chunk {i+1}:\")\n",
    "        print(f\"  Token count: {chunk.token_count}\")\n",
    "        print(f\"  Character count: {len(chunk.text)}\")\n",
    "        if hasattr(chunk, 'embedding') and chunk.embedding is not None:\n",
    "            print(f\"  Embedding shape: {chunk.embedding.shape}\")\n",
    "        print(f\"  Preview: {chunk.text[:150]}...\")\n",
    "    \n",
    "    # Visualize with colors\n",
    "    print(\"\\n\\nðŸŽ¨ HTML Visualization with Color-Coded Chunks:\")\n",
    "    print(\"Each chunk contains embeddings derived from the full document context!\")\n",
    "    viz = Visualizer()\n",
    "    viz.save(\"late_chunks_viz.html\", late_chunks)\n",
    "    with open(\"late_chunks_viz.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "        html_content = f.read()\n",
    "        display(HTML(html_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5522c4bb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ’» 6. CodeChunker: AST-Based Code Structure Chunking\n",
    "\n",
    "## Overview\n",
    "The **CodeChunker** is specialized for source code. It uses Abstract Syntax Trees (AST) to understand code structure and creates chunks that respect programming language syntax. This is perfect for code documentation, code search, and AI-assisted coding.\n",
    "\n",
    "### Key Features:\n",
    "- âœ… AST-based parsing\n",
    "- âœ… Respects code structure (functions, classes, etc.)\n",
    "- âœ… Supports multiple programming languages\n",
    "- âœ… Maintains syntactic validity\n",
    "- âœ… Optional AST node information\n",
    "\n",
    "### Supported Languages:\n",
    "Python, JavaScript, TypeScript, Java, C++, Go, Rust, and many more via tree-sitter!\n",
    "\n",
    "### Use Cases:\n",
    "- Code documentation systems\n",
    "- Code search engines\n",
    "- AI code assistants\n",
    "- Code analysis tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3089b809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2853bcfd86549bb80ffe13759559767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Tokenizer:', index=2, options=('character', 'word', 'gpt2', 'bert-â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample Python code for demonstration\n",
    "sample_code = \"\"\"\n",
    "import numpy as np\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "class DataProcessor:\n",
    "    \\\"\\\"\\\"A class for processing and analyzing data.\\\"\\\"\\\"\n",
    "    \n",
    "    def __init__(self, data: List[float]):\n",
    "        self.data = data\n",
    "        self.processed = False\n",
    "    \n",
    "    def normalize(self) -> np.ndarray:\n",
    "        \\\"\\\"\\\"Normalize the data using min-max scaling.\\\"\\\"\\\"\n",
    "        data_array = np.array(self.data)\n",
    "        min_val = np.min(data_array)\n",
    "        max_val = np.max(data_array)\n",
    "        normalized = (data_array - min_val) / (max_val - min_val)\n",
    "        self.processed = True\n",
    "        return normalized\n",
    "    \n",
    "    def calculate_statistics(self) -> Dict[str, float]:\n",
    "        \\\"\\\"\\\"Calculate basic statistics of the data.\\\"\\\"\\\"\n",
    "        data_array = np.array(self.data)\n",
    "        stats = {\n",
    "            'mean': np.mean(data_array),\n",
    "            'median': np.median(data_array),\n",
    "            'std': np.std(data_array),\n",
    "            'min': np.min(data_array),\n",
    "            'max': np.max(data_array)\n",
    "        }\n",
    "        return stats\n",
    "\n",
    "def create_sample_data(size: int = 100) -> List[float]:\n",
    "    \\\"\\\"\\\"Generate sample data for testing.\\\"\\\"\\\"\n",
    "    return np.random.randn(size).tolist()\n",
    "\n",
    "def main():\n",
    "    \\\"\\\"\\\"Main function to demonstrate the DataProcessor.\\\"\\\"\\\"\n",
    "    # Create sample data\n",
    "    data = create_sample_data(50)\n",
    "    \n",
    "    # Initialize processor\n",
    "    processor = DataProcessor(data)\n",
    "    \n",
    "    # Normalize and get statistics\n",
    "    normalized = processor.normalize()\n",
    "    stats = processor.calculate_statistics()\n",
    "    \n",
    "    print(f\"Statistics: {stats}\")\n",
    "    print(f\"First 5 normalized values: {normalized[:5]}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "# Interactive CodeChunker with parameter controls\n",
    "@interact(\n",
    "    tokenizer=widgets.Dropdown(\n",
    "        options=all_tokenizers,\n",
    "        value=\"gpt2\",\n",
    "        description='Tokenizer:',\n",
    "        style={'description_width': 'initial'}\n",
    "    ),\n",
    "    chunk_size=widgets.IntSlider(min=128, max=768, step=64, value=256, description='Chunk Size')\n",
    ")\n",
    "def visualize_code_chunker(tokenizer=\"gpt2\", chunk_size=256):\n",
    "    print(f\"ðŸ”„ Chunking Python code with CodeChunker...\")\n",
    "    print(f\"ðŸ”„ Using tokenizer: {tokenizer}\")\n",
    "    \n",
    "    # Initialize CodeChunker for Python\n",
    "    code_chunker = CodeChunker(\n",
    "        language=\"python\",\n",
    "        tokenizer=tokenizer,\n",
    "        chunk_size=chunk_size,\n",
    "        include_nodes=False\n",
    "    )\n",
    "    \n",
    "    # Chunk the code\n",
    "    code_chunks = code_chunker.chunk(sample_code)\n",
    "    \n",
    "    # Display statistics\n",
    "    print(f\"\\nðŸ“Š CodeChunker Results:\")\n",
    "    print(f\"Total chunks created: {len(code_chunks)}\")\n",
    "    print(f\"\\nChunk details:\")\n",
    "    for i, chunk in enumerate(code_chunks):\n",
    "        print(f\"\\nðŸ”¹ Chunk {i+1}:\")\n",
    "        print(f\"  Token count: {chunk.token_count}\")\n",
    "        print(f\"  Lines of code: {chunk.text.count(chr(10)) + 1}\")\n",
    "        print(f\"  Preview:\")\n",
    "        print(f\"  {chunk.text[:200]}...\")\n",
    "    \n",
    "    # Visualize with colors\n",
    "    print(\"\\n\\nðŸŽ¨ HTML Visualization with Color-Coded Code Chunks:\")\n",
    "    print(\"Notice how chunks respect code structure (classes, functions, etc.)!\")\n",
    "    viz = Visualizer()\n",
    "    viz.save(\"code_chunks_viz.html\", code_chunks)\n",
    "    with open(\"code_chunks_viz.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "        html_content = f.read()\n",
    "        display(HTML(html_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d24ad2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ“Š Comparison: How Different Chunkers Affect the Same Text\n",
    "\n",
    "Let's compare how each chunker handles the same piece of text to understand their unique characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3a7d8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Creating chunks with default parameters for comparison...\n",
      "âœ… All chunks created!\n",
      "\n",
      "ðŸ“Š Chunking Strategy Comparison:\n",
      "================================================================================\n",
      "         Chunker  Total Chunks  Avg Tokens/Chunk      Key Characteristic\n",
      "    TokenChunker             8             457.1  Fixed token boundaries\n",
      " SentenceChunker             8             446.8     Sentence boundaries\n",
      "RecursiveChunker             8             413.4 Hierarchical delimiters\n",
      " SemanticChunker            52              56.0     Semantic similarity\n",
      "     LateChunker             7               1.0        Document context\n",
      "================================================================================\n",
      "\n",
      "\n",
      "ðŸ“ˆ Detailed Statistics:\n",
      "\n",
      "1ï¸âƒ£ TokenChunker:\n",
      "   - Most consistent chunk sizes (target: 512 tokens)\n",
      "   - Min tokens: 73\n",
      "   - Max tokens: 512\n",
      "\n",
      "2ï¸âƒ£ SentenceChunker:\n",
      "   - Preserves sentence boundaries\n",
      "   - Variable chunk sizes based on sentence length\n",
      "   - Min tokens: 234\n",
      "   - Max tokens: 490\n",
      "\n",
      "3ï¸âƒ£ RecursiveChunker:\n",
      "   - Hierarchical splitting approach\n",
      "   - Respects paragraph and sentence structure\n",
      "   - Min tokens: 72\n",
      "   - Max tokens: 504\n",
      "\n",
      "4ï¸âƒ£ SemanticChunker:\n",
      "   - Groups semantically similar content\n",
      "   - Variable sizes based on topic coherence\n",
      "   - Min tokens: 4\n",
      "   - Max tokens: 199\n",
      "\n",
      "5ï¸âƒ£ LateChunker:\n",
      "   - Document-level contextual embeddings\n",
      "   - Similar to RecursiveChunker but with richer embeddings\n",
      "   - Min tokens: 1\n",
      "   - Max tokens: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create chunks for comparison (using default parameters)\n",
    "print(\"ðŸ”„ Creating chunks with default parameters for comparison...\")\n",
    "\n",
    "token_chunker = TokenChunker(tokenizer=\"gpt2\", chunk_size=512, chunk_overlap=50)\n",
    "token_chunks = token_chunker.chunk(sample_text)\n",
    "\n",
    "sentence_chunker = SentenceChunker(tokenizer=\"gpt2\", chunk_size=512, chunk_overlap=50, min_sentences_per_chunk=2)\n",
    "sentence_chunks = sentence_chunker.chunk(sample_text)\n",
    "\n",
    "recursive_chunker = RecursiveChunker(tokenizer=\"gpt2\", chunk_size=512, min_characters_per_chunk=24)\n",
    "recursive_chunks = recursive_chunker.chunk(sample_text)\n",
    "\n",
    "semantic_chunker = SemanticChunker(embedding_model=\"minishlab/potion-base-32M\", threshold=0.7, chunk_size=512)\n",
    "semantic_chunks = semantic_chunker.chunk(sample_text)\n",
    "\n",
    "late_chunker = LateChunker(embedding_model=\"minishlab/potion-base-32M\", chunk_size=512, min_characters_per_chunk=24)\n",
    "late_chunks = late_chunker.chunk(sample_text)\n",
    "\n",
    "print(\"âœ… All chunks created!\\n\")\n",
    "\n",
    "# Create comparison data\n",
    "comparison_data = {\n",
    "    'Chunker': [\n",
    "        'TokenChunker',\n",
    "        'SentenceChunker', \n",
    "        'RecursiveChunker',\n",
    "        'SemanticChunker',\n",
    "        'LateChunker'\n",
    "    ],\n",
    "    'Total Chunks': [\n",
    "        len(token_chunks),\n",
    "        len(sentence_chunks),\n",
    "        len(recursive_chunks),\n",
    "        len(semantic_chunks),\n",
    "        len(late_chunks)\n",
    "    ],\n",
    "    'Avg Tokens/Chunk': [\n",
    "        sum(c.token_count for c in token_chunks) / len(token_chunks),\n",
    "        sum(c.token_count for c in sentence_chunks) / len(sentence_chunks),\n",
    "        sum(c.token_count for c in recursive_chunks) / len(recursive_chunks),\n",
    "        sum(c.token_count for c in semantic_chunks) / len(semantic_chunks),\n",
    "        sum(c.token_count for c in late_chunks) / len(late_chunks)\n",
    "    ],\n",
    "    'Key Characteristic': [\n",
    "        'Fixed token boundaries',\n",
    "        'Sentence boundaries',\n",
    "        'Hierarchical delimiters',\n",
    "        'Semantic similarity',\n",
    "        'Document context'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(comparison_data)\n",
    "df['Avg Tokens/Chunk'] = df['Avg Tokens/Chunk'].round(1)\n",
    "\n",
    "print(\"ðŸ“Š Chunking Strategy Comparison:\")\n",
    "print(\"=\" * 80)\n",
    "print(df.to_string(index=False))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Detailed breakdown\n",
    "print(\"\\n\\nðŸ“ˆ Detailed Statistics:\")\n",
    "print(\"\\n1ï¸âƒ£ TokenChunker:\")\n",
    "print(f\"   - Most consistent chunk sizes (target: 512 tokens)\")\n",
    "print(f\"   - Min tokens: {min(c.token_count for c in token_chunks)}\")\n",
    "print(f\"   - Max tokens: {max(c.token_count for c in token_chunks)}\")\n",
    "\n",
    "print(\"\\n2ï¸âƒ£ SentenceChunker:\")\n",
    "print(f\"   - Preserves sentence boundaries\")\n",
    "print(f\"   - Variable chunk sizes based on sentence length\")\n",
    "print(f\"   - Min tokens: {min(c.token_count for c in sentence_chunks)}\")\n",
    "print(f\"   - Max tokens: {max(c.token_count for c in sentence_chunks)}\")\n",
    "\n",
    "print(\"\\n3ï¸âƒ£ RecursiveChunker:\")\n",
    "print(f\"   - Hierarchical splitting approach\")\n",
    "print(f\"   - Respects paragraph and sentence structure\")\n",
    "print(f\"   - Min tokens: {min(c.token_count for c in recursive_chunks)}\")\n",
    "print(f\"   - Max tokens: {max(c.token_count for c in recursive_chunks)}\")\n",
    "\n",
    "print(\"\\n4ï¸âƒ£ SemanticChunker:\")\n",
    "print(f\"   - Groups semantically similar content\")\n",
    "print(f\"   - Variable sizes based on topic coherence\")\n",
    "print(f\"   - Min tokens: {min(c.token_count for c in semantic_chunks)}\")\n",
    "print(f\"   - Max tokens: {max(c.token_count for c in semantic_chunks)}\")\n",
    "\n",
    "print(\"\\n5ï¸âƒ£ LateChunker:\")\n",
    "print(f\"   - Document-level contextual embeddings\")\n",
    "print(f\"   - Similar to RecursiveChunker but with richer embeddings\")\n",
    "print(f\"   - Min tokens: {min(c.token_count for c in late_chunks)}\")\n",
    "print(f\"   - Max tokens: {max(c.token_count for c in late_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1564b5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸŽ¯ Choosing the Right Chunker: Decision Guide\n",
    "\n",
    "```mermaid\n",
    "%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#3498db', 'primaryTextColor': '#fff', 'primaryBorderColor': '#2980b9', 'lineColor': '#e74c3c', 'secondaryColor': '#2ecc71', 'tertiaryColor': '#f39c12'}}}%%\n",
    "graph TD\n",
    "    A[What's your use case?] --> B{Text Type?}\n",
    "    \n",
    "    B -->|Source Code| C[ðŸ’» CodeChunker]\n",
    "    B -->|Natural Language| D{Priority?}\n",
    "    \n",
    "    D -->|Simple & Fast| E[ðŸ”¢ TokenChunker]\n",
    "    D -->|Preserve Sentences| F[ðŸ“„ SentenceChunker]\n",
    "    D -->|Document Structure| G[ðŸ”„ RecursiveChunker]\n",
    "    D -->|Semantic Coherence| H[ðŸ§  SemanticChunker]\n",
    "    D -->|RAG Performance| I[âš¡ LateChunker]\n",
    "    \n",
    "    E --> J[âœ“ Fixed sizes<br/>âœ“ Fast processing<br/>âœ— May split sentences]\n",
    "    F --> K[âœ“ Sentence boundaries<br/>âœ“ Context preserved<br/>âœ— Variable sizes]\n",
    "    G --> L[âœ“ Hierarchical<br/>âœ“ Structure aware<br/>~ Medium speed]\n",
    "    H --> M[âœ“ Topic coherent<br/>âœ“ Smart grouping<br/>âœ— Slower processing]\n",
    "    I --> N[âœ“ Rich context<br/>âœ“ Best retrieval<br/>âœ— Slowest]\n",
    "    C --> O[âœ“ Syntax aware<br/>âœ“ Multi-language<br/>âœ“ AST-based]\n",
    "    \n",
    "    style A fill:#e74c3c,stroke:#c0392b,stroke-width:3px,color:#fff\n",
    "    style B fill:#3498db,stroke:#2980b9,stroke-width:2px,color:#fff\n",
    "    style D fill:#3498db,stroke:#2980b9,stroke-width:2px,color:#fff\n",
    "    style E fill:#1abc9c,stroke:#16a085,stroke-width:2px,color:#fff\n",
    "    style F fill:#9b59b6,stroke:#8e44ad,stroke-width:2px,color:#fff\n",
    "    style G fill:#e67e22,stroke:#d35400,stroke-width:2px,color:#fff\n",
    "    style H fill:#f39c12,stroke:#e67e22,stroke-width:2px\n",
    "    style I fill:#2ecc71,stroke:#27ae60,stroke-width:2px,color:#fff\n",
    "    style C fill:#34495e,stroke:#2c3e50,stroke-width:2px,color:#fff\n",
    "```\n",
    "\n",
    "## ðŸ“‹ Quick Reference Table\n",
    "\n",
    "| Chunker | Best For | Speed | Semantic Awareness | Embedding Support |\n",
    "|---------|----------|-------|-------------------|-------------------|\n",
    "| **TokenChunker** | Fixed-size requirements, API limits | âš¡âš¡âš¡ Very Fast | âŒ Low | âž– N/A |\n",
    "| **SentenceChunker** | Q&A, semantic completeness | âš¡âš¡âš¡ Very Fast | âš ï¸ Medium | âž– N/A |\n",
    "| **RecursiveChunker** | Structured documents, markdown | âš¡âš¡ Fast | âš ï¸ Medium | âž– N/A |\n",
    "| **SemanticChunker** | Topic-based retrieval, coherence | âš¡ Moderate | âœ… High | âœ… Yes |\n",
    "| **LateChunker** | Advanced RAG, best retrieval | ðŸŒ Slower | âœ… Very High | âœ… Yes (contextual) |\n",
    "| **CodeChunker** | Source code, syntax preservation | âš¡âš¡ Fast | âš ï¸ Structure-aware | âž– N/A |\n",
    "\n",
    "## ðŸ’¡ Pro Tips\n",
    "\n",
    "### For RAG Applications:\n",
    "- **SemanticChunker**: Best for topic-based retrieval and when semantic coherence matters\n",
    "- **LateChunker**: Best for highest retrieval accuracy, use when performance isn't critical\n",
    "- **SentenceChunker**: Good balance of speed and context preservation\n",
    "\n",
    "### For Production Systems:\n",
    "- **TokenChunker**: Most predictable, great for scaling\n",
    "- **RecursiveChunker**: Good for structured content with clear hierarchy\n",
    "- Use smaller `chunk_size` for more precise retrieval, larger for more context\n",
    "\n",
    "### For Code Documentation:\n",
    "- **CodeChunker**: Only choice for respecting code syntax\n",
    "- Set smaller chunk_size (256-512) to keep functions/classes together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29070d07",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ”¬ Advanced: Customizing Chunker Parameters\n",
    "\n",
    "Let's explore how different parameters affect chunking behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49224696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Testing SemanticChunker with different similarity thresholds:\n",
      "\n",
      "Threshold 0.5:\n",
      "  â†’ 5 chunks created\n",
      "  â†’ Average 60.2 tokens per chunk\n",
      "  â†’ Larger, diverse chunks\n",
      "\n",
      "Threshold 0.7:\n",
      "  â†’ 6 chunks created\n",
      "  â†’ Average 50.2 tokens per chunk\n",
      "  â†’ Balanced grouping\n",
      "\n",
      "Threshold 0.9:\n",
      "  â†’ 8 chunks created\n",
      "  â†’ Average 37.6 tokens per chunk\n",
      "  â†’ Smaller, very similar chunks\n",
      "\n",
      "\n",
      "ðŸ“Š Summary Table:\n",
      " Threshold  Total Chunks  Avg Tokens                  Description\n",
      "       0.5             5        60.2       Larger, diverse chunks\n",
      "       0.7             6        50.2            Balanced grouping\n",
      "       0.9             8        37.6 Smaller, very similar chunks\n",
      "\n",
      "ðŸ’¡ Insight: Lower threshold â†’ Fewer, larger chunks (more diverse content)\n",
      "           Higher threshold â†’ More, smaller chunks (very similar content)\n"
     ]
    }
   ],
   "source": [
    "## Experiment: Effect of Different Thresholds on SemanticChunker\n",
    "\n",
    "test_text = sample_text[:2000]  # Use first 2000 chars for quick testing\n",
    "\n",
    "print(\"ðŸ§ª Testing SemanticChunker with different similarity thresholds:\\n\")\n",
    "\n",
    "thresholds = [0.5, 0.7, 0.9]\n",
    "results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    chunker = SemanticChunker(\n",
    "        embedding_model=\"minishlab/potion-base-32M\",\n",
    "        threshold=threshold,\n",
    "        chunk_size=512\n",
    "    )\n",
    "    chunks = chunker.chunk(test_text)\n",
    "    \n",
    "    avg_tokens = sum(c.token_count for c in chunks) / len(chunks)\n",
    "    results.append({\n",
    "        'Threshold': threshold,\n",
    "        'Total Chunks': len(chunks),\n",
    "        'Avg Tokens': round(avg_tokens, 1),\n",
    "        'Description': 'Larger, diverse chunks' if threshold < 0.6 else \n",
    "                       'Balanced grouping' if threshold < 0.8 else \n",
    "                       'Smaller, very similar chunks'\n",
    "    })\n",
    "    \n",
    "    print(f\"Threshold {threshold}:\")\n",
    "    print(f\"  â†’ {len(chunks)} chunks created\")\n",
    "    print(f\"  â†’ Average {avg_tokens:.1f} tokens per chunk\")\n",
    "    print(f\"  â†’ {results[-1]['Description']}\\n\")\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nðŸ“Š Summary Table:\")\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "print(\"\\nðŸ’¡ Insight: Lower threshold â†’ Fewer, larger chunks (more diverse content)\")\n",
    "print(\"           Higher threshold â†’ More, smaller chunks (very similar content)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb22473b",
   "metadata": {},
   "source": [
    "## Experiment: Effect of Chunk Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08439c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Testing TokenChunker with different chunk sizes:\n",
      "\n",
      "Chunk Size 256:\n",
      "  â†’ 16 chunks created\n",
      "  â†’ Smaller chunks = More granular retrieval\n",
      "  â†’ Larger chunks = More context per chunk\n",
      "\n",
      "Chunk Size 512:\n",
      "  â†’ 8 chunks created\n",
      "  â†’ Smaller chunks = More granular retrieval\n",
      "  â†’ Larger chunks = More context per chunk\n",
      "\n",
      "Chunk Size 1024:\n",
      "  â†’ 4 chunks created\n",
      "  â†’ Smaller chunks = More granular retrieval\n",
      "  â†’ Larger chunks = More context per chunk\n",
      "\n",
      "ðŸ“Š Summary Table:\n",
      " Chunk Size  Total Chunks  Avg Tokens\n",
      "        256            16       253.6\n",
      "        512             8       457.1\n",
      "       1024             4       864.2\n",
      "\n",
      "ðŸ’¡ Choosing chunk size:\n",
      "   â€¢ 128-256: High precision retrieval, less context\n",
      "   â€¢ 512: Balanced (recommended for most use cases)\n",
      "   â€¢ 1024+: Maximum context, lower precision\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ§ª Testing TokenChunker with different chunk sizes:\\n\")\n",
    "\n",
    "chunk_sizes = [256, 512, 1024]\n",
    "size_results = []\n",
    "\n",
    "for size in chunk_sizes:\n",
    "    chunker = TokenChunker(\n",
    "        tokenizer=\"gpt2\",\n",
    "        chunk_size=size,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "    chunks = chunker.chunk(sample_text)\n",
    "    \n",
    "    size_results.append({\n",
    "        'Chunk Size': size,\n",
    "        'Total Chunks': len(chunks),\n",
    "        'Avg Tokens': round(sum(c.token_count for c in chunks) / len(chunks), 1)\n",
    "    })\n",
    "    \n",
    "    print(f\"Chunk Size {size}:\")\n",
    "    print(f\"  â†’ {len(chunks)} chunks created\")\n",
    "    print(f\"  â†’ Smaller chunks = More granular retrieval\")\n",
    "    print(f\"  â†’ Larger chunks = More context per chunk\\n\")\n",
    "\n",
    "df_size = pd.DataFrame(size_results)\n",
    "print(\"ðŸ“Š Summary Table:\")\n",
    "print(df_size.to_string(index=False))\n",
    "\n",
    "print(\"\\nðŸ’¡ Choosing chunk size:\")\n",
    "print(\"   â€¢ 128-256: High precision retrieval, less context\")\n",
    "print(\"   â€¢ 512: Balanced (recommended for most use cases)\")\n",
    "print(\"   â€¢ 1024+: Maximum context, lower precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5713149",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸŽ¨ Visual Comparison: Side-by-Side Chunk Visualization\n",
    "\n",
    "Let's visualize how different chunkers split the same paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e2eb3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¨ Comparing chunking strategies on the same paragraph:\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ðŸ”¢ TokenChunker: 1 chunks\n",
      "   Chunk 1: '\n",
      "The field of artificial intelligence has undergone tremendous transformation in...'\n",
      "\n",
      "ðŸ“„ SentenceChunker: 1 chunks\n",
      "   Chunk 1: '\n",
      "The field of artificial intelligence has undergone tremendous transformation in...'\n",
      "\n",
      "ðŸ§  SemanticChunker: 1 chunks\n",
      "   Chunk 1: '\n",
      "The field of artificial intelligence has undergone tremendous transformation in...'\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ðŸ’¡ Observations:\n",
      "   â€¢ TokenChunker: May split mid-sentence for fixed size\n",
      "   â€¢ SentenceChunker: Always keeps sentences complete\n",
      "   â€¢ SemanticChunker: Groups semantically related sentences together\n"
     ]
    }
   ],
   "source": [
    "# Extract a specific paragraph for detailed comparison\n",
    "comparison_text = \"\"\"\n",
    "The field of artificial intelligence has undergone tremendous transformation in recent years. Machine learning algorithms have become increasingly sophisticated, enabling computers to perform tasks that once seemed exclusively human. Deep learning, a subset of machine learning, uses neural networks with multiple layers to process complex patterns in data. These networks can recognize images, understand natural language, and even generate creative content. The impact of AI extends across multiple industries. In healthcare, machine learning models can diagnose diseases from medical images with accuracy rivaling expert physicians.\n",
    "\"\"\"\n",
    "\n",
    "# Small chunk size for detailed comparison\n",
    "chunk_size_compare = 200\n",
    "\n",
    "print(\"ðŸŽ¨ Comparing chunking strategies on the same paragraph:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# TokenChunker\n",
    "tc = TokenChunker(tokenizer=\"gpt2\", chunk_size=chunk_size_compare, chunk_overlap=0)\n",
    "tc_chunks = tc.chunk(comparison_text)\n",
    "print(f\"\\nðŸ”¢ TokenChunker: {len(tc_chunks)} chunks\")\n",
    "for i, chunk in enumerate(tc_chunks):\n",
    "    print(f\"   Chunk {i+1}: '{chunk.text[:80]}...'\")\n",
    "\n",
    "# SentenceChunker  \n",
    "sc = SentenceChunker(tokenizer=\"gpt2\", chunk_size=chunk_size_compare, chunk_overlap=0)\n",
    "sc_chunks = sc.chunk(comparison_text)\n",
    "print(f\"\\nðŸ“„ SentenceChunker: {len(sc_chunks)} chunks\")\n",
    "for i, chunk in enumerate(sc_chunks):\n",
    "    print(f\"   Chunk {i+1}: '{chunk.text[:80]}...'\")\n",
    "\n",
    "# SemanticChunker\n",
    "semc = SemanticChunker(\n",
    "    embedding_model=\"minishlab/potion-base-32M\",\n",
    "    threshold=0.7,\n",
    "    chunk_size=chunk_size_compare\n",
    ")\n",
    "semc_chunks = semc.chunk(comparison_text)\n",
    "print(f\"\\nðŸ§  SemanticChunker: {len(semc_chunks)} chunks\")\n",
    "for i, chunk in enumerate(semc_chunks):\n",
    "    print(f\"   Chunk {i+1}: '{chunk.text[:80]}...'\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nðŸ’¡ Observations:\")\n",
    "print(\"   â€¢ TokenChunker: May split mid-sentence for fixed size\")\n",
    "print(\"   â€¢ SentenceChunker: Always keeps sentences complete\")\n",
    "print(\"   â€¢ SemanticChunker: Groups semantically related sentences together\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6c72c4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸŽ“ Conclusion and Best Practices\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Different chunkers for different needs**: No one-size-fits-all solution exists. Choose based on your specific requirements.\n",
    "\n",
    "2. **Semantic chunkers are powerful**: SemanticChunker and LateChunker provide superior context preservation at the cost of processing speed.\n",
    "\n",
    "3. **Token size matters**: Smaller chunks = more precise retrieval, larger chunks = more context per chunk.\n",
    "\n",
    "4. **Code requires special handling**: Always use CodeChunker for source code to respect syntax and structure.\n",
    "\n",
    "5. **Overlap helps continuity**: Using chunk_overlap prevents information loss at boundaries.\n",
    "\n",
    "## Recommended Workflows\n",
    "\n",
    "### For RAG Applications:\n",
    "```python\n",
    "# High accuracy, slower\n",
    "chunker = SemanticChunker(threshold=0.7, chunk_size=512)\n",
    "\n",
    "# Best retrieval performance\n",
    "chunker = LateChunker(chunk_size=512)\n",
    "\n",
    "# Fast and reliable\n",
    "chunker = SentenceChunker(chunk_size=512, chunk_overlap=50)\n",
    "```\n",
    "\n",
    "### For Production Systems:\n",
    "```python\n",
    "# Predictable and scalable\n",
    "chunker = TokenChunker(chunk_size=512, chunk_overlap=50)\n",
    "\n",
    "# Structured documents\n",
    "chunker = RecursiveChunker.from_recipe(\"markdown\")\n",
    "```\n",
    "\n",
    "### For Code Documentation:\n",
    "```python\n",
    "# Python code\n",
    "chunker = CodeChunker(language=\"python\", chunk_size=256)\n",
    "\n",
    "# JavaScript code\n",
    "chunker = CodeChunker(language=\"javascript\", chunk_size=256)\n",
    "```\n",
    "\n",
    "## ðŸš€ Next Steps\n",
    "\n",
    "- Experiment with different chunk sizes and overlap values\n",
    "- Test multiple chunkers on your specific dataset\n",
    "- Combine chunking with Chonkie's refineries for enhanced embeddings\n",
    "- Integrate with vector databases using Chonkie's handshakes\n",
    "- Explore Chonkie's visualization tools for debugging\n",
    "\n",
    "## ðŸ“š Resources\n",
    "\n",
    "- [Chonkie Documentation](https://docs.chonkie.ai/)\n",
    "- [GitHub Repository](https://github.com/chonkie-inc/chonkie)\n",
    "- [Late Chunking Paper](https://arxiv.org/abs/2409.04701)\n",
    "- [Chonkie Discord Community](https://discord.com/invite/Q6zkP8w6ur)\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Chunking! ðŸ¦›âœ¨**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chonkie (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
